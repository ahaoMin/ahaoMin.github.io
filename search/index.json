[{"content":"MyBatisPlus(SpringBoot版)\u0026ndash;2022  教程来自尚硅谷\n MyBatis-Plus简介 简介 MyBatis-Plus(简称 MP)是一个 MyBatis的增强工具，在 MyBatis 的基础上只做增强不做改变，为 简化开发、提高效率而生。\n愿景\n我们的愿景是成为 MyBatis 最好的搭档，就像魂斗罗中的 1P、2P，基友搭配，效率翻倍。\n特性  无侵入:只做增强不做改变，引入它不会对现有工程产生影响，如丝般顺滑 损耗小:启动即会自动注入基本 CURD，性能基本无损耗，直接面向对象操作 强大的 CRUD 操作:内置通用 Mapper、通用 Service，仅仅通过少量配置即可实现单表大部分 CRUD 操作，更有强大的条件构造器，满足各类使用需求 支持 Lambda 形式调用:通过 Lambda 表达式，方便的编写各类查询条件，无需再担心字段写错 支持主键自动生成:支持多达 4 种主键策略(内含分布式唯一 ID 生成器 - Sequence)，可自由 配置，完美解决主键问题 支持 ActiveRecord 模式:支持 ActiveRecord 形式调用，实体类只需继承 Model 类即可进行强 大的 CRUD 操作 支持自定义全局通用操作:支持全局通用方法注入( Write once, use anywhere ) 内置代码生成器:采用代码或者 Maven 插件可快速生成 Mapper 、 Model 、 Service 、 Controller 层代码，支持模板引擎，更有超多自定义配置等您来使用 内置分页插件:基于 MyBatis 物理分页，开发者无需关心具体操作，配置好插件之后，写分页等 同于普通 List 查询 分页插件支持多种数据库:支持 MySQL、MariaDB、Oracle、DB2、H2、HSQL、SQLite、 Postgre、SQLServer 等多种数据库 内置性能分析插件:可输出 SQL 语句以及其执行时间，建议开发测试时启用该功能，能快速揪出 慢查询 内置全局拦截插件:提供全表 delete 、 update 操作智能分析阻断，也可自定义拦截规则，预防 误操作  支持数据库 任何能使用MyBatis进行 CRUD, 并且支持标准 SQL 的数据库，具体支持情况如下\n MySQL，Oracle，DB2，H2，HSQL，SQLite，PostgreSQL，SQLServer，Phoenix，Gauss ， ClickHouse，Sybase，OceanBase，Firebird，Cubrid，Goldilocks，csiidb 达梦数据库，虚谷数据库，人大金仓数据库，南大通用(华库)数据库，南大通用数据库，神通数据 库，瀚高数据库  框架结构 代码文档及文档地址 官方地址: http://mp.baomidou.com\n代码发布地址:\nGithub: https://github.com/baomidou/mybatis-plus\nGitee: https://gitee.com/baomidou/mybatis-plus\n文档发布地址: https://baomidou.com/pages/24112f\n入门案例 开发环境 IDE: idea：2021.3\nJDK: JDK8+\n构建工具: maven 3.8.4\nMySQL版本: MySQL 8.0.27\nSpring Boot: 2.6.4\nMyBatis-Plus: 3.5.1\n创建数据库及表 a\u0026gt;创建表 1 2 3 4 5  CREATEDATABASE`mybatis_plus`/*!40100 DEFAULT CHARACTER SET utf8mb4 */;use`mybatis_plus`;CREATETABLE`user`(`id`bigint(20)NOTNULLCOMMENT\u0026#39;主键ID\u0026#39;,`name`varchar(30)DEFAULTNULLCOMMENT\u0026#39;姓名\u0026#39;,`age`int(11)DEFAULTNULLCOMMENT\u0026#39;年龄\u0026#39;,`email`varchar(50)DEFAULTNULLCOMMENT\u0026#39;邮箱\u0026#39;,PRIMARYKEY(`id`))ENGINE=InnoDBDEFAULTCHARSET=utf8;  b\u0026gt;添加数据 1 2 3 4 5 6  INSERTINTOuser(id,name,age,email)VALUES(1,\u0026#39;Jone\u0026#39;,18,\u0026#39;test1@baomidou.com\u0026#39;),(2,\u0026#39;Jack\u0026#39;,20,\u0026#39;test2@baomidou.com\u0026#39;),(3,\u0026#39;Tom\u0026#39;,28,\u0026#39;test3@baomidou.com\u0026#39;),(4,\u0026#39;Sandy\u0026#39;,21,\u0026#39;test4@baomidou.com\u0026#39;),(5,\u0026#39;Billie\u0026#39;,24,\u0026#39;test5@baomidou.com\u0026#39;);  创建SpringBoot工程 a\u0026gt;初始化工程 b\u0026gt;引入依赖 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-test\u0026lt;/artifactId\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!--MyBatis-plus启动器--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.baomidou\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mybatis-plus-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.5.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!--lombok用于简化实体类开发--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.projectlombok\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;lombok\u0026lt;/artifactId\u0026gt; \u0026lt;optional\u0026gt;true\u0026lt;/optional\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!--mysql驱动--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;mysql\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mysql-connector-java\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt;   c\u0026gt;idea中安装lombok插件 编写代码 a\u0026gt;配置application.yml 1 2 3 4 5 6 7 8 9 10 11  spring:# 配置数据源信息datasource:# 配置数据源类型type:com.zaxxer.hikari.HikariDataSource# 配置连接数据库信息driver-class-name:com.mysql.cj.jdbc.Driver# 我的数据库是8.0.27 5版本的可以使用 jdbc:mysql://localhost:3306/mybatis_plus?characterEncoding=utf-8\u0026amp;useSSL=falseurl:jdbc:mysql://localhost:3306/mybatis_plus?serverTimezone=GMT%2B8\u0026amp;characterEncoding=utf-8\u0026amp;useSSL=falseusername:rootpassword:\u0026#39;root\u0026#39;  注意：  《阿里巴巴 Java 开发手册》的描述如下：\n1、驱动类driver-class-name\nspring boot 2.0(内置jdbc5驱动)，驱动类使用:\ndriver-class-name: com.mysql.jdbc.Driver\nspring boot 2.1及以上(内置jdbc8驱动)，驱动类使用:\ndriver-class-name: com.mysql.cj.jdbc.Driver\n否则运行测试用例的时候会有 WARN 信息\n2、连接地址url\nMySQL5.7版本的url:\njdbc:mysql://localhost:3306/mybatis_plus?characterEncoding=utf-8\u0026amp;useSSL=false\nMySQL8.0版本的url:\njdbc:mysql://localhost:3306/mybatis_plus?serverTimezone=GMT%2B8\u0026amp;characterEncoding=utf-8\u0026amp;useSSL=false\n否则运行测试用例报告如下错误:\njava.sql.SQLException: The server time zone value \u0026lsquo;ÖÐ1ú±ê×1⁄4Ê±1⁄4ä\u0026rsquo; is unrecognized or represents more\n b\u0026gt;启动类 在Spring Boot启动类中添加@MapperScan注解，扫描mapper包\n1 2 3 4 5 6 7 8 9 10  @SpringBootApplication // 扫描mapper接口所在的包 @MapperScan(\u0026#34;com.atguigu.mybatisplus.mapper\u0026#34;) public class MybatisplusApplication { public static void main(String[] args) { SpringApplication.run(MybatisplusApplication.class, args); } }   c\u0026gt;添加实体 1 2 3 4 5 6 7 8 9 10  @Data @AllArgsConstructor @NoArgsConstructor public class User { private Long id; private String name; private Integer age; private String email; }   使用了Lombok注解\nd\u0026gt;添加mapper BaseMapper是MyBatis-Plus提供的模板mapper，其中包含了基本的CRUD方法，泛型为操作的实体类型\n1 2  public interface UserMapper extends BaseMapper\u0026lt;User\u0026gt; { }   e\u0026gt;测试 1 2 3 4 5 6 7 8 9 10 11 12 13  @SpringBootTest class MybatisplusApplicationTests { @Autowired private UserMapper userMapper; @Test public void testSelectList() { // 通过条件构造器查询一个List集合，若没有条件，则可以设置null为参数  List\u0026lt;User\u0026gt; list = userMapper.selectList(null); list.forEach(System.out::println); } }   结果 注意：  IDEA在 userMapper 处报错，因为找不到注入的对象，因为类是动态创建的，但是程序可以正确 的执行。\n为了避免报错，可以在mapper接口上添加 @Repository 注解\n f\u0026gt;添加日志 在application.yml中配置日志输出\n1 2 3 4  # 加入日志功能mybatis-plus:configuration:log-impl:org.apache.ibatis.logging.stdout.StdOutImpl  基本CRUD BaseMapper MyBatis-Plus中的基本CRUD在内置的BaseMapper中已得到了实现，我们可以直接使用，接口如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238  /* * Copyright (c) 2011-2022, baomidou (jobob@qq.com). * * Licensed under the Apache License, Version 2.0 (the \u0026#34;License\u0026#34;); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an \u0026#34;AS IS\u0026#34; BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package com.baomidou.mybatisplus.core.mapper; import com.baomidou.mybatisplus.core.conditions.Wrapper; import com.baomidou.mybatisplus.core.metadata.IPage; import com.baomidou.mybatisplus.core.toolkit.CollectionUtils; import com.baomidou.mybatisplus.core.toolkit.Constants; import com.baomidou.mybatisplus.core.toolkit.ExceptionUtils; import org.apache.ibatis.annotations.Param; import java.io.Serializable; import java.util.Collection; import java.util.List; import java.util.Map; /* :` .:, :::,,. :: `:::::: ::` `,:,` .:` `:: `::::::::.:` `:\u0026#39;;,` ::::, .:::` `@++++++++: `` :::` @+++++++++++# :::, #++++++++++++++` ,: `::::::;\u0026#39;##++++++++++ .@#@;` ::::::::::::::::::::; #@####@, :::::::::::::::+#;::. @@######+@:::::::::::::. #@:; , @@########\u0026#39;:::::::::::: .#\u0026#39;\u0026#39;\u0026#39;:` ;##@@@+:##########@::::::::::: @#;.,:. #@@@######++++#####\u0026#39;::::::::: .##+,:#` @@@@@#####+++++\u0026#39;#####+::::::::` ,`::@#:` `@@@@#####++++++\u0026#39;#####+#\u0026#39;:::::::::::@. @@@@######+++++\u0026#39;\u0026#39;#######+##\u0026#39;;::::;\u0026#39;:,` @@@@#####+++++\u0026#39;\u0026#39;\u0026#39;#######++++++++++` #@@#####++++++\u0026#39;\u0026#39;########++++++++\u0026#39; `#@######+++++\u0026#39;\u0026#39;+########+++++++; `@@#####+++++\u0026#39;\u0026#39;##########++++++, @@######+++++\u0026#39;##########+++++#` @@@@#####+++++############++++; ;#@@@@@####++++##############+++, @@@@@@@@@@@###@###############++\u0026#39; @#@@@@@@@@@@@@###################+: `@#@@@@@@@@@@@@@@###################\u0026#39;` :@#@@@@@@@@@@@@@@@@@##################, ,@@@@@@@@@@@@@@@@@@@@################; ,#@@@@@@@@@@@@@@@@@@@##############+` .#@@@@@@@@@@@@@@@@@@#############@, @@@@@@@@@@@@@@@@@@@###########@, :#@@@@@@@@@@@@@@@@##########@, `##@@@@@@@@@@@@@@@########+, `+@@@@@@@@@@@@@@@#####@:` `:@@@@@@@@@@@@@@##@;. `,\u0026#39;@@@@##@@@+;,` ``...`` _ _ /_ _ _/_. ____ / _ / / //_//_//_|/ /_\\ /_///_/_\\ Talk is cheap. Show me the code. _/ / */ /** * Mapper 继承该接口后，无需编写 mapper.xml 文件，即可获得CRUD功能 * \u0026lt;p\u0026gt;这个 Mapper 支持 id 泛型\u0026lt;/p\u0026gt; * * @author hubin * @since 2016-01-23 */ public interface BaseMapper\u0026lt;T\u0026gt; extends Mapper\u0026lt;T\u0026gt; { /** * 插入一条记录 * * @param entity 实体对象 */ int insert(T entity); /** * 根据 ID 删除 * * @param id 主键ID */ int deleteById(Serializable id); /** * 根据实体(ID)删除 * * @param entity 实体对象 * @since 3.4.4 */ int deleteById(T entity); /** * 根据 columnMap 条件，删除记录 * * @param columnMap 表字段 map 对象 */ int deleteByMap(@Param(Constants.COLUMN_MAP) Map\u0026lt;String, Object\u0026gt; columnMap); /** * 根据 entity 条件，删除记录 * * @param queryWrapper 实体对象封装操作类（可以为 null,里面的 entity 用于生成 where 语句） */ int delete(@Param(Constants.WRAPPER) Wrapper\u0026lt;T\u0026gt; queryWrapper); /** * 删除（根据ID或实体 批量删除） * * @param idList 主键ID列表或实体列表(不能为 null 以及 empty) */ int deleteBatchIds(@Param(Constants.COLLECTION) Collection\u0026lt;?\u0026gt; idList); /** * 根据 ID 修改 * * @param entity 实体对象 */ int updateById(@Param(Constants.ENTITY) T entity); /** * 根据 whereEntity 条件，更新记录 * * @param entity 实体对象 (set 条件值,可以为 null) * @param updateWrapper 实体对象封装操作类（可以为 null,里面的 entity 用于生成 where 语句） */ int update(@Param(Constants.ENTITY) T entity, @Param(Constants.WRAPPER) Wrapper\u0026lt;T\u0026gt; updateWrapper); /** * 根据 ID 查询 * * @param id 主键ID */ T selectById(Serializable id); /** * 查询（根据ID 批量查询） * * @param idList 主键ID列表(不能为 null 以及 empty) */ List\u0026lt;T\u0026gt; selectBatchIds(@Param(Constants.COLLECTION) Collection\u0026lt;? extends Serializable\u0026gt; idList); /** * 查询（根据 columnMap 条件） * * @param columnMap 表字段 map 对象 */ List\u0026lt;T\u0026gt; selectByMap(@Param(Constants.COLUMN_MAP) Map\u0026lt;String, Object\u0026gt; columnMap); /** * 根据 entity 条件，查询一条记录 * \u0026lt;p\u0026gt;查询一条记录，例如 qw.last(\u0026#34;limit 1\u0026#34;) 限制取一条记录, 注意：多条数据会报异常\u0026lt;/p\u0026gt; * * @param queryWrapper 实体对象封装操作类（可以为 null） */ default T selectOne(@Param(Constants.WRAPPER) Wrapper\u0026lt;T\u0026gt; queryWrapper) { List\u0026lt;T\u0026gt; ts = this.selectList(queryWrapper); if (CollectionUtils.isNotEmpty(ts)) { if (ts.size() != 1) { throw ExceptionUtils.mpe(\u0026#34;One record is expected, but the query result is multiple records\u0026#34;); } return ts.get(0); } return null; } /** * 根据 Wrapper 条件，判断是否存在记录 * * @param queryWrapper 实体对象封装操作类 * @return */ default boolean exists(Wrapper\u0026lt;T\u0026gt; queryWrapper) { Long count = this.selectCount(queryWrapper); return null != count \u0026amp;\u0026amp; count \u0026gt; 0; } /** * 根据 Wrapper 条件，查询总记录数 * * @param queryWrapper 实体对象封装操作类（可以为 null） */ Long selectCount(@Param(Constants.WRAPPER) Wrapper\u0026lt;T\u0026gt; queryWrapper); /** * 根据 entity 条件，查询全部记录 * * @param queryWrapper 实体对象封装操作类（可以为 null） */ List\u0026lt;T\u0026gt; selectList(@Param(Constants.WRAPPER) Wrapper\u0026lt;T\u0026gt; queryWrapper); /** * 根据 Wrapper 条件，查询全部记录 * * @param queryWrapper 实体对象封装操作类（可以为 null） */ List\u0026lt;Map\u0026lt;String, Object\u0026gt;\u0026gt; selectMaps(@Param(Constants.WRAPPER) Wrapper\u0026lt;T\u0026gt; queryWrapper); /** * 根据 Wrapper 条件，查询全部记录 * \u0026lt;p\u0026gt;注意： 只返回第一个字段的值\u0026lt;/p\u0026gt; * * @param queryWrapper 实体对象封装操作类（可以为 null） */ List\u0026lt;Object\u0026gt; selectObjs(@Param(Constants.WRAPPER) Wrapper\u0026lt;T\u0026gt; queryWrapper); /** * 根据 entity 条件，查询全部记录（并翻页） * * @param page 分页查询条件（可以为 RowBounds.DEFAULT） * @param queryWrapper 实体对象封装操作类（可以为 null） */ \u0026lt;P extends IPage\u0026lt;T\u0026gt;\u0026gt; P selectPage(P page, @Param(Constants.WRAPPER) Wrapper\u0026lt;T\u0026gt; queryWrapper); /** * 根据 Wrapper 条件，查询全部记录（并翻页） * * @param page 分页查询条件 * @param queryWrapper 实体对象封装操作类 */ \u0026lt;P extends IPage\u0026lt;Map\u0026lt;String, Object\u0026gt;\u0026gt;\u0026gt; P selectMapsPage(P page, @Param(Constants.WRAPPER) Wrapper\u0026lt;T\u0026gt; queryWrapper); }   插入 1 2 3 4 5 6 7 8 9 10 11  /** 测试BaseMapper的新增功能 **/ @Test public void testInsert() { // 实现新增用户信息  User user = new User(null, \u0026#34;张三\u0026#34;, 23, \u0026#34;zhangsan@atguigu.com\u0026#34;); //INSERT INTO user ( id, name, age, email ) VALUES ( ?, ?, ?, ? ) \tint result = userMapper.insert(user); System.out.println(\u0026#34;受影响行数：\u0026#34;+result); //1475754982694199298 \tSystem.out.println(\u0026#34;id自动获取：\u0026#34;+user.getId()); }    最终执行的结果，所获取的id为1475754982694199298\n这是因为MyBatis-Plus在实现插入数据时，会默认基于雪花算法的策略生成id\n 删除 a\u0026gt;通过id删除记录 1 2 3 4 5 6 7  @Test public void testDeleteById(){ //通过id删除用户信息  //DELETE FROM user WHERE id=?  int result = userMapper.deleteById(1475754982694199298L); System.out.println(\u0026#34;受影响行数：\u0026#34;+result); }   b\u0026gt;通过id批量删除记录 1 2 3 4 5 6 7 8  @Test public void testDeleteBatchIds(){ //通过多个id批量删除  //DELETE FROM user WHERE id IN ( ? , ? , ? )  List\u0026lt;Long\u0026gt; idList = Arrays.asList(1L, 2L, 3L); int result = userMapper.deleteBatchIds(idList); System.out.println(\u0026#34;受影响行数：\u0026#34;+result); }   c\u0026gt;通过map条件删除记录 1 2 3 4 5 6 7 8 9 10 11  /** 测试BaseMapper的 添加功能 **/ @Test public void testDeleteByMap(){ //根据map集合中所设置的条件删除记录  //DELETE FROM user WHERE name = ? AND age = ?  Map\u0026lt;String, Object\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); map.put(\u0026#34;age\u0026#34;, 23); map.put(\u0026#34;name\u0026#34;, \u0026#34;张三\u0026#34;); int result = userMapper.deleteByMap(map); System.out.println(\u0026#34;受影响行数：\u0026#34;+result); }   修改 1 2 3 4 5 6 7  @Test public void testUpdateById(){ User user = new User(4L, \u0026#34;admin\u0026#34;, 22, null); //UPDATE user SET name=?, age=? WHERE id=? int result = userMapper.updateById(user); System.out.println(\u0026#34;受影响行数：\u0026#34;+result); }   查询 a\u0026gt;根据id查询用户信息 1 2 3 4 5 6 7  @Test public void testSelectById(){ //根据id查询用户信息 //SELECT id,name,age,email FROM user WHERE id=? User user = userMapper.selectById(4L); System.out.println(user); }   b\u0026gt;根据多个id查询多个用户信息 1 2 3 4 5 6 7 8  @Test public void testSelectBatchIds(){ // 根据多个id查询多个用户信息  // SELECT id,name,age,email FROM user WHERE id IN ( ? , ? , ? )  List\u0026lt;Long\u0026gt; list = Arrays.asListƑL, 2L, 3L); List\u0026lt;User\u0026gt; users = userMapper.selectBatchIds(list); users.forEach(System.out::println); }   c\u0026gt;通过map条件查询用户信息 1 2 3 4 5 6 7 8 9 10  @Test public void testSelectByMap(){ // 根据map集合中的条件查询用户信息  // SELECT id,name,age,email FROM user WHERE name = ? AND age = ?  Map\u0026lt;String, Object\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); map.put(\u0026#34;name\u0026#34;, \u0026#34;Jack\u0026#34;); map.put(\u0026#34;age\u0026#34;, 18); List\u0026lt;User\u0026gt; users = userMapper.selectByMap(map); users.forEach(System.out::println); }   d\u0026gt; 查询所有数据 1 2 3 4 5 6 7  @Test public void testSelectList(){ // 查询所有数据  // SELECT id,name,age,email FROM user  List\u0026lt;User\u0026gt; users = userMapper.selectList(null); users.forEach(System.out::println); }   e\u0026gt; 自定义功能 1 2 3 4 5 6 7 8 9 10 11  /** 根据id查询用户信息为map集合 **/ Map\u0026lt;String,Object\u0026gt; selectMapById(Long id); \u0026lt;!--Map\u0026lt;String,Object\u0026gt; selectMapById(Long id);--\u0026gt; \u0026lt;select id=\u0026#34;selectMapById\u0026#34; resultType=\u0026#34;map\u0026#34;\u0026gt; select id,name,age,email from t_user where id = #{id} \u0026lt;/select\u0026gt; @Test public void testConsumer() { Map\u0026lt;String, Object\u0026gt; map = userMapper.selectMapById(1L); System.out.println(\u0026#34;map = \u0026#34; + map); }    通过观察BaseMapper中的方法，大多方法中都有Wrapper类型的形参，此为条件构造器，可针对于SQL语句设置不同的条件，若没有条件，则可以为该形参赋值null，即查询（删除/修改）所有数据\n 通用Service  通用 Service CRUD 封装IService接口，进一步封装 CRUD 采用 get 查询单行 remove 删除 list 查询集合 page 分页 前缀命名方式区分 Mapper 层避免混淆 泛型 T 为任意实体对象 建议如果存在自定义通用 Service 方法的可能，请创建自己的 IBaseService 继承 Mybatis-Plus 提供的基类 官网地址  a\u0026gt;IService MyBatis-Plus中有一个接口 IService和其实现类 ServiceImpl，封装了常见的业务层逻辑\n详情查看源码IService和ServiceImpl\nb\u0026gt;创建Service接口和实现类 1 2 3 4 5 6 7 8 9 10 11 12 13 14  // 接口 UserService继承IService模板提供的基础功能 public interface UserService extends IService\u0026lt;User\u0026gt; { } // 实现类 /* ServiceImpl实现了IService，提供了IService中基础功能的实现 若ServiceImpl无法满足业务需求，则可以使用自定的UserService定义方法， 并在实现类中实现 */ @Service public class UserServiceImpl extends ServiceImpl\u0026lt;UserMapper, User\u0026gt; implements UserService { }   c\u0026gt;测试查询记录数 1 2 3 4 5 6 7 8 9 10 11 12  @Autowired private UserService userService; /** 查询总记录数 **/ @Test public void testGetCount() { // 查询记录数  // SELECT COUNT( * ) FROM user  long count = userService.count(); System.out.println(\u0026#34;总记录数 = \u0026#34; + count); }   d\u0026gt;测试批量插入 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  /** 批量添加的功能 **/ @Test public void testInsertMore() { // SQL长度有限制，海量数据插入单条SQL无法实行，  // 因此MP将批量插入放在了通用Service中实现，而不是通用Mapper  // 批量添加  // INSERT INTO user ( id, name, age ) VALUES ( ?, ?, ? )  List\u0026lt;User\u0026gt; users = new ArrayList\u0026lt;\u0026gt;(); for (int i = 1; i \u0026lt;= 10; i++) { User user = new User(); user.setName(\u0026#34;lxg\u0026#34; + i); user.setAge(20 + i); users.add(user); } boolean b = userService.saveBatch(users); System.out.println(b); }   常用注解 @TableName  经过以上的测试，在使用MyBatis-Plus实现基本的CRUD时，我们并没有指定要操作的表，只是在 Mapper接口继承BaseMapper时，设置了泛型User，而操作的表为user表\n由此得出结论，MyBatis-Plus在确定操作的表时，由BaseMapper的泛型决定，即实体类型决 定，且默认操作的表名和实体类型的类名一致\n a\u0026gt;问题  若实体类类型的类名和要操作的表的表名不一致，会出现什么问题？\n我们将表user更名为t_user，测试查询功能程序抛出异常，Table \u0026lsquo;mybatis_plus.user\u0026rsquo; doesn\u0026rsquo;t exist，因为现在的表名为t_user，而默认操作的表名和实体类型的类名一致，即user表\n b\u0026gt;通过@TableName 解决问题 在实体类类型上添加**@TableName(\u0026ldquo;t_user\u0026rdquo;)**，标识实体类对应的表，即可成功执行SQL语句\nc\u0026gt;通过全局配置解决问题 在开发的过程中，我们经常遇到以上的问题，即实体类所对应的表都有固定的前缀，例如 t_ 或 tbl_ .此时，可以使用MyBatis-Plus提供的全局配置，为实体类所对应的表名设置默认的前缀，那么就 不需要在每个实体类上通过**@TableName标识实体类对应的表**\n1 2 3 4 5 6 7 8 9  mybatis-plus:configuration:# 配置MyBatis日志log-impl:org.apache.ibatis.logging.stdout.StdOutImpl# 设置MyBatis-Plus的全局配置global-config:db-config:# 设置实体类所对应的表的统一前缀table-prefix:t_  @Tableld 经过以上的测试，MyBatis-Plus在实现CRUD时，会默认将id作为主键列，并在插入数据时，默认 基于雪花算法的策略生成id\na\u0026gt;问题 若实体类和表中表示主键的不是id，而是其他字段，例如uid，MyBatis-Plus会自动识别uid为主 键列吗？\n我们实体类中的属性id改为uid，将表中的字段id也改为uid，测试添加功能\n程序抛出异常，Field \u0026lsquo;uid\u0026rsquo; doesn\u0026rsquo;t have a default value，说明MyBatis-Plus没有将uid作为主键\n赋值\nb\u0026gt;通过@TableId解决问题 在实体类中uid属性上通过**@TableId**将其标识为主键，即可成功执行SQL语句\nc\u0026gt;@TableId的value属性 若实体类中主键对应的属性为id，而表中表示主键的字段为uid，此时若只在属性id上添加注解 @TableId，则抛出异常Unknown column \u0026lsquo;id\u0026rsquo; in \u0026lsquo;field list\u0026rsquo;，即MyBatis-Plus仍然会将id作为表的主键操作，而表中表示主键的是字段uid\n此时需要通过**@TableId注解的value属性，指定表中的主键字段**，@TableId(\u0026ldquo;uid\u0026rdquo;)或 @TableId(value=\u0026ldquo;uid\u0026rdquo;)\nd\u0026gt;@Tableld的type属性 type属性用来定义主键策略\n常用的主键策略： 配置全局主键策略： 1 2 3 4 5 6 7 8 9 10 11  # 加入日志功能mybatis-plus:configuration:log-impl:org.apache.ibatis.logging.stdout.StdOutImpl# 设置MyBatis-Plus的全局配置global-config:db-config:# 设置实体类所对应的表的统一前缀table-prefix:t_# 设置统一的主键生成策略id-type:auto  e\u0026gt;雪花算法 - 背景 需要选择合适的方案去应对数据规模的增长，以应对逐渐增长的访问压力和数据量。\n数据库的扩展方式主要包括：业务分库、主从复制，数据库分表。\n- 数据库分表 将不同业务数据分散存储到不同的数据库服务器，能够支撑百万甚至千万用户规模的业务，但如果业务\n继续发展，同一业务的单表数据也会达到单台数据库服务器的处理瓶颈。例如，淘宝的几亿用户数据，\n如果全部存放在一台数据库服务器的一张表中，肯定是无法满足性能要求的，此时就需要对单表数据进\n行拆分。\n单表数据拆分有两种方式：垂直分表和水平分表。示意图如下：\n- 垂直分表 垂直分表适合将表中某些不常用且占了大量空间的列拆分出去。\n例如，前面示意图中的 nickname 和 description 字段，假设我们是一个婚恋网站，用户在筛选其他用\n户的时候，主要是用 age 和 sex 两个字段进行查询，而 nickname 和 description 两个字段主要用于展\n示，一般不会在业务查询中用到。description 本身又比较长，因此我们可以将这两个字段独立到另外\n一张表中，这样在查询 age 和 sex 时，就能带来一定的性能提升。\n- 水平分表 水平分表适合表行数特别大的表，有的公司要求单表行数超过 5000 万就必须进行分表，这个数字可以\n作为参考，但并不是绝对标准，关键还是要看表的访问性能。对于一些比较复杂的表，可能超过 1000\n万就要分表了；而对于一些简单的表，即使存储数据超过 1 亿行，也可以不分表。\n但不管怎样，当看到表的数据量达到千万级别时，作为架构师就要警觉起来，因为这很可能是架构的性\n能瓶颈或者隐患。\n水平分表相比垂直分表，会引入更多的复杂性，例如要求全局唯一的数据id该如何处\n主键自增\n①以最常见的用户 ID 为例，可以按照 1000000 的范围大小进行分段，1 ~ 999999 放到表 1中，\n1000000 ~ 1999999 放到表2中，以此类推。\n②复杂点：分段大小的选取。分段太小会导致切分后子表数量过多，增加维护复杂度；分段太大可能会\n导致单表依然存在性能问题，一般建议分段大小在 100 万至 2000 万之间，具体需要根据业务选取合适\n的分段大小。\n③优点：可以随着数据的增加平滑地扩充新的表。例如，现在的用户是 100 万，如果增加到 1000 万，\n只需要增加新的表就可以了，原有的数据不需要动。\n④缺点：分布不均匀。假如按照 1000 万来进行分表，有可能某个分段实际存储的数据量只有 1 条，而\n另外一个分段实际存储的数据量有 1000 万条。\n取模\n①同样以用户 ID 为例，假如我们一开始就规划了 10 个数据库表，可以简单地用 user_id % 10 的值来\n表示数据所属的数据库表编号，ID 为 985 的用户放到编号为 5 的子表中，ID 为 10086 的用户放到编号\n为 6 的子表中。\n②复杂点：初始表数量的确定。表数量太多维护比较麻烦，表数量太少又可能导致单表性能存在问题。\n③优点：表分布比较均匀。\n④缺点：扩充新的表很麻烦，所有数据都要重分布。\n雪花算法\n雪花算法是由Twitter公布的分布式主键生成算法，它能够保证不同表的主键的不重复性，以及相同表的\n主键的有序性。\n①核心思想：\n长度共64bit（一个long型）。\n首先是一个符号位，1bit标识，由于long基本类型在Java中是带符号的，最高位是符号位，正数是0，负\n数是1，所以id一般是正数，最高位是0。\n41bit时间截(毫秒级)，存储的是时间截的差值（当前时间截 - 开始时间截)，结果约等于69.73年。\n10bit作为机器的ID（\n5个bit是数据中心，5个bit的机器ID，可以部署在1024个节点）。\n12bit作为毫秒内的流水号（意味着每个节点在每毫秒可以产生 4096 个 ID）。\n②优点：整体上按照时间自增排序，并且整个分布式系统内不会产生ID碰撞，并且效率较高。\n@TableField 经过以上的测试，我们可以发现，MyBatis-Plus在执行SQL语句时，要保证实体类中的属性名和表中的字段名一致\n如果实体类中的属性名和字段名不一致的情况，会出现什么问题呢？\na\u0026gt;情况1 若实体类中的属性使用的是驼峰命名风格，而表中的字段使用的是下划线命名风格\n例如实体类属性userName，表中字段user_name\n此时MyBatis-Plus会自动将下划线命名风格转化为驼峰命名风格\n相当于在MyBatis中配置\na\u0026gt;情况2 若实体类中的属性和表中的字段不满足情况1\n例如实体类属性name，表中字段username\n此时需要在实体类属性上使用**@TableField(\u0026ldquo;username\u0026rdquo;)设置属性所对应的字段名**\n@TableLogic a\u0026gt;逻辑删除  物理删除：真实删除，将对应数据从数据库中删除，之后查询不到此条被删除的数据 逻辑删除：假删除，将对应数据中代表是否被删除字段的状态修改为“被删除状态”，之后在数据库  中仍旧能看到此条数据记录\n 使用场景：可以进行数据恢复  b\u0026gt;实现逻辑删除 **step1：**数据库中创建逻辑删除状态列，设置默认值为0\n**step2：**实体类中添加逻辑删除属性\nstep3**：**测试\n测试删除功能，真正执行的是修改\nUPDATE t_user SET is_deleted=1 WHERE id=? AND is_deleted=0\n测试查询功能，被逻辑删除的数据默认不会被查询\nSELECT id,username AS name,age,email,is_deleted FROM t_user WHERE is_deleted=0\n条件构造器和常用接口 wrapper介绍 Wrapper ： 条件构造抽象类，最顶端父类\n  AbstractWrapper ： 用于查询条件封装，生成 sql 的 where 条件\n   QueryWrapper ： 查询条件封装 UpdateWrapper ： Update 条件封装 AbstractLambdaWrapper ： 使用Lambda 语法       LambdaQueryWrapper ：用于Lambda语法使用的查询Wrapper LambdaUpdateWrapper ： Lambda 更新封装Wrapper      QueryWrapper a\u0026gt;例1：组装查询条件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  /** 查询用户包含a,年龄在20到30之间，邮箱信息不为null的用户信息 **/ @Test public void test01() { /* SELECT uid AS id,user_name AS name,age,email,is_deleted FROM t_user WHERE is_deleted=0 AND (user_name LIKE ? AND age BETWEEN ? AND ? AND email IS NOT NULL) */ QueryWrapper\u0026lt;User\u0026gt; queryWrapper = new QueryWrapper\u0026lt;\u0026gt;(); queryWrapper.like(\u0026#34;user_name\u0026#34;, \u0026#34;a\u0026#34;) .between(\u0026#34;age\u0026#34;, 20, 30) .isNotNull(\u0026#34;email\u0026#34;); List\u0026lt;User\u0026gt; users = userMapper.selectList(queryWrapper); users.forEach(System.out::println); }   b\u0026gt;例2：组装排序条件 1 2 3 4 5 6 7 8 9 10 11 12 13  /** 组装排序条件 查询用户信息，按照年龄的降序排序，若年龄相同，则按照id升序排序 **/ @Test public void test02() { /* SELECT uid AS id,user_name AS name,age,email,is_deleted FROM t_user WHERE is_deleted=0 ORDER BY age DESC,uid ASC */ QueryWrapper\u0026lt;User\u0026gt; queryWrapper = new QueryWrapper\u0026lt;\u0026gt;(); queryWrapper.orderByDesc(\u0026#34;age\u0026#34;) .orderByAsc(\u0026#34;uid\u0026#34;); List\u0026lt;User\u0026gt; users = userMapper.selectList(queryWrapper); users.forEach(System.out::println); }   c\u0026gt;例3：组装删除条件 1 2 3 4 5 6 7 8 9 10 11  /** 组装删除条件 删除邮箱地址为null的用户信息 **/ @Test public void test03() { /* UPDATE t_user SET is_deleted=1 WHERE is_deleted=0 AND (email IS NOT NULL) */ QueryWrapper\u0026lt;User\u0026gt; queryWrapper = new QueryWrapper\u0026lt;\u0026gt;(); queryWrapper.isNull(\u0026#34;email\u0026#34;); int result = userMapper.delete(queryWrapper); System.out.println(\u0026#34;result = \u0026#34; + result); }   d\u0026gt;例4：条件的优先级 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36  /** 组装修改条件 将(年龄大于20并且用户名中包含有a)或邮箱为null的用户信息修改 **/ @Test public void test04() { /* UPDATE t_user SET user_name=?, email=? WHERE is_deleted=0 AND (age \u0026gt; ? AND user_name LIKE ? OR email IS NOT NULL) */ QueryWrapper\u0026lt;User\u0026gt; queryWrapper = new QueryWrapper\u0026lt;\u0026gt;(); queryWrapper.gt(\u0026#34;age\u0026#34;, 20) .like(\u0026#34;user_name\u0026#34;, \u0026#34;a\u0026#34;) .or() .isNotNull(\u0026#34;email\u0026#34;); User user = new User(); user.setName(\u0026#34;小明\u0026#34;); user.setEmail(\u0026#34;test@atguigu.com\u0026#34;); int result = userMapper.update(user, queryWrapper); System.out.println(\u0026#34;result = \u0026#34; + result); } /** 条件优先级 将用户名中包含a并且(年龄大于20或邮箱为null)的用户信息修改 **/ @Test public void test05() { // lambda中条件优先级  /* UPDATE t_user SET user_name=?, email=? WHERE is_deleted=0 AND (user_name LIKE ? AND (age \u0026gt; ? OR email IS NULL)) */ QueryWrapper\u0026lt;User\u0026gt; queryWrapper = new QueryWrapper\u0026lt;\u0026gt;(); queryWrapper.like(\u0026#34;user_name\u0026#34;, \u0026#34;a\u0026#34;) .and(i -\u0026gt; i.gt(\u0026#34;age\u0026#34;, 20).or().isNull(\u0026#34;email\u0026#34;)); User user = new User(); user.setName(\u0026#34;小红\u0026#34;); user.setEmail(\u0026#34;test@atguigu.com\u0026#34;); int result = userMapper.update(user, queryWrapper); System.out.println(\u0026#34;result = \u0026#34; + result); }   e\u0026gt;例5：组装select子句 1 2 3 4 5 6 7 8 9 10 11  /** 组装select字句 查询用户名的用户名、年龄、邮箱信息 **/ @Test public void test06() { /* SELECT user_name,age,email FROM t_user WHERE is_deleted=0 */ QueryWrapper\u0026lt;User\u0026gt; queryWrapper = new QueryWrapper\u0026lt;\u0026gt;(); queryWrapper.select(\u0026#34;user_name\u0026#34;, \u0026#34;age\u0026#34;, \u0026#34;email\u0026#34;); List\u0026lt;Map\u0026lt;String, Object\u0026gt;\u0026gt; users = userMapper.selectMaps(queryWrapper); users.forEach(System.out::println); }   f\u0026gt;例6：实现子查询 1 2 3 4 5 6 7 8 9 10 11 12  /** 组装子查询 查询id小于100的用户信息**/ @Test public void test07() { /* SELECT uid AS id,user_name AS name,age,email,is_deleted FROM t_user WHERE is_deleted=0 AND (uid IN (select uid from t_user where uid \u0026lt;= 100)) */ QueryWrapper\u0026lt;User\u0026gt; queryWrapper = new QueryWrapper\u0026lt;\u0026gt;(); queryWrapper.inSql(\u0026#34;uid\u0026#34;, \u0026#34;select uid from t_user where uid \u0026lt;= 100\u0026#34;); List\u0026lt;User\u0026gt; list = userMapper.selectList(queryWrapper); list.forEach(System.out::println); }   UpdateWrapper 1 2 3 4 5 6 7 8 9 10 11 12 13 14  /** 使用UpdateWrapper实现修改功能 将用户名中包含a并且(年龄大于20或邮箱为null)的用户信息修改 **/ @Test public void test08() { /* UPDATE t_user SET user_name=?,email=? WHERE is_deleted=0 AND (user_name LIKE ? AND (age \u0026gt; ? OR email IS NULL)) */ UpdateWrapper\u0026lt;User\u0026gt; updateWrapper = new UpdateWrapper\u0026lt;\u0026gt;(); updateWrapper.like(\u0026#34;user_name\u0026#34;, \u0026#34;a\u0026#34;) .and(i -\u0026gt; i.gt(\u0026#34;age\u0026#34;, 20).or().isNull(\u0026#34;email\u0026#34;)); updateWrapper.set(\u0026#34;user_name\u0026#34;, \u0026#34;小黑\u0026#34;).set(\u0026#34;email\u0026#34;, \u0026#34;abc@atguigu.com\u0026#34;); int result = userMapper.update(null, updateWrapper); System.out.println(\u0026#34;result = \u0026#34; + result); }   Condition 在真正开发的过程中，组装条件是常见的功能，而这些条件数据来源于用户输入，是可选的，因此我们在组装这些条件时，必须先判断用户是否选择了这些条件，若选择则需要组装该条件，若\n没有选择则一定不能组装，以免影响SQL执行的结果\n思路一： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  /** 模拟开发中组装条件的情况 **/ @Test public void test09() { /* SELECT uid AS id,user_name AS name,age,email,is_deleted FROM t_user WHERE is_deleted=0 AND (user_name LIKE ? AND age \u0026lt;= ?) */ String username = \u0026#34;a\u0026#34;; Integer ageBegin = null; Integer ageEnd = 30; QueryWrapper\u0026lt;User\u0026gt; queryWrapper = new QueryWrapper\u0026lt;\u0026gt;(); if (StringUtils.isNotBlank(username)) { // isNotBlank判断某个字符串是否不为空字符串、不为null、不为空白符  queryWrapper.like(\u0026#34;user_name\u0026#34;, username); } if (ageBegin != null) { queryWrapper.gt(\u0026#34;age\u0026#34;, ageBegin); } if (ageEnd != null) { queryWrapper.le(\u0026#34;age\u0026#34;, ageEnd); } List\u0026lt;User\u0026gt; list = userMapper.selectList(queryWrapper); list.forEach(System.out::println); }   思路二： 上面的实现方案没有问题，但是代码比较复杂，我们可以使用带condition参数的重载方法构建查询条件**，**简化代码的编写\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  /** 使用condition组装条件 **/ @Test public void test10() { /* SELECT uid AS id,user_name AS name,age,email,is_deleted FROM t_user WHERE is_deleted=0 AND (user_name LIKE ? AND age \u0026lt;= ?) */ String username = \u0026#34;a\u0026#34;; Integer ageBegin = null; Integer ageEnd = 30; QueryWrapper\u0026lt;User\u0026gt; queryWrapper = new QueryWrapper\u0026lt;\u0026gt;(); queryWrapper.like(StringUtils.isNotBlank(username), \u0026#34;user_name\u0026#34;, username) .gt(ageBegin != null, \u0026#34;age\u0026#34;, ageBegin) .le(ageEnd != null, \u0026#34;age\u0026#34;, ageEnd); List\u0026lt;User\u0026gt; list = userMapper.selectList(queryWrapper); list.forEach(System.out::println); }   LambdaQueryWrapper 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  /** LambdaQueryWrapper **/ @Test public void test11() { /* SELECT uid AS id,user_name AS name,age,email,is_deleted FROM t_user WHERE is_deleted=0 AND (user_name LIKE ? AND age \u0026lt;= ?) */ String username = \u0026#34;a\u0026#34;; Integer ageBegin = null; Integer ageEnd = 30; //组装set子句  LambdaQueryWrapper\u0026lt;User\u0026gt; queryWrapper = new LambdaQueryWrapper\u0026lt;\u0026gt;(); //避免使用字符串表示字段，防止运行时错误  queryWrapper.like(StringUtils.isNotBlank(username), User::getName, username) .gt(ageBegin != null, User::getAge, ageBegin) .le(ageEnd != null, User::getAge, ageEnd); List\u0026lt;User\u0026gt; list = userMapper.selectList(queryWrapper); list.forEach(System.out::println); }   LambdaUpdateWrapper 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  /** LambdaUpdateWrapper **/ @Test public void test12() { /* UPDATE t_user SET user_name=?,email=? WHERE is_deleted=0 AND (user_name LIKE ? AND (age \u0026gt; ? OR email IS NULL)) */ LambdaUpdateWrapper\u0026lt;User\u0026gt; updateWrapper = new LambdaUpdateWrapper\u0026lt;\u0026gt;(); updateWrapper.like(User::getName, \u0026#34;a\u0026#34;) //lambda表达式内的逻辑优先运算  .and(i -\u0026gt; i.gt(User::getAge, 20).or().isNull(User::getEmail)); updateWrapper.set(User::getName, \u0026#34;小黑\u0026#34;).set(User::getEmail, \u0026#34;abc@atguigu.com\u0026#34;); int result = userMapper.update(null, updateWrapper); System.out.println(\u0026#34;result = \u0026#34; + result); }   插件 分页插件 MyBatis Plus自带分页插件，只要简单的配置即可实现分页功能\na\u0026gt;添加配置类 1 2 3 4 5 6 7 8 9 10 11 12 13  @Configuration // 扫描mapper接口所在的包 @MapperScan(\u0026#34;com.atguigu.mybatisplus.mapper\u0026#34;) // //可以将主类中的注解移到此处 public class myBatisPlusConfig { /** 添加MyBatisPlus分页插件 **/ @Bean public MybatisPlusInterceptor mybatisPlusInterceptor() { MybatisPlusInterceptor interceptor = new MybatisPlusInterceptor(); // 添加分页插件  interceptor.addInnerInterceptor(new PaginationInnerInterceptor(DbType.MYSQL)); } }   b\u0026gt;测试 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  @Autowired private ProductMapper productMapper; /** MyBatis-Plus分页插件的配置和使用和分页相关数据的获取 **/ @Test public void testPage() { /* SELECT uid AS id,user_name AS name,age,email,is_deleted FROM t_user WHERE is_deleted=0 LIMIT ? */ Page\u0026lt;User\u0026gt; page = new Page\u0026lt;\u0026gt;(1, 3); userMapper.selectPage(page, null); System.out.println( page.getRecords()); System.out.println(\u0026#34;总页数:\u0026#34; + page.getPages()); System.out.println(\u0026#34;总记录数\u0026#34; + page.getTotal()); System.out.println(\u0026#34;是否有上一页\u0026#34; + page.hasNext()); System.out.println(\u0026#34;是否有下一页:\u0026#34; + page.hasPrevious()); }    测试结果：\n[User(id=1, name=Jone, age=18, email=test1@baomidou.com, sex=null, isDeleted=0), User(id=2, name=Jack, age=18, email=test2@baomidou.com, sex=null, isDeleted=0), User(id=3, name=Tom, age=18, email=test3@baomidou.com, sex=null, isDeleted=0)]\n总页数:3\n总记录数8\n是否有上一页true\n是否有下一页:false\n xml自定义分页 a\u0026gt;UserMapper中定义接口方法 1 2 3 4 5 6  /** * 根据年龄查询用户列表，分页显示 * @param page 分页对象,xml中可以从里面进行取值,传递参数 Page 即自动分页,必须放在第一位 * @param age 年龄 * @return */ Page\u0026lt;User\u0026gt; selectPageVo(@Param(\u0026#34;page\u0026#34;) Page\u0026lt;User\u0026gt; page, @Param(\u0026#34;age\u0026#34;) Integer age);   b\u0026gt;UserMapper.xml中编写SQL 1 2 3 4  \u0026lt;!--Page\u0026lt;User\u0026gt; selectPageVo(@Param(\u0026#34;page\u0026#34;) Page\u0026lt;User\u0026gt; page, @Param(\u0026#34;age\u0026#34;) Integer age);--\u0026gt; \u0026lt;select id=\u0026#34;selectPageVo\u0026#34; resultType=\u0026#34;User\u0026#34;\u0026gt; select uid as `id`,user_name as `name`,age,email from t_user where age \u0026gt; #{age} \u0026lt;/select\u0026gt;   c\u0026gt;测试 1 2 3 4 5 6 7 8 9 10 11 12 13 14  @Test public void testSelectPageVo(){ //设置分页参数  Page\u0026lt;User\u0026gt; page = new Page\u0026lt;\u0026gt;(1, 5); userMapper.selectPageVo(page, 20); //获取分页数据  List\u0026lt;User\u0026gt; list = page.getRecords(); list.forEach(System.out::println); System.out.println(\u0026#34;当前页:\u0026#34;+page.getCurrent()); System.out.println(\u0026#34;每页显示的条数:\u0026#34;+page.getSize()); System.out.println(\u0026#34;总记录数:\u0026#34;+page.getTotal()); System.out.println(\u0026#34;总页数:\u0026#34;+page.getPages()); System.out.println(\u0026#34;是否有上一页:\u0026#34;+page.hasPrevious()); System.out.println(\u0026#34;是否有下一页:\u0026#34;+page.hasNext()); }    User(id=3, name=Tom, age=28, email=test3@baomidou.com, isDeleted=null) User(id=4,\nname=Sandy, age=21, email=test4@baomidou.com, isDeleted=null) User(id=5, name=Billie,\nage=24, email=test5@baomidou.com, isDeleted=null) User(id=8, name=ybc1, age=21,\nemail=null, isDeleted=null) User(id=9, name=ybc2, age=22, email=null, isDeleted=null)\n当前页：1 每页显示的条数：5 总记录数：12 总页数：3 是否有上一页：false 是否有下一页：true\n 乐观锁 a\u0026gt;场景 一件商品，成本价是80元，售价是100元。老板先是通知小李，说你去把商品价格增加50元。小\n李正在玩游戏，耽搁了一个小时。正好一个小时后，老板觉得商品价格增加到150元，价格太\n高，可能会影响销量。又通知小王，你把商品价格降低30元。\n此时，小李和小王同时操作商品后台系统。小李操作的时候，系统先取出商品价格100元；小王\n也在操作，取出的商品价格也是100元。小李将价格加了50元，并将100+50=150元存入了数据\n库；小王将商品减了30元，并将100-30=70元存入了数据库。是的，如果没有锁，小李的操作就\n完全被小王的覆盖了。\n现在商品价格是70元，比成本价低10元。几分钟后，这个商品很快出售了1千多件商品，老板亏1\n万多。\nb\u0026gt;乐观锁和悲观锁 上面的故事，如果是乐观锁，小王保存价格前，会检查下价格是否被人修改过了。如果被修改过了，则重新取出的被修改后的价格，150元，这样他会将120元存入数据库。\n如果是悲观锁，小李取出数据后，小王只能等小李操作完之后，才能对价格进行操作，也会保证\n最终的价格是120元。\nc\u0026gt;模拟修改冲突 数据库中增加商品表 1 2 3 4 5 6  CREATETABLEt_product(idBIGINT(20)NOTNULLCOMMENT\u0026#39;主键ID\u0026#39;,NAMEVARCHAR(30)NULLDEFAULTNULLCOMMENT\u0026#39;商品名称\u0026#39;,priceINT(11)DEFAULT0COMMENT\u0026#39;价格\u0026#39;,VERSIONINT(11)DEFAULT0COMMENT\u0026#39;乐观锁版本号\u0026#39;,PRIMARYKEY(id));  添加数据 1  INSERTINTOt_product(id,NAME,price)VALUES(1,\u0026#39;外星人笔记本\u0026#39;,100);  添加实体 1 2 3 4 5 6 7 8 9 10 11  package com.atguigu.mybatisplus.entity; import lombok.Data; @Data public class Product { private Long id; private String name; private Integer price; private Integer version; }   添加mapper 1 2 3 4  @Repository public interface ProductMapper extends BaseMapper\u0026lt;Product\u0026gt; { }   测试 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  @Test public void testProduct01() { // 1.小李查询商品价格  Product productLi = productMapper.selectById(1); System.out.println(\u0026#34;小李查询的商品价格:\u0026#34; + productLi.getPrice()); // 2.小王查询商品价格  Product productWang = productMapper.selectById(1); System.out.println(\u0026#34;小王查询的商品价格:\u0026#34; + productWang.getPrice()); // 3.小李商品价格+50  productLi.setPrice(productLi.getPrice() + 50); productMapper.updateById(productLi); // 4.小王将商品价格-30  productWang.setPrice(productWang.getPrice() - 30); int result = productMapper.updateById(productWang); // 5.老板查询商品价格  Product productBoss = productMapper.selectById(1); System.out.println(\u0026#34;老板查询的商品价格:\u0026#34; + productBoss.getPrice()); }   d\u0026gt;乐观锁实现流程 数据库中添加version字段\n取出记录时，获取当前version\n1  SELECTid,`name`,price,`version`FROMproductWHEREid=1  更新时，version + 1，如果where语句中的version版本不对，则更新失败\n1 2  UPDATEproductSETprice=price+50,`version`=`version`+1WHEREid=1AND`version`=1  e\u0026gt;MyBatis-Plus实现乐观锁 修改实体类 1 2 3 4 5 6 7 8 9 10  @Data public class Product { private Long id; private String name; private Integer price; @Version // 设置乐观锁版本号字段  private Integer version; }   添加乐观锁插件配置 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  @Configuration // 扫描mapper接口所在的包 @MapperScan(\u0026#34;com.atguigu.mybatisplus.mapper\u0026#34;) public class myBatisPlusConfig { /** 添加MyBatisPlus分页插件 **/ @Bean public MybatisPlusInterceptor mybatisPlusInterceptor() { MybatisPlusInterceptor interceptor = new MybatisPlusInterceptor(); // 添加分页插件  interceptor.addInnerInterceptor(new PaginationInnerInterceptor(DbType.MYSQL)); // 添加乐观锁插件  interceptor.addInnerInterceptor(new OptimisticLockerInnerInterceptor()); return interceptor; } }   测试修改冲突  小李查询商品信息:\nSELECT id,name,price,version FROM t_product WHERE id=?\n小王查询商品信息:\nSELECT id,name,price,version FROM t_product WHERE id=?\n小李修改商品价格，自动将version+1\nUPDATE t_product SET name=?, price=?, version=? WHERE id=? AND version=? Parameters: 外星人笔记本(String), 150(Integer), 1(Integer), 1(Long), 0(Integer)\n小王修改商品价格，此时version已更新，条件不成立，修改失败\nUPDATE t_product SET name=?, price=?, version=? WHERE id=? AND version=? Parameters: 外星人笔记本(String), 70(Integer), 1(Integer), 1(Long), 0(Integer)\n最终，小王修改失败，查询价格:150\nSELECT id,name,price,version FROM t_product WHERE id=?\n 优化流程 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  @Test public void testProduct01() { // 1.小李查询商品价格  Product productLi = productMapper.selectById(1); System.out.println(\u0026#34;小李查询的商品价格:\u0026#34; + productLi.getPrice()); // 2.小王查询商品价格  Product productWang = productMapper.selectById(1); System.out.println(\u0026#34;小王查询的商品价格:\u0026#34; + productWang.getPrice()); // 3.小李商品价格+50  productLi.setPrice(productLi.getPrice() + 50); productMapper.updateById(productLi); // 4.小王将商品价格-30  productWang.setPrice(productWang.getPrice() - 30); int result = productMapper.updateById(productWang); if (result == 0) { // 操作失败,重试  Product productNew = productMapper.selectById(1); productNew.setPrice(productNew.getPrice() - 30); productMapper.updateById(productNew); } // 5.老板查询商品价格  Product productBoss = productMapper.selectById(1); System.out.println(\u0026#34;老板查询的商品价格:\u0026#34; + productBoss.getPrice()); }   通用枚举 表中的有些字段值是固定的，例如性别(男或女)，此时我们可以使用MyBatis-Plus的通用枚举 来实现\na\u0026gt;数据库表添加字段sex b\u0026gt;创建通过枚举类型 1 2 3 4 5 6 7 8 9 10 11 12 13 14  @Getter // 因为枚举里面都是常量 public enum SexEnum { MALE(1, \u0026#34;男\u0026#34;), FEMALE(2, \u0026#34;女\u0026#34;); @EnumValue // 将注解所标识的属性的值存储到数据库中  private Integer sex; private String sexName; SexEnum(Integer sex, String sexName) { this.sex = sex; this.sexName = sexName; } }   c\u0026gt;配置扫描通过枚举 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  # 加入日志功能mybatis-plus:configuration:log-impl:org.apache.ibatis.logging.stdout.StdOutImpl# 设置MyBatis-Plus的全局配置global-config:db-config:# 设置实体类所对应的表的统一前缀table-prefix:t_# 设置统一的主键生成策略id-type:auto# 配置类型别名所对应的包type-aliases-package:com.atguigu.mybatisplus.pojo# 扫描枚举的包type-enums-package:com.atguigu.mybatisplus.enums  d\u0026gt;测试 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  @SpringBootTest public class MyBatisPlusEnumTest { @Autowired private UserMapper userMapper; @Test public void test() { User user = new User(); user.setName(\u0026#34;admin\u0026#34;); user.setAge(33); user.setSex(SexEnum.MALE); int result = userMapper.insert(user); System.out.println(\u0026#34;result = \u0026#34; + result); } }   代码生成器 引入依赖 1 2 3 4 5 6 7 8 9 10  \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.baomidou\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mybatis-plus-generator\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.5.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.freemarker\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;freemarker\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.3.31\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt;   快速生成 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  public class FastAutoGeneratorTest { public static void main(String[] args) { // 设置我们需要创建在哪的路径  String path = \u0026#34;/Users/luxiaogen/Documents/RoadTo2w/Java/尚硅谷/MyBatisPlus-2022/demo\u0026#34;; // 这里我是mysql8 5版本可以换成 jdbc:mysql://localhost:3306/mybatis_plus?characterEncoding=utf-8\u0026amp;useSSL=false  FastAutoGenerator.create(\u0026#34;jdbc:mysql://localhost:3306/mybatis_plus?serverTimezone=GMT%2B8\u0026amp;characterEncoding=utf-8\u0026amp;useSSL=false\u0026#34;, \u0026#34;root\u0026#34;, \u0026#34;root\u0026#34;) .globalConfig(builder -\u0026gt; { builder.author(\u0026#34;atguigu\u0026#34;) // 设置作者  // .enableSwagger() // 开启 swagger 模式  .fileOverride() // 覆盖已生成文件  .outputDir(path); // 指定输出目录  }) .packageConfig(builder -\u0026gt; { builder.parent(\u0026#34;com.atguigu\u0026#34;) // 设置父包名  .moduleName(\u0026#34;mybatisplus\u0026#34;) // 设置父包模块名  .pathInfo(Collections.singletonMap(OutputFile.mapperXml, path)); // 设置mapperXml生成路径  }) .strategyConfig(builder -\u0026gt; { builder.addInclude(\u0026#34;t_user\u0026#34;) // 设置需要生成的表名  .addTablePrefix(\u0026#34;t_\u0026#34;, \u0026#34;c_\u0026#34;); // 设置过滤表前缀  }).templateEngine(new FreemarkerTemplateEngine()) // 使用Freemarker 引擎模板，默认的是Velocity引擎模板  .execute(); } }   点击运行\n多数据源 适用于多种场景:纯粹多库、 读写分离、 一主多从、 混合模式等 目前我们就来模拟一个纯粹多库的一个场景，其他场景类似\n场景说明:\n我们创建两个库，分别为:mybatis_plus(以前的库不动)与mybatis_plus_1(新建)，将 mybatis_plus库的product表移动到mybatis_plus_1库，这样每个库一张表，通过一个测试用例 分别获取用户数据与商品数据，如果获取到说明多库模拟成功\n创建数据库及表 创建数据库mybatis_plus_1和表product\n1 2 3 4 5 6 7 8  CREATEDATABASE`mybatis_plus_1`/*!40100 DEFAULT CHARACTER SET utf8mb4 */;use`mybatis_plus_1`;CREATETABLEproduct(idBIGINT(20)NOTNULLCOMMENT\u0026#39;主键ID\u0026#39;,nameVARCHAR(30)NULLDEFAULTNULLCOMMENT\u0026#39;商品名称\u0026#39;,priceINT(11)DEFAULT0COMMENT\u0026#39;价格\u0026#39;,versionINT(11)DEFAULT0COMMENT\u0026#39;乐观锁版本号\u0026#39;,PRIMARYKEY(id));  添加测试数据\n1  INSERTINTOproduct(id,NAME,price)VALUES(1,\u0026#39;外星人笔记本\u0026#39;,100);  删除mybatis_plus库product表\n1 2  usemybatis_plus;DROPTABLEIFEXISTSproduct;  引入依赖 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  \u0026lt;!--MyBatis-plus启动器--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.baomidou\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mybatis-plus-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.5.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!--lombok用于简化实体类开发--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.projectlombok\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;lombok\u0026lt;/artifactId\u0026gt; \u0026lt;optional\u0026gt;true\u0026lt;/optional\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!--mysql驱动--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;mysql\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mysql-connector-java\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!--多数据源依赖--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.baomidou\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;dynamic-datasource-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.5.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt;   配置多数据源 说明:注释掉之前的数据库连接，添加新配置\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  spring:datasource:# 配置数据源信息 datasource:dynamic:# 设置默认的数据源或者数据源组,默认值即为masterprimary:master# 严格匹配数据源,默认false.true未匹配到指定数据源时抛异常,false使用默认数据源strict:falsedatasource:master:url:jdbc:mysql://localhost:3306/mybatis_plus?serverTimezone=GMT%2B8\u0026amp;characterEncoding=utf-8\u0026amp;useSSL=falsedriver-class-name:com.mysql.cj.jdbc.Driverusername:rootpassword:\u0026#39;root\u0026#39;slave_1:# 我的数据库是8.0.27 5版本的可以使用jdbc:mysql://localhost:3306/mybatis_plus?characterEncoding=utf-8\u0026amp;useSSL=falseurl:jdbc:mysql://localhost:3306/mybatis_plus_1?serverTimezone=GMT%2B8\u0026amp;characterEncoding=utf-8\u0026amp;useSSL=falsedriver-class-name:com.mysql.cj.jdbc.Driverusername:rootpassword:\u0026#39;root\u0026#39;  创建用户service 1 2 3 4 5 6 7  public interface UserService extends IService\u0026lt;User\u0026gt; { } @Service @DS(\u0026#34;master\u0026#34;) // 指定所操作的数据源 public class UserServiceImpl extends ServiceImpl\u0026lt;UserMapper, User\u0026gt; implements UserService { }   创建商品service 1 2 3 4 5 6  public interface ProductService extends IService\u0026lt;Product\u0026gt; { } @Service @DS(\u0026#34;slave_1\u0026#34;) // 要操作的数据源 public class ProductServiceImpl extends ServiceImpl\u0026lt;ProductMapper, Product\u0026gt; implements ProductService { }   测试 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  @SpringBootTest class MybatisPlusDatasourceApplicationTests { @Autowired private UserService userService; @Autowired private ProductService productService; @Test public void test() { // 测试  System.out.println(userService.getById(1L)); System.out.println(productService.getById(1L)); } }   结果:\n1、都能顺利获取对象，则测试成功\n2、如果我们实现读写分离，将写操作方法加上主库数据源，读操作方法加上从库数据源，自动切换，是不是就能实现读写分离?\nMyBatisX插件 MyBatis-Plus为我们提供了强大的mapper和service模板，能够大大的提高开发效率\n但是在真正开发过程中，MyBatis-Plus并不能为我们解决所有问题，例如一些复杂的SQL，多表 联查，我们就需要自己去编写代码和SQL语句，我们该如何快速的解决这个问题呢，这个时候可 以使用MyBatisX插件\nMyBatisX一款基于 IDEA 的快速开发插件，为效率而生\nMyBatisX插件用法\n","date":"2022-03-09T13:36:41Z","image":"https://ahao.ink/1.jpg","permalink":"https://ahao.ink/posts/mybatisplusspringboot%E7%89%88--2022/","title":"MyBatisPlus(SpringBoot版)--2022"},{"content":"前言 博客已经搭建完成了，如果要更新岂不是每次都要编译再上传，这就很麻烦，接下来利用 GitHub Actions 来自动部署静态博客。\nGitHub Actions 虽然是静态博客，但配合 GitHub Actions 这种 Serverless 的服务也可以让静态博客的更新变得稍微方便一些。原有的静态博客的更新流程，是在文章写好之后，在本地机器上编译成静态的 HTML 文件，再 push 到 GitHub Pages 的仓库里。这样需要在写文章之后至少本地跑一次 Hugo。而利用 GitHub Actions，这一次“跑 Hugo”的过程可以挪到远端进行，并且自动触发。\n具体地，我们需要两个仓库：一个是公开的页面仓库 username.github.io，另一个是公开或者私有的源码仓库 blog-source-code。前一个仓库配置为 GitHub Pages 仓库。\n我们需要配置 GitHub Actions，使得当源码仓库更新的时候（例如，push 了一篇新的 .md 文件），远端自动运行一次 Hugo，生成好新的网页文件并存入 username.github.io 仓库。这样，我们只需要直接 push 新的文章文件，就能在 GitHub Actions 执行结束之后得到一个更新完成的网站了。\n上面这部分已经在第一部分创建完成了 博客搭建 。\n配置 GitHub Pages 和 GitHub Actions 准备两个仓库 如上文所言，需要准备两个 GitHub 仓库：username.github.io 和 blog-source-code。前者必须是公开（Public）的（不过好像你有 GitHub PRO 的话，也可以为私有仓库配置 Pages，但我没试过），后者可以是私有（Private）的。\n生成一对 SSH 秘钥 接下来需要配置一对 SSH 秘钥。在上面的叙述中提到，blog-source-code 这个仓库会将编译好的页面放入 username.github.io，这意味着前者运行的 Actions 必须要有权限向后者进行 push。有三种方式可以实现这个过程的鉴权，这里我们选择传统的 SSH 秘钥。在 Shell 中运行\n1  ssh-keygen -t rsa -b 4096 -C \u0026#34;$(git config user.email)\u0026#34; -f gh-pages -N \u0026#34;\u0026#34;   我们会得到两个文件：gh-pages.pub（公钥，给 username.github.io）以及 gh-pages（私钥，给 blog-source-code）。\n为两个仓库部署秘钥  部署源码仓库的秘钥。首先打开源码仓库 blog-source-code，找到 Settings → Secrets。点击 New repository secret 来添加一条秘钥，秘钥的名字设置为 ACTIONS_DEPLOY_KEY，秘钥内容为 gh-pages 文件的内容。 部署页面仓库的秘钥。打开页面仓库 username.github.io，找到 Settings → Deploy Keys。点击 Add deploy key 来添加一条秘钥，秘钥的名字任意，内容为 gh-pages.pub 文件的内容。  安装 Hugo 并配置源码仓库 Hugo 的安装请参见官方文档。作为一个 Go 语言程序，它不需要借助其他包管理器（比如 Node.JS 的 npm）来安装。\n将空的源码仓库克隆到本地：\n1  git clone git@github.com:username/blog-source-code.git   初始化 Hugo 站点。执行下面的语句，可能会提示需要 --force 参数，加上即可（这是因为那个目录并非是空的，内有 .git 文件夹）\n1  hugo new site ./blog-source-code   这样这个站点就配置好了。安装主题（注意主题如果是从 GitHub 克隆来的，请使用 submodule）、调整页面、添加文章等步骤不再赘述。现在我们将这个站点源码 push 到远端：\n1 2 3  git add . git commit -m \u0026#34;New site!\u0026#34; git push -u origin master   配置 GitHub Actions 上一步完成之后，在 GitHub 打开源码仓库，点击 Actions → set up a workflow yourself。将下面的代码保存为 main.yml 文件，然后 commit。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33  name: GitHub Pages on: push: branches: - master jobs: deploy: runs-on: ubuntu-20.04 steps: - name: Checkout repositories uses: actions/checkout@v2 with: submodules: true # Fetch Hugo themes (true OR recursive) fetch-depth: 0 # Fetch all history for .GitInfo and .Lastmod - name: Setup Hugo uses: peaceiris/actions-hugo@v2 with: hugo-version: \u0026#39;latest\u0026#39; - name: Build run: hugo - name: Deploy uses: peaceiris/actions-gh-pages@v3 with: deploy_key: ${{ secrets.ACTIONS_DEPLOY_KEY }} external_repository: criwits/criwits.github.io publish_branch: master publish_dir: ./public cname: ahao.ink   需要进行手动修改的部分集中在代码最后几行。分别是\n external_repository：设置成页面仓库 username.github.io 的地址。 publish_branch：设置成页面仓库的主分支，比如 master 或者 main。 cname：设置成网站的域名。如果使用 .github.io 域名就不需要这一行。  提交（commit）之后，回到本地 blog-source-code 的 git 命令行，输入\n1  git pull origin master   来拉取更改。\n现在，源码仓库的 GitHub Actions 已经配置完成了。当每一次对 blog-source-code 仓库进行 push 的时候，都会触发 GitHub Pages 这个 Action，进而将编译好的页面推送至 username.github.io 仓库，实现博客的自动化编译。\n总结 以后更新时，直接全部 push 上去，不需要本地执行再上传了，那么操作步骤如下\n1 2 3 4  git add . git commit -m \u0026#34;更新\u0026#34; git pull origin master git push -u origin master   ","date":"2022-02-05T13:36:41Z","image":"https://ahao.ink/11.png","permalink":"https://ahao.ink/posts/hugo-%E5%8D%9A%E5%AE%A2%E8%87%AA%E5%8A%A8%E9%83%A8%E7%BD%B2/","title":"Hugo 博客自动部署"},{"content":"前言 之前一直用 hexo 搭建博客，最近想把 hexo 上的博客迁移到 hugo 上，于是就有了这个新的博客。\n安装 Hugo 环境   首先下载安装包管理器 Chocolatey 为了便于安装hugo-extended。检查是否安装成功\n1  choco version     安装完成后，用管理员打开命令窗口，安装hugo-extended\n1  choco install hugo-extended     检查是否安装完成\n1  hugo version     构建 Hugo 项目   新建博客站点\n1  hugo new site Myblog     创建之后的文件结构\n1 2 3 4 5 6 7 8 9  Myblog ├── archetypes │ └── default.md ├── config.toml ├── content ├── data ├── layouts ├── static └── themes     添加 DoIt 主题 博客原主题是 LoveIt ，在此基础上修改的 DoIt 便是我的选择。\n将该主题作为子模块\n1 2 3  cd Myblog git init git submodule add https://github.com/dillonzq/LoveIt.git themes/LoveIt   启动 hugo server   启动 hugo 作为本地调试使用，在浏览器打开 http://localhost:1313/ 即可查看效果\n1  hugo server --disableFastRender     生成静态文件，会在 MyBlog 下面生成 public 的静态文件目录\n1  hugo     使用 DoIt 主题自带的 exampleSite 的 config.toml 来进行修改和配置\n1 2  cd MyblogHugo cp themes/LoveIt/exampleSite/config.toml .     创建博客文章之前，使用 example 的默认创建初始化详情来进行配置和修改\n1 2 3  cp themes/LoveIt/archetypes/default.md archetypes/ # 这样，你每次创建文章的时候，都会使用这里的默认配置进行创建 hugo new posts/new.md     default.md\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  \\--- title: \u0026#34;{{ replace .TranslationBaseName \u0026#34;-\u0026#34; \u0026#34; \u0026#34; | title }}\u0026#34; subtitle: \u0026#34;\u0026#34; date: {{ .Date }} lastmod: {{ .Date }} draft: false #是否作为草稿，如果为 true，不会生产静态文件到 public 目录 author: \u0026#34;ahao\u0026#34; authorLink: \u0026#34;\u0026#34; description: \u0026#34;\u0026#34; tags: [] categories: [] hiddenFromHomePage: false hiddenFromSearch: false featuredImage: \u0026#34;\u0026#34; featuredImagePreview: \u0026#34;\u0026#34; toc: enable: true\t#是 否展开右边目录栏 math: enable: false lightgallery: false license: \u0026#34;\u0026#34; \\---     配置 Github Pages   登录 github，在设置那里创建个人 repo 仓库，一共 2 个，一个是 .github.io 作为个人站点 public 的静态文件，一个是 Myblog 作为除了 public 这个静态目录的所有文件的仓库\n  初始化仓库 Myblog，public 目录要忽略，不上传\n1 2 3 4 5 6 7 8  cd MyBlogHugo echo \u0026#34;!public/\u0026#34; \u0026gt;\u0026gt; .gitignore git init git remote add origin /Myblog.git git add . git commit -m \u0026#34;no public\u0026#34; git pull --rebase origin master git push -u origin master     初始化仓库 .github.io\n1 2 3 4 5 6 7  cd public git init git remote add origin [email protected]:ZhaoUncle/zhaouncle.github.io.git git add . git commit -m \u0026#34;my blog hugo\u0026#34; git pull --rebase origin master git push -u origin master     这样，就完成了博客的搭建，可通过 http://username.github.io 进入到你的博客了。\n","date":"2022-02-01T13:36:41Z","image":"https://ahao.ink/10.jpg","permalink":"https://ahao.ink/posts/hugo-%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/","title":"Hugo 搭建个人博客"},{"content":"Git 基础操作 常用 git 基础操作\n创建版本库 创建空目录 1 2 3  $ mkdir learngit $ cd learngit $ pwd   git init 通过 git init 命令把这个目录变成 Git 可以管理的仓库：\n1  $ git init   把文件添加到版本库 编写文件，放在库目录下。把一个文件放到 Git 仓库只需要两步\n第一步，用命令 git add 告诉 Git ，把文件添加到仓库\n1  $ git add readme.txt   第二步，用命令 git commit 告诉 Git ，把文件提交到仓库\n1  $ git commit -m \u0026#34;wrote a readme file\u0026#34;   为什么 Git 添加文件需要 add，commit 一共两步呢？因为 commit 可以一次提交很多文件，所以你可以多次 add 不同的文件，比如：\n1 2 3  $ git add file1.txt $ git add file2.txt file3.txt $ git commit -m \u0026#34;add 3 files.\u0026#34;   查看状态 git status  命令可以时刻掌握仓库当前的状态\n1  $ git status   git diff顾名思义就是查看 difference ，显示的格式正是 Unix 通用的 diff 格式\n查看历史记录 1  $ git log   如果嫌输出信息太多，看得眼花缭乱的，可以试试加上 --pretty=oneline 参数：\n回退版本 1  $ git reset --hard HEAD^   Windows 下命令为 git reset --hard 'HEAD^'\n回退到指定版本，带上 commit id\n1  $ git reset --hard 1094a   查看记录的每一条命令，以便重返未来\n1  $ git reflog   Git管理的文件分为：工作区，版本库，版本库又分为暂存区stage和暂存区分支master(仓库)\n工作区\u0026raquo;\u0026raquo;暂存区\u0026raquo;\u0026raquo;仓库\ngit add把文件从工作区\u0026raquo;\u0026raquo;暂存区，git commit把文件从暂存区\u0026raquo;\u0026raquo;仓库，\ngit diff查看工作区和暂存区差异，\ngit diff \u0026ndash;cached查看暂存区和仓库差异，\ngit diff HEAD 查看工作区和仓库的差异，\ngit add的反向命令git checkout，撤销工作区修改，即把暂存区最新版本转移到工作区，\ngit commit的反向命令git reset HEAD，就是把仓库最新版本转移到暂存区。\n","date":"2022-01-05T13:36:41Z","image":"https://ahao.ink/8.jpg","permalink":"https://ahao.ink/posts/git/","title":"Git"},{"content":"Redis 主从同步 主从同步（主从复制）是 Redis 高可用服务的基石，也是多机运行中最基础的一个。我们把主要存储数据的节点叫做主节点 (master），把其他通过复制主节点数据的副本节点叫做从节点 (slave），如下图所示：\n在 Redis 中一个主节点可以拥有多个从节点，一个从节点也可以是其他服务器的主节点，如下图所示：\n主从同步的优点 主从同步具有以下三个优点：\n 性能方面：有了主从同步之后，可以把查询任务分配给从服务器，用主服务器来执行写操作，这样极大的提高了程序运行的效率，把所有压力分摊到各个服务器了； 高可用：当有了主从同步之后，当主服务器节点宕机之后，可以很迅速的把从节点提升为主节点，为 Redis 服务器的宕机恢复节省了宝贵的时间； 防止数据丢失：当主服务器磁盘坏掉之后，其他从服务器还保留着相关的数据，不至于数据全部丢失。  既然主从同步有这么多的优点，那接下来我们来看如何开启和使用主从同步功能。\n开启主从同步 运行中设置从服务器 在 Redis 运行过程中，我们可以使用 replicaof host port 命令，把自己设置为目标 IP 的从服务器，执行命令如下：\n1 2  127.0.0.1:6379\u0026gt; replicaof 127.0.0.1 6380 OK   如果主服务设置了密码，需要在从服务器输入主服务器的密码，使用 config set masterauth 主服务密码 命令的方式，例如：\n1 2  127.0.0.1:6377\u0026gt; config set masterauth pwd654321 OK   1. 执行流程\n在执行完 replicaof 命令之后，从服务器的数据会被清空，主服务会把它的数据副本同步给从服务器。\n2. 测试同步功能\n主从服务器设置完同步之后，我们来测试一下主从数据同步，首先我们先在主服务器上执行保存数据操作，再去从服务器查询。\n主服务器执行命令：\n1 2  127.0.0.1:6379\u0026gt; set lang redis OK   从服务执行查询：\n1 2  127.0.0.1:6379\u0026gt; get lang \u0026#34;redis\u0026#34;   可以看出数据已经被正常同步过来了。\n启动时设置从服务器 我们可以使用命令 redis-server --port 6380 --replicaof 127.0.0.1 6379 将自己设置成目标服务器的从服务器。\n数据同步 完整数据同步 当有新的从服务器连接时，为了保障多个数据库的一致性，主服务器会执行一次 bgsave 命令生成一个 RDB 文件，然后再以 Socket 的方式发送给从服务器，从服务器收到 RDB 文件之后再把所有的数据加载到自己的程序中，就完成了一次全量的数据同步。\n部分数据同步 在 Redis 2.8 之前每次从服务器离线再重新上线之前，主服务器会进行一次完整的数据同步，然后这种情况如果发生在离线时间比较短的情况下，只有少量的数据不同步却要同步所有的数据是非常笨拙和不划算的，在 Redis 2.8 这个功能得到了优化。\nRedis 2.8 的优化方法是当从服务离线之后，主服务器会把离线之后的写入命令，存储在一个特定大小的队列中，队列是可以保证先进先出的执行顺序的，当从服务器重写恢复上线之后，主服务会判断离线这段时间内的命令是否还在队列中，如果在就直接把队列中的数据发送给从服务器，这样就避免了完整同步的资源浪费。\n 小贴士：存储离线命令的队列大小默认是 1MB，使用者可以自行修改队列大小的配置项 repl-backlog-size。\n 无盘数据同步 从前面的内容我们可以得知，在第一次主从连接的时候，会先产生一个 RDB 文件，再把 RDB 文件发送给从服务器，如果主服务器是非固态硬盘的时候，系统的 I/O 操作是非常高的，为了缓解这个问题，Redis 2.8.18 新增了无盘复制功能，无盘复制功能不会在本地创建 RDB 文件，而是会派生出一个子进程，然后由子进程通过 Socket 的方式，直接将 RDB 文件写入到从服务器，这样主服务器就可以在不创建RDB文件的情况下，完成与从服务器的数据同步。\n要使用无须复制功能，只需把配置项 repl-diskless-sync 的值设置为 yes 即可，它默认配置值为 no。\n查询服务器的角色 我们使用 role 命令，来查询当前服务器的主从角色信息。\n主服务查看 在主服务器上执行 role 结果如下：\n1 2 3 4 5 6  127.0.0.1:6379\u0026gt; role 1) \u0026#34;master\u0026#34; 2) (integer) 546 3) 1) 1) \u0026#34;172.17.0.1\u0026#34; 2) \u0026#34;6379\u0026#34; 3) \u0026#34;546\u0026#34;   master 表示主服务器，底下是从服务器的 IP、端口和连接时间。\n从服务器查看 在从服务器执行 role 命令，执行结果如下：\n1 2 3 4 5 6  127.0.0.1:6379\u0026gt; role 1) \u0026#34;slave\u0026#34; 2) \u0026#34;192.168.1.71\u0026#34; 3) (integer) 6380 4) \u0026#34;connected\u0026#34; 5) (integer) 14   slave 表示从服务器，底下主服务器的 IP、端口和连接时间。\n关闭主从同步 我们可以使用 replicaof no one 命令来停止从服务器的复制，操作命令如下：\n1 2 3 4 5 6 7 8 9 10 11 12  127.0.0.1:6379\u0026gt; role #查询当前角色 1) \u0026#34;slave\u0026#34; #从服务器 2) \u0026#34;192.168.1.71\u0026#34; 3) (integer) 6380 4) \u0026#34;connected\u0026#34; 5) (integer) 14 127.0.0.1:6379\u0026gt; replicaof no one #关闭同步 OK 127.0.0.1:6379\u0026gt; role #查询当前角色 1) \u0026#34;master\u0026#34; #主服务器 2) (integer) 1097 3) (empty list or set)   可以看出执行了 replicaof no one 命令之后，自己就从服务器变成主服务器了。\n 小贴士：服务器类型的转换并不会影响数据，这台服务器的数据将会被保留。\n 注意事项 主从同步有一些需要注意的点，我们来看一下。\n数据一致性问题 当从服务器已经完成和主服务的数据同步之后，再新增的命令会以异步的方式发送至从服务器，在这个过程中主从同步会有短暂的数据不一致，如在这个异步同步发生之前主服务器宕机了，会造成数据不一致。\n从服务器只读性 默认在情况下，处于复制模式的主服务器既可以执行写操作也可以执行读操作，而从服务器则只能执行读操作。\n可以在从服务器上执行 config set replica-read-only no 命令，使从服务器开启写模式，但需要注意以下几点：\n 在从服务器上写的数据不会同步到主服务器； 当键值相同时主服务器上的数据可以覆盖从服务器； 在进行完整数据同步时，从服务器数据会被清空。  复制命令的变化 Redis 5.0 之前使用的复制命令是 slaveof，在 Redis 5.0 之后复制命令才被改为 replicaof，在高版本（Redis 5+）中我们应该尽量使用 replicaof，因为 slaveof 命令可能会被随时废弃掉。\n小结 本文我们了解了 Redis 多机运行的基础功能主从同步，主从同步可以通过 replicaof host port 命令开启，知道了同步的三种方式：完整数据同步（第一次全量 RDB 同步），部分数据同步（Redis 2.8 对于短时间离线的同步功能优化），无盘同步（非 RDB 生成的方式同步数据），我们也可以使用 replicaof no one 命令来停止从服务器的复制功能。\nRedis 哨兵模式 主从复制模式，它是属于 Redis 多机运行的基础，但这种模式本身存在一个致命的问题，当主节点奔溃之后，需要人工干预才能恢复 Redis 的正常使用。\n例如，我们有 3 台服务器做了主从复制，一个主服务器 A 和两个从服务器 B、C，当 A 发生故障之后，需要人工把 B 服务器设置为主服务器，同时再去 C 服务器设置成从服务器并且从主服务器 B 同步数据，如果是发生在晚上或者从服务器节点很多的情况下，对于人工来说想要立即实现恢复的难度很多，所以我们需要一个自动的工具——Redis Sentinel（哨兵模式）来把手动的过程变成自动的，让 Redis 拥有自动容灾恢复（failover）的能力。\n哨兵模式如下所示：\n 小贴士：Redis Sentinel 的最小分配单位是一主一从。\n Redis Sentinel 搭建 Redis 官方提供了 Redis Sentinel 的功能，它的运行程序保存在 src 目录下，如图所示：\n我们需要使用命令 ./src/redis-sentinel sentinel.conf 来启动 Sentinel，可以看出我们在启动它时必须设置一个 sentinel.conf 文件，这个配置文件中必须包含监听的主节点信息：\n1  sentinel monitor master-name ip port quorum   例如：\n1  sentinel monitor mymaster 127.0.0.1 6379 1   其中：\n master-name 表示给监视的主节点起一个名称； ip 表示主节点的 IP； port 表示主节点的端口； quorum 表示确认主节点下线的 Sentinel 数量，如果 quorum 设置为 1 表示只要有一台 Sentinel 判断它下线了，就可以确认它真的下线了。  注意：如果主节点 Redis 服务器有密码，还必须在 sentinel.conf 中添加主节点的密码，不然会导致 Sentinel 不能自动监听到主节点下面的从节点。\n所以如果 Redis 有密码，sentinel.conf 必须包含以下内容：\n1 2  sentinel monitor mymaster 127.0.0.1 6379 1 sentinel auth-pass mymaster pwd654321   当我们配置好 sentinel.conf 并执行启动命令 ./src/redis-sentinel sentinel.conf 之后，Redis Sentinel 就会被启动，如下图所示：\n从上图可以看出 Sentinel 只需配置监听主节点的信息，它会自动监听对应的从节点。\n启动 Sentinel 集群 上面我们演示了单个 Sentinel 的启动，但生产环境我们不会只启动一台 Sentinel，因为如果启动一台 Sentinel 假如它不幸宕机的话，就不能提供自动容灾的服务了，不符合我们高可用的宗旨，所以我们会在不同的物理机上启动多个 Sentinel 来组成 Sentinel 集群，来保证 Redis 服务的高可用。\n启动 Sentinel 集群的方法很简单，和上面启动单台的方式一样，我们只需要把多个 Sentinel 监听到一个主服务器节点，那么多个 Sentinel 就会自动发现彼此，并组成一个 Sentinel 集群。\n我们启动第二个 Sentinel 来试一下，执行结果如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  [@iZ2ze0nc5n41zomzyqtksmZ:redis2]$ ./src/redis-sentinel sentinel.conf 5547:X 19 Feb 2020 20:29:30.047 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo 5547:X 19 Feb 2020 20:29:30.047 # Redis version=5.0.5, bits=64, commit=00000000, modified=0, pid=5547, just started 5547:X 19 Feb 2020 20:29:30.047 # Configuration loaded _._ _.-``__ \u0026#39;\u0026#39;-._ _.-`` `. `_. \u0026#39;\u0026#39;-._ Redis 5.0.5 (00000000/0) 64 bit .-`` .-```. ```\\/ _.,_ \u0026#39;\u0026#39;-._ ( \u0026#39; , .-` | `, ) Running in sentinel mode |`-._`-...-` __...-.``-._|\u0026#39;` _.-\u0026#39;| Port: 26377 | `-._ `._ / _.-\u0026#39; | PID: 5547 `-._ `-._ `-./ _.-\u0026#39; _.-\u0026#39; |`-._`-._ `-.__.-\u0026#39; _.-\u0026#39;_.-\u0026#39;| | `-._`-._ _.-\u0026#39;_.-\u0026#39; | http://redis.io `-._ `-._`-.__.-\u0026#39;_.-\u0026#39; _.-\u0026#39; |`-._`-._ `-.__.-\u0026#39; _.-\u0026#39;_.-\u0026#39;| | `-._`-._ _.-\u0026#39;_.-\u0026#39; | `-._ `-._`-.__.-\u0026#39;_.-\u0026#39; _.-\u0026#39; `-._ `-.__.-\u0026#39; _.-\u0026#39; `-._ _.-\u0026#39; `-.__.-\u0026#39; 5547:X 19 Feb 2020 20:29:30.049 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128. 5547:X 19 Feb 2020 20:29:30.049 # Sentinel ID is 6455f2f74614a71ce0a63398b2e48d6cd1cf0d06 5547:X 19 Feb 2020 20:29:30.049 # +monitor master mymaster 127.0.0.1 6379 quorum 1 5547:X 19 Feb 2020 20:29:30.049 * +slave slave 127.0.0.1:6377 127.0.0.1 6377 @ mymaster 127.0.0.1 6379 5547:X 19 Feb 2020 20:29:30.052 * +slave slave 127.0.0.1:6378 127.0.0.1 6378 @ mymaster 127.0.0.1 6379 5547:X 19 Feb 2020 20:29:30.345 * +sentinel sentinel 6455f2f74614a71ce0a63398b2e48d6cd1cf0d08 127.0.0.1 26379 @ mymaster 127.0.0.1 6379   从以上启动命令可以看出，比单机模式多了最后一行发现其他 Sentinel 服务器的命令，说明这两个 Sentinel 已经组成一个集群了。\nSentinel 集群示意图如下：\n一般情况下 Sentinel 集群的数量取大于 1 的奇数，例如 3、5、7、9，而 quorum 的配置要根据 Sentinel 的数量来发生变化，例如 Sentinel 是 3 台，那么对应的 quorum 最好是 2，如果 Sentinel 是 5 台，那么 quorum 最好是 3，它表示当有 3 台 Sentinel 都确认主节点下线了，就可以确定主节点真的下线了。\n与 quorum 参数相关的有两个概念：主观下线和客观下线。\n当 Sentinel 集群中，有一个 Sentinel 认为主服务器已经下线时，它会将这个主服务器标记为主观下线（Subjectively Down，SDOWN），然后询问集群中的其他 Sentinel，是否也认为该服务器已下线，当同意主服务器已下线的 Sentinel 数量达到 quorum 参数所指定的数量时，Sentinel 就会将相应的主服务器标记为客观下线（Objectively down，ODOWN），然后开始对其进行故障转移。\n自动容灾测试 前面我们已经搭建了 Redis Sentinel，接下来我们就尝试一下自动容灾的功能，为了模拟故障我们先把主节点手动 kill 掉，执行命令如下：\n1 2 3 4 5 6 7 8 9 10  [@iZ2ze0nc5n41zomzyqtksmZ:~]$ ps -ef|grep redis #找到主节点的进程id root 5186 1 0 16:54 ? 00:00:23 ./src/redis-server *:6377 root 5200 1 0 16:56 ? 00:00:22 ./src/redis-server *:6378 root 5304 5287 0 17:31 pts/2 00:00:00 redis-cli -a pwd654321 root 5395 5255 0 18:26 pts/1 00:00:19 ./src/redis-sentinel *:26379 [sentinel] root 5547 5478 0 20:29 pts/4 00:00:02 ./src/redis-sentinel *:26377 [sentinel] root 5551 5517 0 20:29 pts/5 00:00:00 redis-cli -h 127.0.0.1 -p 26377 -a pwd654321 root 5568 5371 0 20:48 pts/0 00:00:00 grep --color=auto redis root 28517 1 0 Feb13 ? 00:15:33 ./src/redis-server *:6379 [@iZ2ze0nc5n41zomzyqtksmZ:~]$ kill -9 28517 #关闭主节点服务   这个时候我们在连接上另一台 Redis 服务器，查看当前主从服务器信息，执行命令如下：\n1 2 3 4 5 6 7  [@iZ2ze0nc5n41zomzyqtksmZ:~]$ redis-cli -h 127.0.0.1 -p 6377 -a pwd654321 2\u0026gt;/dev/null 127.0.0.1:6377\u0026gt; role 1) \u0026#34;master\u0026#34; 2) (integer) 770389 3) 1) 1) \u0026#34;127.0.0.1\u0026#34; 2) \u0026#34;6378\u0026#34; 3) \u0026#34;770389\u0026#34;   可以看出之前的从服务 6377 被提升为主服务器了，还剩下一台从服务 6378，而之前的主服务器 6379 被我们手动下线了，可以看出 Sentinel 已经完美的完成的它的故障自动转移的任务。\n主服务竞选规则 上面我们模拟了 Redis Sentinel 自动容灾恢复，那接下来我们来看一下，主服务器竞选的规则和相关设置项。\n新主节点竞选优先级设置 我们可以 redis.conf 中的 replica-priority 选项来设置竞选新主节点的优先级，它的默认值是 100，它的最大值也是 100，这个值越小它的权重就越高，例如从节点 A 的 replica-priority 值为 100，从节点 B 的值为 50，从节点 C 的值为 5，那么在竞选时从节点 C 会作为新的主节点。\n新主节点竞选规则 新主节点的竞选会排除不符合条件的从节点，然后再剩余的从节点按照优先级来挑选。首先来说，存在以下条件的从节点会被排除：\n 排除所有已经下线以及长时间没有回复心跳检测的疑似已下线从服务器； 排除所有长时间没有与主服务器通信，数据状态过时的从服务器； 排除所有优先级（replica-priority）为 0 的服务器。  符合条件的从节点竞选顺序：\n 优先级最高的从节点将会作为新主节点； 优先级相等则判断复制偏移量，偏移量最大的从节点获胜； 如果以上两个条件都相同，选择 Redis 运行时随机生成 ID 最小那个为新的主服务器。  旧主节点恢复上线 如果之前的旧主节点恢复上线，会作为从节点运行在主从服务器模式中。\n哨兵工作原理 哨兵的工作原理是这样的，首先每个 Sentinel 会以每秒钟 1 次的频率，向已知的主服务器、从服务器和以及其他 Sentinel 实例，发送一个 PING 命令。\n如果最后一次有效回复 PING 命令的时间超过 down-after-milliseconds 所配置的值（默认 30s），那么这个实例会被 Sentinel 标记为主观下线。\n如果一个主服务器被标记为主观下线，那么正在监视这个主服务器的所有 Sentinel 节点，要以每秒 1 次的频率确认 主服务器的确进入了主观下线状态。\n如果有足够数量（quorum 配置值）的 Sentinel 在指定的时间范围内同意这一判断，那么这个主服务器被标记为客观下线。此时所有的 Sentinel 会按照规则协商自动选出新的主节点。\n 注意：一个有效的 PING 回复可以是：+PONG、-LOADING 或者 -MASTERDOWN。如果返回值非以上三种回复，或者在指定时间内没有回复 PING 命令， 那么 Sentinel 认为服务器返回的回复无效（non-valid)。\n 小结 本文我们讲了主从模式的步骤，需要手动切换故障服务器的弊端，引出了 Sentinel 模式，可以实现监控和自动容灾，我们通过 Redis 提供的 Redis-Sentinel 来启动哨兵模式，当我们启动多个哨兵模式监视同一个主节点时，它们就会彼此发现形成一个新的高可用的 Sentinel 网络。同时我们讲了 Sentinel 的工作原理是通过 PING 命令来检查节点是否存活的，并通过配置项和复制偏移量 ID 来确定新主节点。\nRedis 集群模式 Redis Cluster 是 Redis 3.0 版本推出的 Redis 集群方案，它将数据分布在不同的服务区上，以此来降低系统对单主节点的依赖，并且可以大大的提高 Redis 服务的读写性能。\nRedis 将所有的数据分为 16384 个 slots（槽），每个节点负责其中的一部分槽位，当有 Redis 客户端连接集群时，会得到一份集群的槽位配置信息，这样它就可以直接把请求命令发送给对应的节点进行处理。\nRedis Cluster 是无代理模式去中心化的运行模式，客户端发送的绝大数命令会直接交给相关节点执行，这样大部分情况请求命令无需转发，或仅转发一次的情况下就能完成请求与响应，所以集群单个节点的性能与单机 Redis 服务器的性能是非常接近的，因此在理论情况下，当水平扩展一倍的主节点就相当于请求处理的性能也提高了一倍，所以 Redis Cluster 的性能是非常高的。\nRedis Cluster 架构图如下所示：\n搭建 Redis Cluster Redis Cluster 的搭建方式有两种，一种是使用 Redis 源码中提供的 create-cluster 工具快速的搭建 Redis 集群环境，另一种是配置文件的方式手动创建 Redis 集群环境。\n快速搭建 Redis Cluster create-cluster 工具在 utils/create-cluster 目录下，如下图所示：\n使用命令 ./create-cluster start 就可以急速创建一个 Redis 集群，执行如下：\n1 2 3 4 5 6 7  $ ./create-cluster start # 创建集群 Starting 30001 Starting 30002 Starting 30003 Starting 30004 Starting 30005 Starting 30006   接下来我们需要把以上创建的 6 个节点通过 create 命令组成一个集群，执行如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51  [@iZ2ze0nc5n41zomzyqtksmZ:create-cluster]$ ./create-cluster create # 组建集群 \u0026gt;\u0026gt;\u0026gt; Performing hash slots allocation on 6 nodes... Master[0] -\u0026gt; Slots 0 - 5460 Master[1] -\u0026gt; Slots 5461 - 10922 Master[2] -\u0026gt; Slots 10923 - 16383 Adding replica 127.0.0.1:30005 to 127.0.0.1:30001 Adding replica 127.0.0.1:30006 to 127.0.0.1:30002 Adding replica 127.0.0.1:30004 to 127.0.0.1:30003 \u0026gt;\u0026gt;\u0026gt; Trying to optimize slaves allocation for anti-affinity [WARNING] Some slaves are in the same host as their master M: 445f2a86fe36d397613839d8cc1ae6702c976593 127.0.0.1:30001 slots:[0-5460] (5461 slots) master M: 63bb14023c0bf58926738cbf857ea304bff8eb50 127.0.0.1:30002 slots:[5461-10922] (5462 slots) master M: 864d4dfe32e3e0b81a64cec8b393bbd26a65cbcc 127.0.0.1:30003 slots:[10923-16383] (5461 slots) master S: 64828ab44566fc5ad656e831fd33de87be1387a0 127.0.0.1:30004 replicates 445f2a86fe36d397613839d8cc1ae6702c976593 S: 0b17b00542706343583aa73149ec5ff63419f140 127.0.0.1:30005 replicates 63bb14023c0bf58926738cbf857ea304bff8eb50 S: e35f06ca9b700073472d72001a39ea4dfcb541cd 127.0.0.1:30006 replicates 864d4dfe32e3e0b81a64cec8b393bbd26a65cbcc Can I set the above configuration? (type \u0026#39;yes\u0026#39; to accept): yes \u0026gt;\u0026gt;\u0026gt; Nodes configuration updated \u0026gt;\u0026gt;\u0026gt; Assign a different config epoch to each node \u0026gt;\u0026gt;\u0026gt; Sending CLUSTER MEET messages to join the cluster Waiting for the cluster to join . \u0026gt;\u0026gt;\u0026gt; Performing Cluster Check (using node 127.0.0.1:30001) M: 445f2a86fe36d397613839d8cc1ae6702c976593 127.0.0.1:30001 slots:[0-5460] (5461 slots) master 1 additional replica(s) M: 864d4dfe32e3e0b81a64cec8b393bbd26a65cbcc 127.0.0.1:30003 slots:[10923-16383] (5461 slots) master 1 additional replica(s) S: e35f06ca9b700073472d72001a39ea4dfcb541cd 127.0.0.1:30006 slots: (0 slots) slave replicates 864d4dfe32e3e0b81a64cec8b393bbd26a65cbcc S: 0b17b00542706343583aa73149ec5ff63419f140 127.0.0.1:30005 slots: (0 slots) slave replicates 63bb14023c0bf58926738cbf857ea304bff8eb50 M: 63bb14023c0bf58926738cbf857ea304bff8eb50 127.0.0.1:30002 slots:[5461-10922] (5462 slots) master 1 additional replica(s) S: 64828ab44566fc5ad656e831fd33de87be1387a0 127.0.0.1:30004 slots: (0 slots) slave replicates 445f2a86fe36d397613839d8cc1ae6702c976593 [OK] All nodes agree about slots configuration. \u0026gt;\u0026gt;\u0026gt; Check for open slots... \u0026gt;\u0026gt;\u0026gt; Check slots coverage... [OK] All 16384 slots covered.   在执行的过程中会询问你是否通过把 30001、30002、30003 作为主节点，把 30004、30005、30006 作为它们的从节点，输入 yes 后会执行完成。\n我们可以先使用 redis-cli 连接到集群，命令如下：\n1  $ redis-cli -c -p 30001   在使用 nodes 命令来查看集群的节点信息，命令如下：\n1 2 3 4 5 6 7  127.0.0.1:30001\u0026gt; cluster nodes 864d4dfe32e3e0b81a64cec8b393bbd26a65cbcc 127.0.0.1:30003@40003 master - 0 1585125835078 3 connected 10923-16383 e35f06ca9b700073472d72001a39ea4dfcb541cd 127.0.0.1:30006@40006 slave 864d4dfe32e3e0b81a64cec8b393bbd26a65cbcc 0 1585125835078 6 connected 0b17b00542706343583aa73149ec5ff63419f140 127.0.0.1:30005@40005 slave 63bb14023c0bf58926738cbf857ea304bff8eb50 0 1585125835078 5 connected 63bb14023c0bf58926738cbf857ea304bff8eb50 127.0.0.1:30002@40002 master - 0 1585125834175 2 connected 5461-10922 445f2a86fe36d397613839d8cc1ae6702c976593 127.0.0.1:30001@40001 myself,master - 0 1585125835000 1 connected 0-5460 64828ab44566fc5ad656e831fd33de87be1387a0 127.0.0.1:30004@40004 slave 445f2a86fe36d397613839d8cc1ae6702c976593 0 1585125835000 4 connected   可以看出 30001、30002、30003 都为主节点，30001 对应的槽位是 0~5460，30002 对应的槽位是 5461~10922，30003 对应的槽位是 10923~16383，总共有槽位 16384 个（0~16383）。\ncreate-cluster 搭建的方式虽然速度很快，但是该方式搭建的集群主从节点数量固定以及槽位分配模式固定，并且安装在同一台服务器上，所以只能用于测试环境。\n我们测试完成之后，可以使用以下命令，关闭并清理集群：\n1 2 3 4 5 6 7 8  $ ./create-cluster stop # 关闭集群 Stopping 30001 Stopping 30002 Stopping 30003 Stopping 30004 Stopping 30005 Stopping 30006 $ ./create-cluster clean # 清理集群   手动搭建 Redis Cluster 由于 create-cluster 本身的限制，在实际生产环境中我们需要使用手动添加配置的方式搭建 Redis 集群，为此我们先要把 Redis 安装包复制到 node1 到 node6 文件中，因为我们要安装 6 个节点，3 主 3 从，如下图所示：\n接下来我们进行配置并启动 Redis 集群。\n1. 设置配置文件\n我们需要修改每个节点内的 redis.conf 文件，设置 cluster-enabled yes 表示开启集群模式，并且修改各自的端口，我们继续使用 30001 到 30006，通过 port 3000X 设置。\n2. 启动各个节点\nredis.conf 配置好之后，我们就可以启动所有的节点了，命令如下：\n1 2  cd /usr/local/soft/mycluster/node1 ./src/redis-server redis.conf   3. 创建集群并分配槽位\n之前我们已经启动了 6 个节点，但这些节点都在各自的集群之内并未互联互通，因此接下来我们需要把这些节点串连成一个集群，并为它们指定对应的槽位，执行命令如下：\n1  redis-cli --cluster create 127.0.0.1:30001 127.0.0.1:30002 127.0.0.1:30003 127.0.0.1:30004 127.0.0.1:30005 127.0.0.1:30006 --cluster-replicas 1   其中 create 后面跟多个节点，表示把这些节点作为整个集群的节点，而 cluster-replicas 表示给集群中的主节点指定从节点的数量，1 表示为每个主节点设置一个从节点。\n在执行了 create 命令之后，系统会为我们指定节点的角色和槽位分配计划，如下所示：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  \u0026gt;\u0026gt;\u0026gt; Performing hash slots allocation on 6 nodes... Master[0] -\u0026gt; Slots 0 - 5460 Master[1] -\u0026gt; Slots 5461 - 10922 Master[2] -\u0026gt; Slots 10923 - 16383 Adding replica 127.0.0.1:30005 to 127.0.0.1:30001 Adding replica 127.0.0.1:30006 to 127.0.0.1:30002 Adding replica 127.0.0.1:30004 to 127.0.0.1:30003 \u0026gt;\u0026gt;\u0026gt; Trying to optimize slaves allocation for anti-affinity [WARNING] Some slaves are in the same host as their master M: bdd1c913f87eacbdfeabc71befd0d06c913c891c 127.0.0.1:30001 slots:[0-5460] (5461 slots) master M: bdd1c913f87eacbdfeabc71befd0d06c913c891c 127.0.0.1:30002 slots:[5461-10922] (5462 slots) master M: bdd1c913f87eacbdfeabc71befd0d06c913c891c 127.0.0.1:30003 slots:[10923-16383] (5461 slots) master S: bdd1c913f87eacbdfeabc71befd0d06c913c891c 127.0.0.1:30004 replicates bdd1c913f87eacbdfeabc71befd0d06c913c891c S: bdd1c913f87eacbdfeabc71befd0d06c913c891c 127.0.0.1:30005 replicates bdd1c913f87eacbdfeabc71befd0d06c913c891c S: bdd1c913f87eacbdfeabc71befd0d06c913c891c 127.0.0.1:30006 replicates bdd1c913f87eacbdfeabc71befd0d06c913c891c Can I set the above configuration? (type \u0026#39;yes\u0026#39; to accept):   从以上信息可以看出，Redis 打算把 30001、30002、30003 设置为主节点，并为他们分配的槽位，30001 对应的槽位是 0~5460，30002 对应的槽位是 5461~10922，30003 对应的槽位是 10923~16383，并且把 30005 设置为 30001 的从节点、30006 设置为 30002 的从节点、30004 设置为 30003 的从节点，我们只需要输入 yes 即可确认并执行分配，如下所示：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  Can I set the above configuration? (type \u0026#39;yes\u0026#39; to accept): yes \u0026gt;\u0026gt;\u0026gt; Nodes configuration updated \u0026gt;\u0026gt;\u0026gt; Assign a different config epoch to each node \u0026gt;\u0026gt;\u0026gt; Sending CLUSTER MEET messages to join the cluster Waiting for the cluster to join .... \u0026gt;\u0026gt;\u0026gt; Performing Cluster Check (using node 127.0.0.1:30001) M: 887397e6fefe8ad19ea7569e99f5eb8a803e3785 127.0.0.1:30001 slots:[0-5460] (5461 slots) master 1 additional replica(s) S: abec9f98f9c01208ba77346959bc35e8e274b6a3 127.0.0.1:30005 slots: (0 slots) slave replicates 887397e6fefe8ad19ea7569e99f5eb8a803e3785 S: 1a324d828430f61be6eaca7eb2a90728dd5049de 127.0.0.1:30004 slots: (0 slots) slave replicates f5958382af41d4e1f5b0217c1413fe19f390b55f S: dc0702625743c48c75ea935c87813c4060547cef 127.0.0.1:30006 slots: (0 slots) slave replicates 3da35c40c43b457a113b539259f17e7ed616d13d M: 3da35c40c43b457a113b539259f17e7ed616d13d 127.0.0.1:30002 slots:[5461-10922] (5462 slots) master 1 additional replica(s) M: f5958382af41d4e1f5b0217c1413fe19f390b55f 127.0.0.1:30003 slots:[10923-16383] (5461 slots) master 1 additional replica(s) [OK] All nodes agree about slots configuration. \u0026gt;\u0026gt;\u0026gt; Check for open slots... \u0026gt;\u0026gt;\u0026gt; Check slots coverage... [OK] All 16384 slots covered.   显示 OK 表示整个集群就已经成功启动了。\n接下来，我们使用 redis-cli 连接并测试一下集群的运行状态，代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  $ redis-cli -c -p 30001 # 连接到集群 127.0.0.1:30001\u0026gt; cluster info # 查看集群信息 cluster_state:ok # 状态正常 cluster_slots_assigned:16384 # 槽位数 cluster_slots_ok:16384 # 正常的槽位数 cluster_slots_pfail:0 cluster_slots_fail:0 cluster_known_nodes:6 # 集群的节点数 cluster_size:3 # 集群主节点数 cluster_current_epoch:6 cluster_my_epoch:1 cluster_stats_messages_ping_sent:130 cluster_stats_messages_pong_sent:127 cluster_stats_messages_sent:257 cluster_stats_messages_ping_received:122 cluster_stats_messages_pong_received:130 cluster_stats_messages_meet_received:5 cluster_stats_messages_received:257   相关字段的说明已经标识在上述的代码中了，这里就不再赘述。\n动态增删节点 某些情况下，我们需要根据实际的业务情况，对已经在运行的集群进行动态的添加或删除节点，那我们就需要进行以下操作。\n增加主节点 添加方式一：cluster meet\n使用 cluster meet ip:port 命令就可以把一个节点加入到集群中，执行命令如下：\n1 2 3 4 5 6 7 8 9 10  127.0.0.1:30001\u0026gt; cluster meet 127.0.0.1 30007 OK 127.0.0.1:30001\u0026gt; cluster nodes dc0702625743c48c75ea935c87813c4060547cef 127.0.0.1:30006@40006 slave 3da35c40c43b457a113b539259f17e7ed616d13d 0 1585142916000 6 connected df0190853a53d8e078205d0e2fa56046f20362a7 127.0.0.1:30007@40007 master - 0 1585142917740 0 connected f5958382af41d4e1f5b0217c1413fe19f390b55f 127.0.0.1:30003@40003 master - 0 1585142916738 3 connected 10923-16383 3da35c40c43b457a113b539259f17e7ed616d13d 127.0.0.1:30002@40002 master - 0 1585142913000 2 connected 5461-10922 abec9f98f9c01208ba77346959bc35e8e274b6a3 127.0.0.1:30005@40005 slave 887397e6fefe8ad19ea7569e99f5eb8a803e3785 0 1585142917000 5 connected 887397e6fefe8ad19ea7569e99f5eb8a803e3785 127.0.0.1:30001@40001 myself,master - 0 1585142915000 1 connected 0-5460 1a324d828430f61be6eaca7eb2a90728dd5049de 127.0.0.1:30004@40004 slave f5958382af41d4e1f5b0217c1413fe19f390b55f 0 1585142916000 4 connected   可以看出端口为 30007 的节点并加入到集群中，并设置成了主节点。\n添加方式二：add-node\n使用 redis-cli --cluster add-node 添加节点ip:port 集群某节点ip:port 也可以把一个节点添加到集群中，执行命令如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  $ redis-cli --cluster add-node 127.0.0.1:30008 127.0.0.1:30001 \u0026gt;\u0026gt;\u0026gt; Adding node 127.0.0.1:30008 to cluster 127.0.0.1:30001 \u0026gt;\u0026gt;\u0026gt; Performing Cluster Check (using node 127.0.0.1:30001) M: 887397e6fefe8ad19ea7569e99f5eb8a803e3785 127.0.0.1:30001 slots:[0-5460] (5461 slots) master 1 additional replica(s) S: dc0702625743c48c75ea935c87813c4060547cef 127.0.0.1:30006 slots: (0 slots) slave replicates 3da35c40c43b457a113b539259f17e7ed616d13d M: df0190853a53d8e078205d0e2fa56046f20362a7 127.0.0.1:30007 slots: (0 slots) master M: f5958382af41d4e1f5b0217c1413fe19f390b55f 127.0.0.1:30003 slots:[10923-16383] (5461 slots) master 1 additional replica(s) M: 1d09d26fd755298709efe60278457eaa09cefc26 127.0.0.1:30008 slots: (0 slots) master M: 3da35c40c43b457a113b539259f17e7ed616d13d 127.0.0.1:30002 slots:[5461-10922] (5462 slots) master 1 additional replica(s) S: abec9f98f9c01208ba77346959bc35e8e274b6a3 127.0.0.1:30005 slots: (0 slots) slave replicates 887397e6fefe8ad19ea7569e99f5eb8a803e3785 S: 1a324d828430f61be6eaca7eb2a90728dd5049de 127.0.0.1:30004 slots: (0 slots) slave replicates f5958382af41d4e1f5b0217c1413fe19f390b55f [OK] All nodes agree about slots configuration. \u0026gt;\u0026gt;\u0026gt; Check for open slots... \u0026gt;\u0026gt;\u0026gt; Check slots coverage... [OK] All 16384 slots covered. [ERR] Node 127.0.0.1:30008 is not empty. Either the node already knows other nodes (check with CLUSTER NODES) or contains some key in database 0.   从以上结果可以看出 30008 节点也被设置成了主节点。\n添加从节点 使用 cluster replicate nodeId 命令就可以把当前节点设置为目标节点的从节点，执行命令如下：\n1 2 3 4 5 6 7 8 9 10 11  127.0.0.1:30008\u0026gt; cluster replicate df0190853a53d8e078205d0e2fa56046f20362a7 OK 127.0.0.1:30008\u0026gt; cluster nodes df0190853a53d8e078205d0e2fa56046f20362a7 127.0.0.1:30007@40007 master - 0 1585147827000 0 connected abec9f98f9c01208ba77346959bc35e8e274b6a3 127.0.0.1:30005@40005 slave 887397e6fefe8ad19ea7569e99f5eb8a803e3785 0 1585147827000 1 connected 1a324d828430f61be6eaca7eb2a90728dd5049de 127.0.0.1:30004@40004 slave f5958382af41d4e1f5b0217c1413fe19f390b55f 0 1585147823000 3 connected 887397e6fefe8ad19ea7569e99f5eb8a803e3785 127.0.0.1:30001@40001 master - 0 1585147826000 1 connected 0-5460 dc0702625743c48c75ea935c87813c4060547cef 127.0.0.1:30006@40006 slave 3da35c40c43b457a113b539259f17e7ed616d13d 0 1585147826930 2 connected f5958382af41d4e1f5b0217c1413fe19f390b55f 127.0.0.1:30003@40003 master - 0 1585147826000 3 connected 10923-16383 1d09d26fd755298709efe60278457eaa09cefc26 127.0.0.1:30008@40008 myself,slave df0190853a53d8e078205d0e2fa56046f20362a7 0 1585147823000 7 connected 3da35c40c43b457a113b539259f17e7ed616d13d 127.0.0.1:30002@40002 master - 0 1585147827933 2 connected 5461-10922   可以看出 30008 已经变为 30007 的从节点了。\n删除节点 使用 cluster forget nodeId 命令就可以把一个节点从集群中移除。\n此命令和 meet 命令不同的时，删除节点需要把使用节点的 Id 进行删除，可以通过 cluster nodes 命令查看所有节点的 Id 信息，其中每一行的最前面的 40 位字母和数组的组合就是该节点的 Id，如下图所示：\n执行命令如下：\n1 2  127.0.0.1:30001\u0026gt; cluster forget df0190853a53d8e078205d0e2fa56046f20362a7 OK   此时我们使用 cluster nodes 命令查看集群的所有节点信息：\n1 2 3 4 5 6 7  127.0.0.1:30001\u0026gt; cluster nodes dc0702625743c48c75ea935c87813c4060547cef 127.0.0.1:30006@40006 slave 3da35c40c43b457a113b539259f17e7ed616d13d 0 1585143789940 6 connected f5958382af41d4e1f5b0217c1413fe19f390b55f 127.0.0.1:30003@40003 master - 0 1585143791000 3 connected 10923-16383 3da35c40c43b457a113b539259f17e7ed616d13d 127.0.0.1:30002@40002 master - 0 1585143789000 2 connected 5461-10922 abec9f98f9c01208ba77346959bc35e8e274b6a3 127.0.0.1:30005@40005 slave 887397e6fefe8ad19ea7569e99f5eb8a803e3785 0 1585143789000 5 connected 887397e6fefe8ad19ea7569e99f5eb8a803e3785 127.0.0.1:30001@40001 myself,master - 0 1585143786000 1 connected 0-5460 1a324d828430f61be6eaca7eb2a90728dd5049de 127.0.0.1:30004@40004 slave f5958382af41d4e1f5b0217c1413fe19f390b55f 0 1585143791945 4 connected   可以看出之前的端口为 30007 的节点已经被我们成功的移除了。\n小结 本文讲了 Redis 集群的两种搭建方式：create-cluster start 和 cluster create，前一种方式虽然速度比较快，但它只能创建数量固定的主从节点，并且所有节点都在同一台服务器上，因此只能用于测试环境。我们还讲了 Redis 集群动态添加主、从节点和删除任意节点的功能。\n","date":"2021-09-26T13:36:41Z","image":"https://ahao.ink/24.jpg","permalink":"https://ahao.ink/posts/redis-%E9%AB%98%E5%8F%AF%E7%94%A8%E6%96%B9%E5%BC%8F/","title":"Redis 高可用方式"},{"content":"Redis 发展到现在已经有 9 种数据类型了，其中最基础、最常用的数据类型有 5 种，它们分别是：字符串类型、哈希表类型、列表类型、集合类型、有序集合类型，而在这 5 种数据类型中最常用的是字符串类型，所以我们先从字符串的使用开始说起。\n字符串类型的全称是 Simple Dynamic Strings 简称 SDS，中文意思是：简单动态字符串。它是以键值对 key-value 的形式进行存储的，根据 key 来存储和获取 value 值，它的使用相对来说比较简单，但在实际项目中应用非常广泛。\n字符串使用与内部实现原理 字符串类型能做什么？ 字符串类型的使用场景有很多，但从功能的角度来区分，大致可分为以下两种：\n 字符串存储和操作； 整数类型和浮点类型的存储和计算。  字符串最常用的业务场景有以下几个。\n页面数据缓存 我们知道，一个系统最宝贵的资源就是数据库资源，随着公司业务的发展壮大，数据库的存储量也会越来越大，并且要处理的请求也越来越多，当数据量和并发量到达一定级别之后，数据库就变成了拖慢系统运行的“罪魁祸首”，为了避免这种情况的发生，我们可以把查询结果放入缓存(Redis)中，让下次同样的查询直接去缓存系统取结果，而非查询数据库，这样既减少了数据库的压力，同时也提高了程序的运行速度。\n介于以上这个思路，我们可以把文章详情页的数据放入缓存系统。具体的做法是先将文章详情页序列化为字符串存入缓存，再从缓存中读取到字符串，反序列化成对象，然后再赋值到页面进行显示 (当然也可以用哈希类型进行存储，这会在下一篇文章中讲到)，这样我们就实现了文章详情页的缓存功能，架构流程对比图如下所示。\n原始系统运行流程图：\n引入缓存系统后的流程图：\n数字计算与统计 Redis 可以用来存储整数和浮点类型的数据，并且可以通过命令直接累加并存储整数信息，这样就省去了每次先要取数据、转换数据、拼加数据、再存入数据的麻烦，只需要使用一个命令就可以完成此流程，具体实现过程本文下半部分会讲。这样我们就可以使用此功能来实现访问量的统计，当有人访问时访问量 +1 就可以了。\n共享 Session 信息 通常我们在开发后台管理系统时，会使用 Session 来保存用户的会话(登录)状态，这些 Session 信息会被保存在服务器端，但这只适用于单系统应用，如果是分布式系统此模式将不再适用。\n例如用户一的 Session 信息被存储在服务器一，但第二次访问时用户一被分配到服务器二，这个时候服务器并没有用户一的 Session 信息，就会出现需要重复登录的问题。分布式系统每次会把请求随机分配到不同的服务器，因此我们需要借助缓存系统对这些 Session 信息进行统一的存储和管理，这样无论请求发送到那台服务器，服务器都会去统一的缓存系统获取相关的 Session 信息，这样就解决了分布式系统下 Session 存储的问题。\n分布式系统单独存储 Session 流程图：\n分布式系统使用同一的缓存系统存储 Session 流程图：\n字符串如何使用？ 通常我们会使用两种方式来操作 Redis：第一种是使用命令行来操作，例如 redis-cli；另一种是使用代码的方式来操作，下面我们分别来看。\n命令行操作方式 字符串的操作命令有很多，但大体可分为以下几类：\n 单个键值对操作 多个键值对操作 数字统计  我们本文使用 redis-cli 来实现对 Redis 的操作，在使用命令之前，先输入 redis-cli 来链接到 Redis 服务器。\n单个键值对操作 添加键值对 语法：set key value [expiration EX seconds|PX milliseconds] [NX|XX] 示例：\n1 2  127.0.0.1:6379\u0026gt; set k1 val1 OK   获取键值对 语法：get key 示例：\n1 2  127.0.0.1:6379\u0026gt; get k1 \u0026#34;val1\u0026#34;   给元素追加值 语法：append key value 示例：\n1 2 3 4 5 6  127.0.0.1:6379\u0026gt; get k1 \u0026#34;v1\u0026#34; 127.0.0.1:6379\u0026gt; append k1 append (integer) 5 127.0.0.1:6379\u0026gt; get k1 \u0026#34;v1append\u0026#34;   查询字符串的长度 语法：strlen key 示例：\n1 2  127.0.0.1:6379\u0026gt; strlen k1 (integer) 5   多个键值对操作 创建一个或多个键值对 语法：mset key value [key value …] 示例：\n1 2  127.0.0.1:6379\u0026gt; mset k2 v2 k3 v3 OK    小贴士：mset 是一个原子性(atomic)操作，所有给定 key 都会在同一时间内被设置，不会出现某些 key 被更新，而另一些 key 没被更新的情况。\n 查询一个或多个元素 语法：mget key [key …] 示例：\n1 2 3  127.0.0.1:6379\u0026gt; mget k2 k3 1) \u0026#34;v2\u0026#34; 2) \u0026#34;v3\u0026#34;   数字统计 在 Redis 中可以直接操作整型和浮点型，例如可以直接使用命令来加、减值。\n给整数类型的值加 1 语法：incr key 示例：\n1 2 3 4 5 6  127.0.0.1:6379\u0026gt; get k1 \u0026#34;3\u0026#34; 127.0.0.1:6379\u0026gt; incr k1 (integer) 4 127.0.0.1:6379\u0026gt; get k1 \u0026#34;4\u0026#34;   给整数类型的值减 1 语法：decr key 示例：\n1 2 3 4 5 6  127.0.0.1:6379\u0026gt; get k1 \u0026#34;4\u0026#34; 127.0.0.1:6379\u0026gt; decr k1 (integer) 3 127.0.0.1:6379\u0026gt; get k1 \u0026#34;3\u0026#34;   根据 key 减去指定的值 语法：decrby key decrement 示例：\n1 2 3 4 5 6  127.0.0.1:6379\u0026gt; get k1 \u0026#34;3\u0026#34; 127.0.0.1:6379\u0026gt; decrby k1 2 (integer) 1 127.0.0.1:6379\u0026gt; get k1 \u0026#34;1\u0026#34;   如果 key 不存在，则会先初始化此 key 为 0 ，然后再执行减法操作：\n1 2 3 4 5 6  127.0.0.1:6379\u0026gt; get k2 (nil) 127.0.0.1:6379\u0026gt; decrby k2 3 (integer) -3 127.0.0.1:6379\u0026gt; get k2 \u0026#34;-3\u0026#34;   根据 key 加指定的整数值 语法：incrby key increment 示例：\n1 2 3 4 5 6  127.0.0.1:6379\u0026gt; get k1 \u0026#34;1\u0026#34; 127.0.0.1:6379\u0026gt; incrby k1 2 (integer) 3 127.0.0.1:6379\u0026gt; get k1 \u0026#34;3\u0026#34;   如果 key 不存在，则会先初始化此 key 为 0 ，然后再执行加整数值的操作：\n1 2 3 4 5 6  127.0.0.1:6379\u0026gt; get k3 (nil) 127.0.0.1:6379\u0026gt; incrby k3 5 (integer) 5 127.0.0.1:6379\u0026gt; get k3 \u0026#34;5\u0026#34;   根据 key 加上指定的浮点数 语法：incrbyfloat key increment 示例：\n1 2 3 4 5 6  127.0.0.1:6379\u0026gt; get k3 \u0026#34;5\u0026#34; 127.0.0.1:6379\u0026gt; incrbyfloat k3 4.9 \u0026#34;9.9\u0026#34; 127.0.0.1:6379\u0026gt; get k3 \u0026#34;9.9\u0026#34;   如果 key 不存在，则会先初始化此 key 为 0 ，然后再执行加浮点数的操作：\n1 2 3 4 5 6  127.0.0.1:6379\u0026gt; get k4 (nil) 127.0.0.1:6379\u0026gt; incrbyfloat k4 4.4 \u0026#34;4.4\u0026#34; 127.0.0.1:6379\u0026gt; get k4 \u0026#34;4.4\u0026#34;   代码操作方式 本文我们使用 Java 语言来实现对 Redis 的操作，首先我们在项目中添加对 Jedis 框架的引用，如果是 Maven 项目，我们会在 pom.xml 文件中添加如下信息：\n1 2 3 4 5  \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;redis.clients\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jedis\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt;   Jedis 是 Redis 官方推荐的 Java 客户端开发包，用于实现快速简单的操作 Redis。添加完 Jedis 之后，我们来写具体的操作代码，操作函数与命令方式的调用比较相似，如下代码所示：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36  import redis.clients.jedis.Jedis; import java.util.List; public class StringExample { public static void main(String[] args) { Jedis jedis = new Jedis(\u0026#34;127.0.0.1\u0026#34;, 6379); // jedis.auth(\u0026#34;xxx\u0026#34;); // 输入密码，没有密码，可以不设置  // 添加一个元素  jedis.set(\u0026#34;mystr\u0026#34;, \u0026#34;redis\u0026#34;); // 获取元素  String myStr = jedis.get(\u0026#34;mystr\u0026#34;); System.out.println(myStr); // 输出：redis  // 添加多个元素(key,value,key2,value2)  jedis.mset(\u0026#34;db\u0026#34;, \u0026#34;redis\u0026#34;, \u0026#34;lang\u0026#34;, \u0026#34;java\u0026#34;); // 获取多个元素  List\u0026lt;String\u0026gt; mlist = jedis.mget(\u0026#34;db\u0026#34;, \u0026#34;lang\u0026#34;); System.out.println(mlist); // 输出：[redis, java]  // 给元素追加字符串  jedis.append(\u0026#34;db\u0026#34;, \u0026#34;,mysql\u0026#34;); // 打印追加的字符串  System.out.println(jedis.get(\u0026#34;db\u0026#34;)); // 输出：redis,mysql  // 当 key 不存在时，赋值键值  Long setnx = jedis.setnx(\u0026#34;db\u0026#34;, \u0026#34;db2\u0026#34;); // 因为 db 元素已经存在，所以会返回 0 条修改  System.out.println(setnx); // 输出：0  // 字符串截取  String range = jedis.getrange(\u0026#34;db\u0026#34;, 0, 2); System.out.println(range); // 输出：red  // 添加键值并设置过期时间(单位：毫秒)  String setex = jedis.setex(\u0026#34;db\u0026#34;, 1000, \u0026#34;redis\u0026#34;); System.out.println(setex); // 输出：ok  // 查询键值的过期时间  Long ttl = jedis.ttl(\u0026#34;db\u0026#34;); System.out.println(ttl); // 输出：1000  } }   代码实战 本文的上半部分我们讲到了字符串的很多种使用场景，本小节就以字符串存储用户对象信息为例，我们先将用户对象信息序列化为字符串存储在 Redis，再从 Redis 中取出字符串并反序列化为对象信息为例，使用 Java 语言来实现。\n首先添加 JSON 转换类，用于对象和字符串之间的序列化和反序列化，我们这里采用 Google 的 Gson 来实现，首先在 pom.xml 文件中添加如下引用：\n1 2 3 4 5 6  \u0026lt;!-- https://mvnrepository.com/artifact/com.google.code.gson/gson --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.google.code.gson\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;gson\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.8.6\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt;   添加完 Gson 引用之后，我们来写具体的业务代码，先见用户信息序列化之后存储在 Redis 中：\n1 2 3 4 5 6 7 8 9 10 11 12 13  Jedis jedis = new Jedis(\u0026#34;xxx.xxx.xxx.xxx\u0026#34;, 6379); jedis.auth(\u0026#34;xxx\u0026#34;); Gson gson = new Gson(); // 构建用户数据 User user = new User(); user.setId(1); user.setName(\u0026#34;Redis\u0026#34;); user.setAge(10); String jsonUser = gson.toJson(user); // 打印用户信息(json) System.out.println(jsonUser); // 输出：{\u0026#34;id\u0026#34;:1,\u0026#34;name\u0026#34;:\u0026#34;Redis\u0026#34;,\u0026#34;age\u0026#34;:10} // 把字符串存入 Redis jedis.set(\u0026#34;user\u0026#34;, jsonUser);   当使用用户信息时，我们从 Redis 反序列化出来，代码如下：\n1 2 3 4  String getUserData = jedis.get(\u0026#34;user\u0026#34;); User userData = gson.fromJson(getUserData, User.class); // 打印对象属性信息 System.out.println(userData.getId() + \u0026#34;:\u0026#34; + userData.getName()); // 输出结果：1:Redis   以上两个步骤就完成了用户信息存放至 Redis 中的过程，也是常用的经典使用场景之一。\n字符串的内部实现 源码分析 Redis 3.2 之前 SDS 源码如下：\n1 2 3 4 5  struct sds{ int len; // 已占用的字节数  int free; // 剩余可以字节数  char buf[]; // 存储字符串的数据空间 }   可以看出 Redis 3.2 之前 SDS 内部是一个带有长度信息的字节数组，存储结构如下图所示：\n为了更加有效的利用内存，Redis 3.2 优化了 SDS 的存储结构，源码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  typedef char *sds; struct __attribute__ ((__packed__)) sdshdr5 { // 对应的字符串长度小于 1\u0026lt;\u0026lt;5  unsigned char flags; char buf[]; }; struct __attribute__ ((__packed__)) sdshdr8 { // 对应的字符串长度小于 1\u0026lt;\u0026lt;8  uint8_t len; /* 已使用长度，1 字节存储 */ uint8_t alloc; /* 总长度 */ unsigned char flags; char buf[]; // 真正存储字符串的数据空间 }; struct __attribute__ ((__packed__)) sdshdr16 { // 对应的字符串长度小于 1\u0026lt;\u0026lt;16  uint16_t len; /* 已使用长度，2 字节存储 */ uint16_t alloc; unsigned char flags; char buf[]; }; struct __attribute__ ((__packed__)) sdshdr32 { // 对应的字符串长度小于 1\u0026lt;\u0026lt;32  uint32_t len; /* 已使用长度，4 字节存储 */ uint32_t alloc; unsigned char flags; char buf[]; }; struct __attribute__ ((__packed__)) sdshdr64 { // 对应的字符串长度小于 1\u0026lt;\u0026lt;64  uint64_t len; /* 已使用长度，8 字节存储 */ uint64_t alloc; unsigned char flags; char buf[]; };   这样就可以针对不同长度的字符串申请相应的存储类型，从而有效的节约了内存使用。\n数据类型 我们可以使用 object encoding key 命令来查看对象(键值对)存储的数据类型，当我们使用此命令来查询 SDS 对象时，发现 SDS 对象竟然包含了三种不同的数据类型：int、embstr 和 raw。\nint 类型 1 2 3 4  127.0.0.1:6379\u0026gt; set key 666 OK 127.0.0.1:6379\u0026gt; object encoding key \u0026#34;int\u0026#34;   embstr 类型 1 2 3 4  127.0.0.1:6379\u0026gt; set key abc OK 127.0.0.1:6379\u0026gt; object encoding key \u0026#34;embstr\u0026#34;   raw 类型 1 2 3 4  127.0.0.1:6379\u0026gt; set key abcdefghigklmnopqrstyvwxyzabcdefghigklmnopqrs OK 127.0.0.1:6379\u0026gt; object encoding key \u0026#34;raw\u0026#34;   int 类型很好理解，整数类型对应的就是 int 类型，而字符串则对应是 embstr 类型，当字符串长度大于 44 字节时，会变为 raw 类型存储。\n为什么是 44 字节？ 在 Redis 中，如果 SDS 的存储值大于 64 字节时，Redis 的内存分配器会认为此对象为大字符串，并使用 raw 类型来存储，当数据小于 64 字节时(字符串类型)，会使用 embstr 类型存储。既然内存分配器的判断标准是 64 字节，那为什么 embstr 类型和 raw 类型的存储判断值是 44 字节？\n这是因为 Redis 在存储对象时，会创建此对象的关联信息，redisObject 对象头和 SDS 自身属性信息，这些信息都会占用一定的存储空间，因此长度判断标准就从 64 字节变成了 44 字节。\n在 Redis 中，所有的对象都会包含 redisObject 对象头。我们先来看 redisObject 对象的源码：\n1 2 3 4 5 6 7  typedef struct redisObject { unsigned type:4; // 4 bit  unsigned encoding:4; // 4 bit  unsigned lru:LRU_BITS; // 3 个字节  int refcount; // 4 个字节  void *ptr; // 8 个字节 } robj;   它的参数说明如下：\n type：对象的数据类型，例如：string、list、hash 等，占用 4 bits 也就是半个字符的大小； encoding：对象数据编码，占用 4 bits； lru：记录对象的 LRU(Least Recently Used 的缩写，即最近最少使用)信息，内存回收时会用到此属性，占用 24 bits(3 字节)； refcount：引用计数器，占用 32 bits(4 字节)； *ptr：对象指针用于指向具体的内容，占用 64 bits(8 字节)。  redisObject 总共占用 0.5 bytes + 0.5 bytes + 3 bytes + 4 bytes + 8 bytes = 16 bytes(字节)。\n了解了 redisObject 之后，我们再来看 SDS 自身的数据结构，从 SDS 的源码可以看出，SDS 的存储类型一共有 5 种：SDSTYPE5、SDSTYPE8、SDSTYPE16、SDSTYPE32、SDSTYPE64，在这些类型中最小的存储类型为 SDSTYPE５，但 SDSTYPE５ 类型会默认转成 SDSTYPE8，以下源码可以证明，如下图所示：那我们直接来看 SDSTYPE8 的源码：\n1 2 3 4 5 6  struct __attribute__ ((__packed__)) sdshdr8 { uint8_t len; // 1 byte  uint8_t alloc; // 1 byte  unsigned char flags; // 1 byte  char buf[]; };   可以看出除了内容数组(buf)之外，其他三个属性分别占用了 1 个字节，最终分隔字符等于 64 字节，减去 redisObject 的 16 个字节，再减去 SDS 自身的 3 个字节，再减去结束符 \\0 结束符占用 1 个字节，最终的结果是 44 字节(64-16-3-1=44)，内存占用如下图所示：\n小结 本文介绍了字符串的定义及其使用，它的使用主要分为：单键值对操作、多键值对操作、数字统计、键值对过期操作、字符串操作进阶等。同时也介绍了字符串使用的三个场景，字符串类型可用作为：页面数据缓存，可以缓存一些文章详情信息等；数字计算与统计，例如计算页面的访问次数；也可以用作 Session 共享，用来记录管理员的登录信息等。同时我们深入的介绍了字符串的五种数据存储结构，以及字符串的三种内部数据类型，如下图所示：\n同时我们也知道了 embstr 类型向 raw 类型转化，是因为每个 Redis 对象都包含了一个 redisObject 对象头和 SDS 自身属性占用了一定的空间，最终导致数据类型的判断长度是 44 字节。\n哈希表使用与内部实现原理 字典类型 (Hash) 又被成为散列类型或者是哈希表类型，它是将一个键值 (key) 和一个特殊的“哈希表”关联起来，这个“哈希表”表包含两列数据：字段和值。例如我们使用字典类型来存储一篇文章的详情信息，存储结构如下图所示：\n同理我们也可以使用字典类型来存储用户信息，并且使用字典类型来存储此类信息，是不需要手动序列化和反序列化数据的，所以使用起来更加的方便和高效。\n基础使用 首先我们使用命令行工具 redis-cli，来对字典类型进行相关的操作。\n插入单个元素 语法：hset key field value 示例：\n1 2 3 4  127.0.0.1:6379\u0026gt; hset myhash key1 value1 (integer) 1 127.0.0.1:6379\u0026gt; hset myhash key2 value2 (integer) 1   当某键不存在时，插入数据 语法：hsetnx key field value 示例：\n1 2 3 4  127.0.0.1:6379\u0026gt; hsetnx myhash k4 v4 (integer) 1 127.0.0.1:6379\u0026gt; hget myhash k4 \u0026#34;v4\u0026#34;   如果尝试插入已存在的键，不会改变原来的值，示例如下：\n1 2 3 4  127.0.0.1:6379\u0026gt; hsetnx myhash k4 val4 (integer) 0 127.0.0.1:6379\u0026gt; hget myhash k4 \u0026#34;v4\u0026#34;   尝试修改已经存在的 k4 赋值为 val4，但并没有生效，查询 k4 的结果依然是原来的值 v4。\n查询单个元素 语法：hget key field 示例：\n1 2  127.0.0.1:6379\u0026gt; hget myhash key1 \u0026#34;value1\u0026#34;   删除 key 中的一个或多个元素 语法：hdel myhash field [field \u0026hellip;] 示例：\n1 2  127.0.0.1:6379\u0026gt; hdel myhash key1 key2 (integer) 1   注意：不能使用类似于 hdel myhash 的命令删除整个 Hash 值的。\n某个整数值累加计算 语法：hincrby key field increment 示例：\n1 2 3 4 5 6  127.0.0.1:6379\u0026gt; hset myhash k3 3 (integer) 1 127.0.0.1:6379\u0026gt; hincrby myhash k3 2 (integer) 5 127.0.0.1:6379\u0026gt; hget myhash k3 \u0026#34;5\u0026#34;   代码实战 接下来我们用 Java 代码实现对 Redis 的操作，同样我们先引入 Jedis 框架 ，接下来再用代码来对字典类型进行操作，示例代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  import redis.clients.jedis.Jedis; import java.util.Map; public class HashExample { public static void main(String[] args) throws InterruptedException { Jedis jedis = new Jedis(\u0026#34;127.0.0.1\u0026#34;, 6379); // 把 Key 值定义为变量  final String REDISKEY = \u0026#34;myhash\u0026#34;; // 插入单个元素  jedis.hset(REDISKEY, \u0026#34;key1\u0026#34;, \u0026#34;value1\u0026#34;); // 查询单个元素  Map\u0026lt;String, String\u0026gt; singleMap = jedis.hgetAll(REDISKEY); System.out.println(singleMap.get(\u0026#34;key1\u0026#34;)); // 输出：value1  // 查询所有元素  Map\u0026lt;String, String\u0026gt; allMap = jedis.hgetAll(REDISKEY); System.out.println(allMap.get(\u0026#34;k2\u0026#34;)); // 输出：val2  System.out.println(allMap); // 输出：{key1=value1, k1=val1, k2=val2, k3=9.2, k4=v4...}  // 删除单个元素  Long delResult = jedis.hdel(REDISKEY, \u0026#34;key1\u0026#34;); System.out.println(\u0026#34;删除结果：\u0026#34; + delResult); // 输出：删除结果：1  // 查询单个元素  System.out.println(jedis.hget(REDISKEY, \u0026#34;key1\u0026#34;)); // 输出：返回 null  } }   从代码中可以看出，在 Jedis 中我们可以直接使用 Map 来接收 Redis 中读取的字典类型的数据，省去了手动转化的麻烦，还是比较方便的。\n数据结构 字典类型本质上是由数组和链表结构组成的，来看字典类型的源码实现：\n1 2 3 4 5 6 7 8 9 10  typedef struct dictEntry { // dict.h  void *key; union { void *val; uint64_t u64; int64_t s64; double d; } v; struct dictEntry *next; // 下一个 entry } dictEntry;   字典类型的数据结构，如下图所示：\n通常情况下字典类型会使用数组的方式来存储相关的数据，但发生哈希冲突时才会使用链表的结构来存储数据。\n哈希冲突 字典类型的存储流程是先将键值进行 Hash 计算，得到存储键值对应的数组索引，再根据数组索引进行数据存储，但在小概率事件下可能会出完全不相同的键值进行 Hash 计算之后，得到相同的 Hash 值，这种情况我们称之为哈希冲突。\n哈希冲突一般通过链表的形式解决，相同的哈希值会对应一个链表结构，每次有哈希冲突时，就把新的元素插入到链表的尾部，请参考上面数据结构的那张图。\n键值查询的流程如下：\n 通过算法 (Hash，计算和取余等) 操作获得数组的索引值，根据索引值找到对应的元素； 判断元素和查找的键值是否相等，相等则成功返回数据，否则需要查看 next 指针是否还有对应其他元素，如果没有，则返回 null，如果有的话，重复此步骤。  键值查询流程，如下图所示：\n渐进式rehash Redis 为了保证应用的高性能运行，提供了一个重要的机制——渐进式 rehash。 渐进式 rehash 是用来保证字典缩放效率的，也就是说在字典进行扩容或者缩容是会采取渐进式 rehash 的机制。\n扩容 当元素数量等于数组长度时就会进行扩容操作，源码在 dict.c 文件中，核心代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  int dictExpand(dict *d, unsigned long size) { /* 需要的容量小于当前容量，则不需要扩容 */ if (dictIsRehashing(d) || d-\u0026gt;ht[0].used \u0026gt; size) return DICT_ERR; dictht n; unsigned long realsize = _dictNextPower(size); // 重新计算扩容后的值  /* 计算新的扩容大小等于当前容量，不需要扩容 */ if (realsize == d-\u0026gt;ht[0].size) return DICT_ERR; /* 分配一个新的哈希表，并将所有指针初始化为NULL */ n.size = realsize; n.sizemask = realsize-1; n.table = zcalloc(realsize*sizeof(dictEntry*)); n.used = 0; if (d-\u0026gt;ht[0].table == NULL) { // 第一次初始化  d-\u0026gt;ht[0] = n; return DICT_OK; } d-\u0026gt;ht[1] = n; // 把增量输入放入新 ht[1] 中  d-\u0026gt;rehashidx = 0; // 非默认值 -1，表示需要进行 rehash  return DICT_OK; }   从以上源码可以看出，如果需要扩容则会申请一个新的内存地址赋值给 ht[1]，并把字典的 rehashindex 设置为 0，表示之后需要进行 rehash 操作。\n缩容 当字典的使用容量不足总空间的 10% 时就会触发缩容，Redis 在进行缩容时也会把 rehashindex 设置为 0，表示之后需要进行 rehash 操作。\n渐进式rehash流程 在进行渐进式 rehash 时，会同时保留两个 hash 结构，新键值对加入时会直接插入到新的 hash 结构中，并会把旧 hash 结构中的元素一点一点的移动到新的 hash 结构中，当移除完最后一个元素时，清空旧 hash 结构，主要的执行流程如下：\n 扩容或者缩容时把字典中的字段 rehashidx 标识为 0； 在执行定时任务或者执行客户端的 hset、hdel 等操作指令时，判断是否需要触发 rehash 操作（通过 rehashidx 标识判断），如果需要触发 rehash 操作，也就是调用 dictRehash 函数，dictRehash 函数会把 ht[0] 中的元素依次添加到新的 Hash 表 ht[1] 中； rehash 操作完成之后，清空 Hash 表 ht[0]，然后对调 ht[1] 和 ht[0] 的值，把新的数据表 ht[1] 更改为 ht[0]，然后把字典中的 rehashidx 标识为 -1，表示不需要执行 rehash 操作。  使用场景 哈希字典的典型使用场景如下：\n 商品购物车，购物车非常适合用哈希字典表示，使用人员唯一编号作为字典的 key，value 值可以存储商品的 id 和数量等信息； 存储用户的属性信息，使用人员唯一编号作为字典的 key，value 值为属性字段和对应的值； 存储文章详情页信息等。  小结 本文我们学习了字典类型的操作命令和在代码中的使用，也明白了字典类型实际是由数组和链表组成的，当字典进行扩容或者缩容时会进行渐进式 rehash 操作，渐进式 rehash 是用来保证 Redis 运行效率的，它的执行流程是同时保留两个哈希表，把旧表中的元素一点一点的移动到新表中，查询的时候会先查询两个哈希表，当所有元素都移动到新的哈希表之后，就会删除旧的哈希表。\n列表使用与内部实现原理 列表类型 (List) 是一个使用链表结构存储的有序结构，它的元素插入会按照先后顺序存储到链表结构中，因此它的元素操作 (插入\\删除) 时间复杂度为 O(1)，所以相对来说速度还是比较快的，但它的查询时间复杂度为 O(n)，因此查询可能会比较慢。\n基础使用 列表类型的使用相对来说比较简单，对它的操作就相当操作一个没有任何 key 值的 value 集合，如下图所示：\n给列表添加一个或多个元素 语法：lpush key value [value …] 示例：\n1 2  127.0.0.1:6379\u0026gt; lpush list 1 2 3 (integer) 3   给列表尾部添加一个或多个元素 语法：rpush key value [value …] 示例：\n1 2  127.0.0.1:6379\u0026gt; rpush list2 1 2 3 (integer) 3   返回列表指定区间内的元素 语法：lrange key start stop 示例：\n1 2 3 4 5 6 7 8  127.0.0.1:6379\u0026gt; lrange list 0 -1 \u0026#34;3\u0026#34; \u0026#34;2\u0026#34; \u0026#34;1\u0026#34; 127.0.0.1:6379\u0026gt; lrange list2 0 -1 \u0026#34;1\u0026#34; \u0026#34;2\u0026#34; \u0026#34;3\u0026#34;   其中 -1 代表列表中的最后一个元素。\n获取并删除列表的第一个元素 语法：lpop key 示例：\n1 2 3 4 5 6 7 8 9 10 11  127.0.0.1:6379\u0026gt; lrange list 0 -1 1) \u0026#34;d\u0026#34; 2) \u0026#34;c\u0026#34; 3) \u0026#34;b\u0026#34; 4) \u0026#34;a\u0026#34; 127.0.0.1:6379\u0026gt; lpop list \u0026#34;d\u0026#34; 127.0.0.1:6379\u0026gt; lrange list 0 -1 1) \u0026#34;c\u0026#34; 2) \u0026#34;b\u0026#34; 3) \u0026#34;a\u0026#34;   获取并删除列表的最后一个元素 语法：rpop key 示例：\n1 2 3 4 5 6 7 8 9  127.0.0.1:6379\u0026gt; lrange list 0 -1 1) \u0026#34;c\u0026#34; 2) \u0026#34;b\u0026#34; 3) \u0026#34;a\u0026#34; 127.0.0.1:6379\u0026gt; rpop list \u0026#34;a\u0026#34; 127.0.0.1:6379\u0026gt; lrange list 0 -1 1) \u0026#34;c\u0026#34; 2) \u0026#34;b\u0026#34;   根据下标获取对应的元素 语法：lindex key index 示例：\n1 2 3 4  127.0.0.1:6379\u0026gt; rpush list3 a b c (integer) 3 127.0.0.1:6379\u0026gt; lindex list3 0 \u0026#34;a\u0026#34;   代码实战 下面来看列表类型在 Java 中的使用，同样先添加 Jedis 框架，使用代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  public class ListExample { public static void main(String[] args) { Jedis jedis = new Jedis(\u0026#34;127.0.0.1\u0026#34;, 6379); // 声明 Redis key  final String REDISKEY = \u0026#34;list\u0026#34;; // 在头部插入一个或多个元素  Long lpushResult = jedis.lpush(REDISKEY, \u0026#34;Java\u0026#34;, \u0026#34;Sql\u0026#34;); System.out.println(lpushResult); // 输出：2  // 获取第 0 个元素的值  String idValue = jedis.lindex(REDISKEY, 0); System.out.println(idValue); // 输出：Sql  // 查询指定区间的元素  List\u0026lt;String\u0026gt; list = jedis.lrange(REDISKEY, 0, -1); System.out.println(list); // 输出：[Sql, Java]  // 在元素 Java 前面添加 MySQL 元素  jedis.linsert(REDISKEY, ListPosition.BEFORE, \u0026#34;Java\u0026#34;, \u0026#34;MySQL\u0026#34;); System.out.println(jedis.lrange(REDISKEY, 0, -1)); // 输出：[Sql, MySQL, Java]  jedis.close(); } }   程序运行结果如下：\n 2 Sql [Sql, Java] [Sql, MySQL, Java]\n 内部实现 我们先用 debug encoding key 来查看列表类型的内部存储类型，如下所示：\n1 2  127.0.0.1:6379\u0026gt; object encoding list \u0026#34;quicklist\u0026#34;   从结果可以看出，列表类型的底层数据类型是 quicklist。\nquicklist (快速列表) 是 Redis 3.2 引入的数据类型，早期的列表类型使用的是ziplist (压缩列表) 和双向链表组成的，Redis 3.2 改为用 quicklist 来存储列表元素。\n我们来看下 quicklist 的实现源码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  typedef struct quicklist { // src/quicklist.h  quicklistNode *head; quicklistNode *tail; unsigned long count; /* ziplist 的个数 */ unsigned long len; /* quicklist 的节点数 */ unsigned int compress : 16; /* LZF 压缩算法深度 */ //... } quicklist; typedef struct quicklistNode { struct quicklistNode *prev; struct quicklistNode *next; unsigned char *zl; /* 对应的 ziplist */ unsigned int sz; /* ziplist 字节数 */ unsigned int count : 16; /* ziplist 个数 */ unsigned int encoding : 2; /* RAW==1 or LZF==2 */ unsigned int container : 2; /* NONE==1 or ZIPLIST==2 */ unsigned int recompress : 1; /* 该节点先前是否被压缩 */ unsigned int attempted_compress : 1; /* 节点太小无法压缩 */ //... } quicklistNode; typedef struct quicklistLZF { unsigned int sz; char compressed[]; } quicklistLZF;   从以上源码可以看出 quicklist 是一个双向链表，链表中的每个节点实际上是一个 ziplist，它们的结构如下图所示：\nziplist 作为 quicklist 的实际存储结构，它本质是一个字节数组，ziplist 数据结构如下图所示：\n其中的字段含义如下：\n zlbytes：压缩列表字节长度，占 4 字节； zltail：压缩列表尾元素相对于起始元素地址的偏移量，占 4 字节； zllen：压缩列表的元素个数； entryX：压缩列表存储的所有元素，可以是字节数组或者是整数； zlend：压缩列表的结尾，占 1 字节。  源码解析 下面我们来看一下更多关于列表类型的源码实现。\n添加功能源码分析 quicklist 添加操作对应函数是 quicklistPush，源码如下：\n1 2 3 4 5 6 7 8 9 10  void quicklistPush(quicklist *quicklist, void *value, const size_t sz, int where) { if (where == QUICKLIST_HEAD) { // 在列表头部添加元素  quicklistPushHead(quicklist, value, sz); } else if (where == QUICKLIST_TAIL) { // 在列表尾部添加元素  quicklistPushTail(quicklist, value, sz); } }   以 quicklistPushHead 为例，源码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  int quicklistPushHead(quicklist *quicklist, void *value, size_t sz) { quicklistNode *orig_head = quicklist-\u0026gt;head; if (likely( _quicklistNodeAllowInsert(quicklist-\u0026gt;head, quicklist-\u0026gt;fill, sz))) { // 在头部节点插入元素  quicklist-\u0026gt;head-\u0026gt;zl = ziplistPush(quicklist-\u0026gt;head-\u0026gt;zl, value, sz, ZIPLIST_HEAD); quicklistNodeUpdateSz(quicklist-\u0026gt;head); } else { // 头部节点不能继续插入，需要新建 quicklistNode、ziplist 进行插入  quicklistNode *node = quicklistCreateNode(); node-\u0026gt;zl = ziplistPush(ziplistNew(), value, sz, ZIPLIST_HEAD); quicklistNodeUpdateSz(node); // 将新建的 quicklistNode 插入到 quicklist 结构中  _quicklistInsertNodeBefore(quicklist, quicklist-\u0026gt;head, node); } quicklist-\u0026gt;count++; quicklist-\u0026gt;head-\u0026gt;count++; return (orig_head != quicklist-\u0026gt;head); }   quicklistPushHead 函数的执行流程，先判断 quicklist 的 head 节点是否可以插入数据，如果可以插入则使用 ziplist 的接口进行插入，否则就新建 quicklistNode 节点进行插入。\n函数的入参是待插入的 quicklist，还有需要插入的值 value 以及他的大小 sz。\n函数的返回值为 int，0 表示没有新建 head，1 表示新建了 head。 quicklistPushHead 执行流程，如下图所示：\n删除功能源码分析 quicklist 元素删除分为两种情况：单一元素删除和区间元素删除，它们都位于 src/quicklist.c 文件中。\n单一元素删除 单一元素的删除函数是 quicklistDelEntry，源码如下：\n1 2 3 4 5 6 7 8  void quicklistDelEntry(quicklistIter *iter, quicklistEntry *entry) { quicklistNode *prev = entry-\u0026gt;node-\u0026gt;prev; quicklistNode *next = entry-\u0026gt;node-\u0026gt;next; // 删除指定位置的元素  int deleted_node = quicklistDelIndex((quicklist *)entry-\u0026gt;quicklist, entry-\u0026gt;node, \u0026amp;entry-\u0026gt;zi); //... }   可以看出 quicklistDelEntry 函数的底层，依赖 quicklistDelIndex 函数进行元素删除。\n区间元素删除 区间元素删除的函数是 quicklistDelRange，源码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60  // start 表示开始删除的下标，count 表示要删除的个数 int quicklistDelRange(quicklist *quicklist, const long start, const long count) { if (count \u0026lt;= 0) return 0; unsigned long extent = count; if (start \u0026gt;= 0 \u0026amp;\u0026amp; extent \u0026gt; (quicklist-\u0026gt;count - start)) { // 删除的元素个数大于已有元素  extent = quicklist-\u0026gt;count - start; } else if (start \u0026lt; 0 \u0026amp;\u0026amp; extent \u0026gt; (unsigned long)(-start)) { // 删除指定的元素个数  extent = -start; /* c.f. LREM -29 29; just delete until end. */ } //...  // extent 为剩余需要删除的元素个数，  while (extent) { // 保存下个 quicklistNode，因为本节点可能会被删除  quicklistNode *next = node-\u0026gt;next; unsigned long del; int delete_entire_node = 0; if (entry.offset == 0 \u0026amp;\u0026amp; extent \u0026gt;= node-\u0026gt;count) { // 删除整个 quicklistNode  delete_entire_node = 1; del = node-\u0026gt;count; } else if (entry.offset \u0026gt;= 0 \u0026amp;\u0026amp; extent \u0026gt;= node-\u0026gt;count) { // 删除本节点的所有元素  del = node-\u0026gt;count - entry.offset; } else if (entry.offset \u0026lt; 0) { // entry.offset\u0026lt;0 表示从后向前，相反则表示从前向后剩余的元素个数  del = -entry.offset; if (del \u0026gt; extent) del = extent; } else { // 删除本节点部分元素  del = extent; } D(\u0026#34;[%ld]: asking to del: %ld because offset: %d; (ENTIRE NODE: %d), \u0026#34; \u0026#34;node count: %u\u0026#34;, extent, del, entry.offset, delete_entire_node, node-\u0026gt;count); if (delete_entire_node) { __quicklistDelNode(quicklist, node); } else { quicklistDecompressNodeForUse(node); node-\u0026gt;zl = ziplistDeleteRange(node-\u0026gt;zl, entry.offset, del); quicklistNodeUpdateSz(node); node-\u0026gt;count -= del; quicklist-\u0026gt;count -= del; quicklistDeleteIfEmpty(quicklist, node); if (node) quicklistRecompressOnly(quicklist, node); } // 剩余待删除元素的个数  extent -= del; // 下个 quicklistNode  node = next; // 从下个 quicklistNode 起始位置开始删除  entry.offset = 0; } return 1; }   从上面代码可以看出，quicklist 在区间删除时，会先找到 start 所在的 quicklistNode，计算删除的元素是否小于要删除的 count，如果不满足删除的个数，则会移动至下一个 quicklistNode 继续删除，依次循环直到删除完成为止。\nquicklistDelRange 函数的返回值为 int 类型，当返回 1 时表示成功的删除了指定区间的元素，返回 0 时表示没有删除任何元素。\n更多源码 除了上面介绍的几个常用函数之外，还有一些更多的函数，例如：\n quicklistCreate：创建 quicklist； quicklistInsertAfter：在某个元素的后面添加数据； quicklistInsertBefore：在某个元素的前面添加数据； quicklistPop：取出并删除列表的第一个或最后一个元素； quicklistReplaceAtIndex：替换某个元素。  使用场景 列表的典型使用场景有以下两个：\n 消息队列：列表类型可以使用 rpush 实现先进先出的功能，同时又可以使用 lpop 轻松的弹出（查询并删除）第一个元素，所以列表类型可以用来实现消息队列； 文章列表：对于博客站点来说，当用户和文章都越来越多时，为了加快程序的响应速度，我们可以把用户自己的文章存入到 List 中，因为 List 是有序的结构，所以这样又可以完美的实现分页功能，从而加速了程序的响应速度。  小结 通过本文我们可以知道列表类型并不是简单的双向链表，而是采用了 quicklist 的数据结构对数据进行存取，quicklist 是 Redis 3.2 新增的数据类型，它的底层采取的是压缩列表加双向链表的存储结构，quicklist 为了存储更多的数据，会对每个 quicklistNode 节点进行压缩，这样就可以有效的存储更多的消息队列或者文章的数据了。\n集合使用与内部实现原理 集合类型 (Set) 是一个无序并唯一的键值集合。\n之所以说集合类型是一个无序集合，是因为它的存储顺序不会按照插入的先后顺序进行存储，如下代码所示：\n1 2 3 4 5 6  127.0.0.1:6379\u0026gt; sadd myset v2 v1 v3 #插入数据 v2、v1、v3  (integer) 3 127.0.0.1:6379\u0026gt; smembers myset #查询数据 1) \u0026#34;v1\u0026#34; 2) \u0026#34;v3\u0026#34; 3) \u0026#34;v2\u0026#34;   从上面代码执行结果可以看出，myset 的存储顺序并不是以插入的先后顺序进行存储的。\n集合类型和列表类型的区别如下：\n 列表可以存储重复元素，集合只能存储非重复元素； 列表是按照元素的先后顺序存储元素的，而集合则是无序方式存储元素的。  基础使用 集合类型的功能比列表类型丰富一些，集合类型可以用来统计多个集合的交集、错集和并集，如下代码所示。\n添加一个或多个元素 语法：sadd key member [member \u0026hellip;] 示例：\n1 2  127.0.0.1:6379\u0026gt; sadd myset v1 v2 v3 (integer) 3   查询集合所有元素 语法：smembers key 示例：\n1 2 3 4  127.0.0.1:6379\u0026gt; smembers myset 1) \u0026#34;v1\u0026#34; 2) \u0026#34;v3\u0026#34; 3) \u0026#34;v2\u0026#34;   查询集合的成员数量 语法：scard key 示例：\n1 2  127.0.0.1:6379\u0026gt; scard myset (integer) 3   查询集合中是否包含某个元素 语法：sismember key member 示例：\n1 2 3 4  127.0.0.1:6379\u0026gt; sismember myset v1 (integer) 1 127.0.0.1:6379\u0026gt; sismember myset v4 (integer) 0   从一个集合中移动一个元素到另一个集合 语法：smove source destination member 示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  127.0.0.1:6379\u0026gt; smembers myset 1) \u0026#34;v1\u0026#34; 2) \u0026#34;v3\u0026#34; 3) \u0026#34;v2\u0026#34; 127.0.0.1:6379\u0026gt; smembers myset2 1) \u0026#34;v1\u0026#34; 2) \u0026#34;v8\u0026#34; 127.0.0.1:6379\u0026gt; smove myset myset2 v3 (integer) 1 127.0.0.1:6379\u0026gt; smembers myset2 1) \u0026#34;v1\u0026#34; 2) \u0026#34;v8\u0026#34; 3) \u0026#34;v3\u0026#34; 127.0.0.1:6379\u0026gt; smembers myset 1) \u0026#34;v1\u0026#34; 2) \u0026#34;v2\u0026#34;   移除集合中一个或多个元素 语法：srem key member [member \u0026hellip;] 示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13  127.0.0.1:6379\u0026gt; smembers myset 1) \u0026#34;v4\u0026#34; 2) \u0026#34;v1\u0026#34; 3) \u0026#34;v3\u0026#34; 4) \u0026#34;v2\u0026#34; 5) \u0026#34;v5\u0026#34; 127.0.0.1:6379\u0026gt; srem myset v5 (integer) 1 127.0.0.1:6379\u0026gt; smembers myset 1) \u0026#34;v3\u0026#34; 2) \u0026#34;v2\u0026#34; 3) \u0026#34;v1\u0026#34; 4) \u0026#34;v4\u0026#34;   注意：使用 srem 指令，不存在的元素将会被忽略。\n代码实战 下面来看集合类型在 Java 中的使用，同样先添加 Jedis 框架，使用代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  import redis.clients.jedis.Jedis; import java.util.Set; public class SetExample { public static void main(String[] args) { Jedis jedis = new Jedis(\u0026#34;xxx.xxx.xxx.xxx\u0026#34;, 6379); jedis.auth(\u0026#34;xxx\u0026#34;); // 创建集合并添加元素  jedis.sadd(\u0026#34;set1\u0026#34;, \u0026#34;java\u0026#34;, \u0026#34;golang\u0026#34;); // 查询集合中的所有元素  Set\u0026lt;String\u0026gt; members = jedis.smembers(\u0026#34;set1\u0026#34;); System.out.println(members); // 输出：[java, golang]  // 查询集合中的元素数量  System.out.println(jedis.scard(\u0026#34;set1\u0026#34;)); // 移除集合中的一个元素  jedis.srem(\u0026#34;set1\u0026#34;, \u0026#34;golang\u0026#34;); System.out.println(jedis.smembers(\u0026#34;set1\u0026#34;)); // 输出：[java]  // 创建集合 set2 并添加元素  jedis.sadd(\u0026#34;set2\u0026#34;, \u0026#34;java\u0026#34;, \u0026#34;golang\u0026#34;); // 查询两个集合中交集  Set\u0026lt;String\u0026gt; inters = jedis.sinter(\u0026#34;set1\u0026#34;, \u0026#34;set2\u0026#34;); System.out.println(inters); // 输出：[java]  // 查询两个集合中并集  Set\u0026lt;String\u0026gt; unions = jedis.sunion(\u0026#34;set1\u0026#34;, \u0026#34;set2\u0026#34;); System.out.println(unions); // 输出：[java,golang]  // 查询两个集合的错集  Set\u0026lt;String\u0026gt; diffs = jedis.sdiff(\u0026#34;set2\u0026#34;, \u0026#34;set1\u0026#34;); System.out.println(diffs); // 输出：[golang]  } }   内部实现 集合类型是由 intset (整数集合) 或 hashtable (普通哈希表) 组成的。当集合类型以 hashtable 存储时，哈希表的 key 为要插入的元素值，而哈希表的 value 则为 Null，如下图所示：\n当集合中所有的值都为整数时，Redis 会使用 intset 结构来存储，如下代码所示：\n1 2 3 4  127.0.0.1:6379\u0026gt; sadd myset 1 9 3 -2 (integer) 4 127.0.0.1:6379\u0026gt; object encoding myset \u0026#34;intset\u0026#34;   从上面代码可以看出，当所有元素都为整数时，集合会以 intset 结构进行(数据)存储。 当发生以下两种情况时，会导致集合类型使用 hashtable 而非 intset 存储： 1）当元素的个数超过一定数量时，默认是 512 个，该值可通过命令 set-max-intset-entries xxx 来配置。 2）当元素为非整数时，集合将会使用 hashtable 来存储，如下代码所示：\n1 2 3 4  127.0.0.1:6379\u0026gt; sadd myht \u0026#34;redis\u0026#34; \u0026#34;db\u0026#34; (integer) 2 127.0.0.1:6379\u0026gt; object encoding myht \u0026#34;hashtable\u0026#34;   从上面代码可以看出，当元素为非整数时，集合会使用 hashtable 进行存储。\n源码解析 集合源码在 t_set.c 文件中，核心源码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38  /* * 添加元素到集合 * 如果当前值已经存在，则返回 0 不作任何处理，否则就添加该元素，并返回 1。 */ int setTypeAdd(robj *subject, sds value) { long long llval; if (subject-\u0026gt;encoding == OBJ_ENCODING_HT) { // 字典类型  dict *ht = subject-\u0026gt;ptr; dictEntry *de = dictAddRaw(ht,value,NULL); if (de) { // 把 value 作为字典到 key，将 Null 作为字典到 value，将元素存入到字典  dictSetKey(ht,de,sdsdup(value)); dictSetVal(ht,de,NULL); return 1; } } else if (subject-\u0026gt;encoding == OBJ_ENCODING_INTSET) { // inset 数据类型  if (isSdsRepresentableAsLongLong(value,\u0026amp;llval) == C_OK) { uint8_t success = 0; subject-\u0026gt;ptr = intsetAdd(subject-\u0026gt;ptr,llval,\u0026amp;success); if (success) { // 超过 inset 的最大存储数量，则使用字典类型存储  if (intsetLen(subject-\u0026gt;ptr) \u0026gt; server.set_max_intset_entries) setTypeConvert(subject,OBJ_ENCODING_HT); return 1; } } else { // 转化为整数类型失败，使用字典类型存储  setTypeConvert(subject,OBJ_ENCODING_HT); serverAssert(dictAdd(subject-\u0026gt;ptr,sdsdup(value),NULL) == DICT_OK); return 1; } } else { // 未知编码(类型)  serverPanic(\u0026#34;Unknown set encoding\u0026#34;); } return 0; }   以上这些代码验证了，我们上面所说的内容，当元素都为整数并且元素的个数没有到达设置的最大值时，键值的存储使用的是 intset 的数据结构，反之到元素超过了一定的范围，又或者是存储的元素为非整数时，集合会选择使用 hashtable 的数据结构进行存储。\n使用场景 集合类型的经典使用场景如下：\n 微博关注我的人和我关注的人都适合用集合存储，可以保证人员不会重复； 中奖人信息也适合用集合类型存储，这样可以保证一个人不会重复中奖。  小结 通过本文我们知道了，集合类型是由整数集合 (intset) 或者是哈希表 (hashtable) 组成的，集合类型比较适合用来数据去重和保障数据的唯一性，除此之外，集合类型还可以用来统计多个集合的交集、错集和并集 (见附录)。当我们存储的数据是无序并且需要去重的情况下，比较适合使用集合类型进行存储。\n有序集合使用与内部实现原理 有序集合类型 (Sorted Set) 相比于集合类型多了一个排序属性 score（分值），对于有序集合 ZSet 来说，每个存储元素相当于有两个值组成的，一个是有序结合的元素值，一个是排序值。有序集合的存储元素值也是不能重复的，但分值是可以重复的。\n当我们把学生的成绩存储在有序集合中时，它的存储结构如下图所示：\n下面我们先从有序集合的使用开始说起。\n基础使用 添加一个或多个元素 语法：zadd key [NX|XX] [CH] [INCR] score member [score member \u0026hellip;] 示例：\n1 2 3 4  127.0.0.1:6379\u0026gt; zadd zset1 10 java (integer) 1 127.0.0.1:6379\u0026gt; zadd zset1 3 golang 4 sql 1 redis (integer) 3   可以看出有序集合的添加是 zadd 键值 分值1 元素值1 分值2 元素值2 的形式添加的。\n查询所有元素列表 语法：zrange key start stop [WITHSCORES] 示例：\n1 2 3 4  127.0.0.1:6379\u0026gt; zrange zset 0 -1 1) \u0026#34;redis\u0026#34; 2) \u0026#34;mysql\u0026#34; 3) \u0026#34;java\u0026#34;   其中 -1 表示最后一个元素，查询结果包含开始和结束元素。\n删除一个或多个元素(根据元素值) 语法：zrem key member [member \u0026hellip;] 示例：\n1 2 3 4 5 6 7 8 9 10  127.0.0.1:6379\u0026gt; zrangebyscore zset1 0 -1 #查询所有元素 1) \u0026#34;golang\u0026#34; 2) \u0026#34;redis\u0026#34; 3) \u0026#34;sql\u0026#34; 4) \u0026#34;java\u0026#34; 127.0.0.1:6379\u0026gt; zrem zset1 redis sql #删除元素：reids、sql (integer) 2 127.0.0.1:6379\u0026gt; zrange zset1 0 -1 #查询所有元素 1) \u0026#34;golang\u0026#34; 2) \u0026#34;java\u0026#34;   删除命令中如果包含了不存在的元素，并不会影响命令的正常执行，不存在的元素将会被忽略。\n查询某元素的 score 值 语法：zscore key member 示例：\n1 2  127.0.0.1:6379\u0026gt; zscore zset1 redis \u0026#34;1\u0026#34;   查询 score 区间内元素 语法：zrangebyscore key min max [WITHSCORES] [LIMIT offset count] 示例：\n1 2 3 4 5  127.0.0.1:6379\u0026gt; zrangebyscore zset1 3 10 1) \u0026#34;golang\u0026#34; 2) \u0026#34;redis\u0026#34; 3) \u0026#34;sql\u0026#34; 4) \u0026#34;java\u0026#34;   查询某元素排名 语法：zrank key member 示例：\n1 2 3 4 5 6  127.0.0.1:6379\u0026gt; zadd zset 5 redis 10 java 8 mysql #创建有序集合 (integer) 3 127.0.0.1:6379\u0026gt; zrank zset java #查询元素排序 (integer) 2 127.0.0.1:6379\u0026gt; zrank zset redis (integer) 0   可以看出，排名是从 0 开始的，排名可以理解为元素排序后的下标值。\n代码实战 下面来看有序集合在 Java 中的使用，同样先添加 Jedis 框架，示例代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  import redis.clients.jedis.Jedis; import java.util.HashMap; import java.util.Map; import java.util.Set; public class ZSetExample { public static void main(String[] args) { Jedis jedis = new Jedis(\u0026#34;127.0.0.1\u0026#34;, 6379); Map\u0026lt;String, Double\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); map.put(\u0026#34;小明\u0026#34;, 80.5d); map.put(\u0026#34;小红\u0026#34;, 75d); map.put(\u0026#34;老王\u0026#34;, 85d); // 为有序集合(ZSet)添加元素  jedis.zadd(\u0026#34;grade\u0026#34;, map); // 查询分数在 80 分到 100 分之间的人(包含 80 分和 100 分)  Set\u0026lt;String\u0026gt; gradeSet = jedis.zrangeByScore(\u0026#34;grade\u0026#34;, 80, 100); System.out.println(gradeSet); // 输出：[小明, 老王]  // 查询小红的排名(排名从 0 开始)  System.out.println(jedis.zrank(\u0026#34;grade\u0026#34;, \u0026#34;小明\u0026#34;)); // 输出：1  // 从集合中移除老王  jedis.zrem(\u0026#34;grade\u0026#34;, \u0026#34;老王\u0026#34;); // 查询有序集合中的所有元素(根据排名从小到大)  Set\u0026lt;String\u0026gt; range = jedis.zrange(\u0026#34;grade\u0026#34;, 0, -1); System.out.println(range); // 输出：[小红, 小明]  // 查询有序集合中的所有元素(根据 score 从小到大)  Set\u0026lt;String\u0026gt; rangeByScore = jedis.zrangeByScore(\u0026#34;grade\u0026#34;, 0, 100); System.out.println(rangeByScore); } }   内部实现 有序集合是由 ziplist (压缩列表) 或 skiplist (跳跃表) 组成的。\nziplist 当数据比较少时，有序集合使用的是 ziplist 存储的，如下代码所示：\n1 2 3 4  127.0.0.1:6379\u0026gt; zadd myzset 1 db 2 redis 3 mysql (integer) 3 127.0.0.1:6379\u0026gt; object encoding myzset \u0026#34;ziplist\u0026#34;   从结果可以看出，有序集合把 myset 键值对存储在 ziplist 结构中了。 有序集合使用 ziplist 格式存储必须满足以下两个条件：\n 有序集合保存的元素个数要小于 128 个； 有序集合保存的所有元素成员的长度都必须小于 64 字节。  如果不能满足以上两个条件中的任意一个，有序集合将会使用 skiplist 结构进行存储。 接下来我们来测试以下，当有序集合中某个元素长度大于 64 字节时会发生什么情况？ 代码如下：\n1 2 3 4 5 6 7 8  127.0.0.1:6379\u0026gt; zadd zmaxleng 1.0 redis (integer) 1 127.0.0.1:6379\u0026gt; object encoding zmaxleng \u0026#34;ziplist\u0026#34; 127.0.0.1:6379\u0026gt; zadd zmaxleng 2.0 aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa (integer) 1 127.0.0.1:6379\u0026gt; object encoding zmaxleng \u0026#34;skiplist\u0026#34;   通过以上代码可以看出，当有序集合保存的所有元素成员的长度大于 64 字节时，有序集合就会从 ziplist 转换成为 skiplist。\n 小贴士：可以通过配置文件中的 zset-max-ziplist-entries（默认 128）和 zset-max-ziplist-value（默认 64）来设置有序集合使用 ziplist 存储的临界值。\n skiplist skiplist 数据编码底层是使用 zset 结构实现的，而 zset 结构中包含了一个字典和一个跳跃表，源码如下：\n1 2 3 4  typedef struct zset { dict *dict; zskiplist *zsl; } zset;   更多关于跳跃表的源码实现，会在后面的章节详细介绍。\n跳跃表实现原理 跳跃表的结构如下图所示：\n根据以上图片展示，当我们在跳跃表中查询值 32 时，执行流程如下：\n 从最上层开始找，1 比 32 小，在当前层移动到下一个节点进行比较； 7 比 32 小，当前层移动下一个节点比较，由于下一个节点指向 Null，所以以 7 为目标，移动到下一层继续向后比较； 18 小于 32，继续向后移动查找，对比 77 大于 32，以 18 为目标，移动到下一层继续向后比较； 对比 32 等于 32，值被顺利找到。  从上面的流程可以看出，跳跃表会想从最上层开始找起，依次向后查找，如果本层的节点大于要找的值，或者本层的节点为 Null 时，以上一个节点为目标，往下移一层继续向后查找并循环此流程，直到找到该节点并返回，如果对比到最后一个元素仍未找到，则返回 Null。\n为什么是跳跃表？而非红黑树？ 因为跳跃表的性能和红黑树基本相近，但却比红黑树更好实现，所有 Redis 的有序集合会选用跳跃表来实现存储。\n使用场景 有序集合的经典使用场景如下：\n 学生成绩排名 粉丝列表，根据关注的先后时间排序  小结 通过本文的学习我们了解到，有序集合具有唯一性和排序的功能，排序功能是借助分值字段 score 实现的，score 字段不仅可以实现排序功能，还可以实现数据的赛选与过滤的功能。我们还了解到了有序集合是由 压缩列表 (ziplist) 或跳跃列表 (skiplist) 来存储的，当元素个数小于 128 个，并且所有元素的值都小于 64 字节时，有序集合会采取 ziplist 来存储，反之则会用 skiplist 来存储，其中 skiplist 是从上往下、从前往后进行元素查找的，相比于传统的普通列表，可能会快很多，因为普通列表只能从前往后依次查找。\n","date":"2021-09-26T13:36:41Z","image":"https://ahao.ink/23.jpg","permalink":"https://ahao.ink/posts/redis%E5%B8%B8%E7%94%A8%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/","title":"Redis常用数据类型"},{"content":" Redis 的读写都是在内存中，所以它的性能较高，但在内存中的数据会随着服务器的重启而丢失，为了保证数据不丢失，我们需要将内存中的数据存储到磁盘，以便 Redis 重启时能够从磁盘中恢复原有的数据，而整个过程就叫做 Redis 持久化。\n Redis 持久化也是 Redis 和 Memcached 的主要区别之一，因为 Memcached 不具备持久化功能。\n持久化的几种方式 Redis 持久化拥有以下三种方式：\n 快照方式（RDB, Redis DataBase）将某一个时刻的内存数据，以二进制的方式写入磁盘； 文件追加方式（AOF, Append Only File），记录所有的操作命令，并以文本的形式追加到文件中； 混合持久化方式，Redis 4.0 之后新增的方式，混合持久化是结合了 RDB 和 AOF 的优点，在写入的时候，先把当前的数据以 RDB 的形式写入文件的开头，再将后续的操作命令以 AOF 的格式存入文件，这样既能保证 Redis 重启时的速度，又能减低数据丢失的风险。  因为每种持久化方案，都有特定的使用场景，让我们先从 RDB 持久化说起吧。\nRedis持久化\u0026ndash;RDB RDB（Redis DataBase）是将某一个时刻的内存快照（Snapshot），以二进制的方式写入磁盘的过程。\n持久化触发 RDB 的持久化触发方式有两类：一类是手动触发，另一类是自动触发。\n手动触发 手动触发持久化的操作有两个： save 和 bgsave ，它们主要区别体现在：是否阻塞 Redis 主线程的执行。\nsave 命令 在客户端中执行 save 命令，就会触发 Redis 的持久化，但同时也是使 Redis 处于阻塞状态，直到 RDB 持久化完成，才会响应其他客户端发来的命令，所以在生产环境一定要慎用。\nsave 命令使用如下：从图片可以看出，当执行完 save 命令之后，持久化文件 dump.rdb 的修改时间就变了，这就表示 save 成功的触发了 RDB 持久化。 save 命令执行流程，如下图所示：\nbgsave 命令 bgsave（background save）既后台保存的意思， 它和 save 命令最大的区别就是 bgsave 会 fork() 一个子进程来执行持久化，整个过程中只有在 fork() 子进程时有短暂的阻塞，当子进程被创建之后，Redis 的主进程就可以响应其他客户端的请求了，相对于整个流程都阻塞的 save 命令来说，显然 bgsave 命令更适合我们使用。 bgsave 命令使用，如下图所示：\nbgsave 执行流程，如下图所示：\n自动触发 说完了 RDB 的手动触发方式，下面来看如何自动触发 RDB 持久化？ RDB 自动持久化主要来源于以下几种情况。\nsave m n save m n 是指在 m 秒内，如果有 n 个键发生改变，则自动触发持久化。 参数 m 和 n 可以在 Redis 的配置文件中找到，例如，save 60 1 则表明在 60 秒内，至少有一个键发生改变，就会触发 RDB 持久化。 自动触发持久化，本质是 Redis 通过判断，如果满足设置的触发条件，自动执行一次 bgsave 命令。 注意：当设置多个 save m n 命令时，满足任意一个条件都会触发持久化。 例如，我们设置了以下两个 save m n 命令：\n save 60 10 save 600 1  当 60s 内如果有 10 次 Redis 键值发生改变，就会触发持久化；如果 60s 内 Redis 的键值改变次数少于 10 次，那么 Redis 就会判断 600s 内，Redis 的键值是否至少被修改了一次，如果满足则会触发持久化。\nflushall flushall 命令用于清空 Redis 数据库，在生产环境下一定慎用，当 Redis 执行了 flushall 命令之后，则会触发自动持久化，把 RDB 文件清空。 执行结果如下图所示：\n主从同步触发 在 Redis 主从复制中，当从节点执行全量复制操作时，主节点会执行 bgsave 命令，并将 RDB 文件发送给从节点，该过程会自动触发 Redis 持久化。\n配置说明 合理的设置 RDB 的配置，可以保障 Redis 高效且稳定的运行，下面一起来看 RDB 的配置项都有哪些？\nRDB 配置参数可以在 Redis 的配置文件中找见，具体内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  # RDB 保存的条件 save 900 1 save 300 10 save 60 10000 # bgsave 失败之后，是否停止持久化数据到磁盘，yes 表示停止持久化，no 表示忽略错误继续写文件。 stop-writes-on-bgsave-error yes # RDB 文件压缩 rdbcompression yes # 写入文件和读取文件时是否开启 RDB 文件检查，检查是否有无损坏，如果在启动是检查发现损坏，则停止启动。 rdbchecksum yes # RDB 文件名 dbfilename dump.rdb # RDB 文件目录 dir ./   其中比较重要的参数如下列表： ① save 参数 它是用来配置触发 RDB 持久化条件的参数，满足保存条件时将会把数据持久化到硬盘。 默认配置说明如下：\n save 900 1：表示 900 秒内如果至少有 1 个 key 值变化，则把数据持久化到硬盘； save 300 10：表示 300 秒内如果至少有 10 个 key 值变化，则把数据持久化到硬盘； save 60 10000：表示 60 秒内如果至少有 10000 个 key 值变化，则把数据持久化到硬盘。  ② rdbcompression 参数 它的默认值是 yes 表示开启 RDB 文件压缩，Redis 会采用 LZF 算法进行压缩。如果不想消耗 CPU 性能来进行文件压缩的话，可以设置为关闭此功能，这样的缺点是需要更多的磁盘空间来保存文件。 ③ rdbchecksum 参数 它的默认值为 yes 表示写入文件和读取文件时是否开启 RDB 文件检查，检查是否有无损坏，如果在启动是检查发现损坏，则停止启动。\n配置查询 Redis 中可以使用命令查询当前配置参数。查询命令的格式为：config get xxx ，例如，想要获取 RDB 文件的存储名称设置，可以使用 config get dbfilename ，执行效果如下图所示：\n查询 RDB 的文件目录，可使用命令 config get dir ，执行效果如下图所示：\n配置设置 设置 RDB 的配置，可以通过以下两种方式：\n 手动修改 Redis 配置文件； 使用命令行设置，例如，使用 config set dir \u0026quot;/usr/data\u0026quot; 就是用于修改 RDB 的存储目录。  注意：手动修改 Redis 配置文件的方式是全局生效的，即重启 Redis 服务器设置参数也不会丢失，而使用命令修改的方式，在 Redis 重启之后就会丢失。但手动修改 Redis 配置文件，想要立即生效需要重启 Redis 服务器，而命令的方式则不需要重启 Redis 服务器。\n 小贴士：Redis 的配置文件位于 Redis 安装目录的根路径下，默认名称为 redis.conf。\n RDB 文件恢复 当 Redis 服务器启动时，如果 Redis 根目录存在 RDB 文件 dump.rdb，Redis 就会自动加载 RDB 文件恢复持久化数据。 如果根目录没有 dump.rdb 文件，请先将 dump.rdb 文件移动到 Redis 的根目录。 验证 RDB 文件是否被加载 Redis 在启动时有日志信息，会显示是否加载了 RDB 文件，我们执行 Redis 启动命令：src/redis-server redis.conf ，如下图所示：\n从日志上可以看出， Redis 服务在启动时已经正常加载了 RDB 文件。\n 小贴士：Redis 服务器在载入 RDB 文件期间，会一直处于阻塞状态，直到载入工作完成为止。\n RDB 优缺点 RDB 优点  RDB 的内容为二进制的数据，占用内存更小，更紧凑，更适合做为备份文件； RDB 对灾难恢复非常有用，它是一个紧凑的文件，可以更快的传输到远程服务器进行 Redis 服务恢复； RDB 可以更大程度的提高 Redis 的运行速度，因为每次持久化时 Redis 主进程都会 fork() 一个子进程，进行数据持久化到磁盘，Redis 主进程并不会执行磁盘 I/O 等操作； 与 AOF 格式的文件相比，RDB 文件可以更快的重启。  RDB 缺点  因为 RDB 只能保存某个时间间隔的数据，如果中途 Redis 服务被意外终止了，则会丢失一段时间内的 Redis 数据； RDB 需要经常 fork() 才能使用子进程将其持久化在磁盘上。如果数据集很大，fork() 可能很耗时，并且如果数据集很大且 CPU 性能不佳，则可能导致 Redis 停止为客户端服务几毫秒甚至一秒钟。  禁用持久化 禁用持久化可以提高 Redis 的执行效率，如果对数据丢失不敏感的情况下，可以在连接客户端的情况下，执行 config set save \u0026quot;\u0026quot; 命令即可禁用 Redis 的持久化，如下图所示：\n小结 通过本文我们可以得知，RDB 持久化分为手动触发和自动触发两种方式，它的优点是存储文件小，Redis 启动 时恢复数据比较快，缺点是有丢失数据的风险。RDB 文件的恢复也很简单，只需要把 RDB 文件放到 Redis 的根目录，在 Redis 启动时就会自动加载并恢复数据。\nRedis持久化\u0026ndash;AOF 使用 RDB 持久化有一个风险，它可能会造成最新数据丢失的风险。因为 RDB 的持久化有一定的时间间隔，在这个时间段内如果 Redis 服务意外终止的话，就会造成最新的数据全部丢失。\n可能会操作 Redis 服务意外终止的条件：\n 安装 Redis 的机器停止运行，蓝屏或者系统崩溃； 安装 Redis 的机器出现电源故障，例如突然断电； 使用 kill -9 Redis_PID 等。  那么如何解决以上的这些问题呢？Redis 为我们提供了另一种持久化的方案——AOF。\n简介 AOF（Append Only File）中文是附加到文件，顾名思义 AOF 可以把 Redis 每个键值对操作都记录到文件（appendonly.aof）中。\n持久化查询和设置 查询 AOF 启动状态 使用 config get appendonly 命令，如下图所示：\n其中，第一行为 AOF 文件的名称，而最后一行表示 AOF 启动的状态，yes 表示已启动，no 表示未启动。\n开启 AOF 持久化 Redis 默认是关闭 AOF 持久化的，想要开启 AOF 持久化，有以下两种方式：\n 通过命令行的方式； 通过修改配置文件的方式（redis.conf）。  下面分别来看以上两种方式的实现。\n命令行启动 AOF 命令行启动 AOF，使用 config set appendonly yes 命令，如下图所示：\n命令行启动 AOF 的优缺点：命令行启动优点是无需重启 Redis 服务，缺点是如果 Redis 服务重启，则之前使用命令行设置的配置就会失效。\n配置文件启动 AOF Redis 的配置文件在它的根路径下的 redis.conf 文件中，获取 Redis 的根目录可以使用命令 config get dir 获取，如下图所示：\n只需要在配置文件中设置 appendonly yes 即可，默认 appendonly no 表示关闭 AOF 持久化。 配置文件启动 AOF 的优缺点：修改配置文件的缺点是每次修改配置文件都要重启 Redis 服务才能生效，优点是无论重启多少次 Redis 服务，配置文件中设置的配置信息都不会失效。\n触发持久化 AOF 持久化开启之后，只要满足一定条件，就会触发 AOF 持久化。AOF 的触发条件分为两种：自动触发和手动触发。\n自动触发 有两种情况可以自动触发 AOF 持久化，分为是：满足 AOF 设置的策略触发和**满足 AOF 重写触发。**其中，AOF 重写触发会在本文的后半部分详细介绍，这里重点来说 AOF 持久化策略都有哪些。 AOF 持久化策略，分为以下三种：\n always：每条 Redis 操作命令都会写入磁盘，最多丢失一条数据； everysec：每秒钟写入一次磁盘，最多丢失一秒的数据； no：不设置写入磁盘的规则，根据当前操作系统来决定何时写入磁盘，Linux 默认 30s 写入一次数据至磁盘。  这三种配置可以在 Redis 的配置文件（redis.conf）中设置，如下代码所示：\n1 2  # 开启每秒写入一次的持久化策略 appendfsync everysec    小贴士：因为每次写入磁盘都会对 Redis 的性能造成一定的影响，所以要根据用户的实际情况设置相应的策略，一般设置每秒写入一次磁盘的频率就可以满足大部分的使用场景了。\n 触发自动持久化的两种情况，如下图所示：\n手动触发 在客户端执行 bgrewriteaof 命令就可以手动触发 AOF 持久化，如下图所示：\n可以看出执行完 bgrewriteaof 命令之后，AOF 持久化就会被触发。\nAOF 文件重写 AOF 是通过记录 Redis 的执行命令来持久化（保存）数据的，所以随着时间的流逝 AOF 文件会越来越多，这样不仅增加了服务器的存储压力，也会造成 Redis 重启速度变慢，为了解决这个问题 Redis 提供了 AOF 重写的功能。\n什么是 AOF 重写？ AOF 重写指的是它会直接读取 Redis 服务器当前的状态，并压缩保存为 AOF 文件。例如，我们增加了一个计数器，并对它做了 99 次修改，如果不做 AOF 重写的话，那么持久化文件中就会有 100 条记录执行命令的信息，而 AOF 重写之后，之后记录一条此计数器最终的结果信息，这样就去除了所有的无效信息。\nAOF 重写实现 触发 AOF 文件重写，要满足两个条件，这两个条件也是配置在 Redis 配置文件中的，它们分别：\n auto-aof-rewrite-min-size：允许 AOF 重写的最小文件容量，默认是 64mb 。 auto-aof-rewrite-percentage：AOF 文件重写的大小比例，默认值是 100，表示 100%，也就是只有当前 AOF 文件，比最后一次（上次）的 AOF 文件大一倍时，才会启动 AOF 文件重写。  查询 auto-aof-rewrite-min-size 和 auto-aof-rewrite-percentage 的值，可使用 config get xxx 命令，如下图所示：\n 小贴士：只有同时满足 auto-aof-rewrite-min-size 和 auto-aof-rewrite-percentage 设置的条件，才会触发 AOF 文件重写。\n 注意：使用 bgrewriteaof 命令，可以自动触发 AOF 文件重写。\nAOF 重写流程 AOF 文件重写是生成一个全新的文件，并把当前数据的最少操作命令保存到新文件上，当把所有的数据都保存至新文件之后，Redis 会交换两个文件，并把最新的持久化操作命令追加到新文件上。\n配置说明 合理的设置 AOF 的配置，可以保障 Redis 高效且稳定的运行，以下是 AOF 的全部配置信息和说明。\nAOF 的配置参数在 Redis 的配置文件中，也就是 Redis 根路径下的 redis.conf 文件中，配置参数和说明如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  # 是否开启 AOF，yes 为开启，默认是关闭 appendonly no # AOF 默认文件名 appendfilename \u0026#34;appendonly.aof\u0026#34; # AOF 持久化策略配置 # appendfsync always appendfsync everysec # appendfsync no # AOF 文件重写的大小比例，默认值是 100，表示 100%，也就是只有当前 AOF 文件，比最后一次的 AOF 文件大一倍时，才会启动 AOF 文件重写。 auto-aof-rewrite-percentage 100 # 允许 AOF 重写的最小文件容量 auto-aof-rewrite-min-size 64mb # 是否开启启动时加载 AOF 文件效验，默认值是 yes，表示尽可能的加载 AOF 文件，忽略错误部分信息，并启动 Redis 服务。 # 如果值为 no，则表示，停止启动 Redis，用户必须手动修复 AOF 文件才能正常启动 Redis 服务。 aof-load-truncated yes   其中比较重要的是 appendfsync 参数，用它来设置 AOF 的持久化策略，可以选择按时间间隔或者操作次数来存储 AOF 文件，这个参数的三个值在文章开头有说明，这里就不再复述了。\n数据恢复 正常数据恢复 正常情况下，只要开启了 AOF 持久化，并且提供了正常的 appendonly.aof 文件，在 Redis 启动时就会自定加载 AOF 文件并启动，执行如下图所示：\n其中 DB loaded from append only file...... 表示 Redis 服务器在启动时，先去加载了 AOF 持久化文件。\n 小贴士：默认情况下 appendonly.aof 文件保存在 Redis 的根目录下。\n 持久化文件加载规则\n 如果只开启了 AOF 持久化，Redis 启动时只会加载 AOF 文件（appendonly.aof），进行数据恢复； 如果只开启了 RDB 持久化，Redis 启动时只会加载 RDB 文件（dump.rdb），进行数据恢复； 如果同时开启了 RDB 和 AOF 持久化，Redis 启动时只会加载 AOF 文件（appendonly.aof），进行数据恢复。  在 AOF 开启的情况下，即使 AOF 文件不存在，只有 RDB 文件，也不会加载 RDB 文件。 AOF 和 RDB 的加载流程如下图所示：\n简单异常数据恢复 在 AOF 写入文件时如果服务器崩溃，或者是 AOF 存储已满的情况下，AOF 的最后一条命令可能被截断，这就是异常的 AOF 文件。\n在 AOF 文件异常的情况下，如果为修改 Redis 的配置文件，也就是使用 aof-load-truncated 等于 yes 的配置，Redis 在启动时会忽略最后一条命令，并顺利启动 Redis，执行结果如下：\n1 2 3 4 5  * Reading RDB preamble from AOF file... * Reading the remaining AOF tail... # !!! Warning: short read while loading the AOF file !!! # !!! Truncating the AOF at offset 439 !!! # AOF loaded anyway because aof-load-truncated is enabled   复杂异常数据恢复 AOF 文件可能出现更糟糕的情况，当 AOF 文件不仅被截断，而且中间的命令也被破坏，这个时候再启动 Redis 会提示错误信息并中止运行，错误信息如下：\n1 2  * Reading the remaining AOF tail... # Bad file format reading the append only file: make a backup of your AOF file, then use ./redis-check-aof --fix \u0026lt;filename\u0026gt;   出现此类问题的解决方案如下：\n 首先使用 AOF 修复工具，检测出现的问题，在命令行中输入 redis-check-aof 命令，它会跳转到出现问题的命令行，这个时候可以尝试手动修复此文件； 如果无法手动修复，我们可以使用 redis-check-aof --fix 自动修复 AOF 异常文件，不过执行此命令，可能会导致异常部分至文件末尾的数据全部被丢弃。  优缺点 AOF 优点  AOF 持久化保存的数据更加完整，AOF 提供了三种保存策略：每次操作保存、每秒钟保存一次、跟随系统的持久化策略保存，其中每秒保存一次，从数据的安全性和性能两方面考虑是一个不错的选择，也是 AOF 默认的策略，即使发生了意外情况，最多只会丢失 1s 钟的数据； AOF 采用的是命令追加的写入方式，所以不会出现文件损坏的问题，即使由于某些意外原因，导致了最后操作的持久化数据写入了一半，也可以通过 redis-check-aof 工具轻松的修复； AOF 持久化文件，非常容易理解和解析，它是把所有 Redis 键值操作命令，以文件的方式存入了磁盘。即使不小心使用 flushall 命令删除了所有键值信息，只要使用 AOF 文件，删除最后的 flushall 命令，重启 Redis 即可恢复之前误删的数据。  AOF 缺点  对于相同的数据集来说，AOF 文件要大于 RDB 文件； 在 Redis 负载比较高的情况下，RDB 比 AOF 性能更好； RDB 使用快照的形式来持久化整个 Redis 数据，而 AOF 只是将每次执行的命令追加到 AOF 文件中，因此从理论上说，RDB 比 AOF 更健壮。  小结 AOF 保存数据更加完整，它可以记录每次 Redis 的键值变化，或者是选择每秒保存一次数据。AOF 的持久化文件更加易读，但相比与二进制的 RDB 来说，所占的存储空间也越大，为了解决这个问题，AOF 提供自动化重写机制，最大程度的减少了 AOF 占用空间大的问题。同时 AOF 也提供了很方便的异常文件恢复命令： redis-check-aof --fix ，为使用 AOF 提供了很好的保障。\nRedis持久化\u0026ndash;混合持久化 RDB 和 AOF 持久化各有利弊，RDB 可能会导致一定时间内的数据丢失，而 AOF 由于文件较大则会影响 Redis 的启动速度，为了能同时使用 RDB 和 AOF 各种的优点，Redis 4.0 之后新增了混合持久化的方式。\n在开启混合持久化的情况下，AOF 重写时会把 Redis 的持久化数据，以 RDB 的格式写入到 AOF 文件的开头，之后的数据再以 AOF 的格式化追加的文件的末尾。\n混合持久化的数据存储结构如下图所示：\n开启混合持久化 查询是否开启混合持久化可以使用 config get aof-use-rdb-preamble 命令，执行结果如下图所示：\n其中 yes 表示已经开启混合持久化，no 表示关闭，Redis 5.0 默认值为 yes。 如果是其他版本的 Redis 首先需要检查一下，是否已经开启了混合持久化，如果关闭的情况下，可以通过以下两种方式开启：\n 通过命令行开启 通过修改 Redis 配置文件开启  通过命令行开启 使用命令 config set aof-use-rdb-preamble yes 执行结果如下图所示：\n 小贴士：命令行设置配置的缺点是重启 Redis 服务之后，设置的配置就会失效。\n 通过修改 Redis 配置文件开启 在 Redis 的根路径下找到 redis.conf 文件，把配置文件中的 aof-use-rdb-preamble no 改为 aof-use-rdb-preamble yes 如下图所示：\n实例运行 当在混合持久化关闭的情况下，使用 bgrewriteaof 触发 AOF 文件重写之后，查看 appendonly.aof 文件的持久化日志，如下图所示：\n可以看出，当混合持久化关闭的情况下 AOF 持久化文件存储的为标准的 AOF 格式的文件。 当混合持久化开启的模式下，使用 bgrewriteaof 命令触发 AOF 文件重写，得到 appendonly.aof 的文件内容如下图所示：\n可以看出 appendonly.aof 文件存储的内容是 REDIS 开头的 RDB 格式的内容，并非为 AOF 格式的日志。\n数据恢复和源码解析 混合持久化的数据恢复和 AOF 持久化过程是一样的，只需要把 appendonly.aof 放到 Redis 的根目录，在 Redis 启动时，只要开启了 AOF 持久化，Redis 就会自动加载并恢复数据。 Redis 启动信息如下图所示：\n可以看出 Redis 在服务器初始化的时候加载了 AOF 文件的内容。\n混合持久化的加载流程 混合持久化的加载流程如下：\n 判断是否开启 AOF 持久化，开启继续执行后续流程，未开启执行加载 RDB 文件的流程； 判断 appendonly.aof 文件是否存在，文件存在则执行后续流程； 判断 AOF 文件开头是 RDB 的格式, 先加载 RDB 内容再加载剩余的 AOF 内容； 判断 AOF 文件开头不是 RDB 的格式，直接以 AOF 格式加载整个文件。  AOF 加载流程图如下图所示：\n源码解析 Redis 判断 AOF 文件的开头是否是 RDB 格式的，是通过关键字 REDIS 判断的，RDB 文件的开头一定是 REDIS 关键字开头的，判断源码在 Redis 的 src/aof.c 中，核心代码如下所示：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  char sig[5]; /* \u0026#34;REDIS\u0026#34; */ if (fread(sig,1,5,fp) != 5 || memcmp(sig,\u0026#34;REDIS\u0026#34;,5) != 0) { // AOF 文件开头非 RDB 格式，非混合持久化文件  if (fseek(fp,0,SEEK_SET) == -1) goto readerr; } else { /* RDB preamble. Pass loading the RDB functions. */ rio rdb; serverLog(LL_NOTICE,\u0026#34;Reading RDB preamble from AOF file...\u0026#34;); if (fseek(fp,0,SEEK_SET) == -1) goto readerr; rioInitWithFile(\u0026amp;rdb,fp); // AOF 文件开头是 RDB 格式，先加载 RDB 再加载 AOF  if (rdbLoadRio(\u0026amp;rdb,NULL,1) != C_OK) { serverLog(LL_WARNING,\u0026#34;Error reading the RDB preamble of the AOF file, AOF loading aborted\u0026#34;); goto readerr; } else { serverLog(LL_NOTICE,\u0026#34;Reading the remaining AOF tail...\u0026#34;); } } // 加载 AOF 格式的数据   可以看出 Redis 是通过判断 AOF 文件的开头是否是 REDIS 关键字，来确定此文件是否为混合持久化文件的。\n 小贴士：AOF 格式的开头是 *，而 RDB 格式的开头是 REDIS。\n 优缺点 混合持久化优点：\n 混合持久化结合了 RDB 和 AOF 持久化的优点，开头为 RDB 的格式，使得 Redis 可以更快的启动，同时结合 AOF 的优点，有减低了大量数据丢失的风险。  混合持久化缺点：\n AOF 文件中添加了 RDB 格式的内容，使得 AOF 文件的可读性变得很差； 兼容性差，如果开启混合持久化，那么此混合持久化 AOF 文件，就不能用在 Redis 4.0 之前版本了。  持久化最佳实践 持久化虽然保证了数据不丢失，但同时拖慢了 Redis 的运行速度，那怎么更合理的使用 Redis 的持久化功能呢？ Redis 持久化的最佳实践可从以下几个方面考虑。\n控制持久化开关 使用者可根据实际的业务情况考虑，如果对数据的丢失不敏感的情况下，可考虑关闭 Redis 的持久化，这样所以的键值操作都在内存中，就可以保证最高效率的运行 Redis 了。 持久化关闭操作：\n 关闭 RDB 持久化，使用命令： config set save \u0026quot;\u0026quot; 关闭 AOF 和 混合持久化，使用命令： config set appendonly no  主从部署 使用主从部署，一台用于响应主业务，一台用于数据持久化，这样就可能让 Redis 更加高效的运行。\n使用混合持久化 混合持久化结合了 RDB 和 AOF 的优点，Redis 5.0 默认是开启的。\n使用配置更高的机器 Redis 对 CPU 的要求并不高，反而是对内存和磁盘的要求很高，因为 Redis 大部分时候都在做读写操作，使用更多的内存和更快的磁盘，对 Redis 性能的提高非常有帮助。\n","date":"2021-09-26T13:36:41Z","image":"https://ahao.ink/26.jpg","permalink":"https://ahao.ink/posts/redis%E6%8C%81%E4%B9%85%E5%8C%96/","title":"Redis持久化"},{"content":"命令执行流程 一条命令的执行过程有很多细节，但大体可分为：客户端先将用户输入的命令，转化为 Redis 相关的通讯协议，再用 socket 连接的方式将内容发送给服务器端，服务器端在接收到相关内容之后，先将内容转化为具体的执行命令，再判断用户授权信息和其他相关信息，当验证通过之后会执行最终命令，命令执行完之后，会进行相关的信息记录和数据统计，然后再把执行结果发送给客户端，这样一条命令的执行流程就结束了。如果是集群模式的话，主节点还会将命令同步至子节点，下面我们一起来看更加具体的执行流程。\n步骤一：用户输入一条命令\n步骤二：客户端先将命令转换成 Redis 协议，然后再通过 socket 连接发送给服务器端\n客户端和服务器端是基于 socket 通信的，服务器端在初始化时会创建了一个 socket 监听，用于监测链接客户端的 socket 链接，源码如下：\n1 2 3 4 5 6 7 8  void initServer(void) { //......  // 开启 Socket 事件监听  if (server.port != 0 \u0026amp;\u0026amp; listenToPort(server.port,server.ipfd,\u0026amp;server.ipfd_count) == C_ERR) exit(1); //...... }    socket 小知识：每个 socket 被创建后，会分配两个缓冲区，输入缓冲区和输出缓冲区。 写入函数并不会立即向网络中传输数据，而是先将数据写入缓冲区中，再由 TCP 协议将数据从缓冲区发送到目标机器。一旦将数据写入到缓冲区，函数就可以成功返回，不管它们有没有到达目标机器，也不管它们何时被发送到网络，这些都是 TCP 协议负责的事情。 注意：数据有可能刚被写入缓冲区就发送到网络，也可能在缓冲区中不断积压，多次写入的数据被一次性发送到网络，这取决于当时的网络情况、当前线程是否空闲等诸多因素，不由程序员控制。 读取函数也是如此，它也是从输入缓冲区中读取数据，而不是直接从网络中读取。\n 当 socket 成功连接之后，客户端会先把命令转换成 Redis 通讯协议（RESP 协议，REdis Serialization Protocol）发送给服务器端，这个通信协议是为了保障服务器能最快速的理解命令的含义而制定的，如果没有这个通讯协议，那么 Redis 服务器端要遍历所有的空格以确认此条命令的含义，这样会加大服务器的运算量，而直接发送通讯协议，相当于把服务器端的解析工作交给了每一个客户端，这样会很大程度的提高 Redis 的运行速度。例如，当我们输入 set key val 命令时，客户端会把这个命令转换为 *3\\r\\n$3\\r\\nSET\\r\\n$4\\r\\nKEY\\r\\n$4\\r\\nVAL\\r\\n 协议发送给服务器端。 更多通讯协议，可访问官方文档：https://redis.io/topics/protocol\n扩展知识：I/O 多路复用\nRedis 使用的是 I/O 多路复用功能来监听多 socket 链接的，这样就可以使用一个线程链接来处理多个请求，减少线程切换带来的开销，同时也避免了 I/O 阻塞操作，从而大大提高了 Redis 的运行效率。\nI/O 多路复用机制如下图所示：综合来说，此步骤的执行流程如下：\n 与服务器端以 socket 和 I/O 多路复用的技术建立链接； 将命令转换为 Redis 通讯协议，再将这些协议发送至缓冲区。  步骤三：服务器端接收到命令\n服务器会先去输入缓冲中读取数据，然后判断数据的大小是否超过了系统设置的值(默认是 1GB)，如果大于此值就会返回错误信息，并关闭客户端连接。 默认大小如下图所示：当数据大小验证通过之后，服务器端会对输入缓冲区中的请求命令进行分析，提取命令请求中包含的命令参数，存储在 client 对象(服务器端会为每个链接创建一个 Client 对象)的属性中。\n步骤四：执行前准备\n① 判断是否为退出命令，如果是则直接返回；\n② 非 null 判断，检查 client 对象是否为 null，如果是返回错误信息；\n③ 获取执行命令，根据 client 对象存储的属性信息去 redisCommand 结构中查询执行命令；\n④ 用户权限效验，未通过身份验证的客户端只能执行 AUTH(授权) 命令，未通过身份验证的客户端执行了 AUTH 之外的命令则返回错误信息；\n⑤ 集群相关操作，如果是集群模式，把命令重定向到目标节点，如果是 master(主节点) 则不需要重定向；\n⑥ 检查服务器端最大内存限制，如果服务器端开启了最大内存限制，会先检查内存大小，如果内存超过了最大值会对内存进行回收操作；\n⑦ 持久化检测，检查服务器是否开启了持久化和持久化出错停止写入配置，如果开启了此配置并且有持久化失败的情况，禁止执行写命令；\n⑧ 集群模式最少从节点(slave)验证，如果是集群模式并且配置了 replminslavestowrite(最小从节点写入)，当从节点的数量少于配置项时，禁止执行写命令；\n⑨ 只读从节点验证，当此服务器为只读从节点时，只接受 master 的写命令；\n⑩ 客户端订阅判断，当客户端正在订阅频道时，只会执行部分命令（只会执行 SUBSCRIBE、PSUBSCRIBE、UNSUBSCRIBE、PUNSUBSCRIBE，其他命令都会被拒绝）。\n⑪ 从节点状态效验，当服务器为 slave 并且没有连接 master 时，只会执行状态查询相关的命令，如 info 等；\n⑫ 服务器初始化效验，当服务器正在启动时，只会执行 loading 标志的命令，其他的命令都会被拒绝；\n⑬ lua 脚本阻塞效验，当服务器因为执行 lua 脚本阻塞时，只会执行部分命令；\n⑭ 事务命令效验，如果执行的是事务命令，则开启事务把命令放入等待队列；\n⑮ 监视器 (monitor) 判断，如果服务器打开了监视器功能，那么服务器也会把执行命令和相关参数发送给监视器 (监视器是用于监控服务器运行状态的)。\n当服务器经过以上操作之后，就可以执行真正的操作命令了。\n步骤五：执行最终命令，调用 redisCommand 中的 proc 函数执行命令。\n步骤六：执行完后相关记录和统计 ① 检查慢查询是否开启，如果开启会记录慢查询日志； ② 检查统计信息是否开启，如果开启会记录一些统计信息，例如执行命令所耗费时长和计数器(calls)加1； ③ 检查持久化功能是否开启，如果开启则会记录持久化信息； ④ 如果有其它从服务器正在复制当前服务器，则会将刚刚执行的命令传播给其他从服务器。\n步骤七：返回结果给客户端 命令执行完之后，服务器会通过 socket 的方式把执行结果发送给客户端，客户端再把结果展示给用户，至此一条命令的执行就结束了。\n小结 当用户输入一条命令之后，客户端会以 socket 的方式把数据转换成 Redis 协议，并发送至服务器端，服务器端在接受到数据之后，会先将协议转换为真正的执行命令，在经过各种验证以保证命令能够正确并安全的执行，但验证处理完之后，会调用具体的方法执行此条命令，执行完成之后会进行相关的统计和记录，然后再把执行结果返回给客户端，整个执行流程，如下图所示：\n更多执行细节，可在 Redis 的源码文件 server.c 中查看。\n","date":"2021-09-26T13:36:41Z","image":"https://ahao.ink/27.png","permalink":"https://ahao.ink/posts/redis%E6%98%AF%E5%A6%82%E4%BD%95%E6%89%A7%E8%A1%8C%E7%9A%84/","title":"Redis是如何执行的"},{"content":"本文收集了一些 Redis 使用中经常遇到的一些问题，和与之相对应的解决方案。\n缓存雪崩 缓存雪崩是指在短时间内，有大量缓存同时过期，导致大量的请求直接查询数据库，从而对数据库造成了巨大的压力，严重情况下可能会导致数据库宕机的情况叫做缓存雪崩。\n我们先来看下正常情况下和缓存雪崩时程序的执行流程图，正常情况下系统的执行流程如下图所示：\n缓存雪崩的执行流程，如下图所示：\n以上对比图可以看出缓存雪崩对系统造成的影响，那如何解决缓存雪崩的问题？\n缓存雪崩的常用解决方案有以下几个。\n加锁排队 加锁排队可以起到缓冲的作用，防止大量的请求同时操作数据库，但它的缺点是增加了系统的响应时间，降低了系统的吞吐量，牺牲了一部分用户体验。\n加锁排队的代码实现，如下所示：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  // 缓存 key String cacheKey = \u0026#34;userlist\u0026#34;; // 查询缓存 String data = jedis.get(cacheKey); if (StringUtils.isNotBlank(data)) { // 查询到数据，直接返回结果  return data; } else { // 先排队查询数据库，在放入缓存  synchronized (cacheKey) { data = jedis.get(cacheKey); if (!StringUtils.isNotBlank(data)) { // 双重判断  // 查询数据库  data = findUserInfo(); // 放入缓存  jedis.set(cacheKey, data); } return data; } }   以上为加锁排队的实现示例，读者可根据自己的实际项目情况做相应的修改。\n随机化过期时间 为了避免缓存同时过期，可在设置缓存时添加随机时间，这样就可以极大的避免大量的缓存同时失效。\n示例代码如下：\n1 2 3 4 5 6  // 缓存原本的失效时间 int exTime = 10 * 60; // 随机数生成类 Random random = new Random(); // 缓存设置 jedis.setex(cacheKey, exTime+random.nextInt(1000) , value);   设置二级缓存 二级缓存指的是除了 Redis 本身的缓存，再设置一层缓存，当 Redis 失效之后，先去查询二级缓存。\n例如可以设置一个本地缓存，在 Redis 缓存失效的时候先去查询本地缓存而非查询数据库。\n加入二级缓存之后程序执行流程，如下图所示：\n缓存穿透 缓存穿透是指查询数据库和缓存都无数据，因为数据库查询无数据，出于容错考虑，不会将结果保存到缓存中，因此每次请求都会去查询数据库，这种情况就叫做缓存穿透。\n缓存穿透执行流程如下图所示：\n其中红色路径表示缓存穿透的执行路径，可以看出缓存穿透会给数据库造成很大的压力。\n缓存穿透的解决方案有以下几个。\n使用过滤器 我们可以使用过滤器来减少对数据库的请求，例如使用我们前面章节所学的布隆过滤器，我们这里简单复习一下布隆过滤器，它的原理是将数据库的数据哈希到 bitmap 中，每次查询之前，先使用布隆过滤器过滤掉一定不存在的无效请求，从而避免了无效请求给数据库带来的查询压力。\n缓存空结果 另一种方式是我们可以把每次从数据库查询的数据都保存到缓存中，为了提高前台用户的使用体验 (解决长时间内查询不到任何信息的情况)，我们可以将空结果的缓存时间设置得短一些，例如 3~5 分钟。\n缓存击穿 缓存击穿指的是某个热点缓存，在某一时刻恰好失效了，然后此时刚好有大量的并发请求，此时这些请求将会给数据库造成巨大的压力，这种情况就叫做缓存击穿。\n缓存击穿的执行流程如下图所示：\n它的解决方案有以下 2 个。\n加锁排队 此处理方式和缓存雪崩加锁排队的方法类似，都是在查询数据库时加锁排队，缓冲操作请求以此来减少服务器的运行压力。\n设置永不过期 对于某些热点缓存，我们可以设置永不过期，这样就能保证缓存的稳定性，但需要注意在数据更改之后，要及时更新此热点缓存，不然就会造成查询结果的误差。\n缓存预热 首先来说，缓存预热并不是一个问题，而是使用缓存时的一个优化方案，它可以提高前台用户的使用体验。\n缓存预热指的是在系统启动的时候，先把查询结果预存到缓存中，以便用户后面查询时可以直接从缓存中读取，以节约用户的等待时间。\n缓存预热的执行流程，如下图所示：\n缓存预热的实现思路有以下三种：\n 把需要缓存的方法写在系统初始化的方法中，这样系统在启动的时候就会自动的加载数据并缓存数据； 把需要缓存的方法挂载到某个页面或后端接口上，手动触发缓存预热； 设置定时任务，定时自动进行缓存预热。  小结 本文介绍了缓存雪崩产生的原因是因为短时间内大量缓存同时失效，而导致大量请求直接查询数据库的情况，解决方案是加锁、随机设置过期时间和设置二级缓存等；还介绍了查询数据库无数据时会导致的每次空查询都不走缓存的缓存穿透问题，解决方案是使用布隆过滤器和缓存空结果等；同时还介绍了缓存在某一个高并发时刻突然失效导致的缓存击穿问题，以及解决方案——加锁、设置永不过期等方案，最后还介绍了优化系统性能的手段缓存预热。\n","date":"2021-09-26T13:36:41Z","image":"https://ahao.ink/25.png","permalink":"https://ahao.ink/posts/redis%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB%E5%92%8C%E7%9B%B8%E5%85%B3%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/","title":"Redis问题汇总和相关解决方案"},{"content":"索引 提到数据库索引，大家都不陌生。比如某一个SQL查询比较慢，分析完原因之后，你可能就会说“给某个字段加个索引吧”之类的解决方案。但到底什么是索引，索引又是如何工作的呢？\n一句话简单来说，索引的出现其实就是为了提高数据查询的效率，就像书的目录一样。一本500页的书，如果你想快速找到其中的某一个知识点，在不借助目录的情况下，那我估计你可得找一会儿。同样，对于数据库的表而言，索引其实就是它的“目录”。\n索引的常见模型 索引的出现是为了提高查询效率，但是实现索引的方式却有很多种，所以这里也就引入了索引模型的概念。可以用于提高读写效率的数据结构很多，这里我先给你介绍三种常见、也比较简单的数据结构，它们分别是哈希表、有序数组和搜索树。\n下面主要从使用的角度，简单分析一下这三种模型的区别。\n哈希表是一种以键-值（key-value）存储数据的结构，我们只要输入待查找的值即key，就可以找到其对应的值即Value。哈希的思路很简单，把值放在数组里，用一个哈希函数把key换算成一个确定的位置，然后把value放在数组的这个位置。\n不可避免地，多个key值经过哈希函数的换算，会出现同一个值的情况。处理这种情况的一种方法是，拉出一个链表。\n假设，你现在维护着一个身份证信息和姓名的表，需要根据身份证号查找对应的名字，这时对应的哈希索引的示意图如下所示：\n图中，User2和User4根据身份证号算出来的值都是N，但没关系，后面还跟了一个链表。假设，这时候你要查ID_card_n2对应的名字是什么，处理步骤就是：首先，将ID_card_n2通过哈希函数算出N；然后，按顺序遍历，找到User2。\n需要注意的是，图中四个ID_card_n的值并不是递增的，这样做的好处是增加新的User时速度会很快，只需要往后追加。但缺点是，因为不是有序的，所以哈希索引做区间查询的速度是很慢的。\n你可以设想下，如果你现在要找身份证号在[ID_card_X, ID_card_Y]这个区间的所有用户，就必须全部扫描一遍了。\n所以，哈希表这种结构适用于只有等值查询的场景，比如Memcached及其他一些NoSQL引擎。\n而有序数组在等值查询和范围查询场景中的性能就都非常优秀。还是上面这个根据身份证号查名字的例子，如果我们使用有序数组来实现的话，示意图如下所示：\n这里我们假设身份证号没有重复，这个数组就是按照身份证号递增的顺序保存的。这时候如果你要查ID_card_n2对应的名字，用二分法就可以快速得到，这个时间复杂度是O(log(N))。\n同时很显然，这个索引结构支持范围查询。你要查身份证号在[ID_card_X, ID_card_Y]区间的User，可以先用二分法找到ID_card_X（如果不存在ID_card_X，就找到大于ID_card_X的第一个User），然后向右遍历，直到查到第一个大于ID_card_Y的身份证号，退出循环。\n如果仅仅看查询效率，有序数组就是最好的数据结构了。但是，在需要更新数据的时候就麻烦了，你往中间插入一个记录就必须得挪动后面所有的记录，成本太高。\n所以，有序数组索引只适用于静态存储引擎，比如你要保存的是2017年某个城市的所有人口信息，这类不会再修改的数据。\n二叉搜索树也是课本里的经典数据结构了。还是上面根据身份证号查名字的例子，如果我们用二叉搜索树来实现的话，示意图如下所示：\n二叉搜索树的特点是：每个节点的左儿子小于父节点，父节点又小于右儿子。这样如果你要查ID_card_n2的话，按照图中的搜索顺序就是按照UserA -\u0026gt; UserC -\u0026gt; UserF -\u0026gt; User2这个路径得到。这个时间复杂度是O(log(N))。\n当然为了维持O(log(N))的查询复杂度，你就需要保持这棵树是平衡二叉树。为了做这个保证，更新的时间复杂度也是O(log(N))。\n树可以有二叉，也可以有多叉。多叉树就是每个节点有多个儿子，儿子之间的大小保证从左到右递增。二叉树是搜索效率最高的，但是实际上大多数的数据库存储却并不使用二叉树。其原因是，索引不止存在内存中，还要写到磁盘上。\n你可以想象一下一棵100万节点的平衡二叉树，树高20。一次查询可能需要访问20个数据块。在机械硬盘时代，从磁盘随机读一个数据块需要10 ms左右的寻址时间。也就是说，对于一个100万行的表，如果使用二叉树来存储，单独访问一个行可能需要20个10 ms的时间，这个查询可真够慢的。\n为了让一个查询尽量少地读磁盘，就必须让查询过程访问尽量少的数据块。那么，我们就不应该使用二叉树，而是要使用“N叉”树。这里，“N叉”树中的“N”取决于数据块的大小。\n以InnoDB的一个整数字段索引为例，这个N差不多是1200。这棵树高是4的时候，就可以存1200的3次方个值，这已经17亿了。考虑到树根的数据块总是在内存中的，一个10亿行的表上一个整数字段的索引，查找一个值最多只需要访问3次磁盘。其实，树的第二层也有很大概率在内存中，那么访问磁盘的平均次数就更少了。\nN叉树由于在读写上的性能优点，以及适配磁盘的访问模式，已经被广泛应用在数据库引擎中了。\n不管是哈希还是有序数组，或者N叉树，它们都是不断迭代、不断优化的产物或者解决方案。数据库技术发展到今天，跳表、LSM树等数据结构也被用于引擎设计中，这里就不再一一展开了。\n心里要有个概念，数据库底层存储的核心就是基于这些数据模型的。每碰到一个新数据库，我们需要先关注它的数据模型，这样才能从理论上分析出这个数据库的适用场景。\n截止到这里，我用了半篇文章的篇幅和你介绍了不同的数据结构，以及它们的适用场景，你可能会觉得有些枯燥。但是，我建议你还是要多花一些时间来理解这部分内容，毕竟这是数据库处理数据的核心概念之一，在分析问题的时候会经常用到。当你理解了索引的模型后，就会发现在分析问题的时候会有一个更清晰的视角，体会到引擎设计的精妙之处。\n现在，我们一起进入相对偏实战的内容吧。\n在MySQL中，索引是在存储引擎层实现的，所以并没有统一的索引标准，即不同存储引擎的索引的工作方式并不一样。而即使多个存储引擎支持同一种类型的索引，其底层的实现也可能不同。由于InnoDB存储引擎在MySQL数据库中使用最为广泛，所以下面我就以InnoDB为例，和你分析一下其中的索引模型。\nInnoDB 的索引模型 在InnoDB中，表都是根据主键顺序以索引的形式存放的，这种存储方式的表称为索引组织表。又因为前面我们提到的，InnoDB使用了B+树索引模型，所以数据都是存储在B+树中的。\n每一个索引在InnoDB里面对应一棵B+树。\n假设，我们有一个主键列为ID的表，表中有字段k，并且在k上有索引。\n这个表的建表语句是：\n1 2 3 4 5  mysql\u0026gt; create table T( id int primary key, k int not null, name varchar(16), index (k))engine=InnoDB;   表中R1~R5的(ID,k)值分别为(100,1)、(200,2)、(300,3)、(500,5)和(600,6)，两棵树的示例示意图如下。\n从图中不难看出，根据叶子节点的内容，索引类型分为主键索引和非主键索引。\n主键索引的叶子节点存的是整行数据。在InnoDB里，主键索引也被称为聚簇索引（clustered index）。\n非主键索引的叶子节点内容是主键的值。在InnoDB里，非主键索引也被称为二级索引（secondary index）。\n根据上面的索引结构说明，我们来讨论一个问题：基于主键索引和普通索引的查询有什么区别？\n 如果语句是select * from T where ID=500，即主键查询方式，则只需要搜索ID这棵B+树； 如果语句是select * from T where k=5，即普通索引查询方式，则需要先搜索k索引树，得到ID的值为500，再到ID索引树搜索一次。这个过程称为回表。  也就是说，基于非主键索引的查询需要多扫描一棵索引树。因此，我们在应用中应该尽量使用主键查询。\n索引维护 B+树为了维护索引有序性，在插入新值的时候需要做必要的维护。以上面这个图为例，如果插入新的行ID值为700，则只需要在R5的记录后面插入一个新记录。如果新插入的ID值为400，就相对麻烦了，需要逻辑上挪动后面的数据，空出位置。\n而更糟的情况是，如果R5所在的数据页已经满了，根据B+树的算法，这时候需要申请一个新的数据页，然后挪动部分数据过去。这个过程称为页分裂。在这种情况下，性能自然会受影响。\n除了性能外，页分裂操作还影响数据页的利用率。原本放在一个页的数据，现在分到两个页中，整体空间利用率降低大约50%。\n当然有分裂就有合并。当相邻两个页由于删除了数据，利用率很低之后，会将数据页做合并。合并的过程，可以认为是分裂过程的逆过程。\n基于上面的索引维护过程说明，我们来讨论一个案例：\n 你可能在一些建表规范里面见到过类似的描述，要求建表语句里一定要有自增主键。当然事无绝对，我们来分析一下哪些场景下应该使用自增主键，而哪些场景下不应该。\n 自增主键是指自增列上定义的主键，在建表语句中一般是这么定义的： NOT NULL PRIMARY KEY AUTO_INCREMENT。\n插入新记录的时候可以不指定ID的值，系统会获取当前ID最大值加1作为下一条记录的ID值。\n也就是说，自增主键的插入数据模式，正符合了我们前面提到的递增插入的场景。每次插入一条新记录，都是追加操作，都不涉及到挪动其他记录，也不会触发叶子节点的分裂。\n而有业务逻辑的字段做主键，则往往不容易保证有序插入，这样写数据成本相对较高。\n除了考虑性能外，我们还可以从存储空间的角度来看。假设你的表中确实有一个唯一字段，比如字符串类型的身份证号，那应该用身份证号做主键，还是用自增字段做主键呢？\n由于每个非主键索引的叶子节点上都是主键的值。如果用身份证号做主键，那么每个二级索引的叶子节点占用约20个字节，而如果用整型做主键，则只要4个字节，如果是长整型（bigint）则是8个字节。\n显然，主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小。\n所以，从性能和存储空间方面考量，自增主键往往是更合理的选择。\n有没有什么场景适合用业务字段直接做主键的呢？还是有的。比如，有些业务的场景需求是这样的：\n 只有一个索引； 该索引必须是唯一索引。  你一定看出来了，这就是典型的KV场景。\n由于没有其他索引，所以也就不用考虑其他索引的叶子节点大小的问题。\n这时候我们就要优先考虑上一段提到的“尽量使用主键查询”原则，直接将这个索引设置为主键，可以避免每次查询需要搜索两棵树。\n在上一篇文章中，我和你介绍了InnoDB索引的数据结构模型，今天我们再继续聊聊跟MySQL索引有关的概念。\n在开始这篇文章之前，我们先来看一下这个问题：\n在下面这个表T中，如果我执行 select * from T where k between 3 and 5，需要执行几次树的搜索操作，会扫描多少行？\n下面是这个表的初始化语句。\n1 2 3 4 5 6 7 8  mysql\u0026gt; create table T ( ID int primary key, k int NOT NULL DEFAULT 0, s varchar(16) NOT NULL DEFAULT \u0026#39;\u0026#39;, index k(k)) engine=InnoDB; insert into T values(100,1, \u0026#39;aa\u0026#39;),(200,2,\u0026#39;bb\u0026#39;),(300,3,\u0026#39;cc\u0026#39;),(500,5,\u0026#39;ee\u0026#39;),(600,6,\u0026#39;ff\u0026#39;),(700,7,\u0026#39;gg\u0026#39;);   图1 InnoDB的索引组织结构\n现在，我们一起来看看这条SQL查询语句的执行流程：\n 在k索引树上找到k=3的记录，取得 ID = 300； 再到ID索引树查到ID=300对应的R3； 在k索引树取下一个值k=5，取得ID=500； 再回到ID索引树查到ID=500对应的R4； 在k索引树取下一个值k=6，不满足条件，循环结束。  在这个过程中，回到主键索引树搜索的过程，我们称为回表。可以看到，这个查询过程读了k索引树的3条记录（步骤1、3和5），回表了两次（步骤2和4）。\n在这个例子中，由于查询结果所需要的数据只在主键索引上有，所以不得不回表。那么，有没有可能经过索引优化，避免回表过程呢？\n覆盖索引 如果执行的语句是select ID from T where k between 3 and 5，这时只需要查ID的值，而ID的值已经在k索引树上了，因此可以直接提供查询结果，不需要回表。也就是说，在这个查询里面，索引k已经“覆盖了”我们的查询需求，我们称为覆盖索引。\n由于覆盖索引可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段。\n需要注意的是，在引擎内部使用覆盖索引在索引k上其实读了三个记录，R3~R5（对应的索引k上的记录项），但是对于MySQL的Server层来说，它就是找引擎拿到了两条记录，因此MySQL认为扫描行数是2。\n 备注：关于如何查看扫描行数的问题，我将会在第16文章《如何正确地显示随机消息？》中，和你详细讨论。\n 基于上面覆盖索引的说明，我们来讨论一个问题：在一个市民信息表上，是否有必要将身份证号和名字建立联合索引？\n假设这个市民表的定义是这样的：\n1 2 3 4 5 6 7 8 9 10  CREATETABLE`tuser`(`id`int(11)NOTNULL,`id_card`varchar(32)DEFAULTNULL,`name`varchar(32)DEFAULTNULL,`age`int(11)DEFAULTNULL,`ismale`tinyint(1)DEFAULTNULL,PRIMARYKEY(`id`),KEY`id_card`(`id_card`),KEY`name_age`(`name`,`age`))ENGINE=InnoDB  我们知道，身份证号是市民的唯一标识。也就是说，如果有根据身份证号查询市民信息的需求，我们只要在身份证号字段上建立索引就够了。而再建立一个（身份证号、姓名）的联合索引，是不是浪费空间？\n如果现在有一个高频请求，要根据市民的身份证号查询他的姓名，这个联合索引就有意义了。它可以在这个高频请求上用到覆盖索引，不再需要回表查整行记录，减少语句的执行时间。\n当然，索引字段的维护总是有代价的。因此，在建立冗余索引来支持覆盖索引时就需要权衡考虑了。这正是业务DBA，或者称为业务数据架构师的工作。\n最左前缀原则 看到这里你一定有一个疑问，如果为每一种查询都设计一个索引，索引是不是太多了。如果我现在要按照市民的身份证号去查他的家庭地址呢？虽然这个查询需求在业务中出现的概率不高，但总不能让它走全表扫描吧？反过来说，单独为一个不频繁的请求创建一个（身份证号，地址）的索引又感觉有点浪费。应该怎么做呢？\n这里，我先和你说结论吧。B+树这种索引结构，可以利用索引的“最左前缀”，来定位记录。\n为了直观地说明这个概念，我们用（name，age）这个联合索引来分析。\n可以看到，索引项是按照索引定义里面出现的字段顺序排序的。\n当你的逻辑需求是查到所有名字是“张三”的人时，可以快速定位到ID4，然后向后遍历得到所有需要的结果。\n如果你要查的是所有名字第一个字是“张”的人，你的SQL语句的条件是\u0026quot;where name like ‘张%’\u0026quot;。这时，你也能够用上这个索引，查找到第一个符合条件的记录是ID3，然后向后遍历，直到不满足条件为止。\n可以看到，不只是索引的全部定义，只要满足最左前缀，就可以利用索引来加速检索。这个最左前缀可以是联合索引的最左N个字段，也可以是字符串索引的最左M个字符。\n基于上面对最左前缀索引的说明，我们来讨论一个问题：在建立联合索引的时候，如何安排索引内的字段顺序。\n这里我们的评估标准是，索引的复用能力。因为可以支持最左前缀，所以当已经有了(a,b)这个联合索引后，一般就不需要单独在a上建立索引了。因此，第一原则是，如果通过调整顺序，可以少维护一个索引，那么这个顺序往往就是需要优先考虑采用的。\n所以现在你知道了，这段开头的问题里，我们要为高频请求创建(身份证号，姓名）这个联合索引，并用这个索引支持“根据身份证号查询地址”的需求。\n那么，如果既有联合查询，又有基于a、b各自的查询呢？查询条件里面只有b的语句，是无法使用(a,b)这个联合索引的，这时候你不得不维护另外一个索引，也就是说你需要同时维护(a,b)、(b) 这两个索引。\n这时候，我们要考虑的原则就是空间了。比如上面这个市民表的情况，name字段是比age字段大的 ，那我就建议你创建一个（name,age)的联合索引和一个(age)的单字段索引。\n索引下推 上一段我们说到满足最左前缀原则的时候，最左前缀可以用于在索引中定位记录。这时，你可能要问，那些不符合最左前缀的部分，会怎么样呢？\n我们还是以市民表的联合索引（name, age）为例。如果现在有一个需求：检索出表中“名字第一个字是张，而且年龄是10岁的所有男孩”。那么，SQL语句是这么写的：\n1  mysql\u0026gt; select * from tuser where name like \u0026#39;张%\u0026#39; and age=10 and ismale=1;   你已经知道了前缀索引规则，所以这个语句在搜索索引树的时候，只能用 “张”，找到第一个满足条件的记录ID3。当然，这还不错，总比全表扫描要好。\n然后呢？\n当然是判断其他条件是否满足。\n在MySQL 5.6之前，只能从ID3开始一个个回表。到主键索引上找出数据行，再对比字段值。\n而MySQL 5.6 引入的索引下推优化（index condition pushdown)， 可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。\n图3和图4，是这两个过程的执行流程图。\n图3 无索引下推执行流程\n图4\n在图3和4这两个图里面，每一个虚线箭头表示回表一次。\n图3中，在(name,age)索引里面我特意去掉了age的值，这个过程InnoDB并不会去看age的值，只是按顺序把“name第一个字是’张’”的记录一条条取出来回表。因此，需要回表4次。\n图4跟图3的区别是，InnoDB在(name,age)索引内部就判断了age是否等于10，对于不等于10的记录，直接判断并跳过。在我们的这个例子中，只需要对ID4、ID5这两条记录回表取数据判断，就只需要回表2次。\n小结 今天，我跟你分析了数据库引擎可用的数据结构，介绍了InnoDB采用的B+树结构，以及为什么InnoDB要这么选择。B+树能够很好地配合磁盘的读写特性，减少单次查询的磁盘访问次数。\n由于InnoDB是索引组织表，一般情况下我会建议你创建一个自增主键，这样非主键索引占用的空间最小。但事无绝对，我也跟你讨论了使用业务逻辑字段做主键的应用场景。\n今天这篇文章，我和你继续讨论了数据库索引的概念，包括了覆盖索引、前缀索引、索引下推。你可以看到，在满足语句需求的情况下， 尽量少地访问资源是数据库设计的重要原则之一。我们在使用数据库的时候，尤其是在设计表结构时，也要以减少资源消耗作为目标。\n","date":"2021-06-28T13:36:41Z","image":"https://ahao.ink/4.png","permalink":"https://ahao.ink/posts/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E7%B4%A2%E5%BC%95/","title":"深入浅出索引"},{"content":"事务隔离 提到事务，你肯定不陌生，和数据库打交道的时候，我们总是会用到事务。最经典的例子就是转账，你要给朋友小王转100块钱，而此时你的银行卡只有100块钱。\n转账过程具体到程序里会有一系列的操作，比如查询余额、做加减法、更新余额等，这些操作必须保证是一体的，不然等程序查完之后，还没做减法之前，你这100块钱，完全可以借着这个时间差再查一次，然后再给另外一个朋友转账，如果银行这么整，不就乱了么？这时就要用到“事务”这个概念了。\n简单来说，事务就是要保证一组数据库操作，要么全部成功，要么全部失败。在MySQL中，事务支持是在引擎层实现的。你现在知道，MySQL是一个支持多引擎的系统，但并不是所有的引擎都支持事务。比如MySQL原生的MyISAM引擎就不支持事务，这也是MyISAM被InnoDB取代的重要原因之一。\n本文将会以InnoDB为例，剖析MySQL在事务支持方面的特定实现，并基于原理给出相应的实践建议，加深对MySQL事务原理的理解。\n隔离性与隔离级别 提到事务，你肯定会想到ACID（Atomicity、Consistency、Isolation、Durability，即原子性、一致性、隔离性、持久性），今天我们就来说说其中I，也就是“隔离性”。\n当数据库上有多个事务同时执行的时候，就可能出现脏读（dirty read）、不可重复读（non-repeatable read）、幻读（phantom read）的问题，为了解决这些问题，就有了“隔离级别”的概念。\n在谈隔离级别之前，你首先要知道，你隔离得越严实，效率就会越低。因此很多时候，我们都要在二者之间寻找一个平衡点。SQL标准的事务隔离级别包括：读未提交（read uncommitted）、读提交（read committed）、可重复读（repeatable read）和串行化（serializable ）。\n 读未提交是指，一个事务还没提交时，它做的变更就能被别的事务看到。 读提交是指，一个事务提交之后，它做的变更才会被其他事务看到。 可重复读是指，一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。 串行化，顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。  其中“读提交”和“可重复读”比较难理解，用一个例子说明这几种隔离级别。假设数据表T中只有一列，其中一行的值为1，下面是按照时间顺序执行两个事务的行为。\n1 2  mysql\u0026gt;createtableT(cint)engine=InnoDB;insertintoT(c)values(1);  我们来看看在不同的隔离级别下，事务A会有哪些不同的返回结果，也就是图里面V1、V2、V3的返回值分别是什么。\n 若隔离级别是“读未提交”， 则V1的值就是2。这时候事务B虽然还没有提交，但是结果已经被A看到了。因此，V2、V3也都是2。 若隔离级别是“读提交”，则V1是1，V2的值是2。事务B的更新在提交后才能被A看到。所以， V3的值也是2。 若隔离级别是“可重复读”，则V1、V2是1，V3是2。之所以V2还是1，遵循的就是这个要求：事务在执行期间看到的数据前后必须是一致的。 若隔离级别是“串行化”，则在事务B执行“将1改成2”的时候，会被锁住。直到事务A提交后，事务B才可以继续执行。所以从A的角度看， V1、V2值是1，V3的值是2。  在实现上，数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准。在“可重复读”隔离级别下，这个视图是在事务启动时创建的，整个事务存在期间都用这个视图。在“读提交”隔离级别下，这个视图是在每个SQL语句开始执行的时候创建的。这里需要注意的是，“读未提交”隔离级别下直接返回记录上的最新值，没有视图概念；而“串行化”隔离级别下直接用加锁的方式来避免并行访问。\n我们可以看到在不同的隔离级别下，数据库行为是有所不同的。Oracle数据库的默认隔离级别其实就是“读提交”，因此对于一些从Oracle迁移到MySQL的应用，为保证数据库隔离级别的一致，你一定要记得将MySQL的隔离级别设置为“读提交”。\n配置的方式是，将启动参数transaction-isolation的值设置成READ-COMMITTED。你可以用show variables来查看当前的值。\n1 2 3 4 5 6 7 8 9 10 11  mysql\u0026gt;showvariableslike\u0026#39;transaction_isolation\u0026#39;;+-----------------------+----------------+ |Variable_name|Value|+-----------------------+----------------+ |transaction_isolation|READ-COMMITTED|+-----------------------+----------------+   总结来说，存在即合理，哪个隔离级别都有它自己的使用场景，你要根据自己的业务情况来定。我想你可能会问那什么时候需要“可重复读”的场景呢？我们来看一个数据校对逻辑的案例。\n假设你在管理一个个人银行账户表。一个表存了每个月月底的余额，一个表存了账单明细。这时候你要做数据校对，也就是判断上个月的余额和当前余额的差额，是否与本月的账单明细一致。你一定希望在校对过程中，即使有用户发生了一笔新的交易，也不影响你的校对结果。\n这时候使用“可重复读”隔离级别就很方便。事务启动时的视图可以认为是静态的，不受其他事务更新的影响。\n事务隔离的实现 理解了事务的隔离级别，我们再来看看事务隔离具体是怎么实现的。这里我们展开说明“可重复读”。\n在MySQL中，实际上每条记录在更新的时候都会同时记录一条回滚操作。记录上的最新值，通过回滚操作，都可以得到前一个状态的值。\n假设一个值从1被按顺序改成了2、3、4，在回滚日志里面就会有类似下面的记录。\n当前值是4，但是在查询这条记录的时候，不同时刻启动的事务会有不同的read-view。如图中看到的，在视图A、B、C里面，这一个记录的值分别是1、2、4，同一条记录在系统中可以存在多个版本，就是数据库的多版本并发控制（MVCC)。对于read-view A，要得到1，就必须将当前值依次执行图中所有的回滚操作得到。\n同时你会发现，即使现在有另外一个事务正在将4改成5，这个事务跟read-view A、B、C对应的事务是不会冲突的。\n你一定会问，回滚日志总不能一直保留吧，什么时候删除呢？答案是，在不需要的时候才删除。也就是说，系统会判断，当没有事务再需要用到这些回滚日志时，回滚日志会被删除。\n什么时候才不需要了呢？就是当系统里没有比这个回滚日志更早的read-view的时候。\n基于上面的说明，我们来讨论一下为什么建议你尽量不要使用长事务。\n长事务意味着系统里面会存在很老的事务视图。由于这些事务随时可能访问数据库里面的任何数据，所以这个事务提交之前，数据库里面它可能用到的回滚记录都必须保留，这就会导致大量占用存储空间。\n在MySQL 5.5及以前的版本，回滚日志是跟数据字典一起放在ibdata文件里的，即使长事务最终提交，回滚段被清理，文件也不会变小。我见过数据只有20GB，而回滚段有200GB的库。最终只好为了清理回滚段，重建整个库。\n除了对回滚段的影响，长事务还占用锁资源，也可能拖垮整个库，这个我们会在后面讲锁的时候展开。\n事务的启动方式 如前面所述，长事务有这些潜在风险，我当然是建议你尽量避免。其实很多时候业务开发同学并不是有意使用长事务，通常是由于误用所致。MySQL的事务启动方式有以下几种：\n 显式启动事务语句， begin 或 start transaction。配套的提交语句是commit，回滚语句是rollback。 set autocommit=0，这个命令会将这个线程的自动提交关掉。意味着如果你只执行一个select语句，这个事务就启动了，而且并不会自动提交。这个事务持续存在直到你主动执行commit 或 rollback 语句，或者断开连接。  有些客户端连接框架会默认连接成功后先执行一个set autocommit=0的命令。这就导致接下来的查询都在事务中，如果是长连接，就导致了意外的长事务。\n因此，我会建议你总是使用set autocommit=1, 通过显式语句的方式来启动事务。\n但是有的开发同学会纠结“多一次交互”的问题。对于一个需要频繁使用事务的业务，第二种方式每个事务在开始时都不需要主动执行一次 “begin”，减少了语句的交互次数。如果你也有这个顾虑，我建议你使用commit work and chain语法。\n在autocommit为1的情况下，用begin显式启动的事务，如果执行commit则提交事务。如果执行 commit work and chain，则是提交事务并自动启动下一个事务，这样也省去了再次执行begin语句的开销。同时带来的好处是从程序开发的角度明确地知道每个语句是否处于事务中。\n你可以在information_schema库的innodb_trx这个表中查询长事务，比如下面这个语句，用于查找持续时间超过60s的事务。\n1  select*frominformation_schema.innodb_trxwhereTIME_TO_SEC(timediff(now(),trx_started))\u0026gt;60  小结 这篇文章里面，介绍了MySQL的事务隔离级别的现象和实现，根据实现原理分析了长事务存在的风险，以及如何用正确的方式避免长事务。\n","date":"2021-06-24T13:36:41Z","image":"https://ahao.ink/5.jpg","permalink":"https://ahao.ink/posts/%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB/","title":"事务隔离"},{"content":"一条更新语句的执行流程是怎样的呢？\n之前你可能经常听 DBA 同事说，MySQL 可以恢复到半个月内任意一秒的状态，惊叹的同时，你是不是心中也会不免会好奇，这是怎样做到的呢？\n我们还是从一个表的一条更新语句说起，下面是这个表的创建语句，这个表有一个主键 ID 和一个整型字段 c：\n1  mysql\u0026gt;createtableT(IDintprimarykey,cint);  如果要将 ID=2 这一行的值加 1，SQL 语句就会这么写：\n1  mysql\u0026gt;updateTsetc=c+1whereID=2;  首先，可以确定的说，查询语句的那一套流程，更新语句也是同样会走一遍。\n执行语句前要先连接数据库，这是连接器的工作。\n前面我们说过，在一个表上有更新的时候，跟这个表有关的查询缓存会失效，所以这条语句就会把表 T 上所有缓存结果都清空。这也就是我们一般不建议使用查询缓存的原因。\n接下来，分析器会通过词法和语法解析知道这是一条更新语句。优化器决定要使用 ID 这个索引。然后，执行器负责具体执行，找到这一行，然后更新。\n与查询流程不一样的是，更新流程还涉及两个重要的日志模块：redo log（重做日志）和 binlog（归档日志）。如果接触 MySQL，那这两个词肯定是绕不过的。\nredo log 不知道你还记不记得《孔乙己》这篇文章，酒店掌柜有一个粉板，专门用来记录客人的赊账记录。如果赊账的人不多，那么他可以把顾客名和账目写在板上。但如果赊账的人多了，粉板总会有记不下的时候，这个时候掌柜一定还有一个专门记录赊账的账本。\n如果有人要赊账或者还账的话，掌柜一般有两种做法：\n 一种做法是直接把账本翻出来，把这次赊的账加上去或者扣除掉； 另一种做法是先在粉板上记下这次的账，等打烊以后再把账本翻出来核算。  在生意红火柜台很忙时，掌柜一定会选择后者，因为前者操作实在是太麻烦了。首先，你得找到这个人的赊账总额那条记录。你想想，密密麻麻几十页，掌柜要找到那个名字，可能还得带上老花镜慢慢找，找到之后再拿出算盘计算，最后再将结果写回到账本上。\n这整个过程想想都麻烦。相比之下，还是先在粉板上记一下方便。你想想，如果掌柜没有粉板的帮助，每次记账都得翻账本，效率是不是低得让人难以忍受？\n同样，在 MySQL 里也有这个问题，如果每一次的更新操作都需要写进磁盘，然后磁盘也要找到对应的那条记录，然后再更新，整个过程 IO 成本、查找成本都很高。为了解决这个问题，MySQL 的设计者就用了类似酒店掌柜粉板的思路来提升更新效率。\n而粉板和账本配合的整个过程，其实就是 MySQL 里经常说到的 WAL 技术，WAL 的全称是 Write-Ahead Logging，它的关键点就是先写日志，再写磁盘，也就是先写粉板，等不忙的时候再写账本。\n具体来说，当有一条记录需要更新的时候，InnoDB 引擎就会先把记录写到 redo log（粉板）里面，并更新内存，这个时候更新就算完成了。同时，InnoDB 引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做，这就像打烊以后掌柜做的事。\n如果今天赊账的不多，掌柜可以等打烊后再整理。但如果某天赊账的特别多，粉板写满了，又怎么办呢？这个时候掌柜只好放下手中的活儿，把粉板中的一部分赊账记录更新到账本中，然后把这些记录从粉板上擦掉，为记新账腾出空间。\n与此类似，InnoDB 的 redo log 是固定大小的，比如可以配置为一组 4 个文件，每个文件的大小是 1GB，那么这块“粉板”总共就可以记录 4GB 的操作。从头开始写，写到末尾就又回到开头循环写，如下面这个图所示。\nwrite pos 是当前记录的位置，一边写一边后移，写到第 3 号文件末尾后就回到 0 号文件开头。checkpoint 是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件。\nwrite pos 和 checkpoint 之间的是“粉板”上还空着的部分，可以用来记录新的操作。如果 write pos 追上 checkpoint，表示“粉板”满了，这时候不能再执行新的更新，得停下来先擦掉一些记录，把 checkpoint 推进一下。\n有了 redo log，InnoDB 就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为crash-safe。\n要理解 crash-safe 这个概念，可以想想我们前面赊账记录的例子。只要赊账记录记在了粉板上或写在了账本上，之后即使掌柜忘记了，比如突然停业几天，恢复生意后依然可以通过账本和粉板上的数据明确赊账账目。\nbinlog 前面我们讲过，MySQL 整体来看，其实就有两块：一块是 Server 层，它主要做的是 MySQL 功能层面的事情；还有一块是引擎层，负责存储相关的具体事宜。上面我们聊到的粉板 redo log 是 InnoDB 引擎特有的日志，而 Server 层也有自己的日志，称为 binlog（归档日志）。\n我想你肯定会问，为什么会有两份日志呢？\n因为最开始 MySQL 里并没有 InnoDB 引擎。MySQL 自带的引擎是 MyISAM，但是 MyISAM 没有 crash-safe 的能力，binlog 日志只能用于归档。而 InnoDB 是另一个公司以插件形式引入 MySQL 的，既然只依靠 binlog 是没有 crash-safe 能力的，所以 InnoDB 使用另外一套日志系统——也就是 redo log 来实现 crash-safe 能力。\n这两种日志有以下三点不同。\n redo log 是 InnoDB 引擎特有的；binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用。 redo log 是物理日志，记录的是“在某个数据页上做了什么修改”；binlog 是逻辑日志，记录的是这个语句的原始逻辑，比如“给 ID=2 这一行的 c 字段加 1 ”。 redo log 是循环写的，空间固定会用完；binlog 是可以追加写入的。“追加写”是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。  有了对这两个日志的概念性理解，我们再来看执行器和 InnoDB 引擎在执行这个简单的 update 语句时的内部流程。\n 执行器先找引擎取 ID=2 这一行。ID 是主键，引擎直接用树搜索找到这一行。如果 ID=2 这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。 执行器拿到引擎给的行数据，把这个值加上 1，比如原来是 N，现在就是 N+1，得到新的一行数据，再调用引擎接口写入这行新数据。 引擎将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 里面，此时 redo log 处于 prepare 状态。然后告知执行器执行完成了，随时可以提交事务。 执行器生成这个操作的 binlog，并把 binlog 写入磁盘。 执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交（commit）状态，更新完成。  这里我给出这个 update 语句的执行流程图，图中浅色框表示是在 InnoDB 内部执行的，深色框表示是在执行器中执行的。\n你可能注意到了，最后三步看上去有点“绕”，将 redo log 的写入拆成了两个步骤：prepare 和 commit，这就是\u0026quot;两阶段提交\u0026quot;。\n两阶段提交 为什么必须有“两阶段提交”呢？这是为了让两份日志之间的逻辑一致。要说明这个问题，我们得从文章开头的那个问题说起：怎样让数据库恢复到半个月内任意一秒的状态？\n前面我们说过了，binlog 会记录所有的逻辑操作，并且是采用“追加写”的形式。如果你的 DBA 承诺说半个月内可以恢复，那么备份系统中一定会保存最近半个月的所有 binlog，同时系统会定期做整库备份。这里的“定期”取决于系统的重要性，可以是一天一备，也可以是一周一备。\n当需要恢复到指定的某一秒时，比如某天下午两点发现中午十二点有一次误删表，需要找回数据，那你可以这么做：\n 首先，找到最近的一次全量备份，如果你运气好，可能就是昨天晚上的一个备份，从这个备份恢复到临时库； 然后，从备份的时间点开始，将备份的 binlog 依次取出来，重放到中午误删表之前的那个时刻。  这样你的临时库就跟误删之前的线上库一样了，然后你可以把表数据从临时库取出来，按需要恢复到线上库去。\n好了，说完了数据恢复过程，我们回来说说，为什么日志需要“两阶段提交”。这里不妨用反证法来进行解释。\n由于 redo log 和 binlog 是两个独立的逻辑，如果不用两阶段提交，要么就是先写完 redo log 再写 binlog，或者采用反过来的顺序。我们看看这两种方式会有什么问题。\n仍然用前面的 update 语句来做例子。假设当前 ID=2 的行，字段 c 的值是 0，再假设执行 update 语句过程中在写完第一个日志后，第二个日志还没有写完期间发生了 crash，会出现什么情况呢？\n 先写 redo log 后写 binlog。假设在 redo log 写完，binlog 还没有写完的时候，MySQL 进程异常重启。由于我们前面说过的，redo log 写完之后，系统即使崩溃，仍然能够把数据恢复回来，所以恢复后这一行 c 的值是 1。 但是由于 binlog 没写完就 crash 了，这时候 binlog 里面就没有记录这个语句。因此，之后备份日志的时候，存起来的 binlog 里面就没有这条语句。 然后你会发现，如果需要用这个 binlog 来恢复临时库的话，由于这个语句的 binlog 丢失，这个临时库就会少了这一次更新，恢复出来的这一行 c 的值就是 0，与原库的值不同。 先写 binlog 后写 redo log。如果在 binlog 写完之后 crash，由于 redo log 还没写，崩溃恢复以后这个事务无效，所以这一行 c 的值是 0。但是 binlog 里面已经记录了“把 c 从 0 改成 1”这个日志。所以，在之后用 binlog 来恢复的时候就多了一个事务出来，恢复出来的这一行 c 的值就是 1，与原库的值不同。  可以看到，如果不使用“两阶段提交”，那么数据库的状态就有可能和用它的日志恢复出来的库的状态不一致。\n你可能会说，这个概率是不是很低，平时也没有什么动不动就需要恢复临时库的场景呀？\n其实不是的，不只是误操作后需要用这个过程来恢复数据。当你需要扩容的时候，也就是需要再多搭建一些备库来增加系统的读能力的时候，现在常见的做法也是用全量备份加上应用 binlog 来实现的，这个“不一致”就会导致你的线上出现主从数据库不一致的情况。\n简单说，redo log 和 binlog 都可以用于表示事务的提交状态，而两阶段提交就是让这两个状态保持逻辑上的一致。\n小结 今天，介绍了 MySQL 里面最重要的两个日志，即物理日志 redo log 和逻辑日志 binlog。\nredo log 用于保证 crash-safe 能力。innodb_flush_log_at_trx_commit 这个参数设置成 1 的时候，表示每次事务的 redo log 都直接持久化到磁盘。这个参数建议设置成 1，这样可以保证 MySQL 异常重启之后数据不丢失。\nsync_binlog 这个参数设置成 1 的时候，表示每次事务的 binlog 都持久化到磁盘。这个参数也建议设置成 1，这样可以保证 MySQL 异常重启之后 binlog 不丢失。\n还介绍了与 MySQL 日志系统密切相关的“两阶段提交”。两阶段提交是跨系统维持数据逻辑一致性时常用的一个方案，即使不做数据库内核开发，日常开发中也有可能会用到。\n","date":"2021-06-20T13:36:41Z","image":"https://ahao.ink/22.png","permalink":"https://ahao.ink/posts/%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F%E4%B8%80%E6%9D%A1sql%E6%9B%B4%E6%96%B0%E8%AF%AD%E5%8F%A5%E6%98%AF%E5%A6%82%E4%BD%95%E6%89%A7%E8%A1%8C%E7%9A%84/","title":"日志系统：一条SQL更新语句是如何执行的？"},{"content":"MyBatis 实验环境搭建 前言 MyBatis 是一个理论少，实践性强的框架；它没有太多的概念，最好的学习方式就是实践。本小节，我们将一起搭建 MyBatis 的实践环境，方便后续章节的学习。\n新建项目 考虑到工程的维护性，我们选择 IDE 来新建一个 Maven 项目来使用 MyBatis。当然如果你更倾向了 Gradle，那么没有关系，你只需要更改添加依赖的方式即可。\n在 IDE 上，你可以选择 Eclipse 或者 IDEA，当然我们更推荐你使用 IDEA，因为它的社区版已经足够我们学习 MyBatis 了，而且它也是免费的，本小节我们以 IDEA 作为默认的开发环境。\n打开 IDEA，选择 New Project，点击左侧的Maven项，然后 Next 新建项目，如下图：\n进入下一页后，输入对应的 GroupId 和 ArtifactId，如下图，你也可以选择自己心仪的 id，但是我们推荐你跟我们保持一致，这样在后面的学习中，你的配置和代码才能跟我们完全一致。\n填完以后，点击 Next 直到出现 Finish，点击完成即可。\n添加依赖 项目新建后，在项目根目录下找到 pom.xml文件，并向其中添加如下配置。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38  \u0026lt;dependencies\u0026gt; \u0026lt;!-- MyBatis 依赖 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.mybatis\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mybatis\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.5.4\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- mysql 驱动 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;mysql\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mysql-connector-java\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;8.0.18\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- 日志依赖 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;ch.qos.logback\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;logback-classic\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.2.3\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;!-- 文件打包配置 --\u0026gt; \u0026lt;build\u0026gt; \u0026lt;resources\u0026gt; \u0026lt;resource\u0026gt; \u0026lt;directory\u0026gt;src/main/resources\u0026lt;/directory\u0026gt; \u0026lt;filtering\u0026gt;false\u0026lt;/filtering\u0026gt; \u0026lt;/resource\u0026gt; \u0026lt;resource\u0026gt; \u0026lt;directory\u0026gt;src/main/java\u0026lt;/directory\u0026gt; \u0026lt;includes\u0026gt; \u0026lt;include\u0026gt;**/*.properties\u0026lt;/include\u0026gt; \u0026lt;include\u0026gt;**/*.xml\u0026lt;/include\u0026gt; \u0026lt;include\u0026gt;**/*.tld\u0026lt;/include\u0026gt; \u0026lt;/includes\u0026gt; \u0026lt;filtering\u0026gt;false\u0026lt;/filtering\u0026gt; \u0026lt;/resource\u0026gt; \u0026lt;/resources\u0026gt; \u0026lt;/build\u0026gt;   添加的依赖比较多，虽然在相应的地方我们也打上了注释，不过我们依然得说明一下。dependency 是 Maven 管理依赖的方式，我们分别添加了 mybatis、mysql-connector-java 和 logback-classic。\n其中 MyBatis 作为我们的主角，它的依赖是必不可少的；由于实操需要数据库环境，我们也添加上了 MySQL 驱动依赖；为了更好的查看信息，我们也添加了 logback 日志框架。\n另外，由于 Maven 打包默认不会打包 src/main/java文件夹下的资源文件，但实际的环境中，我们可能需要在该文件夹下存放资源文件，如.xml，所以我们也必须更改这个配置。\n添加依赖后，IDE 会提供你是否导入这些依赖，请你点击确认，并且等待一会儿，待依赖导入完成我们就可以进入下一步了。\n数据准备 项目搭建好后，我们还需要一定的数据支持。首先，请在你可用的数据库环境中新建一个名为mybatisdemo的数据库，当然你也可以使用其它的名称，但还是希望你能与我们保持一致，新建数据库成功后，接着运行以下 SQL 脚本。\n1 2 3 4 5 6 7 8 9 10 11  DROPTABLEIFEXISTSuser;CREATETABLEuser(idintPRIMARYKEYAUTO_INCREMENT,usernamevarchar(20),ageint,scoreint);INSERTINTOuser(id,username,age,score)VALUES(1,\u0026#39;peter\u0026#39;,18,100),(2,\u0026#39;pedro\u0026#39;,24,200),(3,\u0026#39;jerry\u0026#39;,28,500),(4,\u0026#39;mike\u0026#39;,12,300),(5,\u0026#39;tom\u0026#39;,27,1000);  结果如下：\n1 2 3 4 5 6 7 8 9  +----+----------+-----+-------+ |id|username|age|score|+----+----------+-----+-------+ |1|peter|18|100||2|pedro|24|200||3|jerry|28|500||4|mike|12|300||5|tom|27|1000|+----+----------+-----+-------+   小结 本小节是一个纯实操小节，我们没有介绍任何概念，而是带你一起搭建了学习 MyBatis 需要的环境和数据，后续的所有小节都将直接依赖于本小节。\nMyBatis 简单使用 前言 在上面中，我们搭建了 MyBatis 实验环境。本小节，我们将一起学习如何使用 MyBatis，虽然在实际的开发中，你几乎不会按照本小节所介绍的方式去使用 MyBatis，但是这对你熟悉 MyBatis 整体结构有着重要作用，同时这也是面试的重点。\n编程式使用 MyBatis 官方文档中并未详细的介绍如何编程式使用 MyBatis，绝大多数情况下，我们都是通过 配置文件来拿到配置然后开启会话的。这样的方式固然很方便，但是却屏蔽了太多的细节，因此我们想从点到面，层层递进给你介绍 MyBatis 的基础用法。\n接下来，我们一起来写一个简单的 demo 来使用一下 MyBatis。\n启动 MyBatis 在 mybatis-primer 项目中，有一个默认的包com.ahao.mybatis，在该包下，我们新建一个包名为pattern，并在其中新建一个名为StartNoXml.java的类，并向该文件中填充如下代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49  package com.ahao.mybatis.pattern; import org.apache.ibatis.datasource.pooled.PooledDataSource; import org.apache.ibatis.mapping.Environment; import org.apache.ibatis.session.Configuration; import org.apache.ibatis.session.SqlSession; import org.apache.ibatis.session.SqlSessionFactory; import org.apache.ibatis.session.SqlSessionFactoryBuilder; import org.apache.ibatis.transaction.jdbc.JdbcTransactionFactory; import java.sql.PreparedStatement; import java.sql.ResultSet; import java.sql.SQLException; @SuppressWarnings({\u0026#34;SqlResolve\u0026#34;, \u0026#34;SqlNoDataSourceInspection\u0026#34;, \u0026#34;Duplicates\u0026#34;}) public class StartNoXml { public static void main(String[] args) throws SQLException { // 无需xml配置的方式使用MyBatis  // 准备jdbc事务类  JdbcTransactionFactory jdbcTransactionFactory = new JdbcTransactionFactory(); // 配置数据源  PooledDataSource dataSource = new PooledDataSource(\u0026#34;com.mysql.cj.jdbc.Driver\u0026#34;, \u0026#34;jdbc:mysql://localhost:3306/mybatisdemo?useSSL=false\u0026amp;characterEncoding=utf8\u0026amp;serverTimezone = GMT\u0026#34;, \u0026#34;root\u0026#34;, \u0026#34;123456\u0026#34;); // 配置环境，向环境中指定环境id、事务和数据源  Environment environment = new Environment.Builder(\u0026#34;development\u0026#34;) .transactionFactory(jdbcTransactionFactory) .dataSource(dataSource).build(); // 新建 MyBatis 配置类  Configuration configuration = new Configuration(environment); // 得到 SqlSessionFactory 核心类  SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(configuration); // 开始一个 sql 会话  SqlSession session = sqlSessionFactory.openSession(); // 得到 sql 连接并运行 sql 语句  PreparedStatement preStatement = session .getConnection() .prepareStatement(\u0026#34;SELECT * FROM user WHERE id = ?\u0026#34;); preStatement.setInt(1, 1); ResultSet result = preStatement.executeQuery(); // 验证结果  while (result.next()) { System.out.println(\u0026#34;username: \u0026#34; + result.getString(\u0026#34;username\u0026#34;)); } // 关闭会话  session.close(); } }   即使你不熟悉 MyBatis，也没有必要被这段代码给吓到，因为在实际的开发中，你几乎没有机会去写这段代码。但是我们仍需要介绍这段代码，它可能是你面试的重点。\n书写完毕后，请在 PooledDataSource 类构造函数中更改数据用户名、密码和 url 配置以满足你所使用的数据库环境。运行一下这段代码，如果一切顺利，在控制台中你会看到以下输出内容（只截取了部分内容）：\n使用流程 在代码中，我们添加了一定量的注释说明了流程，接下来我们来总结一下。\n对于 MyBatis 的基础使用可大致分为以下3步：\n 得到 MyBatis 配置信息，即代码中的Configuration类。Configuration 负责 MyBatis 架构中的配置部分，例如：dataSource数据源信息都会交给 Configuration 去管理；这一步其实是比较繁杂的，Environment 是 Configuration 中的一部分，而 PooledDataSource 和 JdbcTransactionFactory 又是 Environment 中的一部分，它们是属于层层递进的关系。其中 JdbcTransactionFactory 表示事务工厂，当 MyBatis 需要新建事务的时候，会通过它来新建；PooledDataSource 表示数据源，通过其构造参数，我们传入了数据库 url，数据库用户和密码等配置；Configuration 可以有多个 Environment，因此每个 Environment 都必须有唯一的 id，即代码中的 development，将这些配置搭配组合后就是一个可用的 Configuration。 通过 Configuration 来创建 SqlSessionFactory。MyBatis 是通过会话的方式来执行 SQL 的，因为我们必须拥有一个会话创建器，即会话工厂。 新建SqlSession来执行 SQL。有了 SqlSessionFactory 后，我们就可以方便地新建会话，并通过会话来执行 SQL 了。  而PreparedStatement及以下的内容，其实并不属于 MyBatis，它们是 JDBC 提供的，在实际的 MyBatis 开发中，你也不会这样去执行 SQL，在这里我们只是为了展示 MyBatis 和 JDBC 的关系。\n可以看到，编程式使用 MyBatis 其实是比较复杂，你需要十分熟悉 MyBatis 的 API，而且这种硬编码的方式是比较笨重的，所以绝大多数资料都推荐配置的方式使用 MyBatis。\n配置式使用 接下来，我们一起来看一下如何通过配置来使用 MyBatis。\n配置文件 首先，我们在resources目录下新建mybatis-config.xml配置文件，并在其中添加上如下配置：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34; ?\u0026gt; \u0026lt;!DOCTYPE configuration PUBLIC \u0026#34;-//mybatis.org//DTD Config 3.0//EN\u0026#34; \u0026#34;http://mybatis.org/dtd/mybatis-3-config.dtd\u0026#34;\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;environments default=\u0026#34;development\u0026#34;\u0026gt; \u0026lt;environment id=\u0026#34;development\u0026#34;\u0026gt; \u0026lt;transactionManager type=\u0026#34;JDBC\u0026#34;/\u0026gt; \u0026lt;dataSource type=\u0026#34;POOLED\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;driver\u0026#34; value=\u0026#34;com.mysql.cj.jdbc.Driver\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;url\u0026#34; value=\u0026#34;jdbc:mysql://localhost:3306/mybatisdemo?useSSL=false\u0026amp;amp;serverTimezone = GMT\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;username\u0026#34; value=\u0026#34;root\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;password\u0026#34; value=\u0026#34;123456\u0026#34;/\u0026gt; \u0026lt;/dataSource\u0026gt; \u0026lt;/environment\u0026gt; \u0026lt;/environments\u0026gt; \u0026lt;/configuration\u0026gt;   有了上面编程式 API 的使用经验，那么你一定可以轻松的看懂配置项，configuration 标签对应 Configuration 类，environment 标签对应 Environment 类，transactionManager标签和dataSource标签分别对应 JdbcTransactionFactory 和 PooledDataSource 类。\n有了配置文件后，我们无需一个挨着一个的新建类，而是在配置文件中指定即可，如driver的值指定为com.mysql.cj.jdbc.Driver。当后续需要修改的时候，也不需要去代码中找，而是直接在配置文件中修改即可。\n TIPS： 注意， 请在你自己的配置文件中修改数据库配置，以满足你自己的数据库环境。\n 启动 MyBatis 同样地，我们在 patter 包下新建另一个类，名为StartWithXml.java，并填充以下代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36  package com.ahao.mybatis.pattern; import org.apache.ibatis.io.Resources; import org.apache.ibatis.session.SqlSession; import org.apache.ibatis.session.SqlSessionFactory; import org.apache.ibatis.session.SqlSessionFactoryBuilder; import java.io.IOException; import java.io.InputStream; import java.sql.PreparedStatement; import java.sql.ResultSet; import java.sql.SQLException; @SuppressWarnings({\u0026#34;SqlResolve\u0026#34;, \u0026#34;SqlNoDataSourceInspection\u0026#34;, \u0026#34;Duplicates\u0026#34;}) public class StartWithXml { public static void main(String[] args) throws IOException, SQLException { // 配置式使用MyBatis  String resource = \u0026#34;mybatis-config.xml\u0026#34;; // 读取配置文件  InputStream inputStream = Resources.getResourceAsStream(resource); // 按照配置文件得到 SqlSessionFactory  SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); // 新建会话  SqlSession session = sqlSessionFactory.openSession(); // 执行SQL  PreparedStatement preStatement = session.getConnection().prepareStatement(\u0026#34;SELECT * FROM user WHERE id = ?\u0026#34;); preStatement.setInt(1, 1); ResultSet result = preStatement.executeQuery(); while (result.next()) { System.out.println(\u0026#34;username: \u0026#34; + result.getString(\u0026#34;username\u0026#34;)); } // 关闭会话  session.close(); } }   运行代码，你会看到跟上面一样的结果。\n使用流程 配置式使用 MyBatis，也可分为3步：\n 读取配置文件，即mybatis-config.xml。 通过配置文件来创建 SqlSessionFactory。 新建SqlSession来执行 SQL。  与编程式相比，配置式更为简洁，更易维护，所以使用广泛，几乎所有资料都推荐这种方式来使用 MyBatis。但是编程式并非没有意义，它可以帮助你梳理 MyBatis 结构，有了编程式的基础，你才能更加容易地看懂配置文件中的内容，在后续的学习中，我们都将默认地使用配置式。\n小结  在实际的开发中，你都少有机会去按照本小节的方式去使用 MyBatis，但是这对你深入理解MyBatis结构有重要作用。 编程式使用的 API 较多，我们没有必要去死记硬背，熟练掌握其使用流程，能在需要的时候查阅即可。  MyBatis mapper 前言 本小节，我们将一起学习 MyBatis mapper。\n在上一节中我们以 JDBC 的方式使用了 MyBatis，但在实际应用中是不会选择这种方式来执行 SQL 的，MyBatis提供了 mapper 这种优雅且易维护的方式来帮助我们更好地去使用 SQL。\n定义  mapper 是 Java 方法和 SQL 语句之间的桥梁。\n Java 接口方法与 SQL 语句以及 mapper 之间的关系如下图所示：\n新建 mapper mapper 只是一个抽象的概念，它其实就是 Java 里面的一个接口类，我们不需要实现这个接口类，MyBatis 会通过动态代理自动帮我们执行接口方法所对应的 SQL 语句。\n接下来，我们以UserMapper为例，来看一看 mapper 究竟是如何定义和组成的。\n首先，在 com.ahao.mybatis 包下新建 mapper包，并在 mapper 包下新建接口类UserMapper.java。如下：\n1 2 3 4  package com.ahao.mybatis.mapper; public interface UserMapper { }   MyBatis 提供了注解和XML两种方式来连接接口方法和 SQL 语句。\n注解方式 我们为 UserMapper 添加一个方法selectUsernameById，该方法的作用为通过用户 id 查询用户名称，如下：\n1 2 3 4 5  package com.ahao.mybatis.mapper; public interface UserMapper { String selectUsernameById(Integer id); }   selectUsernameById 方法接受 id 参数（用户 id），返回用户名称（String 类型）。\n有了方法定义后，我们再通过注解为该方法添加上对应的 SQL 语句：\n1 2 3 4 5 6 7 8  package com.ahao.mybatis.mapper; import org.apache.ibatis.annotations.Select; public interface UserMapper { @Select(\u0026#34;SELECT username FROM user WHERE id = #{id}\u0026#34;) String selectUsernameById(Integer id); }   Select注解对应 SQL 的 select 查询，注解中的语句就是相应的 SQL 语句，当然这并非真实的 SQL 语句，具体的差异性我们后续章节再说。\nXML 方式 XML 方式是更加强大和易用的一种方式，虽然它没有注解那么方便，但是功能更强、更易维护，是 MyBatis 官方推荐的一种方式。\n在 mapper 包中，我们新建另一个文件UserMapper.xml，并添加如下内容：\n1 2 3 4 5 6  \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34; ?\u0026gt; \u0026lt;!DOCTYPE mapper PUBLIC \u0026#34;-//mybatis.org//DTD Mapper 3.0//EN\u0026#34; \u0026#34;http://mybatis.org/dtd/mybatis-3-mapper.dtd\u0026#34;\u0026gt; \u0026lt;mapper namespace=\u0026#34;com.ahao.mybatis.mapper.UserMapper\u0026#34;\u0026gt; \u0026lt;/mapper\u0026gt;   mapper 标签对应一个 mapper 接口类，这里应该对应 UserMapper，所以在 mapper 标签里面我们还需要加上 namespace 这个属性，它的值为 UserMapper 的类全路径，这样 UserMapper.xml 配置文件就与 UserMapper.java 对应起来了。\n提示，namespace 命名空间是每一个 mapper 文件所独有的，它唯一标识着一个 mapper。\n 注意： 在这里，.xml 配置文件必须与其对应的接口在同一个包内。\n 二者在目录中的位置如下：\n1 2 3  src/main/java/com/ahao/mybatis/mapper ├── UserMapper.java └── UserMapper.xml   在 UserMapper 接口中，我们再新增一个方法selectUserAgeById，该方法的作用是通过用户 id 查询用户年龄。如下：\n1 2 3 4 5 6 7 8 9 10  package com.ahao.mybatis.mapper; import org.apache.ibatis.annotations.Select; public interface UserMapper { @Select(\u0026#34;SELECT username FROM user WHERE id = #{id}\u0026#34;) String selectUsernameById(Integer id); Integer selectUserAgeById(Integer id); }   与之对应的 xml 文件中，我们也需要添加上对应的 SQL 语句。如下：\n1 2 3 4 5 6 7 8 9  \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34; ?\u0026gt; \u0026lt;!DOCTYPE mapper PUBLIC \u0026#34;-//mybatis.org//DTD Mapper 3.0//EN\u0026#34; \u0026#34;http://mybatis.org/dtd/mybatis-3-mapper.dtd\u0026#34;\u0026gt; \u0026lt;mapper namespace=\u0026#34;com.ahao.mybatis.mapper.UserMapper\u0026#34;\u0026gt; \u0026lt;select id=\u0026#34;selectUserAgeById\u0026#34; resultType=\u0026#34;java.lang.Integer\u0026#34;\u0026gt; SELECT age FROM user WHERE id = #{id} \u0026lt;/select\u0026gt; \u0026lt;/mapper\u0026gt;   在 mapper 标签中，我们新增了 select 标签，对应 SQL 中的 select 查询；select 标签中有两个必填属性，第一个是 id ，它对应接口的方法名，即 selectUserAgeById，通过它 MyBatis 才能将二者对应起来，第二个是 resultType，它对应 SQL 语句的返回类型，与接口方法的返回值相同，为 Integer 类型。\n好了，注解和 XML 的两种方式的简单使用已经介绍完毕了，这里仍然有一个可以完善的点，我们可以为 UserMapper 类打上一个 Mapper注解，虽然这个注解并不是必须的，但是增强了代码的可读性。如下：\n1 2 3 4 5 6 7  // 省略 import org.apache.ibatis.annotations.Mapper; @Mapper public interface UserMapper { // 省略其它诸多代码 }   使用 mapper mapper 定义好以后，我们接下来会介绍如何使用它。在上一节中，我们介绍了 MyBatis 配置式的简单使用，那么使用 mapper 其实很简单，只需在配置式使用的基础上增加几处配置和代码就行了。\nmapper 配置 首先，我们需要在 mybatis-config.xml 配置文件中添加上对应的 mapper 配置：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34; ?\u0026gt; \u0026lt;!DOCTYPE configuration PUBLIC \u0026#34;-//mybatis.org//DTD Config 3.0//EN\u0026#34; \u0026#34;http://mybatis.org/dtd/mybatis-3-config.dtd\u0026#34;\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;environments default=\u0026#34;development\u0026#34;\u0026gt; \u0026lt;environment id=\u0026#34;development\u0026#34;\u0026gt; \u0026lt;transactionManager type=\u0026#34;JDBC\u0026#34;/\u0026gt; \u0026lt;dataSource type=\u0026#34;POOLED\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;driver\u0026#34; value=\u0026#34;com.mysql.cj.jdbc.Driver\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;url\u0026#34; value=\u0026#34;jdbc:mysql://localhost:3306/mybatisdemo?useSSL=false\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;username\u0026#34; value=\u0026#34;root\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;password\u0026#34; value=\u0026#34;123456\u0026#34;/\u0026gt; \u0026lt;/dataSource\u0026gt; \u0026lt;/environment\u0026gt; \u0026lt;/environments\u0026gt; \u0026lt;!-- mapper 对应的配置 --\u0026gt; \u0026lt;mappers\u0026gt; \u0026lt;mapper class=\u0026#34;com.ahao.mybatis.mapper.UserMapper\u0026#34;/\u0026gt; \u0026lt;/mappers\u0026gt; \u0026lt;/configuration\u0026gt;   注意，mapper 可以有多个，对应的标签项应是 mappers，在 mappers 下面才有一个个的 mapper，如上面的 UserMapper；通过mapper 标签中的 class 属性，我们指定其对应的接口类，class 属性值为 UserMapper 的类全路径。\n代码调用 有了配置以后，我们则可以在代码中调用 mapper 方法从而执行 SQL 得到结果了。在 pattern 包下，我们新建一个文件，名为StartWithMapper.java，并向其中添加如下代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  package com.ahao.mybatis.pattern; import com.ahao.mybatis.mapper.UserMapper; import org.apache.ibatis.io.Resources; import org.apache.ibatis.session.SqlSession; import org.apache.ibatis.session.SqlSessionFactory; import org.apache.ibatis.session.SqlSessionFactoryBuilder; import java.io.IOException; import java.io.InputStream; import java.sql.SQLException; @SuppressWarnings({\u0026#34;Duplicates\u0026#34;}) public class StartWithMapper { public static void main(String[] args) throws IOException, SQLException { String resource = \u0026#34;mybatis-config.xml\u0026#34;; InputStream inputStream = Resources.getResourceAsStream(resource); SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); SqlSession session = sqlSessionFactory.openSession(); // 得到 mapper  UserMapper mapper = session.getMapper(UserMapper.class); // 调用注解的SQL  String username = mapper.selectUsernameById(1); System.out.println(\u0026#34;username: \u0026#34; + username); // 调用XML的SQL  Integer age = mapper.selectUserAgeById(1); System.out.println(\u0026#34;age: \u0026#34; + age); // 关闭会话  session.close(); } }   使用流程我们已经写在了代码注释中了，请务必阅读一下。\n与上一节的区别在于，我们不再通过 session 得到连接从而执行 SQL 了，而是在 session 中得到配置好的 UserMapper，再通过调用UserMapper 的方法执行 SQL 从而得到结果。\n执行这段代码，它会在控制台上打印如下信息（截取了部分重要信息）：\n1 2 3 4 5 6 7 8  13:13:50.104 [main] DEBUG com.ahao.mybatis.mapper.UserMapper.selectUsernameById - ==\u0026gt; Preparing: SELECT username FROM user WHERE id = ? 13:13:50.205 [main] DEBUG com.ahao.mybatis.mapper.UserMapper.selectUsernameById - ==\u0026gt; Parameters: 1(Integer) 13:13:50.344 [main] DEBUG com.ahao.mybatis.mapper.UserMapper.selectUsernameById - \u0026lt;== Total: 1 username: peter 13:13:50.351 [main] DEBUG com.ahao.mybatis.mapper.UserMapper.selectUserAgeById - ==\u0026gt; Preparing: SELECT age FROM user WHERE id = ? 13:13:50.351 [main] DEBUG com.ahao.mybatis.mapper.UserMapper.selectUserAgeById - ==\u0026gt; Parameters: 1(Integer) 13:13:50.354 [main] DEBUG com.ahao.mybatis.mapper.UserMapper.selectUserAgeById - \u0026lt;== Total: 1 age: 18   总结 从程序输出的信息中可以看出，UserMapper 的调用都成功了， 结合上一小节中 JDBC 的使用，可以清晰地感受到 MyBatis 完美的将 Java 对象与 SQL 语句分离，并通过 mapper 充当二者的桥梁，极大的提升了代码和 SQL 语句的维护性。\n不同于原生 JDBC 的使用方式，MyBatis 会自动的通过 resultType 等配置来帮我们实现数据库类型到 Java 类型的转换，帮我们节省了大量的工作，当然 MyBatis 的功能远不止如此，我们将在后续的小节中一一揭晓。\n小结  mapper 是 MyBatis 的核心概念，是 MyBatis 解耦 Java 对象与 SQL 语句的桥梁。 MyBatis 官方文档中明确强调注解方式 SQL 无法发挥 MyBatis 的全部功能，但是可以方便地演示一些 demo。 如果单独使用 MyBatis，那么 mapper 接口必须和 .xml 配置文件在同一个包中，但是如果使用 spring 等工具就可以不必受此限制。  MyBatis select 前言 本小节，我们将一起学习 MyBatis select。\n在 MyBatis 中，select 标签对应于 SQL 语句中的 select 查询，我们会在 select 标签中填充 SQL 查询语句，然后在代码中通过对应接口方法来调用。\n定义  select 标签用于映射 SQL 中的查询语句\n 实例 MyBatis select 可分为xml和注解两种使用方式。\nxml 实例 将 select 查询写在 mapper.xml 文件中，比如：\n1 2 3 4 5 6 7 8 9  \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34; ?\u0026gt; \u0026lt;!DOCTYPE mapper PUBLIC \u0026#34;-//mybatis.org//DTD Mapper 3.0//EN\u0026#34; \u0026#34;http://mybatis.org/dtd/mybatis-3-mapper.dtd\u0026#34;\u0026gt; \u0026lt;mapper namespace=\u0026#34;com.ahao.mybatis.mapper.UserMapper\u0026#34;\u0026gt; \u0026lt;select id=\u0026#34;selectUserAgeById\u0026#34; parameterType=\u0026#34;java.lang.Integer\u0026#34; resultType=\u0026#34;java.lang.Integer\u0026#34;\u0026gt; SELECT age FROM user WHERE id = #{id} \u0026lt;/select\u0026gt; \u0026lt;/mapper\u0026gt;   其中名为 selectUserAgeById 的 select 标签(一般以 id 做为名称)，接收 Integer 类型的参数（parameterType），并返回 Integer 类型的结果（resultType）；再看 select 标签中的查询语句，接收 id 参数，类型为 int，返回 age，类型为 int，二者一一对应。\n参数符号 注意，在 select 标签中的 SQL 语句几乎与真实的 SQL 语句一致，但它的参数符号稍有不同：\n1  #{id}   若以 #{}作为参数符号，MyBatis 则会创建一个预处理语句（PreparedStatement），它会被处理成?。如果你不希望使用预处理，那么可以使用${}参数符号，MyBatis 会将其以字符串的形式进行拼接，不过我们推荐你使用 #{}，几乎所有人也都这样做。\n注解实例 将 SQL 语句写在注解中，如下：\n1 2  @Select(\u0026#34;SELECT username FROM user WHERE id = #{id}\u0026#34;) String selectUsernameById(Integer id);   注解中的 select 语句无需再添加 id、parameterType 等属性，只需写上对应的 SQL 语句，MyBatis 会自动根据其修饰的方法来推断出这些参数。\n TIPS： 使用注解来书写 MyBatis 相对会方便一些，但是注解无法发挥 MyBatis 动态 SQL 真正的威力，因此大部分人都还是会选择 xml 的方式来书写 SQL，但是对于一些 demo 的展示，注解无疑容易上手一些。在后面的学习中，我们都会介绍到注解的使用，但是在实践中我们默认使用 xml 方式。\n select 属性 select 标签支持很多属性来改变查询语句的行为。\n我们摘取其中常见且重要的属性，如下表所示：\n   属性 描述     id 在命名空间中唯一的标识符   parameterType 语句的参数类型，默认可选，MyBatis 会自动推断   resultType 语句返回值类型，如果返回的是集合，那应该设置为集合包含的类型   resultMap 语句返回映射的 id；可以使用 resultType 或 resultMap，但不能同时使用。   flushCache 设置为 true 后，只要语句被调用，都会导致本地缓存和二级缓存被清空，默认为 false   useCache 设置为 true 后，本条语句的查询结果被二级缓存缓存起来，默认 select 标签为 true。   timeout 设置超时时间   fetchSize 设置预期返回的记录数量   statementType STATEMENT，PREPARED 或 CALLABLE 中的一个，默认为 PREPARED（预处理）    参数 在上面的实例中，我们介绍了#{id}参数，这是参数的最简单情况，对于复杂情况，参数还有其它更多的妙用。\n对象参数 有时候，参数可以是一个复杂的对象，如 Java 中的一个 User 类。\n1 2 3 4  \u0026lt;select id=\u0026#34;selectUserByAgeAndScore\u0026#34; parameterType=\u0026#34;com.ahao.mybatis.model.User\u0026#34; resultType=\u0026#34;com.ahao.mybatis.model.User\u0026#34;\u0026gt; SELECT * FROM user WHERE age = #{age} AND score = #{score} \u0026lt;/select\u0026gt;   selectUserByAgeAndScore 查询的参数是一个复杂 Java 对象 User，当 User 作为参数对象时，User 中的属性都可作为查询语句的参数，如 age 和 score。\n参数配置 #{}不仅可以传入参数名称，还可以传入参数类型和类型处理器。\n比如：\n1  #{age,javaType=int,jdbcType=int,typeHandler=IntegerTypeHandler}   其中 javaType 表示 age 的 Java 类型，jdbcType 表示 age 的数据库类型，typeHandler 表示 age 的类型处理器，关于类型处理器我们将在后面的章节介绍。\n对于参数配置，90% 的情况你都只需要传入参数名即可，因为 MyBatis 都会自动推断出配置。\n实践 介绍了这么多概念，我们一起来实操巩固一下。\n例1. 通过年龄和分数查询用户 请使用 MyBatis 完成在 user 表中通过年龄和分数查询用户的功能。\n分析：\n按照 MyBatis 的开发模式，先在对应 UserMapper.xml 文件中添加通过年龄和分数查询用户的 select 标签，然后在 UserMapper.java 中增加上对应的方法即可。\n步骤：\n首先，我们在 com.ahao.mybatis 包下新建 model 包，用于保存数据库对象，并在 model 包下新建 User.java 类：\n1 2 3 4 5 6 7 8 9  package com.ahao.mybatis.model; public class User { private Long id; private String username; private Integer age; private Integer score; // 省略了 getter 和 setter 方法，请务必通过 IDE 生成，否则 MyBatis 无法自动映射 }   在 UserMapper.xml 文件中，我们新增 selectUserByAgeAndScore 标签，该 select 标签的作用是：通过年龄和分数查询用户。\n1 2 3 4  \u0026lt;select id=\u0026#34;selectUserByAgeAndScore\u0026#34; parameterType=\u0026#34;com.ahao.mybatis.model.User\u0026#34; resultType=\u0026#34;com.ahao.mybatis.model.User\u0026#34;\u0026gt; SELECT * FROM user WHERE age = #{age} AND score = #{score} \u0026lt;/select\u0026gt;   然后在 UserMapper.java 接口中，我们新增对应的方法，方法接收复杂参数 User：\n1 2 3 4 5 6 7 8 9  package com.ahao.mybatis.mapper; import com.ahao.mybatis.model.User; import org.apache.ibatis.annotations.Mapper; @Mapper public interface UserMapper { User selectUserByAgeAndScore(User user); }   结果：\n通过如下代码，我们运行 selectUserByAgeAndScore 方法。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  package com.ahao.mybatis.pattern; import com.ahao.mybatis.entity.User; import com.ahao.mybatis.mapper.UserMapper; import org.apache.ibatis.io.Resources; import org.apache.ibatis.session.SqlSession; import org.apache.ibatis.session.SqlSessionFactory; import org.apache.ibatis.session.SqlSessionFactoryBuilder; import java.io.IOException; import java.io.InputStream; import java.sql.SQLException; @SuppressWarnings({\u0026#34;Duplicates\u0026#34;}) public class Test { public static void main(String[] args) throws IOException, SQLException { String resource = \u0026#34;mybatis-config.xml\u0026#34;; InputStream inputStream = Resources.getResourceAsStream(resource); SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); SqlSession session = sqlSessionFactory.openSession(); // 得到 mapper  UserMapper userMapper = session.getMapper(UserMapper.class); User condition = new User(); condition.setAge(18); condition.setScore(100); // 调用方法  User user = userMapper.selectUserByAgeAndScore(condition); // 得到 user  System.out.println(user); } }   输出结果为：\n1  User{id=1, username=\u0026#39;peter\u0026#39;, age=18, score=100}   小结  MyBatis 虽然提供了 #{}和${}两种方式来传递参数，但无疑#{}更加实用。 select 标签属性虽然多，但是大部分情况下都不会针对某一个 select 标签来定制化，多会在全局里进行配置。 互联网的应用场景多数为读多写少，那么 select 肯定是使用最为广泛的标签了。  MyBatis resultMap 与 sql 前言 本小节，我们将一起学习 MyBatis resultMap 和 sql。\n在前面的小节中，我们了解到 MyBatis 可以自动帮助我们映射数据库数据和 Java 对象，其实这是 MyBatis 在幕后帮我们创建了 resultMap 对象；虽然 MyBatis 可以自动帮助我们做数据映射，但是对于复杂的对象，我们就必须自定义 resultMap 了。\n而在书写 SQL 时，势必会有一些 SQL 代码段出现了重复，为了更好的复用它们，MyBatis 提供了 sql 标签。\n定义  resultMap 标签用于将数据库数据映射为 Java 对象；sql 标签则用来定义可重用的 SQL 代码段。\n 实例 resultMap 实例 xml 实例 在下面这段 select 标签中，SQL 语句返回的是一个复杂对象，即 resultType 上指定的 User。\n1 2 3 4  \u0026lt;select id=\u0026#34;selectUserByAgeAndScore\u0026#34; parameterType=\u0026#34;com.ahao.mybatis.model.User\u0026#34; resultType=\u0026#34;com.ahao.mybatis.model.User\u0026#34;\u0026gt; SELECT * FROM user WHERE age = #{age} AND score = #{score} \u0026lt;/select\u0026gt;   在这种情况下，MyBatis 会自动创建 resultMap 对象进行数据的映射，接下来我们直接定义出 resultMap，避免 MyBatis 推断和映射带来的性能损耗。如下：\n1 2 3 4 5 6 7 8 9 10 11  \u0026lt;resultMap id=\u0026#34;userMap\u0026#34; type=\u0026#34;com.ahao.mybatis.model.User\u0026#34;\u0026gt; \u0026lt;id property=\u0026#34;id\u0026#34; column=\u0026#34;id\u0026#34;/\u0026gt; \u0026lt;result property=\u0026#34;username\u0026#34; column=\u0026#34;username\u0026#34;/\u0026gt; \u0026lt;result property=\u0026#34;age\u0026#34; column=\u0026#34;age\u0026#34;/\u0026gt; \u0026lt;result property=\u0026#34;score\u0026#34; column=\u0026#34;score\u0026#34;/\u0026gt; \u0026lt;/resultMap\u0026gt; \u0026lt;select id=\u0026#34;selectUserByAgeAndScore\u0026#34; parameterType=\u0026#34;com.ahao.mybatis.model.User\u0026#34; resultMap=\u0026#34;userMap\u0026#34;\u0026gt; SELECT * FROM user WHERE age = #{age} AND score = #{score} \u0026lt;/select\u0026gt;   我们定义了名为 userMap 的 resultMap 且指定其对应的 Java 类型为 User，在标签的内部，我们还需指定字段之间的映射，除 id 这个特殊的字段外，其它字段均使用 result 标签来映射。\n其中 property 是 Java 对象中的字段名称，column 是数据表与之对应的字段名称。\nresultMap 定义完毕后，我们在 select 标签中通过 resultMap 属性来设置对应的 id。\n TIPS： 注意， resultMap 和 resultType 不能共存，只能二选一。\n 这样，一次简单的 resultMap 使用就完毕了。\n注解实例 通过注解，我们也可以指定 Java 模型对象与数据库字段之间的映射关系，如下：\n1 2 3 4 5 6 7 8  @Results({ @Result(property = \u0026#34;id\u0026#34;, column = \u0026#34;id\u0026#34;, id = true), @Result(property = \u0026#34;username\u0026#34;, column = \u0026#34;username\u0026#34;), @Result(property = \u0026#34;age\u0026#34;, column = \u0026#34;age\u0026#34;), @Result(property = \u0026#34;score\u0026#34;, column = \u0026#34;score\u0026#34;) }) @Select(\u0026#34;SELECT * FROM user WHERE id = #{id}\u0026#34;) User selectUserById(Integer id);   Results 注解与 resultMap 对象，包含多个 Result 注解，每个 Result 注解对应了一个字段映射关系。\n 提示： Results 注解以及 ResultMap 注解虽然存在，但是很少在实际的开发中使用，只需了解即可。\n SQL 实例 我们将目光放到 selectUserByAgeAndScore 语句的内部，在实际的开发中像SELECT * FROM user这样的代码段其实非常常见，会在多个 select 标签中用到它。我们可以将其定义为一个 sql 标签，这样所有的 select 标签都可以快速复用到这段代码。\n1 2 3  \u0026lt;sql id=\u0026#34;selectUser\u0026#34;\u0026gt; SELECT * FROM user \u0026lt;/sql\u0026gt;   同样的，我们必须为这个代码段定义一个唯一的 id，定义好后，我们就可以在其它标签中使用了：\n1 2 3 4 5  \u0026lt;select id=\u0026#34;selectUserByAgeAndScore\u0026#34; parameterType=\u0026#34;com.ahao.mybatis.model.User\u0026#34; resultMap=\u0026#34;userMap\u0026#34;\u0026gt; \u0026lt;include refid=\u0026#34;selectUser\u0026#34;/\u0026gt; WHERE age = #{age} AND score = #{score} \u0026lt;/select\u0026gt;   这里，我们必须使用一个 include 标签来将 SQL 标签包含进来，并且 refid 属性必须是该 SQL 标签的 id 值。这样这段代码仍然可以正常工作。\nSQL 标签没有对应注解，只能在 xml 中使用。\n实践 接下来，我们一起来实操巩固一下。\n例1. 查询用户姓名和年龄 请使用 MyBatis 完成在 user 表中查询用户简略信息的功能。\n分析：\n很多应用都会有查询用户简略信息这样一个需求，比如我们只需获取用户名和年龄，运用本小节的知识我们可以这样实现它。\n先在对应 UserMapper.xml 文件中添加查询用户简略信息的 select 标签，然后在 UserMapper.java 中增加上对应的方法即可。\n步骤：\n首先，我们新建一个用户简略信息的模型 UserShortCut.java：\n1 2 3 4 5 6 7  package com.ahao.mybatis.model; public class UserShortCut { private String username; private Integer age; // 省略了重要的 getter 和 setter 方法 }   并在 UserMapper.xml 添加上 resultMap 、sql 和 select 标签：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  \u0026lt;!-- 复用的 sql 代码段 --\u0026gt; \u0026lt;sql id=\u0026#34;selectUserShortcutMap\u0026#34;\u0026gt; SELECT username,age FROM user \u0026lt;/sql\u0026gt; \u0026lt;!-- 结果映射集 --\u0026gt; \u0026lt;resultMap id=\u0026#34;userShortcutMap\u0026#34; type=\u0026#34;com.ahao.mybatis.model.UserShortCut\u0026#34;\u0026gt; \u0026lt;result property=\u0026#34;username\u0026#34; column=\u0026#34;username\u0026#34;/\u0026gt; \u0026lt;result property=\u0026#34;age\u0026#34; column=\u0026#34;age\u0026#34;/\u0026gt; \u0026lt;/resultMap\u0026gt; \u0026lt;!-- 查询语句 --\u0026gt; \u0026lt;select id=\u0026#34;selectUserShortcutById\u0026#34; resultMap=\u0026#34;userShortcutMap\u0026#34;\u0026gt; \u0026lt;include refid=\u0026#34;selectUserShortcutMap\u0026#34;/\u0026gt; WHERE id = #{id} \u0026lt;/select\u0026gt;   接下来，给 UserMapper.java 接口添加上对应的方法，以便在程序中调用。\n1 2 3 4 5 6 7 8 9  package com.ahao.mybatis.mapper; import com.ahao.mybatis.model.UserShortCut; import org.apache.ibatis.annotations.Mapper; @Mapper public interface UserMapper { UserShortCut selectUserShortcutById(Integer id); }   结果：\n通过如下代码，我们运行 selectUserShortcutById 方法。\n1 2 3  UserMapper userMapper = session.getMapper(UserMapper.class); UserShortCut shortCut = userMapper.selectUserShortcutById(1); System.out.println(shortCut);   结果如下：\n1  UserShortCut{username=\u0026#39;peter\u0026#39;, age=18}   小结  SQL 是一个非常好用的标签，能够减少大量重复的 SQL 代码书写，但是也降低 SQL 的可读性。 MyBatis 会自动生成 resultMap，这会为我们节省了大量的时间，如果不是对性能十分严苛，那么 resultType 是够用的。  MyBatis insert 前言 本小节，我们将一起学习 MyBatis insert。\n在 MyBatis 中，insert 标签对应于 SQL 语句中的 insert 插入；与 select 相比，insert 要简单许多，只有当需要返回主键时，才会麻烦一些，我们将从简单到复杂来依次介绍。\n定义  insert 标签用于映射 SQL 中的插入语句\n 实例 xml 实例 下面是一个简单的 insert 标签。\n1 2 3  \u0026lt;insert id=\u0026#34;insertUser\u0026#34; parameterType=\u0026#34;com.ahao.mybatis.model.User\u0026#34;\u0026gt; INSERT INTO imooc_user(id,username,age,score) VALUES (#{id},#{username},#{age},#{score}) \u0026lt;/insert\u0026gt;   同 select 一样，每一个 insert 标签都必须有一个唯一的 id 和可选的 parameterType。标签里面则是真正的 SQL 语句，该语句共有 4 个参数，分别对应 User 类的四个属性。\n注解实例 如果不使用 xml 的方式，使用注解也可取得同样的效果，如下：\n1 2  @Insert(\u0026#34;INSERT INTO imooc_user(username,age,score) VALUES (#{username},#{age},#{score})\u0026#34;) int insertUser(User user);   insert 属性 insert 标签也支持诸多属性来改变语句的行为。\n其中常见且重要的属性如下表：\n   属性 描述     id 在命名空间中的唯一标识符   parameterType 语句的参数类型，默认可选，MyBatis 会自动推断   flushCache 设置为 true 后，只要语句被调用，都会导致本地缓存和二级缓存被清空，默认为 false   timeout 设置超时时间   statementType STATEMENT，PREPARED 或 CALLABLE 中的一个，默认为 PREPARED（预处理）   useGeneratedKeys 取出由数据库自动生成的主键，仅对支持主键自动生成的数据库有效，默认为 false   keyProperty 主键的名称，必须与useGeneratedKeys 一起使用，默认未设置    返回主键 select 标签在需要返回被添加记录的主键时，会稍微复杂一点。\n自增主键 xml 方式 如果使用的数据库，如 MySQL，PostgreSQL，这些数据库支持自增主键，那么得到返回的主键只需添加上 useGeneratedKeys 和 keyProperty 两个属性即可。如下：\n1 2 3 4  \u0026lt;insert id=\u0026#34;insertUserNoId\u0026#34; useGeneratedKeys=\u0026#34;true\u0026#34; keyProperty=\u0026#34;id\u0026#34; parameterType=\u0026#34;com.ahao.mybatis.model.User\u0026#34;\u0026gt; INSERT INTO user(username,age,score) VALUES (#{username},#{age},#{score}) \u0026lt;/insert\u0026gt;   在 insertUserNoId 中，我们并未添加上 id 参数，而是使用了数据库自增主键的特性，keyProperty 属性值对应 id 字段的名称，这样当语句执行成功后，对象的 id 字段会被自动设置为返回的 id 值。\n注解方式 使用下面的注解方式，同样可以实现同样的效果：\n1 2 3  @Insert(\u0026#34;INSERT INTO imooc_user(username,age,score) VALUES (#{username},#{age},#{score})\u0026#34;) @Options(useGeneratedKeys = true, keyProperty = \u0026#34;id\u0026#34;) int insertUser(User user);   MyBatis 提供了 Options 注解来指定方法调用的行为。\nselectKey 标签 xml 方式 如果使用的数据库不支持主键自增，如 Oracle，MyBatis 提供了 selectKey 标签来通过 SQL 语句获得主键。\n例如：\n1 2 3 4 5 6  \u0026lt;insert id=\u0026#34;insertUserNoId\u0026#34; parameterType=\u0026#34;com.ahao.mybatis.model.User\u0026#34;\u0026gt; INSERT INTO imooc_user(username,age,score) VALUES (#{username},#{age},#{score}) \u0026lt;selectKey keyColumn=\u0026#34;id\u0026#34; resultType=\u0026#34;long\u0026#34; keyProperty=\u0026#34;id\u0026#34; order=\u0026#34;AFTER\u0026#34;\u0026gt; SELECT LAST_INSERT_ID() \u0026lt;/selectKey\u0026gt; \u0026lt;/insert\u0026gt;   selectKey 标签必须在 insert 标签里面，selectKey 有 4 个属性，它们的作用如下表：\n   属性 描述     keyColumn 数据库字段名，对应返回结果集中的名称   keyProperty 目标字段名称，对应Java 对象的字段名   resultType id字段的类型   order 执行的顺序，在 insert 之前调用为 BEFORE，之后为 AFTER    注意，selectKey 中的语句其实就是 SQL 语句，不同数据库得到主键的语句均不一样。\n注解方式 1 2 3  @Insert(\u0026#34;INSERT INTO imooc_user(username,age,score) VALUES (#{username},#{age},#{score})\u0026#34;) @SelectKey(statement = \u0026#34;SELECT LAST_INSERT_ID()\u0026#34;, keyProperty = \u0026#34;id\u0026#34;, before = false, resultType = Long.class) int insertUser(User user);   selectKey 也有相应的注解，不过配置属性略有不同，statement 属性对应标签中的 SQL 语句，而 before 属性则对应标签中的 order 属性，若 before 为 false，则 order 对应为 AFTER。\n实践 下面，我们一起来实操巩固一下。\n例1. 插入用户 请使用 MyBatis 完成在 imooc_user 表中插入用户的功能。\n分析：\n按照 MyBatis 的开发模式，先在对应 UserMapper.xml 文件中添加插入用户的 insert 标签，然后在 UserMapper.java 中增加上对应的方法即可。\n步骤：\n使用 MyBatis 向数据库中插入用户。由于我们使用的数据库是 MySQL，因为直接使用 useGeneratedKeys 得到自增主键。\n首先，我们在 UserMapper.xml 文件中添加上对应的 insert 标签：\n1 2 3 4  \u0026lt;insert id=\u0026#34;insertUser\u0026#34; useGeneratedKeys=\u0026#34;true\u0026#34; keyProperty=\u0026#34;id\u0026#34; parameterType=\u0026#34;com.ahao.mybatis.model.User\u0026#34;\u0026gt; INSERT INTO imooc_user(username,age,score) VALUES (#{username},#{age},#{score}) \u0026lt;/insert\u0026gt;   然后在 UserMapper.java 中添加对应的方法：\n1 2 3 4 5 6 7 8 9  package com.ahao.mybatis.mapper; import com.ahao.mybatis.model.User; import org.apache.ibatis.annotations.Mapper; @Mapper public interface UserMapper { int insertUser(User user); }   结果：\n通过如下代码，我们运行 insertUser 方法：\n1 2 3 4 5 6 7 8 9 10  UserMapper userMapper = session.getMapper(UserMapper.class); User user = new User(); user.setUsername(\u0026#34;insert test\u0026#34;); user.setAge(100); user.setScore(100000); int rows = userMapper.insertUser(user); System.out.println(rows); // 一定要提交 session.commit(); session.close();    TIPS: 注意，这里必须通过 commit 方法提交会话，语句才会生效。\n 小结  绝大多数情况下，我们都不会在插入时指定 id 的值，而是通过数据库自动去生成。 不同数据库获得主键的 SQL 语句也不同，如果通过 selectKey 获得主键，那么一定要注意数据库厂商之间的差异性。  MyBatis update 前言 本小节，我们将一起学习 MyBatis update。\n在 MyBatis 中，update 标签对应于 SQL 语句中的 update 更新。\n定义  update 标签用于映射 SQL 中的更新语句。\n 实例 xml 实例 如下就是一个真实的 update 标签实例。\n1 2 3  \u0026lt;update id=\u0026#34;updateUserAgeById\u0026#34;\u0026gt; UPDATE imooc_user SET age = #{age} WHERE id = #{id} \u0026lt;/update\u0026gt;   每一个 update 标签都必须有一个唯一的 id 属性，在 update 标签内部则是一条 SQL 语句。\n注解实例 使用如下的注解方式，我们也可以实现同样的功能。\n1 2  @Update(\u0026#34;UPDATE imooc_user SET age = #{age} WHERE id = #{id}\u0026#34;) int updateUserAgeById(@Param(\u0026#34;age\u0026#34;) Integer age, @Param(\u0026#34;id\u0026#34;) Integer id);   update 属性 update 标签支持一些属性来改变更新语句的行为。\n其中常见且重要的属性如下表：\n   属性 描述     id 在命名空间中的唯一标识符   parameterType 语句的参数类型，默认可选，MyBatis 会自动推断   flushCache 设置为 true 后，只要语句被调用，都会导致本地缓存和二级缓存被清空，默认为 false   timeout 设置超时时间   statementType STATEMENT，PREPARED 或 CALLABLE 中的一个，默认为 PREPARED（预处理）    实践 例1. 更新用户年龄 请使用 MyBatis 完成对 imooc_user 表中用户年龄更新的功能。\n分析：\n按照 MyBatis 的开发模式，先在对应 UserMapper.xml 文件中添加用户年龄更新的 update 标签，然后在 UserMapper.java 中增加上对应的方法即可。\n步骤：\n首先，在 UserMapper.xml 中添加 update 标签，并在标签中写入 SQL ：\n1 2 3  \u0026lt;update id=\u0026#34;updateUserAgeById\u0026#34;\u0026gt; UPDATE imooc_user SET age = #{age} WHERE id = #{id} \u0026lt;/update\u0026gt;   然后在 UserMapper.java 中添加上对应的接口方法，方法接受 age 和 id 两个参数。\n1 2 3 4 5 6 7 8 9  package com.ahao.mybatis.mapper; import org.apache.ibatis.annotations.Mapper; import org.apache.ibatis.annotations.Param; @Mapper public interface UserMapper { int updateUserAgeById(@Param(\u0026#34;age\u0026#34;) Integer age, @Param(\u0026#34;id\u0026#34;) Integer id); }   注意：这里我们使用了@Param这个注解，由于在 update 标签中有两个参数 age 和 id，我们需要通过 @Param 来告诉 MyBatis 参数的对应关系。\n结果：\n通过如下代码，我们运行 updateUserAgeById 这个方法。\n1 2 3 4 5 6  UserMapper userMapper = session.getMapper(UserMapper.class); int rows = userMapper.updateUserAgeById(180, 1); System.out.println(rows); // 一定要提交 session.commit(); session.close();   成功后，id 为 1 的用户年龄已经被更新为 180。\n1 2 3 4 5  +----+-------------+-----+--------+ | id | username | age | score | +----+-------------+-----+--------+ | 1 | peter | 180 | 100 | +----+-------------+-----+--------+   例2. 更新用户名称和分数 请使用 MyBatis 完成对 imooc_user 表中用户名称和分数更新的功能。\n分析：\n同上。\n步骤：\n首先，在 UserMapper.xml 中添加另一个 update 标签，并在标签中写入 SQL ：\n1 2 3  \u0026lt;update id=\u0026#34;updateUsernameAndScoreById\u0026#34;\u0026gt; UPDATE imooc_user SET username = #{username}, score = #{score} WHERE id = #{id} \u0026lt;/update\u0026gt;   然后在 UserMapper.java 中添加上对应的接口方法，方法接受 username、score 和 id 三个参数。\n1 2 3 4 5 6 7 8 9  package com.ahao.mybatis.mapper; import org.apache.ibatis.annotations.Mapper; import org.apache.ibatis.annotations.Param; @Mapper public interface UserMapper { int updateUsernameAndScoreById(@Param(\u0026#34;username\u0026#34;) String username, @Param(\u0026#34;score\u0026#34;) Integer score, @Param(\u0026#34;id\u0026#34;) Integer id); }   结果：\n通过如下代码，我们运行 updateUsernameAndScoreById 这个方法。\n1 2 3 4 5 6  UserMapper userMapper = session.getMapper(UserMapper.class); int rows = userMapper.updateUsernameAndScoreById(\u0026#34;peter-gao\u0026#34;, 1000,1); System.out.println(rows); // 一定要提交 session.commit(); session.close();   成功后，id 为 1 的用户信息已被更改。\n1 2 3 4 5  +----+-------------+-----+--------+ | id | username | age | score | +----+-------------+-----+--------+ | 1 | peter-gao | 180 | 1000 | +----+-------------+-----+--------+   小结  update 标签并无太多的知识点，主要的工作量在书写 SQL 上，因此良好的 SQL 功底可以帮助你更加快速的上手 MyBatis。  MyBatis delete 前言 本小节，我们将一起学习 MyBatis delete。\n在 MyBatis 中，delete 标签对应于 SQL 语句中的 delete 删除。\n定义  delete 标签用于映射 SQL 中的删除语句。\n 实例 xml 实例 如下，是一个真实的 delete 标签实例。\n1 2 3  \u0026lt;delete id=\u0026#34;deleteUserById\u0026#34;\u0026gt; DELETE FROM imooc_user WHERE id = #{id} \u0026lt;/delete\u0026gt;   每一个 delete 标签都必须有一个唯一的 id 属性，在 delete 标签内部则是一条 SQL 语句。\n注解实例 上面的 delete 标签对应的注解实例如下：\n1 2  @Delete(\u0026#34;DELETE FROM imooc_user WHERE id = #{id}\u0026#34;) int deleteUserById(Integer id);   delete 属性 delete 标签支持一些属性来改变更新语句的行为。\n其中常见且重要的属性如下表：\n   属性 描述     id 在命名空间中的唯一标识符   parameterType 语句的参数类型，默认可选，MyBatis 会自动推断   flushCache 设置为 true 后，只要语句被调用，都会导致本地缓存和二级缓存被清空，默认为 false   timeout 设置超时时间   statementType STATEMENT，PREPARED 或 CALLABLE 中的一个，默认为 PREPARED（预处理）    实践 例1. 根据 id 删除用户 请使用 MyBatis 完成对 imooc_user 表中通过 id 删除用户的功能。\n分析：\n按照 MyBatis 的开发模式，先在对应 UserMapper.xml 文件中添加根据 id 删除用户的 delete 标签，然后在 UserMapper.java 中增加上对应的方法即可。\n步骤：\n首先，在 UserMapper.xml 中添加 delete 标签，并在标签中写入 SQL ：\n1 2 3  \u0026lt;delete id=\u0026#34;deleteUserById\u0026#34;\u0026gt; DELETE FROM imooc_user WHERE id = #{id} \u0026lt;/delete\u0026gt;   然后在 UserMapper.java 中添加上对应的接口方法，方法接受 id 一个参数。\n1 2 3 4 5 6 7 8  package com.ahao.mybatis.mapper; import org.apache.ibatis.annotations.Mapper; @Mapper public interface UserMapper { int deleteUserById(Integer id); }   结果：\n通过如下代码，我们运行 deleteUserById 这个方法。\n1 2 3 4 5 6  UserMapper userMapper = session.getMapper(UserMapper.class); int rows = userMapper.deleteUserById(10); System.out.println(rows); // 一定要提交 session.commit(); session.close();   成功后，id 为 10 的用户已被删除。\n例2. 根据用户名删除用户 请使用 MyBatis 完成对 imooc_user 表中通过用户名删除用户的功能。\n分析：\n同上。\n步骤：\n首先，在 UserMapper.xml 中添加 delete 标签，并在标签中写入 SQL ：\n1 2 3  \u0026lt;delete id=\u0026#34;deleteUserByName\u0026#34;\u0026gt; DELETE FROM imooc_user WHERE username = #{username} \u0026lt;/delete\u0026gt;   然后在 UserMapper.java 中添加上对应的接口方法，方法接受 username 一个参数。\n1 2 3 4 5 6 7 8  package com.ahao.mybatis.mapper; import org.apache.ibatis.annotations.Mapper; @Mapper public interface UserMapper { int deleteUserByName(String username); }   结果：\n通过如下代码，我们运行 deleteUserByName 这个方法。\n1 2 3 4 5  UserMapper userMapper = session.getMapper(UserMapper.class); int rows = userMapper.deleteUserByName(\u0026#34;tom\u0026#34;); System.out.println(rows); session.commit(); session.close();   成功后，用户名为 tom 的用户已被删除。\n小结  delete 标签并无太多的知识点，主要的工作量在书写 SQL 上。  OGNL 表达式 前言 MyBatis 的动态 SQL 广泛应用到了OGNL 表达式，OGNL 表达式可以灵活的组装 SQL 语句，从而完成更多的功能。OGNL 易学易用，与 Java 代码几乎一致，本小节我们将系统的介绍 OGNL 表达式在 MyBatis 中的使用。\n定义  OGNL 全称 Object-Graph Navigation Language，是 Java 中的一个开源的表达式语言，用于访问对象数据。\n 介绍 实例 OGNL 最常用于 if 标签中，用于判断条件是否满足，如下：\n1 2 3  \u0026lt;if test=\u0026#34;age != null\u0026#34;\u0026gt; AND age = #{age} \u0026lt;/if\u0026gt;   if 标签的 test 属性就是个典型的 OGNL 表达式。age != null表示当 age 不为 null 的时候 if 成立，则动态的向 SQL 中插入标签内的 SQL 代码段。\n常见的 OGNL 表达式 在 MyBatis 中常见的 OGNL 表达式如下：\n e1 or e2：或关系 e1 and e2：与关系 e1 == e2 或者 e1 eq e2：相等 e1 != e2 或者 e1 neq e2：不等 e1 lt e2 ；e1 \u0026lt; e2；e1 gt e2；e1 \u0026gt; e2；e1 lte e2；e1 \u0026lt;= e2；e1 gte e2；e1 \u0026gt;= e2：比较关系 e1 + e2；e1 - e2；e1 * e2；e1 / e2；e1 % e2：运算关系 !e 或者 not e：非，取反 e.method(args)：调用对象方法 e.property：访问属性值 e1[e2]：访问数组、链表（e2 为序号）或者 Map（e2 为键值）  其中 1～4 以及 9～10 都是特别常用的几种情况，而其它的情况不利于 SQL 的维护，因此并不常见。\n TIPS： 提示， 如果你熟悉 Python 的话，会发现 OGNL 表达式完全就是在写 Python。\n 实践 下面我们就来以实例来看一看 OGNL 表达式。\n有一个名为 pedro 的 User 对象，如下：\n1 2 3 4  User pedro = new User(); pedro.setUsername(\u0026#34;pedro\u0026#34;); pedro.setTags(Arrays.asList(\u0026#34;admin\u0026#34;, \u0026#34;man\u0026#34;)); pedro.setAge(23);   访问属性 访问用户的 username 属性，OGNL 表达式为pedro.username，结果为：\n1 2  # pedro.username pedro   访问列表 访问用户的第一个标签，OGNL 表达式为pedro.tags[0]，结果为：\n1 2  # pedro.tags[0] admin   比较 比较用户标签长度是否大于 1，OGNL 表达式为pedro.tags[0]，结果为：\n1 2  # pedro.tags.size \u0026gt; 1 true   运算 用户年龄加上一个整数 22，OGNL 表达式为pedro.age + 22，结果为：\n1 2  # pedro.age + 22 45   方法调用 将用户年龄全部大写，OGNL 表达式为pedro.username.toUpperCase，结果为：\n1 2  # pedro.username.toUpperCase PEDRO   小结  OGNL 表达式是 MyBatis 动态 SQL 的核心，小巧精致却功能强大，易学易用。  MyBatis if 和多数据库支持 前言 动态 SQL 是 MyBatis 最标志性的特性之一。在其它框架中，你可能需要根据不同的条件来拼接 SQL，辗转在符号与条件的判断上，处理起来麻烦而且易错，而 MyBatis 的动态 SQL 可以让我们摆脱这种痛苦，简单而又高效的书写 SQL。\nMyBatis 动态 SQL 由 OGNL 表达式和条件标签两部 分组成，我们将会分为多个小节进行介绍。\nOGNL 表达式是动态 SQL 的基础，如果你还不了解，请务必点击学习一下。条件标签部分我们将会在四个小节中分别介绍，它们分别是MyBatis if 和多数据库支持（本小节），MyBatis choose和bind小节，MyBatis where、set、trim小节和MyBatis foreach小节。\n本小节，我们先来学习最基础的条件标签 if，以及如何使用 if 来让 MyBatis 来支持多数据库。\n定义  if 常用于 where 语句中，通过判断参数来决定在 select 语句中是否使用某个查询条件，或者在 update 语句中判断是否更新一个字段，还可以在 insert 语句中决定是否插入一个满足条件的值。\n 实例 我们以一个实际的例子来看一下 if 是如何工作的。\n1 2 3 4 5 6 7  \u0026lt;select id=\u0026#34;selectUserByAgeAndScore\u0026#34; parameterType=\u0026#34;com.ahao.mybatis.model.User\u0026#34; resultMap=\u0026#34;userMap\u0026#34;\u0026gt; SELECT * FROM imooc_user WHERE age = #{age} \u0026lt;if test=\u0026#34;score != null\u0026#34;\u0026gt; AND score = #{score} \u0026lt;/if\u0026gt; \u0026lt;/select\u0026gt;   在 if 标签中，test 属性是 OGNL 的判断表达式。\nselectUserByAgeAndScore 的作用是通过用户年龄和积分来查询用户，当 score 值为 null 时，if 判断不成立，此时生成的 SQL 语句为：\n1  SELECT*FROMimooc_userWHEREage=?  而当 if 成立时，生成的 SQL 语句为：\n1  SELECT*FROMimooc_userWHEREage=?ANDscore=?  通过这样条件判断方式，MyBatis 能根据实际情况来动态生成 SQL 语句。\n实践 例1、动态查询用户 请使用 MyBatis 完成对 imooc_user 表动态查询用户的功能， username为必须的查询条件，年龄和积分若为 null 则不使用该字段进行过滤。\n分析：\n按照 MyBatis 的开发模式，先在 UserMapper.xml 文件中添加动态查询用户的 select 标签，然后在 UserMapper.java 中增加上对应的方法。\n步骤：\n首先，在 UserMapper.xml 中添加 select 标签，并在标签中写入 SQL，使用 if 来判断属性值是否为 null，若为 null，则不使用该字段进行查询。如下：\n1 2 3 4 5 6 7 8 9 10 11  \u0026lt;select id=\u0026#34;selectUserByNameCondition\u0026#34; parameterType=\u0026#34;com.ahao.mybatis.model.User\u0026#34; resultType=\u0026#34;com.ahao.mybatis.model.User\u0026#34;\u0026gt; SELECT * FROM imooc_user WHERE username = #{username} \u0026lt;if test=\u0026#34;age != null\u0026#34;\u0026gt; AND age = #{age} \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;score != null\u0026#34;\u0026gt; AND score = #{score} \u0026lt;/if\u0026gt; \u0026lt;/select\u0026gt;   通过 if 对属性的判断，SQL 的过滤条件就会发生相应的变化。\n然后在 UserMapper.java 中添加上对应的接口方法，方法接受 User对象作为参数。\n1 2 3 4 5 6 7 8 9  package com.ahao.mybatis.mapper; import org.apache.ibatis.annotations.Mapper; import com.ahao.mybatis.model.User; @Mapper public interface UserMapper { User selectUserByNameCondition(User user); }   结果：\n通过如下代码，我们运行 selectUserByNameCondition 这个方法。\n1 2 3 4 5 6  UserMapper userMapper = session.getMapper(UserMapper.class); User condition = new User(); condition.setUsername(\u0026#34;pedro\u0026#34;); condition.setScore(200); User pedro = userMapper.selectUserByNameCondition(condition); System.out.println(pedro);   condition 对象 username 和 score 属性均不为空，而 age 属性为空，因此最后所执行的 SQL 为：\n1  SELECT*FROMimooc_userWHEREusername=?ANDscore=?  成功后，结果为：\n1  User{id=2, username=\u0026#39;pedro\u0026#39;, age=24, score=200}   多数据库支持 MyBatis 可以根据不同的数据库厂商执行不同的语句，这种多厂商的支持是基于配置文件中的 databaseId。\n配置 首先在 MyBatis 的全局配置文件中添加如下配置：\n1 2 3 4 5 6 7  \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34; ?\u0026gt; \u0026lt;!DOCTYPE configuration PUBLIC \u0026#34;-//mybatis.org//DTD Config 3.0//EN\u0026#34; \u0026#34;http://mybatis.org/dtd/mybatis-3-config.dtd\u0026#34;\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;databaseIdProvider type=\u0026#34;DB_VENDOR\u0026#34; /\u0026gt; \u0026lt;/configuration\u0026gt;   在 configuration 中加入 databaseIdProvider 后，还需要在 databaseIdProvider 标签中添加上需要使用到的数据库名称，如：SQL Server。每一个 property 属性都代表了一个数据库，name 表示数据库厂商名称，value 用来设置别名。\n1 2 3 4 5 6 7 8 9 10 11  \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34; ?\u0026gt; \u0026lt;!DOCTYPE configuration PUBLIC \u0026#34;-//mybatis.org//DTD Config 3.0//EN\u0026#34; \u0026#34;http://mybatis.org/dtd/mybatis-3-config.dtd\u0026#34;\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;databaseIdProvider type=\u0026#34;DB_VENDOR\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;SQL Server\u0026#34; value=\u0026#34;sqlserver\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;MySQL\u0026#34; value=\u0026#34;mysql\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;PostgreSQL\u0026#34; value=\u0026#34;postgre\u0026#34;/\u0026gt; \u0026lt;/databaseIdProvider\u0026gt; \u0026lt;/configuration\u0026gt;   使用 配置完毕后，我们就可以在 mapper xml 文件中，通过 if 来判断当前的数据库厂商，从而动态生成不同数据库的 SQL。\n例如，PostgreSQL 支持使用 ||来拼接字符串，而 MySQL 需要使用 concat函数来拼接字符串。\n因此，如果在模糊查询的时候，不同的数据库厂商需要不同的 SQL 语句，通过 if 来判断数据库厂商来生成对于的 SQL 语句。\n如下：\n1 2 3 4 5 6 7 8 9 10  \u0026lt;select id=\u0026#34;selectUserByLikeName\u0026#34; resultType=\u0026#34;com.ahao.mybatis.model.User\u0026#34;\u0026gt; SELECT * FROM imooc_user WHERE username LIKE \u0026lt;if test=\u0026#34;_databaseId == \u0026#39;mysql\u0026#39;\u0026#34;\u0026gt; CONCAT(\u0026#39;%\u0026#39;,#{username},\u0026#39;%\u0026#39;) \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;_databaseId == \u0026#39;postgre\u0026#39;\u0026#34;\u0026gt; \u0026#39;%\u0026#39; || #{username} || \u0026#39;%\u0026#39; \u0026lt;/if\u0026gt; \u0026lt;/select\u0026gt;   注意，这里 _databaseId 参数是由 MyBatis 提供的内置参数，对应于 databaseIdProvider 中配置的数据库名称。\n通过 databaseIdProvider 配置，即时数据库厂商之间存在差异，但仍然可以通过动态 SQL 的形式来支持多数据库。\n小结  if 简单且好用，是动态 SQL 中的最基础的标签，一看便会。 多数据库支持的应用场景其实较少，但如果真的需要，也可通过 MyBatis 来方便的实现。  MyBatis choose 和 bind 前言 在上一小节中，我们介绍了 MyBatis 动态 SQL 中最基础的标签——if 标签，本小节我们将一起学习 choose 和 bind 标签。\nchoose 标签是 if 标签的增强版，适用于更加复杂的条件判断逻辑；而bind 标签则可以在 OGNL 上下文环境中新绑定一个变量，供后面的 SQL 使用。\n定义  choose 标签相当于编程语言 if…else 语句，用于动态 SQL 中的多条件判断，是 if 标签的增强版。\nbind 标签可以在动态 SQL 中通过 OGNL 表达式来创建一个新的变量绑定到上下文中，供后续的 SQL 使用。\n 实例 下面是一个融合了 choose 和 bind 标签的实例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  \u0026lt;select id=\u0026#34;selectUserByLikeName\u0026#34; resultType=\u0026#34;com.ahao.mybatis.model.User\u0026#34;\u0026gt; SELECT * FROM imooc_user WHERE username LIKE \u0026lt;choose\u0026gt; \u0026lt;when test=\u0026#34;_databaseId == \u0026#39;mysql\u0026#39;\u0026#34;\u0026gt; CONCAT(\u0026#39;%\u0026#39;,#{username},\u0026#39;%\u0026#39;) \u0026lt;/when\u0026gt; \u0026lt;when test=\u0026#34;_databaseId == \u0026#39;postgre\u0026#39;\u0026#34;\u0026gt; \u0026#39;%\u0026#39; || #{username} || \u0026#39;%\u0026#39; \u0026lt;/when\u0026gt; \u0026lt;otherwise\u0026gt; \u0026lt;bind name=\u0026#34;usernameLike\u0026#34; value=\u0026#34;\u0026#39;%\u0026#39; + username + \u0026#39;%\u0026#39;\u0026#34;/\u0026gt; #{usernameLike} \u0026lt;/otherwise\u0026gt; \u0026lt;/choose\u0026gt; \u0026lt;/select\u0026gt;   通过 choose 标签来判断当前的数据库厂商，如果是 MySQL 数据库，则调用CONCAT函数来拼接 % 和 username，如果是 PostgreSQL 数据库，则使用操作符||来拼接，如果是其它类型的数据库，则直接通过 OGNL 表达式来绑定一个新的变量 usernameLike。\n在这个例子中，choose 是一个条件选择标签，第一个 when 相当于 if 判断，第二个 when 相当于 else if，最后的 otherwise 相当于 else。比起 if 标签，choose 标签无疑更为易用，适用于同一条件的多次判断逻辑。\n实践 例1. 多条件查询用户 请使用 MyBatis 完成对 imooc_user 表多条件查询用户的功能，如果 id 不为空则直接使用 id 查询用户，否则使用 username 查询用户，如果 username 也为空，则直接查询全部用户。\n分析：\n按照 MyBatis 的开发模式，需先在 UserMapper.xml 文件中添加多条件查询用户的 select 标签，然后在 UserMapper.java 中添加上对应的方法。\n步骤：\n首先，在 UserMapper.xml 中添加 select 标签，并在标签中写入 SQL，使用 choose 中的 when 标签来依次判断 id 和 username 是否为 null，若均为 null，则在 otherwise 中添加上一个永假的值。如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  \u0026lt;select id=\u0026#34;selectUserByIdOrName\u0026#34; resultType=\u0026#34;com.ahao.mybatis.model.User\u0026#34;\u0026gt; SELECT * FROM imooc_user WHERE \u0026lt;choose\u0026gt; \u0026lt;when test=\u0026#34;id != null\u0026#34;\u0026gt; id = #{id} \u0026lt;/when\u0026gt; \u0026lt;when test=\u0026#34;username != null\u0026#34;\u0026gt; username = #{username} \u0026lt;/when\u0026gt; \u0026lt;otherwise\u0026gt; 1 = 0 \u0026lt;/otherwise\u0026gt; \u0026lt;/choose\u0026gt; \u0026lt;/select\u0026gt;   这里使用了1 = 0作为条件判断的永假值。\n然后在 UserMapper.java 中添加上对应的接口方法，方法接受 id 和 username 两个参数，都可为空。\n1 2 3 4 5 6 7 8 9  package com.ahao.mybatis.mapper; import org.apache.ibatis.annotations.Mapper; import com.ahao.mybatis.model.User; @Mapper public interface UserMapper { User selectUserByIdOrName(@Param(\u0026#34;id\u0026#34;) Integer id, @Param(\u0026#34;username\u0026#34;) String username); }   结果：\n通过如下代码，我们运行 selectUserByIdOrName 这个方法。\n1 2 3  UserMapper userMapper = session.getMapper(UserMapper.class); User pedro = userMapper.selectUserByIdOrName(null, null); System.out.println(pedro);   id 和 username 两个属性均为空，因此所执行的 SQL 为：\n1  SELECT*FROMimooc_userWHERE1=0  成功后，结果为：\n1  null   例2. 查询小写名称客户 请使用 MyBatis 完成对 imooc_user 表查询小写名称客户的功能，将名称小写后再进行查询。\n分析：\n同上。\n步骤：\n首先，在 UserMapper.xml 中添加 select 标签，并在标签中写入 SQL，使用 bind 标签将参数小写化成一个新的变量 lowercaseName。\n1 2 3 4 5  \u0026lt;select id=\u0026#34;selectUsernameLowercase\u0026#34; resultType=\u0026#34;com.ahao.mybatis.model.User\u0026#34;\u0026gt; \u0026lt;bind name=\u0026#34;lowercaseName\u0026#34; value=\u0026#34;username.toLowercase\u0026#34;/\u0026gt; SELECT * FROM imooc_user WHERE username = #{lowercaseName} \u0026lt;/select\u0026gt;   然后在 UserMapper.java 中添加上对应的接口方法，方法接受 username 一个参数。\n1 2 3 4 5 6 7 8 9  package com.ahao.mybatis.mapper; import org.apache.ibatis.annotations.Mapper; import com.ahao.mybatis.model.User; @Mapper public interface UserMapper { User selectUsernameLowercase(String username); }   结果：\n通过如下代码，我们运行 selectUsernameLowercase 这个方法。\n1 2 3  UserMapper userMapper = session.getMapper(UserMapper.class); User pedro = userMapper.selectUsernameLowercase(\u0026#34;PEDRO\u0026#34;); System.out.println(pedro);   成功后，结果为：\n1  User{id=2, username=\u0026#39;pedro\u0026#39;, age=24, score=200}   小结  bind 标签虽然可以通过 OGNL 表达式在上下文中绑定一个新的变量，但在实际应用所见不多，我们希望在代码层面上处理好参数，这样既方便维护，也更有利于迁移。 choose 标签是一个增强版的 if 标签，适用于更加复杂的逻辑判断场景。  MyBatis where、set、trim 前言 在前面的小节中，我们一起学习了 if 标签，在通过 if 判断动态插入或查询的时候容易产生多余的前缀（如 WHERE）或后缀（如 , ），为了解决这类问题 MyBatis 提供了 where、set、trim 三个实用的标签。\n其中 where 和 set 标签都是 trim 标签的一种特殊情况，不过使用频率非常高，因此被单独定义成了标签。本小节我们将一起来学习它们。\n定义  where、set、trim 三个标签都是为了解决 MyBatis 在动态生成 SQL 时，产生了多余的前缀和后缀的问题。\n 实例 where 实例 1 2 3 4 5 6 7 8 9 10 11  \u0026lt;select id=\u0026#34;selectUserByIdAndName\u0026#34; resultType=\u0026#34;com.ahao.mybatis.model.User\u0026#34;\u0026gt; SELECT * FROM imooc_user \u0026lt;where\u0026gt; \u0026lt;if test=\u0026#34;id != null\u0026#34;\u0026gt; id = #{id} \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;username != null\u0026#34;\u0026gt; AND username = #{username} \u0026lt;/if\u0026gt; \u0026lt;/where\u0026gt; \u0026lt;/select\u0026gt;   在这个例子中，id 和 username 均非固定的过滤参数，只有当其不为 null 时才会加入到 SQL 语句中。此处 where 标签的作用大概有如下 3 个：\n 在 id 和 username 都为空的情况下，where 标签不会产生任何 SQL 代码段，最后的 SQL 语句为：SELECT * FROM imooc_user； 在 id 不为空，username 为空的情况下，或者在 id 不为空，username 也不为空的情况下，where 标签会自动给 SQL 代码段添加上 WHERE 前缀； 在 id 为空，username 不为空的情况下，where 标签会自定去除 AND 前缀，此时生成的 SQL 语句为： SELECT * FROM imooc_user WHERE username = ?。  set 实例 1 2 3 4 5 6 7 8 9 10  \u0026lt;update id=\u0026#34;updateUsernameAndScoreById\u0026#34;\u0026gt; UPDATE imooc_user \u0026lt;set\u0026gt; \u0026lt;if test=\u0026#34;username != null\u0026#34;\u0026gt; username = #{username}, \u0026lt;/if\u0026gt; id = #{id} \u0026lt;/set\u0026gt; WHERE id = #{id} \u0026lt;/update\u0026gt;   set 标签会自动在 SQL 语句中添加上相应的 SET 前缀，并根据里面的条件动态地添加相应的字段。\n由于 SQL update 的语法问题，若 set 标签里面条件均不满足，此时 set 标签也不会添加上 SET 前缀，但此时 SQL 会报语法错误，所以 set 标签中还是得有一个必然存在的赋值。\ntrim 实例 1 2 3 4 5 6 7 8 9 10 11 12  \u0026lt;update id=\u0026#34;updateUsernameAndScoreById\u0026#34;\u0026gt; UPDATE imooc_user \u0026lt;trim prefix=\u0026#34;SET\u0026#34; suffixOverrides=\u0026#34;,\u0026#34;\u0026gt; \u0026lt;if test=\u0026#34;username != null\u0026#34;\u0026gt; username = #{username}, \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;id != null\u0026#34;\u0026gt; id = #{id} \u0026lt;/if\u0026gt; \u0026lt;/trim\u0026gt; WHERE id = #{id} \u0026lt;/update\u0026gt;   这里的 trim 实例实现了与 set 实例同样的功能，set 标签是 trim 标签的一种特殊情况。\ntrim 标签共有 4 个属性，它们的作用分别如下：\n prefix： 前缀属性，若标签内不为空则在 SQL 中添加上前缀； prefixOverrides： 前缀覆盖属性，若标签中有多余的前缀，将会被覆盖（其实就是丢弃该前缀）； suffix： 后缀属性，若标签内不为空则在 SQL 中添加上后缀； suffixOverrides： 后缀覆盖属性，若标签中有多余的后缀，将会被覆盖（其实就是丢弃该后缀）。  这个例子中，trim 标签的前缀为SET，后缀覆盖属性为,，所以在标签内不为空的情况下给 SQL 语句添加了 SET 关键字，且标签内若有多余的,后缀也会被丢弃。\n实践 例1. 动态插入用户 请使用 MyBatis 完成对 imooc_user 表动态插入用户的功能，若用户属性值不为 null 则插入该字段，否则不插入字段。\n分析：\n按照 MyBatis 的开发模式，先在 UserMapper.xml 文件中添加动态插入用户的 insert 标签，然后在 UserMapper.java 中添加上对应的方法。\n步骤：\n首先，在 UserMapper.xml 中添加 insert 标签，并在标签中写入 SQL，使用 trim 标签来动态判断属性是否为空，若不为空则插入该字段。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  \u0026lt;insert id=\u0026#34;insertUserDynamic\u0026#34; parameterType=\u0026#34;com.ahao.mybatis.model.User\u0026#34;\u0026gt; INSERT INTO imooc_user \u0026lt;trim prefix=\u0026#34;(\u0026#34; suffix=\u0026#34;)\u0026#34; suffixOverrides=\u0026#34;,\u0026#34;\u0026gt; \u0026lt;if test=\u0026#34;username != null\u0026#34;\u0026gt; username, \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;age != null\u0026#34;\u0026gt; age, \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;score != null\u0026#34;\u0026gt; score, \u0026lt;/if\u0026gt; \u0026lt;/trim\u0026gt; VALUES \u0026lt;trim prefix=\u0026#34;(\u0026#34; suffix=\u0026#34;)\u0026#34; suffixOverrides=\u0026#34;,\u0026#34;\u0026gt; \u0026lt;if test=\u0026#34;username != null\u0026#34;\u0026gt; #{username}, \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;age != null\u0026#34;\u0026gt; #{age}, \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;score != null\u0026#34;\u0026gt; #{score}, \u0026lt;/if\u0026gt; \u0026lt;/trim\u0026gt; \u0026lt;/insert\u0026gt;   这里，我们使用了两个 trim 标签，一个用来动态写入字段名，另一个用来动态写入字段值；trim 标签的前缀为(,后缀为)，当出现多余的,时，会通过后缀覆盖属性来丢弃。\n然后在 UserMapper.java 中添加上对应的接口方法：\n1 2 3 4 5 6 7 8 9  package com.ahao.mybatis.mapper; import org.apache.ibatis.annotations.Mapper; import com.ahao.mybatis.model.User; @Mapper public interface UserMapper { int insertUserDynamic(User user); }   结果：\n通过如下代码，我们运行 insertUserDynamic 这个方法。\n1 2 3 4 5 6  UserMapper userMapper = session.getMapper(UserMapper.class); User user = new User(); user.setUsername(\u0026#34;dynamic\u0026#34;); user.setScore(100); int rows = userMapper.insertUserDynamic(user); System.out.println(rows);   成功后，结果为：\n1  1    TIPS: 注意，在 username、score 和 age 均为 null 时， insertUserDynamic 会报 SQL 语法错误，但理论上若是所有属性均为空，那么也不应该插入。\n 小结  where、set 以及 trim 将 MyBatis 的动态 SQL 发挥到了极致，为开发者节省了大量的精力和时间。 trim 标签是 MyBatis 中最为强大的一个标签，使用它可以方便的完成 SQL 动态插入和动态更新。  MyBatis foreach 前言 在 MyBatis 中，常常会遇到集合类型的参数，虽然我们可以通过 OGNL 表达式来访问集合的某一个元素，但是 OGNL 表达式无法遍历集合。foreach 标签就是专门用来解决这类问题的，本小节我们就来一起学习它。\n定义  foreach 标签用来遍历数组、列表和 Map 等集合参数，常与 in 关键字搭配使用。\n 实例 我们以 3 个例子来看一看 foreach 是如何遍历列表、数组和 Map 的。\n遍历列表 xml：\n1 2 3 4 5 6 7  \u0026lt;select id=\u0026#34;selectUserInIds\u0026#34; resultType=\u0026#34;com.ahao.mybatis.model.User\u0026#34;\u0026gt; SELECT * FROM imooc_user WHERE id IN \u0026lt;foreach collection=\u0026#34;list\u0026#34; open=\u0026#34;(\u0026#34; close=\u0026#34;)\u0026#34; separator=\u0026#34;,\u0026#34; item=\u0026#34;item\u0026#34; index=\u0026#34;index\u0026#34;\u0026gt; #{item} \u0026lt;/foreach\u0026gt; \u0026lt;/select\u0026gt;   Java：\n1  List\u0026lt;User\u0026gt; selectUserInIds(List\u0026lt;Integer\u0026gt; ids);   上面是 selectUserInIds 方法在 java 和 xml 中对应的代码段。\nforeach 标签共有 6 个属性，它们的作用分别为：\n collection： 被遍历集合参数的名称，如 list； open： 遍历开始时插入到 SQL 中的字符串，如 ( ； close： 遍历结束时插入到 SQL 中的字符串，如 ) ； separator： 分割符，在每个元素的后面都会插入分割符； item： 元素值，遍历集合时元素的值； index： 元素序列，遍历集合时元素的序列。  当 selectUserInIds 方法的参数 ids 为Arrays.asList(1, 2)时，生成的 SQL 语句为：\n1  SELECT * FROM imooc_user WHERE id IN ( 1 , 2 )   foreach 标签的 collection 属性在接受参数名有两种情况：一、匿名参数，当在 java 方法中没有通过 @Param 注解指定参数名时，列表类型的使用默认参数名 list。二、具名参数，java 方法中使用了@Param 注解指定了参数名称，则 foreach 中的 collection 属性必须为参数名，如：\n1 2 3 4 5  List\u0026lt;User\u0026gt; selectUserInIds(@Param(\u0026#34;ids\u0026#34;) List\u0026lt;Integer\u0026gt; ids); \u0026lt;foreach collection=\u0026#34;ids\u0026#34; open=\u0026#34;(\u0026#34; close=\u0026#34;)\u0026#34; separator=\u0026#34;,\u0026#34; item=\u0026#34;item\u0026#34; index=\u0026#34;index\u0026#34;\u0026gt; #{item} \u0026lt;/foreach\u0026gt;   我们推荐你为列表类型参数用注解指定一个名称，让使用该名称来遍历，方便代码维护和阅读。\n遍历数组 当 Java 方法使用的参数类型为数组时，如下：\n1  List\u0026lt;User\u0026gt; selectUserInIds(Integer[] ids);   如果 ids 参数使用 @Param 注解指定了参数名称，则 foreach 标签中的 collection 属性必须为该名称；但若未指定名称，则在 foreach 标签中使用默认数组名称 array，如下：\n1 2 3 4 5 6 7  \u0026lt;select id=\u0026#34;selectUserInIds\u0026#34; resultType=\u0026#34;com.ahao.mybatis.model.User\u0026#34;\u0026gt; SELECT * FROM imooc_user WHERE id IN \u0026lt;foreach collection=\u0026#34;array\u0026#34; open=\u0026#34;(\u0026#34; close=\u0026#34;)\u0026#34; separator=\u0026#34;,\u0026#34; item=\u0026#34;item\u0026#34; index=\u0026#34;index\u0026#34;\u0026gt; #{item} \u0026lt;/foreach\u0026gt; \u0026lt;/select\u0026gt;   遍历 Map 当 Java 方法使用的参数类型为 Map 时，如下：\n1  int updateUserById(@Param(\u0026#34;params\u0026#34;) Map map, @Param(\u0026#34;id\u0026#34;) Integer id);   使用 foreach 标签遍历 Map 时，collection 属性值为注解指定的参数名，即 params，且 item 是 Map 的键值，index 是键名。\n1 2 3 4 5 6 7 8  \u0026lt;update id=\u0026#34;updateUserById\u0026#34;\u0026gt; UPDATE imooc_user SET \u0026lt;foreach collection=\u0026#34;params\u0026#34; item=\u0026#34;val\u0026#34; index=\u0026#34;key\u0026#34; separator=\u0026#34;,\u0026#34;\u0026gt; ${key} = #{val} \u0026lt;/foreach\u0026gt; WHERE id = #{id} \u0026lt;/update\u0026gt;   注意： 由于 key 是字段名称，因此不能使用#{}作为占位符，只能使用${}在字符串中替换。\nupdateUserById 生成的 SQL 语句大致如下：\n1  UPDATEimooc_userSETscore=?,age=?WHEREid=?  实践 例1. 使用名称批量查询用户 请使用 MyBatis 完成对 imooc_user 表使用名称批量查询用户的功能，参数为一个名称列表，使用 in 关键字进行查询。\n分析：\n按照 MyBatis 的开发模式，先在 UserMapper.xml 文件中添加使用名称批量查询用户的 select 标签，然后在 UserMapper.java 中添加上对应的方法。\n步骤：\n首先，在 UserMapper.xml 中添加 select 标签，并在标签中写入 SQL，使用 foreach 标签来遍历名称列表。\n1 2 3 4 5 6 7  \u0026lt;select id=\u0026#34;selectUserInNames\u0026#34; resultType=\u0026#34;com.ahao.mybatis.model.User\u0026#34;\u0026gt; SELECT * FROM imooc_user WHERE username IN \u0026lt;foreach collection=\u0026#34;names\u0026#34; open=\u0026#34;(\u0026#34; close=\u0026#34;)\u0026#34; separator=\u0026#34;,\u0026#34; item=\u0026#34;item\u0026#34; index=\u0026#34;index\u0026#34;\u0026gt; #{item} \u0026lt;/foreach\u0026gt; \u0026lt;/select\u0026gt;   然后在 UserMapper.java 中添加上对应的接口方法：\n1 2 3 4 5 6 7 8 9  package com.ahao.mybatis.mapper; import org.apache.ibatis.annotations.Mapper; import com.ahao.mybatis.model.User; @Mapper public interface UserMapper { List\u0026lt;User\u0026gt; selectUserInNames(@Param(\u0026#34;names\u0026#34;) List\u0026lt;String\u0026gt; names); }   结果：\n通过如下代码，我们运行 selectUserInNames 这个方法。\n1 2 3  UserMapper userMapper = session.getMapper(UserMapper.class); List\u0026lt;User\u0026gt; users = userMapper.selectUserInNames(Arrays.asList(\u0026#34;pedro\u0026#34;, \u0026#34;peter\u0026#34;)); System.out.println(users);   成功后，结果为：\n1  [User{id=1, username=\u0026#39;peter\u0026#39;, age=18, score=100}, User{id=2, username=\u0026#39;pedro\u0026#39;, age=24, score=200}]   例2. 批量插入用户 请使用 MyBatis 完成对 imooc_user 表批量插入用户的功能，参数为一个用户列表。\n分析：\n同上。\n步骤：\n首先，在 UserMapper.xml 中添加 insert 标签，并在标签中写入 SQL，使用 foreach 标签来遍历用户列表。\n1 2 3 4 5 6 7  \u0026lt;insert id=\u0026#34;insertUsers\u0026#34;\u0026gt; INSERT INTO imooc_user(username,age,score) VALUES \u0026lt;foreach collection=\u0026#34;users\u0026#34; item=\u0026#34;user\u0026#34; separator=\u0026#34;,\u0026#34;\u0026gt; (#{user.username}, #{user.age}, #{user.score}) \u0026lt;/foreach\u0026gt; \u0026lt;/insert\u0026gt;   注意，这里遍历 users 得到的单位是 user，user 是一个对象，因此必须通过 OGNL 表达式来取 user 的属性。\n然后在 UserMapper.java 中添加上对应的接口方法：\n1 2 3 4 5 6 7 8 9  package com.ahao.mybatis.mapper; import org.apache.ibatis.annotations.Mapper; import com.ahao.mybatis.model.User; @Mapper public interface UserMapper { int insertUsers(@Param(\u0026#34;users\u0026#34;) List\u0026lt;User\u0026gt; users); }   结果：\n通过如下代码，我们运行 insertUsers 这个方法。\n1 2 3 4 5 6 7 8 9 10  User user1 = new User(); user1.setUsername(\u0026#34;user1\u0026#34;); user1.setScore(100); user1.setAge(0); User user2 = new User(); user2.setUsername(\u0026#34;user2\u0026#34;); user2.setScore(210); user2.setAge(20); int rows = userMapper.insertUsers(Arrays.asList(user1, user2)); System.out.println(rows);   成功后，结果为：\n1  2   小结  foreach 标签是使用非常广泛的一个标签，当使用 SQL 进行批量插入、查询时都需要使用到它。 列表遍历的使用最为广泛，数组和 Map 则相对较少。  MyBatis script 前言 前面一系列动态 SQL 小节的学习中，我们都是在 xml 中书写 SQL 的。注解无法发挥 MyBatis 动态 SQL 的真正威力，但是 if、choose、bind、where 等标签还是可以在注解中使用的。\nMyBatis 官方文档对于此的介绍只有寥寥一句话和一个简单的例子，在实际的应用中也几乎没有人这样去做，因为它确实不太美观，但是考虑到这个知识点并不复杂，也极有可能成为一个刁钻的面试点，我们还是一起来学习一下。\n实例 在注解中使用动态 SQL 其实十分简单，只需在动态 SQL 语句的外面包上一层script标签即可。如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  @Select({\u0026#34;\u0026lt;script\u0026gt;\u0026#34;, \u0026#34;SELECT * FROM imooc_user\u0026#34;, \u0026#34; WHERE\u0026#34;, \u0026#34; \u0026lt;choose\u0026gt;\u0026#34;, \u0026#34; \u0026lt;when test=\u0026#39;id != null\u0026#39;\u0026gt;\u0026#34;, \u0026#34; id = #{id}\u0026#34;, \u0026#34; \u0026lt;/when\u0026gt;\u0026#34;, \u0026#34; \u0026lt;when test=\u0026#39;username != null\u0026#39;\u0026gt;\u0026#34;, \u0026#34; username = #{username}\u0026#34;, \u0026#34; \u0026lt;/when\u0026gt;\u0026#34;, \u0026#34; \u0026lt;otherwise\u0026gt;\u0026#34;, \u0026#34; 1 = 0\u0026#34;, \u0026#34; \u0026lt;/otherwise\u0026gt;\u0026#34;, \u0026#34; \u0026lt;/choose\u0026gt;\u0026#34;, \u0026#34;\u0026lt;/script\u0026gt;\u0026#34;}) User selectUserByIdOrName(@Param(\u0026#34;id\u0026#34;) Integer id, @Param(\u0026#34;username\u0026#34;) String username);   在 Select 注解中，我们没有直接写入 SQL，而是在最外层套上一个 script 标签，这里考虑到 SQL 语句的美观性，我们把语句分成了字符串数组来书写，MyBatis 会自动将其拼接成一个完整的语句。\n实践 例1. 查询小写名称客户 请使用 MyBatis 完成对 imooc_user 表查询小写名称客户的功能，将名称小写后再进行查询。\n分析：\n使用本小节所学的知识，直接在 UserMapper.java 接口上添加方法，并使用 Select 注解即可。\n步骤：\n在 UserMapper.java 中添加上对应的接口方法，方法接受 username 一个参数。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  package com.ahao.mybatis.mapper; import org.apache.ibatis.annotations.Mapper; import com.ahao.mybatis.model.User; @Mapper public interface UserMapper { @Select({ \u0026#34;\u0026lt;script\u0026gt;\u0026#34;, \u0026#34;\u0026lt;bind name=\\\u0026#34;lowercaseName\\\u0026#34; value=\\\u0026#34;username.toLowercase\\\u0026#34;/\u0026gt;\u0026#34;, \u0026#34;SELECT * FROM imooc_user\u0026#34;, \u0026#34;WHERE username = #{lowercaseName}\u0026#34;, \u0026#34;\u0026lt;/script\u0026gt;\u0026#34; }) User selectUsernameLowercase(String username); }   结果：\n通过如下代码，我们运行 selectUsernameLowercase 这个方法。\n1 2 3  UserMapper userMapper = session.getMapper(UserMapper.class); User pedro = userMapper.selectUsernameLowercase(\u0026#34;PEDRO\u0026#34;); System.out.println(pedro);   成功后，结果为：\n1  User{id=2, username=\u0026#39;pedro\u0026#39;, age=24, score=200}   小结  通过 scirpt 标签，我们可以在注解中使用动态 SQL 的诸多标签，极大地增强了注解的能力，但相对于 xml 这种更为优雅的方式，无疑是后者更佳，因此我们我们强力推荐你使用 xml 的方式。  MyBatis 配置介绍 前言 MyBatis 的配置十分重要，它直接左右 MyBatis 的行为。我们可以将 MyBatis 配置分为两大部分，第一部分是 mapper，也就是容纳 SQL 语句的.xml文件，另一部分是 configuration ，也就是前面小节提到的 mybatis-config.xml 文件。\n本小节，我们将介绍 configuration 中常见且有用的配置项。\n结构 MyBatis 以 .xml 作为配置文件，且以 configuration 作为配置的根节点。在 configuration 下有诸多配置项，它们的结构如下：\nconfiguration（配置）\n properties（属性） settings（设置） typeAliases（类型别名） typeHandlers（类型处理器） objectFactory（对象工厂） plugins（插件） environments（环境配置）  environment（环境变量）  transactionManager（事务管理器） dataSource（数据源）     databaseIdProvider（数据库厂商标识） mappers（映射器）  MyBatis configuration 共 9 项，其中一些配置在前面的小节中已经介绍到了，下面我们将分别介绍每一项配置。\n属性 properties 通过 properties 配置，我们可以将一些重要的配置属性抽离到其它的 .properties 文件。\n比如，dataSource 中的数据库 url、用户名和密码，我们可以单独以 datasource.properties 文件来存储，然后在 mybatis-config.xml 文件中导入使用。\n在 resources 目录下新建 datasource.properties 文件，并填入以下内容：\n1 2 3  url=jdbc:mysql://localhost:3306/imooc?useSSL=false username=root password=123456   然后在 mybatis-config.xml 文件中通过 properties 配置来引入 datasource.properties 文件：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34; ?\u0026gt; \u0026lt;!DOCTYPE configuration PUBLIC \u0026#34;-//mybatis.org//DTD Config 3.0//EN\u0026#34; \u0026#34;http://mybatis.org/dtd/mybatis-3-config.dtd\u0026#34;\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;!-- 引入datasource.properties --\u0026gt; \u0026lt;properties resource=\u0026#34;datasource.properties\u0026#34;/\u0026gt; \u0026lt;environments default=\u0026#34;development\u0026#34;\u0026gt; \u0026lt;environment id=\u0026#34;development\u0026#34;\u0026gt; \u0026lt;transactionManager type=\u0026#34;JDBC\u0026#34;/\u0026gt; \u0026lt;dataSource type=\u0026#34;POOLED\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;driver\u0026#34; value=\u0026#34;com.mysql.cj.jdbc.Driver\u0026#34;/\u0026gt; \u0026lt;!-- 占位符动态替换配置 --\u0026gt; \u0026lt;property name=\u0026#34;url\u0026#34; value=\u0026#34;${url}\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;username\u0026#34; value=\u0026#34;${username}\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;password\u0026#34; value=\u0026#34;${password}\u0026#34;/\u0026gt; \u0026lt;/dataSource\u0026gt; \u0026lt;/environment\u0026gt; \u0026lt;/environments\u0026gt; \u0026lt;/configuration\u0026gt;   通过 properties 中的 resource 属性引入 datasource.properties 后，我们就可以使用占位符的方式去动态替换配置，如 ${url}，表示从 datasource.properties 文件中取出 url 项并填充在此处。\n它们在目录中的位置如下：\n1 2 3  src/main/resources ├── datasource.properties ├── mybatis-config.xml   设置 settings MyBatis 提供了 settings 来设置一些主要的参数，它们会直接的改变 MyBatis 的运行时行为。\nsettings 共有十几项，我们罗列一些常用的：\n   设置名 描述 可选值 默认值     cacheEnabled 全局地开启或关闭所有 mapper 中的缓存 true | false true   lazyLoadingEnabled 延迟加载的全局开关，当开启时，所有关联对象都会延迟加载 true | false false   defaultStatementTimeout 设置数据库查询超时时间 任意正整数 null   mapUnderscoreToCamelCase 是否开启自动驼峰命名规则（camel case）映射 true ｜false false   localCacheScope MyBatis会默认缓存会话中的查询，即 SESSION，若无需缓存则设置为 STATEMENT SESSION ｜ STATEMENT SESSION   defaultEnumTypeHandler 指定 Enum 使用的默认 TypeHandler Java 类的全路径 org.apache.ibatis. type.EnumTypeHandler   logPrefix 指定 MyBatis 日志名称前缀 任何字符串 未设置   logImpl 指定 MyBatis 日志的实现，未指定时将自动查找 SLF4J ｜ LOG4J｜LOG4J2｜JDK_LOGGING｜COMMONS_LOGGING｜STDOUT_LOGGING｜NO_LOGGING 未设置   proxyFactory 指定 Mybatis 创建具有延迟加载能力的对象所用到的代理工具 CGLIB ｜ JAVASSIST JAVASSIST    当使用它们时，你只需要在 mybatis-config.xml 配置文件中打开相应的配置。\n例如，我们开启了下划线转驼峰的配置：\n1 2 3 4 5 6 7 8 9  \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34; ?\u0026gt; \u0026lt;!DOCTYPE configuration PUBLIC \u0026#34;-//mybatis.org//DTD Config 3.0//EN\u0026#34; \u0026#34;http://mybatis.org/dtd/mybatis-3-config.dtd\u0026#34;\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;settings\u0026gt; \u0026lt;setting name=\u0026#34;mapUnderscoreToCamelCase\u0026#34; value=\u0026#34;true\u0026#34;/\u0026gt; \u0026lt;/settings\u0026gt; \u0026lt;/configuration\u0026gt;   别名 typeAliases MyBatis 在指定 Java 类时需要使用到类的全路径，如 com.ahao.mybatis.model.Blog，typeAliases 可以为全路径定义一个别名，这样就能减少一定的重复工作。\n例如，将 com.ahao.mybatis.model.Blog 的别名定义为 Blog：\n1 2 3 4 5 6 7 8 9  \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34; ?\u0026gt; \u0026lt;!DOCTYPE configuration PUBLIC \u0026#34;-//mybatis.org//DTD Config 3.0//EN\u0026#34; \u0026#34;http://mybatis.org/dtd/mybatis-3-config.dtd\u0026#34;\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;typeAliases\u0026gt; \u0026lt;typeAlias type=\u0026#34;com.ahao.mybatis.model.Blog\u0026#34; alias=\u0026#34;Blog\u0026#34;/\u0026gt; \u0026lt;/typeAliases\u0026gt; \u0026lt;/configuration\u0026gt;   MyBatis 还支持为一个包下所有类定义别名：\n1 2 3 4 5 6 7 8 9  \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34; ?\u0026gt; \u0026lt;!DOCTYPE configuration PUBLIC \u0026#34;-//mybatis.org//DTD Config 3.0//EN\u0026#34; \u0026#34;http://mybatis.org/dtd/mybatis-3-config.dtd\u0026#34;\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;typeAliases\u0026gt; \u0026lt;package name=\u0026#34;com.ahao.mybatis.model\u0026#34;/\u0026gt; \u0026lt;/typeAliases\u0026gt; \u0026lt;/configuration\u0026gt;   这样在 com.ahao.mybatis.model 包中的所有类都有了别名，每个类的别名都是其类的名称首字母小写，如 Author 类的别名为 author。\n类型处理器 typeHandlers 类型处理器我们将在类型处理器小节中再详细介绍。\n对象工厂 objectFactory MyBatis 每次创建结果对象的新实例时，它都会使用一个对象工厂（ObjectFactory）来完成。MyBatis 默认的对象工厂仅仅只是实例化目标类，我们可以自定义一个对象工厂类来覆盖默认的对象工厂。\n配置如下：\n1 2 3 4 5 6 7  \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34; ?\u0026gt; \u0026lt;!DOCTYPE configuration PUBLIC \u0026#34;-//mybatis.org//DTD Config 3.0//EN\u0026#34; \u0026#34;http://mybatis.org/dtd/mybatis-3-config.dtd\u0026#34;\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;objectFactory type=\u0026#34;org.mybatis.example.ExampleObjectFactory\u0026#34;/\u0026gt; \u0026lt;/configuration\u0026gt;   绝大多数情况下，这个操作都是极其危险的，改变了 MyBatis 默认的对象创建行为可能会带来一定的兼容错误，所以我们不做过多介绍，如果你确实需要它，可以查阅相关的资料。\n插件 plugins 插件我们将在插件小节中再详细介绍。\n环境配置 environments 环境配置是最为复杂的一项配置，MyBatis 提供了多环境配置机制，例如：开发环境和生产环境上的数据库配置就大概率不一样。\n每个 environment 都有一个唯一的 id 字段，且 environments 需要提供一个默认环境，如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34; ?\u0026gt; \u0026lt;!DOCTYPE configuration PUBLIC \u0026#34;-//mybatis.org//DTD Config 3.0//EN\u0026#34; \u0026#34;http://mybatis.org/dtd/mybatis-3-config.dtd\u0026#34;\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;environments default=\u0026#34;development\u0026#34;\u0026gt; \u0026lt;environment id=\u0026#34;development\u0026#34;\u0026gt; \u0026lt;transactionManager type=\u0026#34;JDBC\u0026#34;/\u0026gt; \u0026lt;dataSource type=\u0026#34;POOLED\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;driver\u0026#34; value=\u0026#34;com.mysql.cj.jdbc.Driver\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;url\u0026#34; value=\u0026#34;jdbc:mysql://localhost:3306/imooc?useSSL=false\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;username\u0026#34; value=\u0026#34;root\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;password\u0026#34; value=\u0026#34;123456\u0026#34;/\u0026gt; \u0026lt;/dataSource\u0026gt; \u0026lt;/environment\u0026gt; \u0026lt;/environments\u0026gt; \u0026lt;/configuration\u0026gt;   在每个 environment 下又有两个子配置项，它们分别负责管理事务和数据源。\n事务管理器 transactionManager 在 xml 文件中对应 \u0026lt;transactionManager type=\u0026quot;JDBC\u0026quot;/\u0026gt;，其中 type 属性对应了事务管理器的两种类型，分别是JDBC和MANAGED。\n JDBC ：直接使用了 JDBC 的提交和回滚机制。 MANAGED：让容器来管理事务的整个生命周期，例如 spring 容器。   提示： 如果你使用 spring 作为容器，那么 transactionManager 会被自动配置且可用。\n 数据源 dataSource 在 xml 文件中对应\u0026lt;dataSource type=\u0026quot;POOLED\u0026quot;\u0026gt;，其中 type 属性代表了数据源的类型，可选的有三种类型，如下：\n UNPOOLED：非池化数据源，每次使用时打开，结束后关闭，不推荐。 POOLED：池化数据源，连接池管理连接，推荐。 JNDI：在 EJB 这类容器中使用，几乎不用。  数据库厂商标识 databaseIdProvider 多数据源支持我们将在多数据源支持小节中详细介绍。\n映射器 mappers 通过 mappers 配置，我们可以指定所对应 SQL 映射文件，这样 MyBatis 才能找到另一部分的 SQL 配置文件。\nmappers 可以包含多个 mapper，mapper 的加载共有 4 种方式。\n相对类路径 通过 resource 属性指定 mapper .xml 文件所对应的类路径。\n1 2 3  \u0026lt;mappers\u0026gt; \u0026lt;mapper resource=\u0026#34;com/imooc/mybatis/mapper/UserMapper.xml\u0026#34;/\u0026gt; \u0026lt;/mappers\u0026gt;   URL路径 通过 url 属性指定 mapper .xml 文件所对应的文件路径。\n1 2 3  \u0026lt;mappers\u0026gt; \u0026lt;mapper url=\u0026#34;file:///mapper/UserMapper.xml\u0026#34;/\u0026gt; \u0026lt;/mappers\u0026gt;   类路径 通过 class 属性指定 mapper 类所对应的类路径。\n1 2 3  \u0026lt;mappers\u0026gt; \u0026lt;mapper class=\u0026#34;com.ahao.mybatis.mapper.UserMapper\u0026#34;/\u0026gt; \u0026lt;/mappers\u0026gt;   包路径 通过制定包路径，将包中的所有接口类自动扫描为 mapper。\n1 2 3  \u0026lt;mappers\u0026gt; \u0026lt;package name=\u0026#34;com.ahao.mybatis.mapper\u0026#34;/\u0026gt; \u0026lt;/mappers\u0026gt;   小结  MyBatis 的配置是比较多的，本小节列举了一些常用且重要的配置，如果你还不满足，可以阅读这里的官方配置文档。 MyBatis 的另一部分 SQL 配置虽然分散在了包中，但通过 mappers 这个中间桥梁，二者又紧密的结合在一起了。 在真实的开发中，会有专门的类库来提供这些配置，但你需要了解它们，以便在需要时迅速作出反应。  ","date":"2021-06-16T13:36:41Z","image":"https://ahao.ink/18.png","permalink":"https://ahao.ink/posts/mybatis-%E5%88%9D%E7%BA%A7%E7%AF%87/","title":"MyBatis 初级篇"},{"content":"MyBatis 使用 Redis 缓存 前言 在MyBatis 缓存一节中，我们介绍了 MyBatis 的多级缓存。MyBatis 的二级缓存可在多个会话中共享缓存，但是这也加大了内存的使用空间，如果二级缓存空间占有量过多势必会导致程序运行空间的不足，因此我们需要将二级缓存转移到专业的缓存服务器上。\nRedis 是一个高性能的 kv 数据库，被广泛的使用在缓存服务上，MyBatis 项目开发者提供了 Redis 缓存的实现。本小节我们将一起来学习如何在 MyBatis 中集成 Redis 缓存。\n准备 添加依赖 在项目的 pom.xml 文件中添加上 mybatis-redis 依赖：\n1 2 3 4 5  \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.mybatis.caches\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mybatis-redis\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.0.0-beta2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt;   mybatis-redis 目前还只有 beta 版，相信不久后就可以到正式版了。\nRedis服务器 请确保你拥有一台可用的 Redis 服务器，并能够正常运行。如下：\n1 2  127.0.0.1:6379\u0026gt; ping PONG   Redis配置文件 在 src/main/resources 目录下新增 redis.properties 配置文件，并向其中添加如下配置：\n1 2 3 4 5 6 7  host=localhost port=6379 connectionTimeout=5OOO soTimeout=5OOO password=123456 database=O clientName=   注意，请根据自己的环境来修改配置，如密码和主机。\n使用 配置 在对应的 mapper 配置文件中，如 UserMapper.xml 文件添加上对应的缓存配置。如下：\n1  \u0026lt;cache type=\u0026#34;org.mybatis.caches.redis.RedisCache\u0026#34; /\u0026gt;   调用 配置好以后，我们就可以直接在程序中调用了。\n1 2 3 4 5 6 7 8  SqlSession session1 = sqlSessionFactory.openSession(); UserMapper userMapper1 = session1.getMapper(UserMapper.class); User user1 = userMapper1.selectUserById(1); System.out.println(user1); SqlSession session2 = sqlSessionFactory.openSession(); UserMapper userMapper2 = session2.getMapper(UserMapper.class); User user2 = userMapper2.selectUserById(1); System.out.println(user2);   注意，User 对象必须实现Serializable接口才可被缓存。 比如：\n1  public class User implements Serializable {}   当缓存成功，程序会有如下输出，表示缓存击中。\n1 2 3 4  20:58:12.462 [main] DEBUG com.ahao.mybatis.mapper.UserMapper - Cache Hit Ratio [com.ahao.mybatis.mapper.UserMapper]: 1.0 User{id=1, username=\u0026#39;peter\u0026#39;, age=18, score=100} 20:58:12.499 [main] DEBUG com.ahao.mybatis.mapper.UserMapper - Cache Hit Ratio [com.ahao.mybatis.mapper.UserMapper]: 1.0 User{id=1, username=\u0026#39;peter\u0026#39;, age=18, score=100}    提示： 在第一次运行时，会向 Redis 中存放数据，不会使用到缓存，第二次运行时则才会使用到缓存。\n 小结  Redis 缓存十分常见，MyBatis 集成 Redis 缓存也异常方便，但是在实际生产环境下如此应用的都不多，而是直接选择其它方式来使用 Redis 缓存。  spring-boot 集成 MyBatis 前言 spring-boot 可谓是 Java 领域中最火的框架之一， 也是目前 Java 应用开发的事实标准，如果不会使用未免有些 out。本小节，我们将一起学习如何使用 spring-boot 来集成 MyBatis。\n项目初始化 对于拥有 IDEA 专业版的人来说，新建 spring-boot 项目是十分方便的，当然如果你没有也没关系，Spring 官方给我们提供了一个快速新建项目的网站。\n打开 https://start.spring.io/ 。如下： 给项目输入合适的 groupId 和 artifactId 然后点击生成按钮，浏览器会自动下载一个压缩包 springboot-mybatis-exmaple.zip。\n解压该包，并通过 IDE 打开这个项目。\n启动器 在项目的 pom 文件中添加如下 3 个依赖：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.mybatis.spring.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mybatis-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.1.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;mysql\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mysql-connector-java\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;8.0.18\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt;   mybatis-spring-boot-starter 是 MyBatis 为 spring-boot 提供的启动器，添加后就可以以少量的配置来快速的使用 MyBatis；spring-boot-starter-web 是 spring-boot 提供的 Web 启动器，会给我们提供一个 Web 应用环境；mysql-connector-java 是 MySQL 数据库驱动依赖。\n配置 在 src/main/resources 有 spring-boot 提供的默认配置文件 application.properties。在该配置文件下，我们需要添加上对于的数据源配置。\n1 2 3 4 5  # 数据源配置，请修改为你项目的实际配置 spring.datasource.url=jdbc:mysql://localhost:3306/imooc spring.datasource.username=root spring.datasource.password=123456 spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver   实践 模型层 在项目的 com.ahao.mybatis.springbootmybatisexample 的包下新建 model 包，并在该包下新建 User 类。如下：\n1 2 3 4 5 6 7  public class User implements Serializable { private Long id; private String username; private Integer age; private Integer score; // 省略 getter 和 setter 方法 }   User 类与数据表 imooc_user 对应。\n数据访问层 在 com.ahao.mybatis.springbootmybatisexample 包下新建 mapper 包，并新建 UserMapper 类。如下：\n1 2 3 4 5  import org.apache.ibatis.annotations.Mapper; @Mapper public interface UserMapper { }   控制层 在 com.ahao.mybatis.springbootmybatisexample 包下新建 controller 包，并新建 UserController 类。如下：\n1 2 3 4 5  import org.springframework.web.bind.annotation.RestController; @RestController public class UserController { }   使用 RestController 注解将 UserController 标记为控制器。\n完善 有了雏形后，我们再为这些类添加上具体的业务，比如查询所有 imooc_user 用户。\n  在 UserMapper 中，我们添加上 getUsers 接口方法，并通过 Select 注解来映射相应的 SQL 语句。\n1 2 3 4 5 6  @Mapper @Repository public interface UserMapper { @Select(\u0026#34;SELECT * FROM imooc_user\u0026#34;) List\u0026lt;User\u0026gt; getUsers(); }     在 UserController 中，我们添加上对应的 getUsers API，该 API 对外暴露所有用户数据。\n1 2 3 4 5 6 7 8 9 10 11  @RestController @RequestMapping(\u0026#34;/user\u0026#34;) public class UserController { @Autowired private UserMapper userMapper; @GetMapping public List\u0026lt;User\u0026gt; getUsers() { return userMapper.getUsers(); } }     测试 运行项目，如果你使用 IDE，可直接通过按钮来运行，如果没有也可使用终端来运行程序：\n1  mvn spring-boot:run   运行成功后，我们测试一下：\n1 2 3 4 5  curl 127.0.0.1:8080/user/ 代码块1 [{\u0026#34;id\u0026#34;:1,\u0026#34;username\u0026#34;:\u0026#34;peter\u0026#34;,\u0026#34;age\u0026#34;:18,\u0026#34;score\u0026#34;:100}, {\u0026#34;id\u0026#34;:2,\u0026#34;username\u0026#34;:\u0026#34;pedro\u0026#34;,\u0026#34;age\u0026#34;:24,\u0026#34;score\u0026#34;:200}, {\u0026#34;id\u0026#34;:3,\u0026#34;username\u0026#34;:\u0026#34;jerry\u0026#34;,\u0026#34;age\u0026#34;:28,\u0026#34;score\u0026#34;:500}]   小结  spring-boot 集成 MyBatis 是十分方便的，只需少量的配置就可轻松使用 MyBatis。 spring-boot + MyBatis 几乎是国内标配，请务必要上手实操一下。  使用 MyBatis-tk 和 pagehelper 前言 在 spring-boot 集成 MyBatis小节中，我们介绍了如何在 spring-boot 中集成 MyBatis，MyBatis 虽然灵活，但是对于业务开发还略显不够。tk.mapper 和 pagehelper 是国内开发者为 MyBatis 定制的两款业务增强库，tk.mapper 可以让开发者从基本的增删查改中解放，pagehelper 则提供了高度易用的分页功能。\n有了它们，MyBatis 可谓是如虎添翼，本小节我们将介绍这两款库的使用。\ntk.mapper 简介 在 tk.mapper 项目的首页有关于它最精确的介绍。\n 通用 mapper 是一个可以实现任意 MyBatis 通用方法的框架，项目提供了常规的增删改查操作以及 example 相关的单表操作。通用 mapper 是为了解决 MyBatis 使用中 90% 的基本操作，使用它可以很方便的进行开发，可以节省开发人员大量的时间。\n 总结来说，tk.mapper 可以为 MyBatis 开发节省大量的时间，精简的 90% 的基本操作。\n依赖 tk.mapper 的使用也十分简单，我们只需引入相应的 starter 即可。如下：\n1 2 3 4 5  \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;tk.mybatis\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mapper-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.1.5\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt;    TIPS： 注意，引入了 mapper starter 后，虽然和 MyBatis 官方的 starter 没有冲突，但是官方的自动配置不会生效！\n 使用 简单地说，tk.mapper 会给普通的 mapper 做一些增强，让 mapper 具有基本的增删查改的能力。如下：\n1 2 3 4 5 6 7 8  import tk.mybatis.mapper.common.BaseMapper; @Mapper @Repository public interface UserMapper extends BaseMapper\u0026lt;User\u0026gt; { @Select(\u0026#34;SELECT * FROM imooc_user\u0026#34;) List\u0026lt;User\u0026gt; getUsers(); }   UserMapper 是原有的 mapper，只需继承 tk.mapper 中的 BaseMapper 就完成的增强。\nUserMapper 继承 BaseMapper 后就拥有了基础的增删查改功能，而无需写 SQL。BaseMapper 必须指定一个与 UserMapper 对应的模型类，即 User 类。\n1 2 3 4 5 6 7 8 9 10 11 12 13  package com.ahao.mybatis.springbootmybatisexample.model; import javax.persistence.Table; import java.io.Serializable; @Table(name = \u0026#34;imooc_user\u0026#34;) public class User implements Serializable { private Long id; private String username; private Integer age; private Integer score; // 省略 getter 和 setter 方法 }   数据表的名称为 imooc_user，这里我们通过 Table 注解来告诉 tk User 模型所对应的数据表。\nmapper 增强后，我们还需要给 SpringbootMybatisExampleApplication 启动类添加上一个注解：\n1 2 3 4 5 6 7 8 9  import tk.mybatis.spring.annotation.MapperScan; @SpringBootApplication @MapperScan(\u0026#34;com.ahao.mybatis.springbootmybatisexample.mapper\u0026#34;) public class SpringbootMybatisExampleApplication { public static void main(String[] args) { SpringApplication.run(SpringbootMybatisExampleApplication.class, args); } }   MapperScan 是 tk 提供的一个 mapper 扫描注解，在注解中我们需要填入 mapper 所在的包路径，即 com.ahao.mybatis.springbootmybatisexample.mapper。\n到此 UserMapper 增强已经完成了，我们尝试在 UserController 中使用。\n1 2 3 4 5 6 7 8 9 10 11 12  @RestController @RequestMapping(\u0026#34;/user\u0026#34;) public class UserController { @Autowired private UserMapper userMapper; @GetMapping public List\u0026lt;User\u0026gt; getUsers() { // return userMapper.getUsers();  return userMapper.selectAll(); } }   在这里，我们替换 getUsers 方法，而是使用了 selectAll 方法，selectAll 是 BaseMapper 提供的方法，也就是增强的方法，我们无需去为这个方法添加相应的 SQL，tk 会自动帮我们搭理好一切。\n再次运行程序，并测试接口：\n1 2  # curl 127.0.0.1:8080/user/ [{\u0026#34;id\u0026#34;:1,\u0026#34;username\u0026#34;:\u0026#34;peter\u0026#34;,\u0026#34;age\u0026#34;:18,\u0026#34;score\u0026#34;:100},{\u0026#34;id\u0026#34;:2,\u0026#34;username\u0026#34;:\u0026#34;pedro\u0026#34;,\u0026#34;age\u0026#34;:24,\u0026#34;score\u0026#34;:200},{\u0026#34;id\u0026#34;:3,\u0026#34;username\u0026#34;:\u0026#34;jerry\u0026#34;,\u0026#34;age\u0026#34;:28,\u0026#34;score\u0026#34;:500},{\u0026#34;id\u0026#34;:4,\u0026#34;username\u0026#34;:\u0026#34;mike\u0026#34;,\u0026#34;age\u0026#34;:12,\u0026#34;score\u0026#34;:300}]   我们得到了与之前一样的结果，可以看到在我们并未书写任何 SQL 的前提下， tk.mapper 自动帮我们生成了需要的 SQL 查询，这就是 tk.mapper 所带来的简化开发能力。\npagehelper 简介 pagehelper 是一个 方便好用的 MyBatis 分页插件，支持复杂的单表、多表分页，是目前 MyBatis 中使用最为广泛的插件之一。\n依赖 和其它一样，pagehelper 也只需导入相应的启动器即可。\n1 2 3 4 5  \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.github.pagehelper\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;pagehelper-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.2.13\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt;   使用 pagehelper 充分的简单易用，在 UserController 中只需添加一行代码即可。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  import com.github.pagehelper.PageHelper; @RestController @RequestMapping(\u0026#34;/user\u0026#34;) public class UserController { @Autowired private UserMapper userMapper; @GetMapping public List\u0026lt;User\u0026gt; getUsers() { PageHelper.startPage(1, 2); return userMapper.selectAll(); } }   PageHelper.startPage(1, 2)会自动拦截后面将要执行的 SQL，然后处理该 SQL 并添加分页参数。startPage 接收两个参数，第一个参数表示当前分页，第二个参数表示分页数目，如这里的 1，2 表示第一页且该页最多有两条记录。\n运行程序，并测试接口：\n1 2  # curl 127.0.0.1:8080/user/ [{\u0026#34;id\u0026#34;:1,\u0026#34;username\u0026#34;:\u0026#34;peter\u0026#34;,\u0026#34;age\u0026#34;:18,\u0026#34;score\u0026#34;:100},{\u0026#34;id\u0026#34;:2,\u0026#34;username\u0026#34;:\u0026#34;pedro\u0026#34;,\u0026#34;age\u0026#34;:24,\u0026#34;score\u0026#34;:200}]   与上面的结果相比，结果的数目只有两条，显然分页插件已经生效。\n TIPS: 提示，pagehelper 的分页是从1开始的，而有些分页插件分页是从0开始的。\n 小结  有了 spring-boot 后，很多项目的开发都将变得简单，mapper 和 pagehelper 都只需添加一个依赖即可使用。 本小节简单的介绍了 mapper 和 pagehelper，如果你想深入了解它们，可以阅读它们的文档：pagehelper，mapper。  使用 MyBatis-plus 前言 在spring-boot 集成 MyBatis小节中，我们介绍了如何在 spring-boot 中集成 MyBatis，MyBatis 虽然灵活，但是对于业务开发还略显不够。MyBatis-Plus 是国内开发者为 MyBatis 定制的一款增强工具，在不侵入 MyBatis 的基础上能够快速地提升 MyBatis 的开发能力，为开发者节省大量的时间。\n简介 MyBatis-Plus（简称 MP）是一个 MyBatis 的增强工具，在 MyBatis 的基础上只做增强不做改变，为简化开发、提高效率而生。\nMyBatis-Plus 内置丰富的基础 mapper 和插件，是目前国内使用最为广泛的开源项目之一。\n依赖 在 spring-boot 的基础上，使用 MyBatis-Plus 也十分简单，只需在 pom 文件中添加上对应的 starter 即可。\n1 2 3 4 5  \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.baomidou\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mybatis-plus-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.3.1.tmp\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt;   准备 MP 提供了十分方便的 BaseMapper 供项目 mapper 继承，如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  package com.ahao.mybatis.springbootmybatisexample.mapper; import com.baomidou.mybatisplus.core.mapper.BaseMapper; import com.ahao.mybatis.springbootmybatisexample.model.User; import org.apache.ibatis.annotations.Mapper; import org.apache.ibatis.annotations.Select; import org.springframework.stereotype.Repository; import java.util.List; @Mapper @Repository public interface UserMapper extends BaseMapper\u0026lt;User\u0026gt; { @Select(\u0026#34;SELECT * FROM imooc_user\u0026#34;) List\u0026lt;User\u0026gt; getUsers(); }   UserMapper 继承 BaseMapper 后就拥有了基础的增删查改功能，而无需写 SQL。BaseMapper 必须指定一个与 UserMapper 对应的模型类，即 User 类。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  package com.ahao.mybatis.springbootmybatisexample.model; import com.baomidou.mybatisplus.annotation.TableId; import com.baomidou.mybatisplus.annotation.TableName; import java.io.Serializable; @TableName(\u0026#34;imooc_user\u0026#34;) public class User implements Serializable { @TableId(\u0026#34;id\u0026#34;) private Long id; private String username; private Integer age; private Integer score; // 省略诸多 getter 和 setter 方法 }   在模型类中，我们需要通过 TableName 注解指定模型对于的数据表名称，并通过 TableId 注解指定数据表字段。\n并在 SpringbootMybatisExampleApplication 启动类上添加 MapperScan 注解来扫描 mapper，如下：\n1 2 3 4 5 6 7 8 9 10 11  import org.mybatis.spring.annotation.MapperScan; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; @SpringBootApplication @MapperScan(\u0026#34;com.ahao.mybatis.springbootmybatisexample.mapper\u0026#34;) public class SpringbootMybatisExampleApplication { public static void main(String[] args) { SpringApplication.run(SpringbootMybatisExampleApplication.class, args); } }   MapperScan 中需填入 mapper 所在的包路径，即 com.ahao.mybatis.springbootmybatisexample.mapper。\n使用 基础使用 接下来，我们在 UserController 中来使用增强后的 UserMapper。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  package com.ahao.mybatis.springbootmybatisexample.controller; import com.ahao.mybatis.springbootmybatisexample.mapper.UserMapper; import com.ahao.mybatis.springbootmybatisexample.model.User; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; import java.util.List; @RestController @RequestMapping(\u0026#34;/user\u0026#34;) public class UserController { @Autowired private UserMapper userMapper; @GetMapping public List\u0026lt;User\u0026gt; getUsers() { // return userMapper.getUsers();  return userMapper.selectList(null); } }   这里，我们替换了之前使用的 getUsers 方法，而是使用了 BaseMapper 提供的 selectList 方法，该方法接收一个参数，这里我们暂时定为 null。\n运行程序，并通过 curl 测试接口：\n1 2  # curl 127.0.0.1:8080/user/ [{\u0026#34;id\u0026#34;:1,\u0026#34;username\u0026#34;:\u0026#34;peter\u0026#34;,\u0026#34;age\u0026#34;:18,\u0026#34;score\u0026#34;:100},{\u0026#34;id\u0026#34;:2,\u0026#34;username\u0026#34;:\u0026#34;pedro\u0026#34;,\u0026#34;age\u0026#34;:24,\u0026#34;score\u0026#34;:200},{\u0026#34;id\u0026#34;:3,\u0026#34;username\u0026#34;:\u0026#34;jerry\u0026#34;,\u0026#34;age\u0026#34;:28,\u0026#34;score\u0026#34;:500},{\u0026#34;id\u0026#34;:4,\u0026#34;username\u0026#34;:\u0026#34;mike\u0026#34;,\u0026#34;age\u0026#34;:12,\u0026#34;score\u0026#34;:300}]   我们仍然取得了与之前一样的结果。可以看到，MP 在增强 UserMapper 后，我们无需再写多余的 SQL，MP 自动的为我们生成了对应的 SQL 语句。\n进阶使用 MP 的功能远不止如此简单，我们还可以通过 Java API 给 selectList 函数传入 SQL 筛选条件。如，我们只想获取分数大于 200 分的用户。\n1 2 3 4 5 6 7 8 9 10 11 12 13  @RestController @RequestMapping(\u0026#34;/user\u0026#34;) public class UserController { @Autowired private UserMapper userMapper; @GetMapping public List\u0026lt;User\u0026gt; getUsers() { QueryWrapper\u0026lt;User\u0026gt; condition = new QueryWrapper\u0026lt;\u0026gt;(); condition.lambda().gt(User::getScore, 200); return userMapper.selectList(condition); } }   QueryWrapper 是 MP 提供的查询条件包装器，通过 Java API 的方式我们就可以构造 SQL 过滤条件。如这里我们通过 lamdba 表示式构造了用户积分需大于200的过滤条件，然后将包装器以参数的形式传递给 selectList 函数。\n再次运行程序，并通过 curl 测试接口：\n1 2  # curl 127.0.0.1:8080/user/ [{\u0026#34;id\u0026#34;:3,\u0026#34;username\u0026#34;:\u0026#34;jerry\u0026#34;,\u0026#34;age\u0026#34;:28,\u0026#34;score\u0026#34;:500},{\u0026#34;id\u0026#34;:4,\u0026#34;username\u0026#34;:\u0026#34;mike\u0026#34;,\u0026#34;age\u0026#34;:12,\u0026#34;score\u0026#34;:300},{\u0026#34;id\u0026#34;:5,\u0026#34;username\u0026#34;:\u0026#34;tom\u0026#34;,\u0026#34;age\u0026#34;:27,\u0026#34;score\u0026#34;:1000}]   从结果中，可以看出积分小于200的用户都已经被过滤掉了。\n分页插件 MP 内置提供了分页插件，只需几行代码我们就可直接引入。\n1 2 3 4 5 6 7 8 9 10 11 12 13  import com.baomidou.mybatisplus.extension.plugins.PaginationInterceptor; @SpringBootApplication @MapperScan(\u0026#34;com.ahao.mybatis.springbootmybatisexample.mapper\u0026#34;) public class SpringbootMybatisExampleApplication { @Bean public PaginationInterceptor paginationInterceptor() { return new PaginationInterceptor(); } public static void main(String[] args) { SpringApplication.run(SpringbootMybatisExampleApplication.class, args); } }   在 SpringbootMybatisExampleApplication 启动类中，我们添加了一个带有 Bean 注解的 paginationInterceptor 方法，该方法返回一个 PaginationInterceptor 对象，这样插件就配置完成了。\n接下来，我们来使用它。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  import com.baomidou.mybatisplus.extension.plugins.pagination.Page; @RestController @RequestMapping(\u0026#34;/user\u0026#34;) public class UserController { @Autowired private UserMapper userMapper; @GetMapping public List\u0026lt;User\u0026gt; getUsers() { Page page = userMapper.selectPage(new Page\u0026lt;\u0026gt;(1, 3), null); return page.getRecords(); } }   UserMapper 的 selectPage 方法接受两个参数，第一个参数是分页配置，第二个参数是查询条件包装器。这里第一个参数，我们直接通过 Page 构造函数来构造，1 表示当前页，3 表示分页最大的记录数，即第一页且最多返回三条记录；第二个参数我们直接设置为 null。\n运行程序，并通过 curl 测试接口：\n1 2  # curl 127.0.0.1:8080/user/ [{\u0026#34;id\u0026#34;:1,\u0026#34;username\u0026#34;:\u0026#34;peter\u0026#34;,\u0026#34;age\u0026#34;:18,\u0026#34;score\u0026#34;:100},{\u0026#34;id\u0026#34;:2,\u0026#34;username\u0026#34;:\u0026#34;pedro\u0026#34;,\u0026#34;age\u0026#34;:24,\u0026#34;score\u0026#34;:200},{\u0026#34;id\u0026#34;:3,\u0026#34;username\u0026#34;:\u0026#34;jerry\u0026#34;,\u0026#34;age\u0026#34;:28,\u0026#34;score\u0026#34;:500}]   从结果可以看出，分页生效了，记录总数却是为 3 条。\n小结  MyBatis-Plus 是国内使用十分广泛的一款 ORM 库，极大的节省了开发者的开发时间，功能强大且使用简单。 MyBatis-Plus 的内容还是较多的，如果你感兴趣，不妨访问它的官网看一看。  ","date":"2021-06-16T13:36:41Z","image":"https://ahao.ink/20.jpg","permalink":"https://ahao.ink/posts/mybatis-%E5%AE%9E%E6%88%98%E7%AF%87/","title":"MyBatis 实战篇"},{"content":"MyBatis 缓存 前言 频繁地查询必然会给数据库带来巨大的压力，为此 MyBatis 提供了丰富的缓存功能。缓存可以有效的提升查询效率、缓解数据库压力，提高应用的稳健性。\nMyBatis 的缓存有两层，默认情况下会开启一级缓存，并提供了开启二级缓存的配置。本小节我们将一起学习 MyBatis 的缓存，充分地了解和使用它。\n一级缓存 MyBatis 一级缓存是默认开启的，缓存的有效范围是一个会话内。一个会话内的 select 查询语句的结果会被缓存起来，当在该会话内调用 update、delete 和 insert 时，会话缓存会被刷新，以前的缓存会失效。\n使用一级缓存 下面，我们以一个简单的例子来看看 MyBatis 的一级缓存是如何工作的。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  package com.ahao.mybatis.cache; import com.ahao.mybatis.mapper.UserMapper; import com.ahao.mybatis.model.User; import org.apache.ibatis.io.Resources; import org.apache.ibatis.session.SqlSession; import org.apache.ibatis.session.SqlSessionFactory; import org.apache.ibatis.session.SqlSessionFactoryBuilder; import java.io.IOException; import java.io.InputStream; @SuppressWarnings({\u0026#34;Duplicates\u0026#34;}) public class CacheTest1 { public static void main(String[] args) throws IOException { String resource = \u0026#34;mybatis-config.xml\u0026#34;; InputStream inputStream = Resources.getResourceAsStream(resource); SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); SqlSession session = sqlSessionFactory.openSession(); // 得到 mapper  UserMapper userMapper = session.getMapper(UserMapper.class); // 查询得到 user1  User user1 = userMapper.selectUserById(1); System.out.println(user1); // 查询得到 user2  User user2 = userMapper.selectUserById(1); // 通过 == 判断 user1 和 user2 是否指向同一内存区间  System.out.println(user1 == user2); session.commit(); session.close(); } }   结果：\n1 2  User{id=1, username=\u0026#39;peter-gao\u0026#39;, age=180, score=1000} true   在这个例子中，我们连续两次调用了 userMapper 的 selectUserById 方法，但是在程序输出中，user1 和 user2 却指向了同一块内存区域。这就是 MyBatis 缓存的作用，当第二次调用查询时，MyBatis 没有查询数据库而是直接从缓存中拿到了数据。\n弃用一级缓存 select 配置关闭缓存 select 默认会启用一级缓存，我们也可通过配置来关闭掉 select 缓存。\n如下，我们通过 flushCache 属性来关闭 select 查询的缓存。\n1 2 3 4  \u0026lt;select id=\u0026#34;selectUserById\u0026#34; flushCache=\u0026#34;true\u0026#34; parameterType=\u0026#34;java.lang.Integer\u0026#34; resultType=\u0026#34;com.ahao.mybatis.model.User\u0026#34;\u0026gt; SELECT * FROM user WHERE id = #{id} \u0026lt;/select\u0026gt;   再次运行程序，结果如下：\n1 2  User{id=1, username=\u0026#39;peter-gao\u0026#39;, age=180, score=1000} false   此时 user1 与 user2 不再指向同一内存区，缓存失效了。\n调用 insert、update、delete 刷新缓存 一般情况下，我们都推荐开启 select 的缓存，因为这会节省查询时间。当然在一个会话中，调用 insert、update、delete 语句时，会话中的缓存也会被刷新。\n如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  UserMapper userMapper = session.getMapper(UserMapper.class); User user1 = userMapper.selectUserById(1); System.out.println(user1); User user = new User(); user.setUsername(\u0026#34;cache test\u0026#34;); user.setAge(10); user.setScore(100); userMapper.insertUser(user); User user2 = userMapper.selectUserById(1); System.out.println(user1 == user2); session.commit(); session.close(); 代码块123456789101112 User{id=1, username=\u0026#39;peter\u0026#39;, age=18, score=100} false   在第一个查询调用前，我们先进行了一次 insert 操作，此时会刷新缓存，user1 和 user2 又没有指向同一处内存。\n二级缓存 MyBatis 二级缓存默认关闭，我们可以通过简单的设置来开启二级缓存。二级缓存的有效范围为一个 SqlSessionFactory 生命周期，绝大多数情况下，应用都会只有一个 SqlSessionFactory，因此我们可以把二级缓存理解为全局缓存。\n全局可用 在 MyBatis 全局配置文件中，即 mybatis-config.xml 文件，二级缓存可由 settings 下的 cacheEnabled 属性开启。如下：\n1 2 3  \u0026lt;settings\u0026gt; \u0026lt;setting name=\u0026#34;cacheEnabled\u0026#34; value=\u0026#34;true\u0026#34;/\u0026gt; \u0026lt;/settings\u0026gt;   当打开 cacheEnabled 属性后，二级缓存全局可用。\n TIPS：注意，这里是可用，cacheEnabled 的默认值其实也是 true，即全局可用，由于二级缓存需要对 mapper 配置后才真正生效，简单来说就是双层开关。当将其设置为 false 后，则全局关闭，mapper 中即使配置了，二级缓存也会失效。\n mapper 中开启 xml 开启 在二级缓存全局可用的情况下，mapper 才可通过 cache 配置开启二级缓存。如，在 UserMapper.xml 文件中开启二级缓存：\n1  \u0026lt;cache/\u0026gt;   这种情况下，缓存的行为如下：\n mapper 下的所有 select 语句会被缓存； mapper 下的 update，insert，delete 语句会刷新缓存； 使用 LRU 算法来回收对象； 最大缓存 1024 个对象； 缓存可读、可写。 缓存不会根据时间来刷新。  cache 提供了诸多属性来修改缓存行为，示例如下：\n1 2 3 4 5  \u0026lt;cache eviction=\u0026#34;FIFO\u0026#34; flushInterval=\u0026#34;60000\u0026#34; size=\u0026#34;512\u0026#34; readOnly=\u0026#34;true\u0026#34;/\u0026gt;   这个例子下的缓存使用 FIFO 算法来回收对象，并每隔 60 秒刷新一次，最多缓存 512 个对象，且缓存只可读。\ncache 有 4 个属性可配置，从而改变缓存的行为。\n   属性 描述     eviction 回收策略，默认 LRU，可选择的有 FIFO（先进先出），SOFT（软引用），WEAK（弱引用）   flushInterval 刷新时间   size 最多缓存对象数   readOnly 是否只读    注解开启 如果你不使用 mapper.xml 文件，也可以使用注解来开启。\n如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  package com.ahao.mybatis.mapper; import org.apache.ibatis.annotations.CacheNamespace; import org.apache.ibatis.annotations.Mapper; import org.apache.ibatis.cache.decorators.FifoCache; @Mapper @CacheNamespace( eviction = FifoCache.class, flushInterval = 60000, size = 512, readWrite = false ) public interface BlogMapper { }   注解 CacheNamespace 的配置与 xml 配置保持一致，唯一区别在于若使用注解，那么 eviction 属性需直接给出缓存实现类。\n缓存共享 xml 共享 有时候，我们想在不同的 mapper 中共享缓存，为了解决这类问题，MyBatis 提供了 cache-ref 配置。\n使用也很简单，如下：\n1  \u0026lt;cache-ref namespace=\u0026#34;com.ahao.mybatis.mapper.UserMapper\u0026#34;/\u0026gt;   mapper 由 namespace 来唯一标识，因此只需在另一个 mapper 文件中添加上 cache-ref 配置，并加上相应的 namespace 即可。\n这样当前的 mapper 可以共享来自 UserMapper 的缓存。\n注解共享 同样的，我们也可以使用注解来共享缓存。\n如下：\n1 2 3  @CacheNamespaceRef(UserMapper.class) public interface BlogMapper { }   这里，BlogMapper 共享了 UserMapper 的缓存。\n TIPS： 注意，CacheNamespaceRef 与 CacheNamespace 不能共存，既然选择了共享就不能再独立开辟缓存区了。\n 小结  MyBatis 的一级缓存默认可用，有效范围小，不会影响到其它会话，因此无特殊情况，不推荐丢弃一级缓存。 MyBatis 二级缓存默认使用程序内存缓存，但这显然不够安全，一般情况下我们都推荐使用 Redis 等专业的缓存。  MyBatis 类型处理器 前言 MyBatis 提供了诸多类型处理器，但是相较于丰富的数据库类型仍然略显不足，比如 MyBatis 只能将 JSON 数据类型当成普通的字符串处理。因此 MyBatis 提供了类型处理器接口，让开发者可以根据具体的业务需求来自定义适合的类型处理器。\n本小节，我们将以 JSON 类型处理器作为落脚点，来介绍类型处理器，并自定义 JSON 类型处理器。\nJSON 数据类型 首先，我们需要为 MyBatis 内置类型处理器增加一个它无法处理的数据类型，这里我们选择 MySQL5.7 中新增的 JSON 数据类型，这也是大家普遍使用的一个数据类型。在可用的数据库环境中，我们运行如下脚本：\n1 2 3 4 5 6 7 8 9 10  DROPTABLEIFEXISTSblog;CREATETABLEblog(idint(11)unsignedprimarykeyauto_increment,infojson,tagsjson);INSERTINTOblog(info,tags)VALUES(\u0026#39;{\u0026#34;title\u0026#34;: \u0026#34;世界更大\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;世界更大的内容\u0026#34;, \u0026#34;rank\u0026#34;: 1}\u0026#39;,\u0026#39;[\u0026#34;世界观\u0026#34;]\u0026#39;),(\u0026#39;{\u0026#34;title\u0026#34;: \u0026#34;人生更短\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;人生更短的内容\u0026#34;, \u0026#34;rank\u0026#34;: 2}\u0026#39;,\u0026#39;[\u0026#34;人文\u0026#34;]\u0026#39;);  在这个脚本中，我们新建了一个 blog 数据表，blog 数据表除 id 外有 info 和 tags 两个字段，这两个字段都是 JSON 类型，并通过 insert 语句添加了两条记录。\n类型处理器 MyBatis 默认是无法很好处理 info 和 tags 这两个字段的，只能将它们当成字符串类型来处理，但显然这不是我们想要的效果。我们希望新增 json 类型处理器来处理好这两个字段。\nMyBatis 提供了 TypeHandler 接口，自定义类型处理器需要实现了这个接口才能工作。考虑到很多开发者不够熟练，MyBatis 还提供了一个 BaseTypeHandler 抽象类来帮助我们做自定义类型处理器，只需继承这个基类，然后实现它的方法即可。\nJsonObject 处理器 JSON 可分为 object 和 array 两大类，分别对应 info 和 tags 字段，这两类需要分别实现类型处理器。由于需要对 JSON 进行处理，我们在 pom.xml 文件中添加上对应的依赖。\n1 2 3 4 5  \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;fastjson\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.2.60\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt;   这里，我们使用阿里巴巴开源的 fastjson库。\n在 com.ahao.mybatis 包下新建 handler 包，并向 handler 包中添加上 json object 的类型处理器 JsonObjectTypeHandler。如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40  package com.ahao.mybatis.handler; import com.alibaba.fastjson.JSON; import com.alibaba.fastjson.JSONObject; import org.apache.ibatis.type.*; import java.sql.CallableStatement; import java.sql.PreparedStatement; import java.sql.ResultSet; import java.sql.SQLException; @MappedJdbcTypes(JdbcType.VARCHAR) // 对应jdbc 类型 @MappedTypes({JSONObject.class}) // 对应处理后类型 public class JsonObjectTypeHandler extends BaseTypeHandler\u0026lt;JSONObject\u0026gt; { // 当为 PreparedStatement 参数时，如何处理对象  @Override public void setNonNullParameter(PreparedStatement preparedStatement, int i, JSONObject o, JdbcType jdbcType) throws SQLException { preparedStatement.setString(i, JSON.toJSONString(o)); } // 当通过名称从结果中取json字段时如何处理  @Override public JSONObject getNullableResult(ResultSet resultSet, String s) throws SQLException { String t = resultSet.getString(s); return JSON.parseObject(t); } // 当通过序列号从结果中取json字段时如何处理  @Override public JSONObject getNullableResult(ResultSet resultSet, int i) throws SQLException { String t = resultSet.getString(i); return JSON.parseObject(t); } // 当通过序列号从 CallableStatement 中取json字段时如何处理  @Override public JSONObject getNullableResult(CallableStatement callableStatement, int i) throws SQLException { String t = callableStatement.getString(i); return JSON.parseObject(t); } }   有了 BaseTypeHandler 作为基础后，实现一个类型处理器就比较简单了，我们只需要为其中 4 个方法添加上对应的实现即可。\n类型处理器有两个作用，第一处理 Java 对象到 JdbcType 类型的转换，对应 setNonNullParameter 方法；第二处理 JdbcType 类型到 Java 类型的转换，对应 getNullableResult 方法，getNullableResult 有 3 个重载方法。下面我们依次来说明这四个方法的作用：\n setNonNullParameter：处理 PreparedStatement 中的 JSONObject 参数，当调用 PreparedStatement 执行 SQL 语句时，调用该处理 JSONObject 类型的参数，这里我们通过 fastjson 的JSON.toJSONString(o)函数将 JSONObject 转化为字符串类型即可。 getNullableResult：从结果集中获取字段，这里 CallableStatement 和 ResultSet 分别对应不同的执行方式，对于 JDBC 而言 JSON 类型也会当做字符串来处理，因此这里我们需要将字符串类型转化为 JSONObject 类型，对应 JSON.parseObject(t)代码。  JsonArray 处理器 与 JsonObjectTypeHandler 一样，在 handler 包下新建 JsonArrayTypeHandler 类，继承 BaseTypeHandler 类，并将具体方法的实现从 JSON.parseObject 改变为 JSON.parseArray，如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  @MappedJdbcTypes(JdbcType.VARCHAR) @MappedTypes({JSONArray.class}) public class JsonArrayTypeHandler extends BaseTypeHandler\u0026lt;JSONArray\u0026gt; { @Override public void setNonNullParameter(PreparedStatement preparedStatement, int i, JSONArray o, JdbcType jdbcType) throws SQLException { preparedStatement.setString(i, JSON.toJSONString(o)); } @Override public JSONArray getNullableResult(ResultSet resultSet, String s) throws SQLException { String t = resultSet.getString(s); // // 变成了 parseArray  return JSON.parseArray(t); } @Override public JSONArray getNullableResult(ResultSet resultSet, int i) throws SQLException { String t = resultSet.getString(i); // // 变成了 parseArray  return JSON.parseArray(t); } @Override public JSONArray getNullableResult(CallableStatement callableStatement, int i) throws SQLException { String t = callableStatement.getString(i); // 变成了 parseArray  return JSON.parseArray(t); } }   注册类型处理器 自定义类型处理器无法直接被 MyBatis 加载，我们需要增加相关的配置告诉 MyBatis 加载类型处理器。\n全局注册 在全局配置配置文件中可通过 typeHandlers 属性来注册类型处理器。如下：\n1 2 3  \u0026lt;typeHandlers\u0026gt; \u0026lt;package name=\u0026#34;com.ahao.mybatis.handler\u0026#34;/\u0026gt; \u0026lt;/typeHandlers\u0026gt;   通过 package 项来指定类型处理器所在的包路径，这样 handler 包中的所有类型处理器都会注册到全局。\n当然如果你的类型处理器分散在其它地方，也可以通过如下方式来注册。\n1 2 3  \u0026lt;typeHandlers\u0026gt; \u0026lt;typeHandler handler=\u0026#34;com.ahao.mybatis.handler.JsonArrayTypeHandler\u0026#34;/\u0026gt; \u0026lt;/typeHandlers\u0026gt;   全局注册的类型处理器会自动被 MyBatis 用来处理所有符合类型的参数。如 JsonArrayTypeHandler 通过 MappedJdbcTypes 注解表明了自己将会处理 JdbcType.VARCHAR 类型，MyBatis 会自动将字符串类型的参数交给 JsonArrayTypeHandler 来进行处理。\n但是，这样显然有问题，因为 JsonObjectTypeHandler 注册的类型也是 JdbcType.VARCHAR 类型，所以全局注册是不推荐的，除非你需要对所有参数都做类型转换。\n局部注册 由于全局注册会对其它类型产生歧义和污染，因此我们选择更加精准的局部注册。在 BlogMapper 中，我们来注册和使用类型处理器。\n在 BlogMapper.xml 文件中，我们添加上如下配置。\n1 2 3 4 5 6 7 8 9  \u0026lt;resultMap id=\u0026#34;blogMap\u0026#34; type=\u0026#34;com.ahao.mybatis.model.Blog\u0026#34;\u0026gt; \u0026lt;result column=\u0026#34;id\u0026#34; property=\u0026#34;id\u0026#34;/\u0026gt; \u0026lt;result column=\u0026#34;info\u0026#34; property=\u0026#34;info\u0026#34; typeHandler=\u0026#34;com.ahao.mybatis.handler.JsonObjectTypeHandler\u0026#34;/\u0026gt; \u0026lt;result column=\u0026#34;tags\u0026#34; property=\u0026#34;tags\u0026#34; typeHandler=\u0026#34;com.ahao.mybatis.handler.JsonArrayTypeHandler\u0026#34;/\u0026gt; \u0026lt;/resultMap\u0026gt; \u0026lt;select id=\u0026#34;selectById\u0026#34; resultMap=\u0026#34;blogMap\u0026#34;\u0026gt; SELECT * FROM blog WHERE id = #{id} \u0026lt;/select\u0026gt;   我们定义了 名为 blogMap 的 resultMap 和名为 selectById 的查询。在 result 映射中，我们注册了相关的类型处理器，info 字段对应\nJsonObjectTypeHandler 类型处理器，tags 字段对应 JsonArrayTypeHandler 类型处理器。\n这样自定义的类型处理器不会污染到其它数据，blogMap 的类型 com.ahao.mybatis.model.Blog 定义如下：\n1 2 3 4 5 6 7 8 9 10 11  package com.ahao.mybatis.model; import com.alibaba.fastjson.JSONArray; import com.alibaba.fastjson.JSONObject; public class Blog { private Long id; private JSONObject info; private JSONArray tags; // 省略了 getter 和 setter 方法 }   处理 JDBC 类型 在对应的 BlogMapper.java 接口上添加上对应的 selectById 方法：\n1 2 3 4 5 6 7 8 9  package com.ahao.mybatis.mapper; import com.ahao.mybatis.model.Blog; import org.apache.ibatis.annotations.Mapper; @Mapper public interface BlogMapper { Blog selectById(Integer id); }   我们测试一下 selectById 方法：\n1 2 3 4 5 6 7  BlogMapper blogMapper = session.getMapper(BlogMapper.class); Blog blog = blogMapper.selectById(1); System.out.println(blog.toString()); String title = blog.getInfo().getString(\u0026#34;title\u0026#34;); System.out.println(title); String tag = blog.getTags().getString(0); System.out.println(tag);   输出结果如下：\n1 2 3  Blog{id=1, info={\u0026#34;rank\u0026#34;:1,\u0026#34;title\u0026#34;:\u0026#34;世界更大\u0026#34;,\u0026#34;content\u0026#34;:\u0026#34;.......****............\u0026#34;}, tags=[\u0026#34;世界观\u0026#34;]} 世界更大 世界观   从结果中可以看出，类型处理器成功的处理了查询的数据，info 和 tags 字段都能够通过 fastjson 的 API 来获取里面的内容。\n处理 JSON 类型 在查询可以工作的情况下，那么如何通过 insert 插入 JSON 对象了。\n我们在 BlogMapper 中新增一个 insertBlog 方法，如下：\n1 2 3 4 5 6 7 8 9  \u0026lt;insert id=\u0026#34;insertBlog\u0026#34;\u0026gt; INSERT INTO blog(info,tags) VALUES(#{info,typeHandler=com.ahao.mybatis.handler.JsonObjectTypeHandler}, #{tags,typeHandler=com.ahao.mybatis.handler.JsonArrayTypeHandler}) \u0026lt;/insert\u0026gt; public interface BlogMapper { int insertBlog(@Param(\u0026#34;info\u0026#34;) JSONObject info, @Param(\u0026#34;tags\u0026#34;) JSONArray tags); }   这样 MyBatis 就可以处理 JSON 类型的参数了，我们再次测试一下：\n1 2 3 4  JSONObject info = new JSONObject().fluentPut(\u0026#34;title\u0026#34;, \u0026#34;测试案例\u0026#34;).fluentPut(\u0026#34;rank\u0026#34;, 1); JSONArray tags = new JSONArray().fluentAdd(\u0026#34;测试\u0026#34;); int rows = blogMapper.insertBlog(info, tags); System.out.println(rows);   输出结果：\n1  1   可以看到类型处理器成为了 Java JSON 类型和 JDBC 类型转换桥梁，在查询的时候主动将数据库类型转化为了可用的 JSON 类型，而在插入的时候将 JSON 类型又转化为了数据库可识别的字符串类型。\n小结  自定义类型处理器并不难，MyBatis 已经帮我们做好了大多数工作，我们只需在适当的位置适当的配置就可以了。 数据库 JSON 类型的用处会越来越广泛，在 MyBatis 官方未内置处理器之前，我们也可以通过本小节的方式来提早的使用它。  MyBatis 插件 前言 MyBatis 允许我们以插件的形式对已映射语句执行过程中的某一点进行拦截调用，通俗一点来说，MyBatis 的插件其实更应该被称作为拦截器。\nMyBatis 插件的使用十分广泛，分页、性能分析、乐观锁、逻辑删除等等常用的功能都可以通过插件来实现。既然插件如此好用，本小节我们就一起来探索插件并且实现一个简单的 SQL 执行时间计时插件。\n介绍 可拦截对象 MyBatis 允许插件拦截如下 4 个对象的方法。\n Executor的 update, query, flushStatements, commit, rollback, getTransaction, close, isClosed 方法 ParameterHandler的 getParameterObject, setParameters 方法 ResultSetHandler的 handleResultSets, handleOutputParameters 方法 StatementHandler的 prepare, parameterize, batch, update, query 方法  注意，这四个对象都是接口，插件会拦截实现了该接口的对象。\n插件接口 插件必须实现 Interceptor 接口。Interceptor 接口共有 3 个方法，如下：\n1 2 3 4 5 6 7 8 9 10  public interface Interceptor { Object intercept(Invocation invocation) throws Throwable; default Object plugin(Object target) { return Plugin.wrap(target, this); } default void setProperties(Properties properties) { } }   其中 plugin 和 setProperties 方法都是默认实现的方法，我们可以选择不覆盖实现，而 intercept 方法则必须实现。如下：\n intercept ： 核心方法，通过 Invocation 我们可以拿到被拦截的对象，从而实现自己的逻辑。 plugin： 给 target 拦截对象生成一个代理对象，已有默认实现。 setProperties： 插件的配置方法，在插件初始化的时候调用。  拦截器签名 插件可对多种对象进行拦截，因此我们需要通过拦截器签名来告诉 MyBatis 插件应该拦截何种对象的何种方法。举例如下：\n1 2 3 4 5 6  @Intercepts({@Signature( type = StatementHandler.class, method = \u0026#34;prepare\u0026#34;, args = {Connection.class, Integer.class} )}) public class XXXPlugin implements Interceptor {}   类 XXXPlugin 上有两个注解：\n Intercepts注解： 拦截声明，只有 Intercepts 注解修饰的插件才具有拦截功能。 Signature注解： 签名注解，共 3 个参数，type 参数表示拦截的对象，如 StatementHandler，另外还有Executor、ParameterHandler和ResultSetHandler；method 参数表示拦截对象的方法名，即对拦截对象的某个方法进行拦截，如 prepare，代表拦截 StatementHandler 的 prepare 方法；args 参数表示拦截方法的参数，因为方法可能会存在重载，因此方法名加上参数才能唯一标识一个方法。  推断可知 XXXPlugin 插件会拦截 StatementHandler对象的 prepare(Connection connection, Integer var2) 方法。\n一个插件可以拦截多个对象的多个方法，因此在 Intercepts 注解中可以添加上多个 Signature注解。\n实践 接下来，我们一起来实现一个简单的 SQL 执行时间计时插件。插件的功能是日志输出每一条 SQL 的执行用时。\n在 com.ahao.mybatis 包下，我们新建 plugin 包，并在包中添加 SqlStaticsPlugin 类。SqlStaticsPlugin 会拦截 StatementHandler的prepare方法，如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  package com.ahao.mybatis.plugin; import org.apache.ibatis.executor.statement.StatementHandler; import org.apache.ibatis.plugin.*; import org.slf4j.Logger; import org.slf4j.LoggerFactory; import java.sql.Connection; @Intercepts({@Signature( type = StatementHandler.class, method = \u0026#34;prepare\u0026#34;, args = {Connection.class, Integer.class} )}) public class SqlStaticsPlugin implements Interceptor { private Logger logger = LoggerFactory.getLogger(SqlStaticsPlugin.class); @Override public Object intercept(Invocation invocation) throws Throwable { return invocation.proceed(); } }   我们一起来完善这个插件。\n 首先需要得到 invocation 的拦截对象 StatementHandler，并从 StatementHandler 中拿到 SQL 语句。 得到当前的时间戳 startTime。 执行 SQL。 得到执行后的时间戳 endTime。 计算时间差，并打印 SQL 耗时。  对应的 intercept 方法代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  public Object intercept(Invocation invocation) throws Throwable { // 得到拦截对象  StatementHandler statementHandler = (StatementHandler) invocation.getTarget(); MetaObject metaObj = SystemMetaObject.forObject(statementHandler); String sql = (String) metaObj.getValue(\u0026#34;delegate.boundSql.sql\u0026#34;); // 开始时间  long startTime = System.currentTimeMillis(); // 执行SQL  Object res = invocation.proceed(); // 结束时间  long endTime = System.currentTimeMillis(); long sqlCost = endTime - startTime; // 去掉无用的换行符，打印美观  logger.info(\u0026#34;sql: {} - cost: {}ms\u0026#34;, sql.replace(\u0026#34;\\n\u0026#34;, \u0026#34;\u0026#34;), sqlCost); // 返回执行的结果  return res; }   注意，通过反射调用后的结果 res，我们一定要记得返回。MyBatis 提供了 MetaObject 这个类来方便我们进行拦截对象属性的修改，这里我们简单的使用了getValue方法来得到 SQL 语句。\n我们在全局配置文件注册这个插件：\n1 2 3  \u0026lt;plugins\u0026gt; \u0026lt;plugin interceptor=\u0026#34;com.ahao.mybatis.plugin.SqlStaticsPlugin\u0026#34; /\u0026gt; \u0026lt;/plugins\u0026gt;   到这，这个插件已经可以工作了，但是我们希望它能更加灵活一点，通过配置来拦截某些类型的 SQL，如只计算 select 类型SQL的耗时。\n插件会在初始化的时候通过 setProperties 方法来加载配置，利用它我们可以得到哪些方法需要被计时。如下：\n1 2 3 4 5 6 7 8 9 10 11 12  public class SqlStaticsPlugin implements Interceptor { private List\u0026lt;String\u0026gt; methods = Arrays.asList(\u0026#34;SELECT\u0026#34;, \u0026#34;INSERT\u0026#34;, \u0026#34;UPDATE\u0026#34;, \u0026#34;DELETE\u0026#34;); @Override public void setProperties(Properties properties) { String methodsStr = properties.getProperty(\u0026#34;methods\u0026#34;); if (methodsStr == null || methodsStr.isBlank()) return; String[] parts = methodsStr.split(\u0026#34;,\u0026#34;); methods = Arrays.stream(parts).map(String::toUpperCase).collect(Collectors.toList()); } }   methods 参数默认可通过 select、insert、update 和 delete 类型的SQL语句，如果插件存在配置项 methods，那么则根据插件配置来覆盖默认配置。\n在全局配置文件中，我们来添加上 methods 这个配置：\n1 2 3 4 5  \u0026lt;plugins\u0026gt; \u0026lt;plugin interceptor=\u0026#34;com.ahao.mybatis.plugin.SqlStaticsPlugin\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;methods\u0026#34; value=\u0026#34;select,update\u0026#34;/\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt;   类型之间以 , 隔开，MyBatis 会在插件初始化时，自动将 methods 对应的值通过 setProperties 方法来传递给SqlStaticsPlugin插件。插件拿到 Properties 后解析并替换默认的 methods 配置。\n再次完善一下 intercept 方法，使其支持配置拦截：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  public Object intercept(Invocation invocation) throws Throwable { StatementHandler statementHandler = (StatementHandler) invocation.getTarget(); MetaObject metaObj = SystemMetaObject.forObject(statementHandler); // 得到SQL类型  String sqlCommandType = metaObj.getValue(\u0026#34;delegate.mappedStatement.sqlCommandType\u0026#34;).toString(); // 如果方法配置中没有SQL类型，则无需计时，直接返回调用  if (!methods.contains(sqlCommandType)) { return invocation.proceed(); } String sql = (String) metaObj.getValue(\u0026#34;delegate.boundSql.sql\u0026#34;); long startTime = System.currentTimeMillis(); Object res = invocation.proceed(); long endTime = System.currentTimeMillis(); long sqlCost = endTime - startTime; logger.info(\u0026#34;sql: {} - cost: {}ms\u0026#34;, sql.replace(\u0026#34;\\n\u0026#34;, \u0026#34;\u0026#34;), sqlCost); return res; }   当插件注册后，应用程序会打印出如下的日志语句：\n1  17:48:14.110 [main] INFO com.ahao.mybatis.plugin.SqlStaticsPlugin - sql: INSERT INTO blog(info,tags) VALUES(?, ?) - cost: 87ms   至此，一个简单的 SQL 计时插件就开发完毕了。\n小结  MyBatis 插件强大且易用，是深入掌握 MyBatis 的必备知识点。 不少 MyBatis 三方库都提供了很多好用的插件，如 Pagehelper 分页插件，我们可以拿来即用。  ","date":"2021-06-16T13:36:41Z","image":"https://ahao.ink/19.jpg","permalink":"https://ahao.ink/posts/mybatis-%E9%AB%98%E7%BA%A7%E7%AF%87/","title":"MyBatis 高级篇"},{"content":"平时我们使用数据库，看到的通常都是一个整体。比如，一个最简单的表，表里只有一个 ID 字段，在执行下面这个查询语句时：\n1  mysql\u0026gt;select*fromTwhereID=10；  我们看到的只是输入一条语句，返回一个结果，却不知道这条语句在 MySQL 内部的执行过程。\n下面给出的是 MySQL 的基本架构示意图，从中可以清楚地看到 SQL 语句在 MySQL 的各个功能模块中的执行过程。\n大体来说，MySQL 可以分为 Server 层和存储引擎层两部分。\nServer 层包括连接器、查询缓存、分析器、优化器、执行器等，涵盖 MySQL 的大多数核心服务功能，以及所有的内置函数（如日期、时间、数学和加密函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。\n而存储引擎层负责数据的存储和提取。其架构模式是插件式的，支持 InnoDB、MyISAM、Memory 等多个存储引擎。现在最常用的存储引擎是 InnoDB，它从 MySQL 5.5.5 版本开始成为了默认存储引擎。\n也就是说，执行 create table 建表的时候，如果不指定引擎类型，默认使用的就是 InnoDB。不过，也可以通过指定存储引擎的类型来选择别的引擎，比如在 create table 语句中使用 engine=memory, 来指定使用内存引擎创建表。不同存储引擎的表数据存取方式不同，支持的功能也不同。\n从图中不难看出，不同的存储引擎共用一个Server 层，也就是从连接器到执行器的部分。接下来结合开头提到的那条 SQL 语句，走一遍整个执行流程，依次看下每个组件的作用。\n连接器 第一步，你会先连接到这个数据库上，这时候接待你的就是连接器。连接器负责跟客户端建立连接、获取权限、维持和管理连接。连接命令一般是这么写的：\n1  mysql -h$ip -P$port -u$user -p   输完命令之后，你就需要在交互对话里面输入密码。虽然密码也可以直接跟在 -p 后面写在命令行中，但这样可能会导致你的密码泄露。如果你连的是生产服务器，强烈建议你不要这么做。\n连接命令中的 mysql 是客户端工具，用来跟服务端建立连接。在完成经典的 TCP 握手后，连接器就要开始认证你的身份，这个时候用的就是你输入的用户名和密码。\n 如果用户名或密码不对，你就会收到一个\u0026quot;Access denied for user\u0026quot;的错误，然后客户端程序结束执行。 如果用户名密码认证通过，连接器会到权限表里面查出你拥有的权限。之后，这个连接里面的权限判断逻辑，都将依赖于此时读到的权限。  这就意味着，一个用户成功建立连接后，即使你用管理员账号对这个用户的权限做了修改，也不会影响已经存在连接的权限。修改完成后，只有再新建的连接才会使用新的权限设置。\n连接完成后，如果你没有后续的动作，这个连接就处于空闲状态，你可以在 show processlist 命令中看到它。文本中这个图是 show processlist 的结果，其中的 Command 列显示为“Sleep”的这一行，就表示现在系统里面有一个空闲连接。\n客户端如果太长时间没动静，连接器就会自动将它断开。这个时间是由参数 wait_timeout 控制的，默认值是 8 小时。\n如果在连接被断开之后，客户端再次发送请求的话，就会收到一个错误提醒： Lost connection to MySQL server during query。这时候如果你要继续，就需要重连，然后再执行请求了。\n数据库里面，长连接是指连接成功后，如果客户端持续有请求，则一直使用同一个连接。短连接则是指每次执行完很少的几次查询就断开连接，下次查询再重新建立一个。\n建立连接的过程通常是比较复杂的，所以我建议你在使用中要尽量减少建立连接的动作，也就是尽量使用长连接。\n但是全部使用长连接后，你可能会发现，有些时候 MySQL 占用内存涨得特别快，这是因为 MySQL 在执行过程中临时使用的内存是管理在连接对象里面的。这些资源会在连接断开的时候才释放。所以如果长连接累积下来，可能导致内存占用太大，被系统强行杀掉（OOM），从现象看就是 MySQL 异常重启了。\n怎么解决这个问题呢？你可以考虑以下两种方案。\n 定期断开长连接。使用一段时间，或者程序里面判断执行过一个占用内存的大查询后，断开连接，之后要查询再重连。 如果你用的是 MySQL 5.7 或更新版本，可以在每次执行一个比较大的操作后，通过执行 mysql_reset_connection 来重新初始化连接资源。这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态。  查询缓存 连接建立完成后，你就可以执行 select 语句了。执行逻辑就会来到第二步：查询缓存。\nMySQL 拿到一个查询请求后，会先到查询缓存看看，之前是不是执行过这条语句。之前执行过的语句及其结果可能会以 key-value 对的形式，被直接缓存在内存中。key 是查询的语句，value 是查询的结果。如果你的查询能够直接在这个缓存中找到 key，那么这个 value 就会被直接返回给客户端。\n如果语句不在查询缓存中，就会继续后面的执行阶段。执行完成后，执行结果会被存入查询缓存中。你可以看到，如果查询命中缓存，MySQL 不需要执行后面的复杂操作，就可以直接返回结果，这个效率会很高。\n但是大多数情况下建议不要使用查询缓存，为什么呢？因为查询缓存往往弊大于利。\n查询缓存的失效非常频繁，只要有对一个表的更新，这个表上所有的查询缓存都会被清空。因此很可能你费劲地把结果存起来，还没使用呢，就被一个更新全清空了。对于更新压力大的数据库来说，查询缓存的命中率会非常低。除非你的业务就是有一张静态表，很长时间才会更新一次。比如，一个系统配置表，那这张表上的查询才适合使用查询缓存。\n好在 MySQL 也提供了这种“按需使用”的方式。可以将参数 query_cache_type 设置成 DEMAND，这样对于默认的 SQL 语句都不使用查询缓存。而对于确定要使用查询缓存的语句，可以用 SQL_CACHE 显式指定，像下面这个语句一样：\n1  mysql\u0026gt;selectSQL_CACHE*fromTwhereID=10；  需要注意的是，MySQL 8.0 版本直接将查询缓存的整块功能删掉了，也就是说 8.0 开始彻底没有这个功能了。\n分析器 如果没有命中查询缓存，就要开始真正执行语句了。首先，MySQL 需要知道你要做什么，因此需要对 SQL 语句做解析。\n分析器先会做“词法分析”。你输入的是由多个字符串和空格组成的一条 SQL 语句，MySQL 需要识别出里面的字符串分别是什么，代表什么。\nMySQL 从你输入的\u0026quot;select\u0026quot;这个关键字识别出来，这是一个查询语句。它也要把字符串“T”识别成“表名 T”，把字符串“ID”识别成“列 ID”。\n做完了这些识别以后，就要做“语法分析”。根据词法分析的结果，语法分析器会根据语法规则，判断你输入的这个 SQL 语句是否满足 MySQL 语法。\n如果你的语句不对，就会收到“You have an error in your SQL syntax”的错误提醒，比如下面这个语句 select 少打了开头的字母“s”。\n1 2 3  mysql\u0026gt;elect*fromtwhereID=1;ERROR1064(42000):YouhaveanerrorinyourSQLsyntax;checkthemanualthatcorrespondstoyourMySQLserverversionfortherightsyntaxtousenear\u0026#39;elect * from t where ID=1\u0026#39;atline1  一般语法错误会提示第一个出现错误的位置，所以你要关注的是紧接“use near”的内容。\n优化器 经过了分析器，MySQL 就知道你要做什么了。在开始执行之前，还要先经过优化器的处理。\n优化器是在表里面有多个索引的时候，决定使用哪个索引；或者在一个语句有多表关联（join）的时候，决定各个表的连接顺序。比如你执行下面这样的语句，这个语句是执行两个表的 join：\n1  mysql\u0026gt;select*fromt1joint2using(ID)wheret1.c=10andt2.d=20;   既可以先从表 t1 里面取出 c=10 的记录的 ID 值，再根据 ID 值关联到表 t2，再判断 t2 里面 d 的值是否等于 20。 也可以先从表 t2 里面取出 d=20 的记录的 ID 值，再根据 ID 值关联到 t1，再判断 t1 里面 c 的值是否等于 10。  这两种执行方法的逻辑结果是一样的，但是执行的效率会有不同，而优化器的作用就是决定选择使用哪一个方案。\n优化器阶段完成后，这个语句的执行方案就确定下来了，然后进入执行器阶段。\n执行器 MySQL 通过分析器知道了你要做什么，通过优化器知道了该怎么做，于是就进入了执行器阶段，开始执行语句。\n开始执行的时候，要先判断一下你对这个表 T 有没有执行查询的权限，如果没有，就会返回没有权限的错误，如下所示 (在工程实现上，如果命中查询缓存，会在查询缓存返回结果的时候，做权限验证。查询也会在优化器之前调用 precheck 验证权限)。\n1 2 3  mysql\u0026gt;select*fromTwhereID=10;ERROR1142(42000):SELECTcommanddeniedtouser\u0026#39;b\u0026#39;@\u0026#39;localhost\u0026#39;fortable\u0026#39;T\u0026#39;  如果有权限，就打开表继续执行。打开表的时候，执行器就会根据表的引擎定义，去使用这个引擎提供的接口。\n比如我们这个例子中的表 T 中，ID 字段没有索引，那么执行器的执行流程是这样的：\n 调用 InnoDB 引擎接口取这个表的第一行，判断 ID 值是不是 10，如果不是则跳过，如果是则将这行存在结果集中； 调用引擎接口取“下一行”，重复相同的判断逻辑，直到取到这个表的最后一行。 执行器将上述遍历过程中所有满足条件的行组成的记录集作为结果集返回给客户端。  至此，这个语句就执行完成了。\n对于有索引的表，执行的逻辑也差不多。第一次调用的是“取满足条件的第一行”这个接口，之后循环取“满足条件的下一行”这个接口，这些接口都是引擎中已经定义好的。\n你会在数据库的慢查询日志中看到一个 rows_examined 的字段，表示这个语句执行过程中扫描了多少行。这个值就是在执行器每次调用引擎获取数据行的时候累加的。\n在有些场景下，执行器调用一次，在引擎内部则扫描了多行，因此引擎扫描行数跟 rows_examined 并不是完全相同的。\n小结 了解MySQL 的逻辑架构，对一个 SQL 语句完整执行流程的各个阶段有了一个初步的印象。\n","date":"2021-06-16T13:36:41Z","image":"https://ahao.ink/21.jpg","permalink":"https://ahao.ink/posts/%E5%9F%BA%E7%A1%80%E6%9E%B6%E6%9E%84%E4%B8%80%E6%9D%A1sql%E6%9F%A5%E8%AF%A2%E8%AF%AD%E5%8F%A5%E6%98%AF%E5%A6%82%E4%BD%95%E6%89%A7%E8%A1%8C%E7%9A%84/","title":"基础架构：一条SQL查询语句是如何执行的？"},{"content":"JVM 内存结构 Java 虚拟机的内存空间分为 5 个部分：\n 程序计数器 Java 虚拟机栈 本地方法栈 堆 方法区  JDK 1.8 同 JDK 1.7 比，最大的差别就是：元数据区取代了永久代。元空间的本质和永久代类似，都是对 JVM 规范中方法区的实现。不过元空间与永久代之间最大的区别在于：元数据空间并不在虚拟机中，而是使用本地内存。\n程序计数器（PC 寄存器） 程序计数器的定义 程序计数器是一块较小的内存空间，是当前线程正在执行的那条字节码指令的地址。若当前线程正在执行的是一个本地方法，那么此时程序计数器为Undefined。\n程序计数器的作用  字节码解释器通过改变程序计数器来依次读取指令，从而实现代码的流程控制。 在多线程情况下，程序计数器记录的是当前线程执行的位置，从而当线程切换回来时，就知道上次线程执行到哪了。  程序计数器的特点  是一块较小的内存空间。 线程私有，每条线程都有自己的程序计数器。 生命周期：随着线程的创建而创建，随着线程的结束而销毁。 是唯一一个不会出现OutOfMemoryError的内存区域。  Java 虚拟机栈（Java 栈） Java 虚拟机栈的定义 Java 虚拟机栈是描述 Java 方法运行过程的内存模型。\nJava 虚拟机栈会为每一个即将运行的 Java 方法创建一块叫做“栈帧”的区域，用于存放该方法运行过程中的一些信息，如：\n 局部变量表 操作数栈 动态链接 方法出口信息 \u0026hellip;\u0026hellip;  压栈出栈过程 当方法运行过程中需要创建局部变量时，就将局部变量的值存入栈帧中的局部变量表中。\nJava 虚拟机栈的栈顶的栈帧是当前正在执行的活动栈，也就是当前正在执行的方法，PC 寄存器也会指向这个地址。只有这个活动的栈帧的本地变量可以被操作数栈使用，当在这个栈帧中调用另一个方法，与之对应的栈帧又会被创建，新创建的栈帧压入栈顶，变为当前的活动栈帧。\n方法结束后，当前栈帧被移出，栈帧的返回值变成新的活动栈帧中操作数栈的一个操作数。如果没有返回值，那么新的活动栈帧中操作数栈的操作数没有变化。\n 由于 Java 虚拟机栈是与线程对应的，数据不是线程共享的，因此不用关心数据一致性问题，也不会存在同步锁的问题。\n Java 虚拟机栈的特点  局部变量表随着栈帧的创建而创建，它的大小在编译时确定，创建时只需分配事先规定的大小即可。在方法运行过程中，局部变量表的大小不会发生改变。 Java 虚拟机栈会出现两种异常：StackOverFlowError 和 OutOfMemoryError。  StackOverFlowError 若 Java 虚拟机栈的大小不允许动态扩展，那么当线程请求栈的深度超过当前 Java 虚拟机栈的最大深度时，抛出 StackOverFlowError 异常。 OutOfMemoryError 若允许动态扩展，那么当线程请求栈时内存用完了，无法再动态扩展时，抛出 OutOfMemoryError 异常。   Java 虚拟机栈也是线程私有，随着线程创建而创建，随着线程的结束而销毁。   出现 StackOverFlowError 时，内存空间可能还有很多。\n 本地方法栈（C 栈） 本地方法栈的定义 本地方法栈是为 JVM 运行 Native 方法准备的空间，由于很多 Native 方法都是用 C 语言实现的，所以它通常又叫 C 栈。它与 Java 虚拟机栈实现的功能类似，只不过本地方法栈是描述本地方法运行过程的内存模型。\n栈帧变化过程 本地方法被执行时，在本地方法栈也会创建一块栈帧，用于存放该方法的局部变量表、操作数栈、动态链接、方法出口信息等。\n方法执行结束后，相应的栈帧也会出栈，并释放内存空间。也会抛出 StackOverFlowError 和 OutOfMemoryError 异常。\n 如果 Java 虚拟机本身不支持 Native 方法，或是本身不依赖于传统栈，那么可以不提供本地方法栈。如果支持本地方法栈，那么这个栈一般会在线程创建的时候按线程分配。\n 堆 堆的定义 堆是用来存放对象的内存空间，几乎所有的对象都存储在堆中。\n堆的特点  线程共享，整个 Java 虚拟机只有一个堆，所有的线程都访问同一个堆。而程序计数器、Java 虚拟机栈、本地方法栈都是一个线程对应一个。 在虚拟机启动时创建。 是垃圾回收的主要场所。 进一步可分为：新生代（Eden 区：From Survior，To Survivor）、老年代。  不同的区域存放不同生命周期的对象，这样可以根据不同的区域使用不同的垃圾回收算法，更具有针对性。\n堆的大小既可以固定也可以扩展，但对于主流的虚拟机，堆的大小是可扩展的，因此当线程请求分配内存，但堆已满，且内存已无法再扩展时，就抛出 OutOfMemoryError 异常。\n Java 堆所使用的内存不需要保证是连续的。而由于堆是被所有线程共享的，所以对它的访问需要注意同步问题，方法和对应的属性都需要保证一致性。\n 方法区 方法区的定义 Java 虚拟机规范中定义方法区是堆的一个逻辑部分。方法区存放以下信息：\n 已经被虚拟机加载的类信息 常量 静态变量 即时编译器编译后的代码  方法区的特点  线程共享。 方法区是堆的一个逻辑部分，因此和堆一样，都是线程共享的。整个虚拟机中只有一个方法区。 永久代。 方法区中的信息一般需要长期存在，而且它又是堆的逻辑分区，因此用堆的划分方法，把方法区称为“永久代”。 内存回收效率低。 方法区中的信息一般需要长期存在，回收一遍之后可能只有少量信息无效。主要回收目标是：对常量池的回收；对类型的卸载。 Java 虚拟机规范对方法区的要求比较宽松。 和堆一样，允许固定大小，也允许动态扩展，还允许不实现垃圾回收。  运行时常量池 方法区中存放：类信息、常量、静态变量、即时编译器编译后的代码。常量就存放在运行时常量池中。\n当类被 Java 虚拟机加载后， .class 文件中的常量就存放在方法区的运行时常量池中。而且在运行期间，可以向常量池中添加新的常量。如 String 类的 intern() 方法就能在运行期间向常量池中添加字符串常量。\n直接内存（堆外内存） 直接内存是除 Java 虚拟机之外的内存，但也可能被 Java 使用。\n操作直接内存 在 NIO 中引入了一种基于通道和缓冲的 IO 方式。它可以通过调用本地方法直接分配 Java 虚拟机之外的内存，然后通过一个存储在堆中的DirectByteBuffer对象直接操作该内存，而无须先将外部内存中的数据复制到堆中再进行操作，从而提高了数据操作的效率。\n直接内存的大小不受 Java 虚拟机控制，但既然是内存，当内存不足时就会抛出 OutOfMemoryError 异常。\n直接内存与堆内存比较  直接内存申请空间耗费更高的性能 直接内存读取 IO 的性能要优于普通的堆内存。 直接内存作用链： 本地 IO -\u0026gt; 直接内存 -\u0026gt; 本地 IO 堆内存作用链：本地 IO -\u0026gt; 直接内存 -\u0026gt; 非直接内存 -\u0026gt; 直接内存 -\u0026gt; 本地 IO   服务器管理员在配置虚拟机参数时，会根据实际内存设置-Xmx等参数信息，但经常忽略直接内存，使得各个内存区域总和大于物理内存限制，从而导致动态扩展时出现OutOfMemoryError异常。\n HotSpot 虚拟机对象探秘 对象的内存布局 在 HotSpot 虚拟机中，对象的内存布局分为以下 3 块区域：\n 对象头（Header） 实例数据（Instance Data） 对齐填充（Padding）  对象头 对象头记录了对象在运行过程中所需要使用的一些数据：\n 哈希码 GC 分代年龄 锁状态标志 线程持有的锁 偏向线程 ID 偏向时间戳  对象头可能包含类型指针，通过该指针能确定对象属于哪个类。如果对象是一个数组，那么对象头还会包括数组长度。\n实例数据 实例数据部分就是成员变量的值，其中包括父类成员变量和本类成员变量。\n对齐填充 用于确保对象的总长度为 8 字节的整数倍。\nHotSpot VM 的自动内存管理系统要求对象的大小必须是 8 字节的整数倍。而对象头部分正好是 8 字节的倍数（1 倍或 2 倍），因此，当对象实例数据部分没有对齐时，就需要通过对齐填充来补全。\n 对齐填充并不是必然存在，也没有特别的含义，它仅仅起着占位符的作用。\n 对象的创建过程 类加载检查 虚拟机在解析.class文件时，若遇到一条 new 指令，首先它会去检查常量池中是否有这个类的符号引用，并且检查这个符号引用所代表的类是否已被加载、解析和初始化过。如果没有，那么必须先执行相应的类加载过程。\n为新生对象分配内存 对象所需内存的大小在类加载完成后便可完全确定，接下来从堆中划分一块对应大小的内存空间给新的对象。分配堆中内存有两种方式：\n 指针碰撞 如果 Java 堆中内存绝对规整（说明采用的是“复制算法”或“标记整理法”），空闲内存和已使用内存中间放着一个指针作为分界点指示器，那么分配内存时只需要把指针向空闲内存挪动一段与对象大小一样的距离，这种分配方式称为“指针碰撞”。 空闲列表 如果 Java 堆中内存并不规整，已使用的内存和空闲内存交错（说明采用的是标记-清除法，有碎片），此时没法简单进行指针碰撞， VM 必须维护一个列表，记录其中哪些内存块空闲可用。分配之时从空闲列表中找到一块足够大的内存空间划分给对象实例。这种方式称为“空闲列表”。  初始化 分配完内存后，为对象中的成员变量赋上初始值，设置对象头信息，调用对象的构造函数方法进行初始化。\n至此，整个对象的创建过程就完成了。\n对象的访问方式 所有对象的存储空间都是在堆中分配的，但是这个对象的引用却是在堆栈中分配的。也就是说在建立一个对象时两个地方都分配内存，在堆中分配的内存实际建立这个对象，而在堆栈中分配的内存只是一个指向这个堆对象的指针（引用）而已。 那么根据引用存放的地址类型的不同，对象有不同的访问方式。\n句柄访问方式 堆中需要有一块叫做“句柄池”的内存空间，句柄中包含了对象实例数据与类型数据各自的具体地址信息。\n引用类型的变量存放的是该对象的句柄地址（reference）。访问对象时，首先需要通过引用类型的变量找到该对象的句柄，然后根据句柄中对象的地址找到对象。\n直接指针访问方式 引用类型的变量直接存放对象的地址，从而不需要句柄池，通过引用能够直接访问对象。但对象所在的内存空间需要额外的策略存储对象所属的类信息的地址。\n需要说明的是，HotSpot 采用第二种方式，即直接指针方式来访问对象，只需要一次寻址操作，所以在性能上比句柄访问方式快一倍。但像上面所说，它需要额外的策略来存储对象在方法区中类信息的地址。\n垃圾收集策略与算法 程序计数器、虚拟机栈、本地方法栈随线程而生，也随线程而灭；栈帧随着方法的开始而入栈，随着方法的结束而出栈。这几个区域的内存分配和回收都具有确定性，在这几个区域内不需要过多考虑回收的问题，因为方法结束或者线程结束时，内存自然就跟随着回收了。\n而对于 Java 堆和方法区，我们只有在程序运行期间才能知道会创建哪些对象，这部分内存的分配和回收都是动态的，垃圾收集器所关注的正是这部分内存。\n判定对象是否存活 若一个对象不被任何对象或变量引用，那么它就是无效对象，需要被回收。\n引用计数法 在对象头维护着一个 counter 计数器，对象被引用一次则计数器 +1；若引用失效则计数器 -1。当计数器为 0 时，就认为该对象无效了。\n引用计数算法的实现简单，判定效率也很高，在大部分情况下它都是一个不错的算法。但是主流的 Java 虚拟机里没有选用引用计数算法来管理内存，主要是因为它很难解决对象之间循环引用的问题。\n 举个栗子 👉 对象 objA 和 objB 都有字段 instance，令 objA.instance = objB 并且 objB.instance = objA，由于它们互相引用着对方，导致它们的引用计数都不为 0，于是引用计数算法无法通知 GC 收集器回收它们。\n 可达性分析法 所有和 GC Roots 直接或间接关联的对象都是有效对象，和 GC Roots 没有关联的对象就是无效对象。\nGC Roots 是指：\n Java 虚拟机栈（栈帧中的本地变量表）中引用的对象 本地方法栈中引用的对象 方法区中常量引用的对象 方法区中类静态属性引用的对象  GC Roots 并不包括堆中对象所引用的对象，这样就不会有循环引用的问题。\n引用的种类 判定对象是否存活与“引用”有关。在 JDK 1.2 以前，Java 中的引用定义很传统，一个对象只有被引用或者没有被引用两种状态，我们希望能描述这一类对象：当内存空间还足够时，则保留在内存中；如果内存空间在进行垃圾收集后还是非常紧张，则可以抛弃这些对象。很多系统的缓存功能都符合这样的应用场景。\n在 JDK 1.2 之后，Java 对引用的概念进行了扩充，将引用分为了以下四种。不同的引用类型，主要体现的是对象不同的可达性状态reachable和垃圾收集的影响。\n强引用（Strong Reference） 类似 \u0026ldquo;Object obj = new Object()\u0026rdquo; 这类的引用，就是强引用，只要强引用存在，垃圾收集器永远不会回收被引用的对象。但是，如果我们错误地保持了强引用，比如：赋值给了 static 变量，那么对象在很长一段时间内不会被回收，会产生内存泄漏。\n软引用（Soft Reference） 软引用是一种相对强引用弱化一些的引用，可以让对象豁免一些垃圾收集，只有当 JVM 认为内存不足时，才会去试图回收软引用指向的对象。JVM 会确保在抛出 OutOfMemoryError 之前，清理软引用指向的对象。软引用通常用来实现内存敏感的缓存，如果还有空闲内存，就可以暂时保留缓存，当内存不足时清理掉，这样就保证了使用缓存的同时，不会耗尽内存。\n弱引用（Weak Reference） 弱引用的强度比软引用更弱一些。当 JVM 进行垃圾回收时，无论内存是否充足，都会回收只被弱引用关联的对象。\n虚引用（Phantom Reference） 虚引用也称幽灵引用或者幻影引用，它是最弱的一种引用关系。一个对象是否有虚引用的存在，完全不会对其生存时间构成影响。它仅仅是提供了一种确保对象被 finalize 以后，做某些事情的机制，比如，通常用来做所谓的 Post-Mortem 清理机制。\n回收堆中无效对象 对于可达性分析中不可达的对象，也并不是没有存活的可能。\n判定 finalize() 是否有必要执行 JVM 会判断此对象是否有必要执行 finalize() 方法，如果对象没有覆盖 finalize() 方法，或者 finalize() 方法已经被虚拟机调用过，那么视为“没有必要执行”。那么对象基本上就真的被回收了。\n如果对象被判定为有必要执行 finalize() 方法，那么对象会被放入一个 F-Queue 队列中，虚拟机会以较低的优先级执行这些 finalize()方法，但不会确保所有的 finalize() 方法都会执行结束。如果 finalize() 方法出现耗时操作，虚拟机就直接停止指向该方法，将对象清除。\n对象重生或死亡 如果在执行 finalize() 方法时，将 this 赋给了某一个引用，那么该对象就重生了。如果没有，那么就会被垃圾收集器清除。\n 任何一个对象的 finalize() 方法只会被系统自动调用一次，如果对象面临下一次回收，它的 finalize() 方法不会被再次执行，想继续在 finalize() 中自救就失效了。\n 回收方法区内存 方法区中存放生命周期较长的类信息、常量、静态变量，每次垃圾收集只有少量的垃圾被清除。方法区中主要清除两种垃圾：\n 废弃常量 无用的类  判定废弃常量 只要常量池中的常量不被任何变量或对象引用，那么这些常量就会被清除掉。比如，一个字符串 \u0026ldquo;bingo\u0026rdquo; 进入了常量池，但是当前系统没有任何一个 String 对象引用常量池中的 \u0026ldquo;bingo\u0026rdquo; 常量，也没有其它地方引用这个字面量，必要的话，\u0026ldquo;bingo\u0026quot;常量会被清理出常量池。\n判定无用的类 判定一个类是否是“无用的类”，条件较为苛刻。\n 该类的所有对象都已经被清除 加载该类的 ClassLoader 已经被回收 该类的 java.lang.Class 对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。   一个类被虚拟机加载进方法区，那么在堆中就会有一个代表该类的对象：java.lang.Class。这个对象在类被加载进方法区时创建，在方法区该类被删除时清除。\n 垃圾收集算法 学会了如何判定无效对象、无用类、废弃常量之后，剩余工作就是回收这些垃圾。常见的垃圾收集算法有以下几个：\n标记-清除算法 标记的过程是：遍历所有的 GC Roots，然后将所有 GC Roots 可达的对象标记为存活的对象。\n清除的过程将遍历堆中所有的对象，将没有标记的对象全部清除掉。与此同时，清除那些被标记过的对象的标记，以便下次的垃圾回收。\n这种方法有两个不足：\n 效率问题：标记和清除两个过程的效率都不高。 空间问题：标记清除之后会产生大量不连续的内存碎片，碎片太多可能导致以后需要分配较大对象时，无法找到足够的连续内存而不得不提前触发另一次垃圾收集动作。  复制算法（新生代） 为了解决效率问题，“复制”收集算法出现了。它将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这一块内存用完，需要进行垃圾收集时，就将存活者的对象复制到另一块上面，然后将第一块内存全部清除。这种算法有优有劣：\n 优点：不会有内存碎片的问题。 缺点：内存缩小为原来的一半，浪费空间。  为了解决空间利用率问题，可以将内存分为三块： Eden、From Survivor、To Survivor，比例是 8:1:1，每次使用 Eden 和其中一块 Survivor。回收时，将 Eden 和 Survivor 中还存活的对象一次性复制到另外一块 Survivor 空间上，最后清理掉 Eden 和刚才使用的 Survivor 空间。这样只有 10% 的内存被浪费。\n但是我们无法保证每次回收都只有不多于 10% 的对象存活，当 Survivor 空间不够，需要依赖其他内存（指老年代）进行分配担保。\n分配担保 为对象分配内存空间时，如果 Eden+Survivor 中空闲区域无法装下该对象，会触发 MinorGC 进行垃圾收集。但如果 Minor GC 过后依然有超过 10% 的对象存活，这样存活的对象直接通过分配担保机制进入老年代，然后再将新对象存入 Eden 区。\n标记-整理算法（老年代） 标记：它的第一个阶段与标记/清除算法是一模一样的，均是遍历 GC Roots，然后将存活的对象标记。\n整理：移动所有存活的对象，且按照内存地址次序依次排列，然后将末端内存地址以后的内存全部回收。因此，第二阶段才称为整理阶段。\n这是一种老年代的垃圾收集算法。老年代的对象一般寿命比较长，因此每次垃圾回收会有大量对象存活，如果采用复制算法，每次需要复制大量存活的对象，效率很低。\n分代收集算法 根据对象存活周期的不同，将内存划分为几块。一般是把 Java 堆分为新生代和老年代，针对各个年代的特点采用最适当的收集算法。\n 新生代：复制算法 老年代：标记-清除算法、标记-整理算法  HotSpot 垃圾收集器 HotSpot 虚拟机提供了多种垃圾收集器，每种收集器都有各自的特点，虽然我们要对各个收集器进行比较，但并非为了挑选出一个最好的收集器。我们选择的只是对具体应用最合适的收集器。\n新生代垃圾收集器 Serial 垃圾收集器（单线程） 只开启一条 GC 线程进行垃圾回收，并且在垃圾收集过程中停止一切用户线程(Stop The World)。\n一般客户端应用所需内存较小，不会创建太多对象，而且堆内存不大，因此垃圾收集器回收时间短，即使在这段时间停止一切用户线程，也不会感觉明显卡顿。因此 Serial 垃圾收集器适合客户端使用。\n由于 Serial 收集器只使用一条 GC 线程，避免了线程切换的开销，从而简单高效。\nParNew 垃圾收集器（多线程） ParNew 是 Serial 的多线程版本。由多条 GC 线程并行地进行垃圾清理。但清理过程依然需要 Stop The World。\nParNew 追求“低停顿时间”,与 Serial 唯一区别就是使用了多线程进行垃圾收集，在多 CPU 环境下性能比 Serial 会有一定程度的提升；但线程切换需要额外的开销，因此在单 CPU 环境中表现不如 Serial。\nParallel Scavenge 垃圾收集器（多线程） Parallel Scavenge 和 ParNew 一样，都是多线程、新生代垃圾收集器。但是两者有巨大的不同点：\n Parallel Scavenge：追求 CPU 吞吐量，能够在较短时间内完成指定任务，因此适合没有交互的后台计算。 ParNew：追求降低用户停顿时间，适合交互式应用。  吞吐量 = 运行用户代码时间 / (运行用户代码时间 + 垃圾收集时间)\n追求高吞吐量，可以通过减少 GC 执行实际工作的时间，然而，仅仅偶尔运行 GC 意味着每当 GC 运行时将有许多工作要做，因为在此期间积累在堆中的对象数量很高。单个 GC 需要花更多的时间来完成，从而导致更高的暂停时间。而考虑到低暂停时间，最好频繁运行 GC 以便更快速完成，反过来又导致吞吐量下降。\n 通过参数 -XX:GCTimeRadio 设置垃圾回收时间占总 CPU 时间的百分比。 通过参数 -XX:MaxGCPauseMillis 设置垃圾处理过程最久停顿时间。 通过命令 -XX:+UseAdaptiveSizePolicy 开启自适应策略。我们只要设置好堆的大小和 MaxGCPauseMillis 或 GCTimeRadio，收集器会自动调整新生代的大小、Eden 和 Survivor 的比例、对象进入老年代的年龄，以最大程度上接近我们设置的 MaxGCPauseMillis 或 GCTimeRadio。  老年代垃圾收集器 Serial Old 垃圾收集器（单线程） Serial Old 收集器是 Serial 的老年代版本，都是单线程收集器，只启用一条 GC 线程，都适合客户端应用。它们唯一的区别就是：Serial Old 工作在老年代，使用“标记-整理”算法；Serial 工作在新生代，使用“复制”算法。\nParallel Old 垃圾收集器（多线程） Parallel Old 收集器是 Parallel Scavenge 的老年代版本，追求 CPU 吞吐量。\nCMS 垃圾收集器 CMS(Concurrent Mark Sweep，并发标记清除)收集器是以获取最短回收停顿时间为目标的收集器（追求低停顿），它在垃圾收集时使得用户线程和 GC 线程并发执行，因此在垃圾收集过程中用户也不会感到明显的卡顿。\n 初始标记：Stop The World，仅使用一条初始标记线程对所有与 GC Roots 直接关联的对象进行标记。 并发标记：使用多条标记线程，与用户线程并发执行。此过程进行可达性分析，标记出所有废弃对象。速度很慢。 重新标记：Stop The World，使用多条标记线程并发执行，将刚才并发标记过程中新出现的废弃对象标记出来。 并发清除：只使用一条 GC 线程，与用户线程并发执行，清除刚才标记的对象。这个过程非常耗时。  并发标记与并发清除过程耗时最长，且可以与用户线程一起工作，因此，总体上说，CMS 收集器的内存回收过程是与用户线程一起并发执行的。\nCMS 的缺点：\n 吞吐量低 无法处理浮动垃圾，导致频繁 Full GC 使用“标记-清除”算法产生碎片空间  对于产生碎片空间的问题，可以通过开启 -XX:+UseCMSCompactAtFullCollection，在每次 Full GC 完成后都会进行一次内存压缩整理，将零散在各处的对象整理到一块。设置参数 -XX:CMSFullGCsBeforeCompaction 告诉 CMS，经过了 N 次 Full GC 之后再进行一次内存整理。\nG1 通用垃圾收集器 G1 是一款面向服务端应用的垃圾收集器，它没有新生代和老年代的概念，而是将堆划分为一块块独立的 Region。当要进行垃圾收集时，首先估计每个 Region 中垃圾的数量，每次都从垃圾回收价值最大的 Region 开始回收，因此可以获得最大的回收效率。\n从整体上看， G1 是基于“标记-整理”算法实现的收集器，从局部（两个 Region 之间）上看是基于“复制”算法实现的，这意味着运行期间不会产生内存空间碎片。\n这里抛个问题 👇 一个对象和它内部所引用的对象可能不在同一个 Region 中，那么当垃圾回收时，是否需要扫描整个堆内存才能完整地进行一次可达性分析？\n并不！每个 Region 都有一个 Remembered Set，用于记录本区域中所有对象引用的对象所在的区域，进行可达性分析时，只要在 GC Roots 中再加上 Remembered Set 即可防止对整个堆内存进行遍历。\n如果不计算维护 Remembered Set 的操作，G1 收集器的工作过程分为以下几个步骤：\n 初始标记：Stop The World，仅使用一条初始标记线程对所有与 GC Roots 直接关联的对象进行标记。 并发标记：使用一条标记线程与用户线程并发执行。此过程进行可达性分析，速度很慢。 最终标记：Stop The World，使用多条标记线程并发执行。 筛选回收：回收废弃对象，此时也要 Stop The World，并使用多条筛选回收线程并发执行。  内存分配与回收策略 对象的内存分配，就是在堆上分配（也可能经过 JIT 编译后被拆散为标量类型并间接在栈上分配），对象主要分配在新生代的 Eden 区上，少数情况下可能直接分配在老年代，分配规则不固定，取决于当前使用的垃圾收集器组合以及相关的参数配置。\n以下列举几条最普遍的内存分配规则，供大家学习。\n对象优先在 Eden 分配 大多数情况下，对象在新生代 Eden 区中分配。当 Eden 区没有足够空间进行分配时，虚拟机将发起一次 Minor GC。\n👇Minor GC vs Major GC/Full GC：\n Minor GC：回收新生代（包括 Eden 和 Survivor 区域），因为 Java 对象大多都具备朝生夕灭的特性，所以 Minor GC 非常频繁，一般回收速度也比较快。 Major GC / Full GC: 回收老年代，出现了 Major GC，经常会伴随至少一次的 Minor GC，但这并非绝对。Major GC 的速度一般会比 Minor GC 慢 10 倍 以上。   在 JVM 规范中，Major GC 和 Full GC 都没有一个正式的定义，所以有人也简单地认为 Major GC 清理老年代，而 Full GC 清理整个内存堆。\n 大对象直接进入老年代 大对象是指需要大量连续内存空间的 Java 对象，如很长的字符串或数据。\n一个大对象能够存入 Eden 区的概率比较小，发生分配担保的概率比较大，而分配担保需要涉及大量的复制，就会造成效率低下。\n虚拟机提供了一个 -XX:PretenureSizeThreshold 参数，令大于这个设置值的对象直接在老年代分配，这样做的目的是避免在 Eden 区及两个 Survivor 区之间发生大量的内存复制。（还记得吗，新生代采用复制算法回收垃圾）\n长期存活的对象将进入老年代 JVM 给每个对象定义了一个对象年龄计数器。当新生代发生一次 Minor GC 后，存活下来的对象年龄 +1，当年龄超过一定值时，就将超过该值的所有对象转移到老年代中去。\n使用 -XXMaxTenuringThreshold 设置新生代的最大年龄，只要超过该参数的新生代对象都会被转移到老年代中去。\n动态对象年龄判定 如果当前新生代的 Survivor 中，相同年龄所有对象大小的总和大于 Survivor 空间的一半，年龄 \u0026gt;= 该年龄的对象就可以直接进入老年代，无须等到 MaxTenuringThreshold 中要求的年龄。\n空间分配担保 JDK 6 Update 24 之前的规则是这样的： 在发生 Minor GC 之前，虚拟机会先检查老年代最大可用的连续空间是否大于新生代所有对象总空间， 如果这个条件成立，Minor GC 可以确保是安全的； 如果不成立，则虚拟机会查看 HandlePromotionFailure 值是否设置为允许担保失败， 如果是，那么会继续检查老年代最大可用的连续空间是否大于历次晋升到老年代对象的平均大小， 如果大于，将尝试进行一次 Minor GC,尽管这次 Minor GC 是有风险的； 如果小于，或者 HandlePromotionFailure 设置不允许冒险，那此时也要改为进行一次 Full GC。\nJDK 6 Update 24 之后的规则变为： 只要老年代的连续空间大于新生代对象总大小或者历次晋升的平均大小，就会进行 Minor GC，否则将进行 Full GC。\n通过清除老年代中废弃数据来扩大老年代空闲空间，以便给新生代作担保。\n这个过程就是分配担保。\n 👇 总结一下有哪些情况可能会触发 JVM 进行 Full GC。\n System.gc() 方法的调用 此方法的调用是建议 JVM 进行 Full GC，注意这只是建议而非一定，但在很多情况下它会触发 Full GC，从而增加 Full GC 的频率。通常情况下我们只需要让虚拟机自己去管理内存即可，我们可以通过 -XX:+ DisableExplicitGC 来禁止调用 System.gc()。 老年代空间不足 老年代空间不足会触发 Full GC 操作，若进行该操作后空间依然不足，则会抛出如下错误： java.lang.OutOfMemoryError: Java heap space 永久代空间不足 JVM 规范中运行时数据区域中的方法区，在 HotSpot 虚拟机中也称为永久代（Permanet Generation），存放一些类信息、常量、静态变量等数据，当系统要加载的类、反射的类和调用的方法较多时，永久代可能会被占满，会触发 Full GC。如果经过 Full GC 仍然回收不了，那么 JVM 会抛出如下错误信息： java.lang.OutOfMemoryError: PermGen space  CMS GC 时出现 promotion failed 和 concurrent mode failure promotion failed，就是上文所说的担保失败，而 concurrent mode failure 是在执行 CMS GC 的过程中同时有对象要放入老年代，而此时老年代空间不足造成的。 统计得到的 Minor GC 晋升到旧生代的平均大小大于老年代的剩余空间  JVM 性能调优 在高性能硬件上部署程序，目前主要有两种方式：\n 通过 64 位 JDK 来使用大内存； 使用若干个 32 位虚拟机建立逻辑集群来利用硬件资源。  使用 64 位 JDK 管理大内存 堆内存变大后，虽然垃圾收集的频率减少了，但每次垃圾回收的时间变长。 如果堆内存为 14 G，那么每次 Full GC 将长达数十秒。如果 Full GC 频繁发生，那么对于一个网站来说是无法忍受的。\n对于用户交互性强、对停顿时间敏感的系统，可以给 Java 虚拟机分配超大堆的前提是有把握把应用程序的 Full GC 频率控制得足够低，至少要低到不会影响用户使用。\n可能面临的问题：\n 内存回收导致的长时间停顿； 现阶段，64 位 JDK 的性能普遍比 32 位 JDK 低； 需要保证程序足够稳定，因为这种应用要是产生堆溢出几乎就无法产生堆转储快照（因为要产生超过 10GB 的 Dump 文件），哪怕产生了快照也几乎无法进行分析； 相同程序在 64 位 JDK 消耗的内存一般比 32 位 JDK 大，这是由于指针膨胀，以及数据类型对齐补白等因素导致的。  使用 32 位 JVM 建立逻辑集群 在一台物理机器上启动多个应用服务器进程，每个服务器进程分配不同端口， 然后在前端搭建一个负载均衡器，以反向代理的方式来分配访问请求。\n考虑到在一台物理机器上建立逻辑集群的目的仅仅是为了尽可能利用硬件资源，并不需要关心状态保留、热转移之类的高可用性能需求， 也不需要保证每个虚拟机进程有绝对的均衡负载，因此使用无 Session 复制的亲合式集群是一个不错的选择。 我们仅仅需要保障集群具备亲合性，也就是均衡器按一定的规则算法（一般根据 SessionID 分配） 将一个固定的用户请求永远分配到固定的一个集群节点进行处理即可。\n可能遇到的问题：\n 尽量避免节点竞争全局资源，如磁盘竞争，各个节点如果同时访问某个磁盘文件的话，很可能导致 IO 异常； 很难高效利用资源池，如连接池，一般都是在节点建立自己独立的连接池，这样有可能导致一些节点池满了而另外一些节点仍有较多空余； 各个节点受到 32 位的内存限制； 大量使用本地缓存的应用，在逻辑集群中会造成较大的内存浪费，因为每个逻辑节点都有一份缓存，这时候可以考虑把本地缓存改成集中式缓存。  调优案例分析与实战 场景描述 一个小型系统，使用 32 位 JDK，4G 内存，测试期间发现服务端不定时抛出内存溢出异常。 加入 -XX:+HeapDumpOnOutOfMemoryError（添加这个参数后，堆内存溢出时就会输出异常日志）， 但再次发生内存溢出时，没有生成相关异常日志。\n分析 在 32 位 JDK 上，1.6G 分配给堆，还有一部分分配给 JVM 的其他内存，直接内存最大也只能在剩余的 0.4G 空间中分出一部分， 如果使用了 NIO，JVM 会在 JVM 内存之外分配内存空间，那么就要小心“直接内存”不足时发生内存溢出异常了。\n直接内存的回收过程 直接内存虽然不是 JVM 内存空间，但它的垃圾回收也由 JVM 负责。\n垃圾收集进行时，虚拟机虽然会对直接内存进行回收， 但是直接内存却不能像新生代、老年代那样，发现空间不足了就通知收集器进行垃圾回收， 它只能等老年代满了后 Full GC，然后“顺便”帮它清理掉内存的废弃对象。 否则只能一直等到抛出内存溢出异常时，先 catch 掉，再在 catch 块里大喊 “System.gc()”。 要是虚拟机还是不听，那就只能眼睁睁看着堆中还有许多空闲内存，自己却不得不抛出内存溢出异常了。\n类文件结构 JVM 的“无关性” 谈论 JVM 的无关性，主要有以下两个：\n 平台无关性：任何操作系统都能运行 Java 代码 语言无关性： JVM 能运行除 Java 以外的其他代码  Java 源代码首先需要使用 Javac 编译器编译成 .class 文件，然后由 JVM 执行 .class 文件，从而程序开始运行。\nJVM 只认识 .class 文件，它不关心是何种语言生成了 .class 文件，只要 .class 文件符合 JVM 的规范就能运行。 目前已经有 JRuby、Jython、Scala 等语言能够在 JVM 上运行。它们有各自的语法规则，不过它们的编译器 都能将各自的源码编译成符合 JVM 规范的 .class 文件，从而能够借助 JVM 运行它们。\n Java 语言中的各种变量、关键字和运算符号的语义最终都是由多条字节码命令组合而成的， 因此字节码命令所能提供的语义描述能力肯定会比 ; Java 语言本身更加强大。 因此，有一些 Java 语言本身无法有效支持的语言特性，不代表字节码本身无法有效支持。\n Class 文件结构 Class 文件是二进制文件，它的内容具有严格的规范，文件中没有任何空格，全都是连续的 0/1。Class 文件 中的所有内容被分为两种类型：无符号数、表。\n 无符号数 无符号数表示 Class 文件中的值，这些值没有任何类型，但有不同的长度。u1、u2、u4、u8 分别代表 1/2/4/8 字节的无符号数。 表 由多个无符号数或者其他表作为数据项构成的复合数据类型。  Class 文件具体由以下几个构成:\n 魔数 版本信息 常量池 访问标志 类索引、父类索引、接口索引集合 字段表集合 方法表集合 属性表集合  魔数 Class 文件的头 4 个字节称为魔数，用来表示这个 Class 文件的类型。\nClass 文件的魔数是用 16 进制表示的“CAFE BABE”，是不是很具有浪漫色彩？\n 魔数相当于文件后缀名，只不过后缀名容易被修改，不安全，因此在 Class 文件中标识文件类型比较合适。\n 版本信息 紧接着魔数的 4 个字节是版本信息，5-6 字节表示次版本号，7-8 字节表示主版本号，它们表示当前 Class 文件中使用的是哪个版本的 JDK。\n高版本的 JDK 能向下兼容以前版本的 Class 文件，但不能运行以后版本的 Class 文件，即使文件格式并未发生任何变化，虚拟机也必需拒绝执行超过其版本号的 Class 文件。\n常量池 版本信息之后就是常量池，常量池中存放两种类型的常量：\n  字面值常量\n字面值常量就是我们在程序中定义的字符串、被 final 修饰的值。\n  符号引用\n符号引用就是我们定义的各种名字：类和接口的全限定名、字段的名字和描述符、方法的名字和描述符。\n  常量池的特点  常量池中常量数量不固定，因此常量池开头放置一个 u2 类型的无符号数，用来存储当前常量池的容量。 常量池的每一项常量都是一个表，表开始的第一位是一个 u1 类型的标志位（tag），代表当前这个常量属于哪种常量类型。  常量池中常量类型    类型 tag 描述     CONSTANT_utf8_info 1 UTF-8 编码的字符串   CONSTANT_Integer_info 3 整型字面量   CONSTANT_Float_info 4 浮点型字面量   CONSTANT_Long_info 5 长整型字面量   CONSTANT_Double_info 6 双精度浮点型字面量   CONSTANT_Class_info 7 类或接口的符号引用   CONSTANT_String_info 8 字符串类型字面量   CONSTANT_Fieldref_info 9 字段的符号引用   CONSTANT_Methodref_info 10 类中方法的符号引用   CONSTANT_InterfaceMethodref_info 11 接口中方法的符号引用   CONSTANT_NameAndType_info 12 字段或方法的符号引用   CONSTANT_MethodHandle_info 15 表示方法句柄   CONSTANT_MethodType_info 16 标识方法类型   CONSTANT_InvokeDynamic_info 18 表示一个动态方法调用点    对于 CONSTANT_Class_info（此类型的常量代表一个类或者接口的符号引用），它的二维表结构如下：\n   类型 名称 数量     u1 tag 1   u2 name_index 1    tag 是标志位，用于区分常量类型；name_index 是一个索引值，它指向常量池中一个 CONSTANT_Utf8_info 类型常量，此常量代表这个类（或接口）的全限定名，这里 name_index 值若为 0x0002，也即是指向了常量池中的第二项常量。\nCONSTANT_Utf8_info 型常量的结构如下：\n   类型 名称 数量     u1 tag 1   u2 length 1   u1 bytes length    tag 是当前常量的类型；length 表示这个字符串的长度；bytes 是这个字符串的内容（采用缩略的 UTF8 编码）\n访问标志 在常量池结束之后，紧接着的两个字节代表访问标志，这个标志用于识别一些类或者接口层次的访问信息，包括：这个 Class 是类还是接口；是否定义为 public 类型；是否被 abstract/final 修饰。\n类索引、父类索引、接口索引集合 类索引和父类索引都是一个 u2 类型的数据，而接口索引集合是一组 u2 类型的数据的集合，Class 文件中由这三项数据来确定类的继承关系。类索引用于确定这个类的全限定名，父类索引用于确定这个类的父类的全限定名。\n由于 Java 不允许多重继承，所以父类索引只有一个，除了 java.lang.Object 之外，所有的 Java 类都有父类，因此除了 java.lang.Object 外，所有 Java 类的父类索引都不为 0。一个类可能实现了多个接口，因此用接口索引集合来描述。这个集合第一项为 u2 类型的数据，表示索引表的容量，接下来就是接口的名字索引。\n类索引和父类索引用两个 u2 类型的索引值表示，它们各自指向一个类型为 CONSTANT_Class_info 的类描述符常量，通过该常量总的索引值可以找到定义在 CONSTANT_Utf8_info 类型的常量中的全限定名字符串。\n字段表集合 字段表集合存储本类涉及到的成员变量，包括实例变量和类变量，但不包括方法中的局部变量。\n每一个字段表只表示一个成员变量，本类中的所有成员变量构成了字段表集合。字段表结构如下：\n   类型 名称 数量 说明     u2 access_flags 1 字段的访问标志，与类稍有不同   u2 name_index 1 字段名字的索引   u2 descriptor_index 1 描述符，用于描述字段的数据类型。 基本数据类型用大写字母表示； 对象类型用“L 对象类型的全限定名”表示。   u2 attributes_count 1 属性表集合的长度   u2 attributes attributes_count 属性表集合，用于存放属性的额外信息，如属性的值。     字段表集合中不会出现从父类（或接口）中继承而来的字段，但有可能出现原本 Java 代码中不存在的字段，譬如在内部类中为了保持对外部类的访问性，会自动添加指向外部类实例的字段。\n 方法表集合 方法表结构与属性表类似。\nvolatile 关键字 和 transient 关键字不能修饰方法，所以方法表的访问标志中没有 ACC_VOLATILE 和 ACC_TRANSIENT 标志。\n方法表的属性表集合中有一张 Code 属性表，用于存储当前方法经编译器编译后的字节码指令。\n属性表集合 每个属性对应一张属性表，属性表的结构如下：\n   类型 名称 数量     u2 attribute_name_index 1   u4 attribute_length 1   u1 info attribute_length    类加载的时机 类的生命周期 类从被加载到虚拟机内存开始，到卸载出内存为止，它的整个生命周期包括以下 7 个阶段：\n 加载 验证 准备 解析 初始化 使用 卸载  验证、准备、解析 3 个阶段统称为连接。\n加载、验证、准备、初始化和卸载这 5 个阶段的顺序是确定的，类的加载过程必须按照这种顺序按部就班地开始（注意是“开始”，而不是“进行”或“完成”），而解析阶段则不一定：它在某些情况下可以在初始化后再开始，这是为了支持 Java 语言的运行时绑定。\n类加载过程中“初始化”开始的时机 Java 虚拟机规范没有强制约束类加载过程的第一阶段（即：加载）什么时候开始，但对于“初始化”阶段，有着严格的规定。有且仅有 5 种情况必须立即对类进行“初始化”：\n 在遇到 new、putstatic、getstatic、invokestatic 字节码指令时，如果类尚未初始化，则需要先触发其初始化。 对类进行反射调用时，如果类还没有初始化，则需要先触发其初始化。 初始化一个类时，如果其父类还没有初始化，则需要先初始化父类。 虚拟机启动时，用于需要指定一个包含 main() 方法的主类，虚拟机会先初始化这个主类。 当使用 JDK 1.7 的动态语言支持时，如果一个 java.lang.invoke.MethodHandle 实例最后的解析结果为 REF_getStatic、REF_putStatic、REF_invokeStatic 的方法句柄，并且这个方法句柄所对应的类还没初始化，则需要先触发其初始化。  这 5 种场景中的行为称为对一个类进行主动引用，除此之外，其它所有引用类的方式都不会触发初始化，称为被动引用。\n被动引用演示 Demo Demo1 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  /** * 被动引用 Demo1: * 通过子类引用父类的静态字段，不会导致子类初始化。 * * @author ylb * */ class SuperClass { static { System.out.println(\u0026#34;SuperClass init!\u0026#34;); } public static int value = 123; } class SubClass extends SuperClass { static { System.out.println(\u0026#34;SubClass init!\u0026#34;); } } public class NotInitialization { public static void main(String[] args) { System.out.println(SubClass.value); // SuperClass init!  } }Copy to clipboardErrorCopied   对于静态字段，只有直接定义这个字段的类才会被初始化，因此通过其子类来引用父类中定义的静态字段，只会触发父类的初始化而不会触发子类的初始化。\nDemo2 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  /** * 被动引用 Demo2: * 通过数组定义来引用类，不会触发此类的初始化。 * * @author ylb * */ public class NotInitialization { public static void main(String[] args) { SuperClass[] superClasses = new SuperClass[10]; } }Copy to clipboardErrorCopied   这段代码不会触发父类的初始化，但会触发“[L 全类名”这个类的初始化，它由虚拟机自动生成，直接继承自 java.lang.Object，创建动作由字节码指令 newarray 触发。\nDemo3 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  /** * 被动引用 Demo3: * 常量在编译阶段会存入调用类的常量池中，本质上并没有直接引用到定义常量的类，因此不会触发定义常量的类的初始化。 * * @author ylb * */ class ConstClass { static { System.out.println(\u0026#34;ConstClass init!\u0026#34;); } public static final String HELLO_BINGO = \u0026#34;Hello Bingo\u0026#34;; } public class NotInitialization { public static void main(String[] args) { System.out.println(ConstClass.HELLO_BINGO); } }Copy to clipboardErrorCopied   编译通过之后，常量存储到 NotInitialization 类的常量池中，NotInitialization 的 Class 文件中并没有 ConstClass 类的符号引用入口，这两个类在编译成 Class 之后就没有任何联系了。\n接口的加载过程 接口加载过程与类加载过程稍有不同。\n当一个类在初始化时，要求其父类全部都已经初始化过了，但是一个接口在初始化时，并不要求其父接口全部都完成了初始化，当真正用到父接口的时候才会初始化。\n类加载的过程 类加载过程包括 5 个阶段：加载、验证、准备、解析和初始化。\n加载 加载的过程 “加载”是“类加载”过程的一个阶段，不能混淆这两个名词。在加载阶段，虚拟机需要完成 3 件事：\n 通过类的全限定名获取该类的二进制字节流。 将二进制字节流所代表的静态结构转化为方法区的运行时数据结构。 在内存中创建一个代表该类的 java.lang.Class 对象，作为方法区这个类的各种数据的访问入口。  获取二进制字节流 对于 Class 文件，虚拟机没有指明要从哪里获取、怎样获取。除了直接从编译好的 .class 文件中读取，还有以下几种方式：\n 从 zip 包中读取，如 jar、war 等 从网络中获取，如 Applet 通过动态代理技术生成代理类的二进制字节流 由 JSP 文件生成对应的 Class 类 从数据库中读取，如 有些中间件服务器可以选择把程序安装到数据库中来完成程序代码在集群间的分发。  “非数组类”与“数组类”加载比较  非数组类加载阶段可以使用系统提供的引导类加载器，也可以由用户自定义的类加载器完成，开发人员可以通过定义自己的类加载器控制字节流的获取方式（如重写一个类加载器的 loadClass() 方法） 数组类本身不通过类加载器创建，它是由 Java 虚拟机直接创建的，再由类加载器创建数组中的元素类。  注意事项  虚拟机规范未规定 Class 对象的存储位置，对于 HotSpot 虚拟机而言，Class 对象比较特殊，它虽然是对象，但存放在方法区中。 加载阶段与连接阶段的部分内容交叉进行，加载阶段尚未完成，连接阶段可能已经开始了。但这两个阶段的开始时间仍然保持着固定的先后顺序。  验证 验证的重要性 验证阶段确保 Class 文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害虚拟机自身的安全。\n验证的过程  文件格式验证 验证字节流是否符合 Class 文件格式的规范，并且能被当前版本的虚拟机处理，验证点如下：  是否以魔数 0XCAFEBABE 开头 主次版本号是否在当前虚拟机处理范围内 常量池是否有不被支持的常量类型 指向常量的索引值是否指向了不存在的常量 CONSTANT_Utf8_info 型的常量是否有不符合 UTF8 编码的数据 \u0026hellip;\u0026hellip;   元数据验证 对字节码描述信息进行语义分析，确保其符合 Java 语法规范。 字节码验证 本阶段是验证过程中最复杂的一个阶段，是对方法体进行语义分析，保证方法在运行时不会出现危害虚拟机的事件。 符号引用验证 本阶段发生在解析阶段，确保解析正常执行。  准备 准备阶段是正式为类变量（或称“静态成员变量”）分配内存并设置初始值的阶段。这些变量（不包括实例变量）所使用的内存都在方法区中进行分配。\n初始值“通常情况下”是数据类型的零值（0, null\u0026hellip;），假设一个类变量的定义为：\n1  public static int value = 123;Copy to clipboardErrorCopied   那么变量 value 在准备阶段过后的初始值为 0 而不是 123，因为这时候尚未开始执行任何 Java 方法。\n存在“特殊情况”：如果类字段的字段属性表中存在 ConstantValue 属性，那么在准备阶段 value 就会被初始化为 ConstantValue 属性所指定的值，假设上面类变量 value 的定义变为：\n1  public static final int value = 123;Copy to clipboardErrorCopied   那么在准备阶段虚拟机会根据 ConstantValue 的设置将 value 赋值为 123。\n解析 解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程。\n初始化 类初始化阶段是类加载过程的最后一步，是执行类构造器 \u0026lt;clinit\u0026gt;() 方法的过程。\n\u0026lt;clinit\u0026gt;() 方法是由编译器自动收集类中的所有类变量的赋值动作和静态语句块（static {} 块）中的语句合并产生的，编译器收集的顺序是由语句在源文件中出现的顺序所决定的。\n静态语句块中只能访问定义在静态语句块之前的变量，定义在它之后的变量，在前面的静态语句块中可以赋值，但不能访问。如下方代码所示：\n1 2 3 4 5 6 7  public class Test { static { i = 0; // 给变量赋值可以正常编译通过  System.out.println(i); // 这句编译器会提示“非法向前引用”  } static int i = 1; }Copy to clipboardErrorCopied   \u0026lt;clinit\u0026gt;() 方法不需要显式调用父类构造器，虚拟机会保证在子类的 \u0026lt;clinit\u0026gt;() 方法执行之前，父类的 \u0026lt;clinit\u0026gt;() 方法已经执行完毕。\n由于父类的 \u0026lt;clinit\u0026gt;() 方法先执行，意味着父类中定义的静态语句块要优先于子类的变量赋值操作。如下方代码所示：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  static class Parent { public static int A = 1; static { A = 2; } } static class Sub extends Parent { public static int B = A; } public static void main(String[] args) { System.out.println(Sub.B); // 输出 2 }Copy to clipboardErrorCopied   \u0026lt;clinit\u0026gt;() 方法不是必需的，如果一个类没有静态语句块，也没有对类变量的赋值操作，那么编译器可以不为这个类生成 \u0026lt;clinit\u0026gt;() 方法。\n接口中不能使用静态代码块，但接口也需要通过 \u0026lt;clinit\u0026gt;() 方法为接口中定义的静态成员变量显式初始化。但接口与类不同，接口的 \u0026lt;clinit\u0026gt;() 方法不需要先执行父类的 \u0026lt;clinit\u0026gt;() 方法，只有当父接口中定义的变量使用时，父接口才会初始化。\n虚拟机会保证一个类的 \u0026lt;clinit\u0026gt;() 方法在多线程环境中被正确加锁、同步。如果多个线程同时去初始化一个类，那么只会有一个线程去执行这个类的 \u0026lt;clinit\u0026gt;() 方法。\n类加载器 类与类加载器 判断类是否“相等” 任意一个类，都由加载它的类加载器和这个类本身一同确立其在 Java 虚拟机中的唯一性，每一个类加载器，都有一个独立的类名称空间。\n因此，比较两个类是否“相等”，只有在这两个类是由同一个类加载器加载的前提下才有意义，否则，即使这两个类来源于同一个 Class 文件，被同一个虚拟机加载，只要加载它们的类加载器不同，那么这两个类就必定不相等。\n这里的“相等”，包括代表类的 Class 对象的 equals() 方法、isInstance() 方法的返回结果，也包括使用 instanceof 关键字做对象所属关系判定等情况。\n加载器种类 系统提供了 3 种类加载器：\n 启动类加载器（Bootstrap ClassLoader）： 负责将存放在 \u0026lt;JAVA_HOME\u0026gt;\\lib 目录中的，并且能被虚拟机识别的（仅按照文件名识别，如 rt.jar，名字不符合的类库即使放在 lib 目录中也不会被加载）类库加载到虚拟机内存中。 扩展类加载器（Extension ClassLoader）： 负责加载 \u0026lt;JAVA_HOME\u0026gt;\\lib\\ext 目录中的所有类库，开发者可以直接使用扩展类加载器。 应用程序类加载器（Application ClassLoader）： 由于这个类加载器是 ClassLoader 中的 getSystemClassLoader() 方法的返回值，所以一般也称它为“系统类加载器”。它负责加载用户类路径（classpath）上所指定的类库，开发者可以直接使用这个类加载器，如果应用程序中没有自定义过自己的类加载器，一般情况下这个就是程序中默认的类加载器。  当然，如果有必要，还可以加入自己定义的类加载器。\n双亲委派模型 什么是双亲委派模型 双亲委派模型是描述类加载器之间的层次关系。它要求除了顶层的启动类加载器外，其余的类加载器都应当有自己的父类加载器。（父子关系一般不会以继承的关系实现，而是以组合关系来复用父加载器的代码）\n工作过程 如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把这个请求委派给父类加载器去完成，每一个层次的类加载器都是如此，因此所有的加载请求最终都应该传送到顶层的启动类加载器中，只有当父加载器反馈自己无法完成这个加载请求（找不到所需的类）时，子加载器才会尝试自己去加载。\n在 java.lang.ClassLoader 中的 loadClass 方法中实现该过程。\n为什么使用双亲委派模型 像 java.lang.Object 这些存放在 rt.jar 中的类，无论使用哪个类加载器加载，最终都会委派给最顶端的启动类加载器加载，从而使得不同加载器加载的 Object 类都是同一个。\n相反，如果没有使用双亲委派模型，由各个类加载器自行去加载的话，如果用户自己编写了一个称为 java.lang.Object 的类，并放在 classpath 下，那么系统将会出现多个不同的 Object 类，Java 类型体系中最基础的行为也就无法保证。\n","date":"2021-05-09T13:36:41Z","image":"https://ahao.ink/17.jpg","permalink":"https://ahao.ink/posts/jvm-%E5%BA%95%E5%B1%82%E5%8E%9F%E7%90%86%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/","title":"JVM 底层原理知识总结"},{"content":"ConcurrentHashMap 1.7 存储结构 Java 7 中 ConcurrentHashMap 的存储结构如上图，ConcurrnetHashMap 由很多个 Segment 组合，而每一个 Segment 是一个类似于 HashMap 的结构，所以每一个 HashMap 的内部可以进行扩容。但是 Segment 的个数一旦初始化就不能改变，默认 Segment 的个数是 16 个，你也可以认为 ConcurrentHashMap 默认支持最多 16 个线程并发。\n初始化 通过 ConcurrentHashMap 的无参构造探寻 ConcurrentHashMap 的初始化流程。\n1 2 3 4 5 6 7  /** * Creates a new, empty map with a default initial capacity (16), * load factor (0.75) and concurrencyLevel (16). */ public ConcurrentHashMap() { this(DEFAULT_INITIAL_CAPACITY, DEFAULT_LOAD_FACTOR, DEFAULT_CONCURRENCY_LEVEL); }   无参构造中调用了有参构造，传入了三个参数的默认值，他们的值是。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  /** * 默认初始化容量 */ static final int DEFAULT_INITIAL_CAPACITY = 16; /** * 默认负载因子 */ static final float DEFAULT_LOAD_FACTOR = 0.75f; /** * 默认并发级别 */ static final int DEFAULT_CONCURRENCY_LEVEL = 16;   接着看下这个有参构造函数的内部实现逻辑。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40  @SuppressWarnings(\u0026#34;unchecked\u0026#34;) public ConcurrentHashMap(int initialCapacity,float loadFactor, int concurrencyLevel) { // 参数校验  if (!(loadFactor \u0026gt; 0) || initialCapacity \u0026lt; 0 || concurrencyLevel \u0026lt;= 0) throw new IllegalArgumentException(); // 校验并发级别大小，大于 1\u0026lt;\u0026lt;16，重置为 65536  if (concurrencyLevel \u0026gt; MAX_SEGMENTS) concurrencyLevel = MAX_SEGMENTS; // Find power-of-two sizes best matching arguments  // 2的多少次方  int sshift = 0; int ssize = 1; // 这个循环可以找到 concurrencyLevel 之上最近的 2的次方值  while (ssize \u0026lt; concurrencyLevel) { ++sshift; ssize \u0026lt;\u0026lt;= 1; } // 记录段偏移量  this.segmentShift = 32 - sshift; // 记录段掩码  this.segmentMask = ssize - 1; // 设置容量  if (initialCapacity \u0026gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; // c = 容量 / ssize ，默认 16 / 16 = 1，这里是计算每个 Segment 中的类似于 HashMap 的容量  int c = initialCapacity / ssize; if (c * ssize \u0026lt; initialCapacity) ++c; int cap = MIN_SEGMENT_TABLE_CAPACITY; //Segment 中的类似于 HashMap 的容量至少是2或者2的倍数  while (cap \u0026lt; c) cap \u0026lt;\u0026lt;= 1; // create segments and segments[0]  // 创建 Segment 数组，设置 segments[0]  Segment\u0026lt;K,V\u0026gt; s0 = new Segment\u0026lt;K,V\u0026gt;(loadFactor, (int)(cap * loadFactor), (HashEntry\u0026lt;K,V\u0026gt;[])new HashEntry[cap]); Segment\u0026lt;K,V\u0026gt;[] ss = (Segment\u0026lt;K,V\u0026gt;[])new Segment[ssize]; UNSAFE.putOrderedObject(ss, SBASE, s0); // ordered write of segments[0]  this.segments = ss; }   总结一下在 Java 7 中 ConcurrnetHashMap 的初始化逻辑。\n 必要参数校验。 校验并发级别 concurrencyLevel 大小，如果大于最大值，重置为最大值。无参构造默认值是 16. 寻找并发级别 concurrencyLevel 之上最近的 2 的幂次方值，作为初始化容量大小，默认是 16。 记录 segmentShift 偏移量，这个值为【容量 = 2 的N次方】中的 N，在后面 Put 时计算位置时会用到。默认是 32 - sshift = 28. 记录 segmentMask，默认是 ssize - 1 = 16 -1 = 15. 初始化 segments[0]，默认大小为 2，负载因子 0.75，扩容阀值是 2*0.75=1.5，插入第二个值时才会进行扩容。  put 接着上面的初始化参数继续查看 put 方法源码。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65  /** * Maps the specified key to the specified value in this table. * Neither the key nor the value can be null. * * \u0026lt;p\u0026gt; The value can be retrieved by calling the \u0026lt;tt\u0026gt;get\u0026lt;/tt\u0026gt; method * with a key that is equal to the original key. * * @param key key with which the specified value is to be associated * @param value value to be associated with the specified key * @return the previous value associated with \u0026lt;tt\u0026gt;key\u0026lt;/tt\u0026gt;, or * \u0026lt;tt\u0026gt;null\u0026lt;/tt\u0026gt; if there was no mapping for \u0026lt;tt\u0026gt;key\u0026lt;/tt\u0026gt; * @throws NullPointerException if the specified key or value is null */ public V put(K key, V value) { Segment\u0026lt;K,V\u0026gt; s; if (value == null) throw new NullPointerException(); int hash = hash(key); // hash 值无符号右移 28位（初始化时获得），然后与 segmentMask=15 做与运算  // 其实也就是把高4位与segmentMask（1111）做与运算  int j = (hash \u0026gt;\u0026gt;\u0026gt; segmentShift) \u0026amp; segmentMask; if ((s = (Segment\u0026lt;K,V\u0026gt;)UNSAFE.getObject // nonvolatile; recheck  (segments, (j \u0026lt;\u0026lt; SSHIFT) + SBASE)) == null) // in ensureSegment  // 如果查找到的 Segment 为空，初始化  s = ensureSegment(j); return s.put(key, hash, value, false); } /** * Returns the segment for the given index, creating it and * recording in segment table (via CAS) if not already present. * * @param k the index * @return the segment */ @SuppressWarnings(\u0026#34;unchecked\u0026#34;) private Segment\u0026lt;K,V\u0026gt; ensureSegment(int k) { final Segment\u0026lt;K,V\u0026gt;[] ss = this.segments; long u = (k \u0026lt;\u0026lt; SSHIFT) + SBASE; // raw offset  Segment\u0026lt;K,V\u0026gt; seg; // 判断 u 位置的 Segment 是否为null  if ((seg = (Segment\u0026lt;K,V\u0026gt;)UNSAFE.getObjectVolatile(ss, u)) == null) { Segment\u0026lt;K,V\u0026gt; proto = ss[0]; // use segment 0 as prototype  // 获取0号 segment 里的 HashEntry\u0026lt;K,V\u0026gt; 初始化长度  int cap = proto.table.length; // 获取0号 segment 里的 hash 表里的扩容负载因子，所有的 segment 的 loadFactor 是相同的  float lf = proto.loadFactor; // 计算扩容阀值  int threshold = (int)(cap * lf); // 创建一个 cap 容量的 HashEntry 数组  HashEntry\u0026lt;K,V\u0026gt;[] tab = (HashEntry\u0026lt;K,V\u0026gt;[])new HashEntry[cap]; if ((seg = (Segment\u0026lt;K,V\u0026gt;)UNSAFE.getObjectVolatile(ss, u)) == null) { // recheck  // 再次检查 u 位置的 Segment 是否为null，因为这时可能有其他线程进行了操作  Segment\u0026lt;K,V\u0026gt; s = new Segment\u0026lt;K,V\u0026gt;(lf, threshold, tab); // 自旋检查 u 位置的 Segment 是否为null  while ((seg = (Segment\u0026lt;K,V\u0026gt;)UNSAFE.getObjectVolatile(ss, u)) == null) { // 使用CAS 赋值，只会成功一次  if (UNSAFE.compareAndSwapObject(ss, u, null, seg = s)) break; } } } return seg; }   上面的源码分析了 ConcurrentHashMap 在 put 一个数据时的处理流程，下面梳理下具体流程。\n  计算要 put 的 key 的位置，获取指定位置的 Segment。\n  如果指定位置的 Segment 为空，则初始化这个 Segment.\n初始化 Segment 流程：\n 检查计算得到的位置的 Segment 是否为null. 为 null 继续初始化，使用 Segment[0] 的容量和负载因子创建一个 HashEntry 数组。 再次检查计算得到的指定位置的 Segment 是否为null. 使用创建的 HashEntry 数组初始化这个 Segment. 自旋判断计算得到的指定位置的 Segment 是否为null，使用 CAS 在这个位置赋值为 Segment.    Segment.put 插入 key,value 值。\n  上面探究了获取 Segment 段和初始化 Segment 段的操作。最后一行的 Segment 的 put 方法还没有查看，继续分析。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49  final V put(K key, int hash, V value, boolean onlyIfAbsent) { // 获取 ReentrantLock 独占锁，获取不到，scanAndLockForPut 获取。  HashEntry\u0026lt;K,V\u0026gt; node = tryLock() ? null : scanAndLockForPut(key, hash, value); V oldValue; try { HashEntry\u0026lt;K,V\u0026gt;[] tab = table; // 计算要put的数据位置  int index = (tab.length - 1) \u0026amp; hash; // CAS 获取 index 坐标的值  HashEntry\u0026lt;K,V\u0026gt; first = entryAt(tab, index); for (HashEntry\u0026lt;K,V\u0026gt; e = first;;) { if (e != null) { // 检查是否 key 已经存在，如果存在，则遍历链表寻找位置，找到后替换 value  K k; if ((k = e.key) == key || (e.hash == hash \u0026amp;\u0026amp; key.equals(k))) { oldValue = e.value; if (!onlyIfAbsent) { e.value = value; ++modCount; } break; } e = e.next; } else { // first 有值没说明 index 位置已经有值了，有冲突，链表头插法。  if (node != null) node.setNext(first); else node = new HashEntry\u0026lt;K,V\u0026gt;(hash, key, value, first); int c = count + 1; // 容量大于扩容阀值，小于最大容量，进行扩容  if (c \u0026gt; threshold \u0026amp;\u0026amp; tab.length \u0026lt; MAXIMUM_CAPACITY) rehash(node); else // index 位置赋值 node，node 可能是一个元素，也可能是一个链表的表头  setEntryAt(tab, index, node); ++modCount; count = c; oldValue = null; break; } } } finally { unlock(); } return oldValue; }   由于 Segment 继承了 ReentrantLock，所以 Segment 内部可以很方便的获取锁，put 流程就用到了这个功能。\n  tryLock() 获取锁，获取不到使用 scanAndLockForPut 方法继续获取。\n  计算 put 的数据要放入的 index 位置，然后获取这个位置上的 HashEntry 。\n  遍历 put 新元素，为什么要遍历？因为这里获取的 HashEntry 可能是一个空元素，也可能是链表已存在，所以要区别对待。\n如果这个位置上的 HashEntry 不存在：\n 如果当前容量大于扩容阀值，小于最大容量，进行扩容。 直接头插法插入。  如果这个位置上的 HashEntry 存在：\n 判断链表当前元素 Key 和 hash 值是否和要 put 的 key 和 hash 值一致。一致则替换值 不一致，获取链表下一个节点，直到发现相同进行值替换，或者链表表里完毕没有相同的。  如果当前容量大于扩容阀值，小于最大容量，进行扩容。 直接链表头插法插入。      如果要插入的位置之前已经存在，替换后返回旧值，否则返回 null.\n  这里面的第一步中的 scanAndLockForPut 操作这里没有介绍，这个方法做的操作就是不断的自旋 tryLock() 获取锁。当自旋次数大于指定次数时，使用 lock() 阻塞获取锁。在自旋时顺表获取下 hash 位置的 HashEntry。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  private HashEntry\u0026lt;K,V\u0026gt; scanAndLockForPut(K key, int hash, V value) { HashEntry\u0026lt;K,V\u0026gt; first = entryForHash(this, hash); HashEntry\u0026lt;K,V\u0026gt; e = first; HashEntry\u0026lt;K,V\u0026gt; node = null; int retries = -1; // negative while locating node  // 自旋获取锁  while (!tryLock()) { HashEntry\u0026lt;K,V\u0026gt; f; // to recheck first below  if (retries \u0026lt; 0) { if (e == null) { if (node == null) // speculatively create node  node = new HashEntry\u0026lt;K,V\u0026gt;(hash, key, value, null); retries = 0; } else if (key.equals(e.key)) retries = 0; else e = e.next; } else if (++retries \u0026gt; MAX_SCAN_RETRIES) { // 自旋达到指定次数后，阻塞等到只到获取到锁  lock(); break; } else if ((retries \u0026amp; 1) == 0 \u0026amp;\u0026amp; (f = entryForHash(this, hash)) != first) { e = first = f; // re-traverse if entry changed  retries = -1; } } return node; }   扩容 rehash ConcurrentHashMap 的扩容只会扩容到原来的两倍。老数组里的数据移动到新的数组时，位置要么不变，要么变为 index+ oldSize，参数里的 node 会在扩容之后使用链表头插法插入到指定位置。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55  private void rehash(HashEntry\u0026lt;K,V\u0026gt; node) { HashEntry\u0026lt;K,V\u0026gt;[] oldTable = table; // 老容量  int oldCapacity = oldTable.length; // 新容量，扩大两倍  int newCapacity = oldCapacity \u0026lt;\u0026lt; 1; // 新的扩容阀值  threshold = (int)(newCapacity * loadFactor); // 创建新的数组  HashEntry\u0026lt;K,V\u0026gt;[] newTable = (HashEntry\u0026lt;K,V\u0026gt;[]) new HashEntry[newCapacity]; // 新的掩码，默认2扩容后是4，-1是3，二进制就是11。  int sizeMask = newCapacity - 1; for (int i = 0; i \u0026lt; oldCapacity ; i++) { // 遍历老数组  HashEntry\u0026lt;K,V\u0026gt; e = oldTable[i]; if (e != null) { HashEntry\u0026lt;K,V\u0026gt; next = e.next; // 计算新的位置，新的位置只可能是不便或者是老的位置+老的容量。  int idx = e.hash \u0026amp; sizeMask; if (next == null) // Single node on list  // 如果当前位置还不是链表，只是一个元素，直接赋值  newTable[idx] = e; else { // Reuse consecutive sequence at same slot  // 如果是链表了  HashEntry\u0026lt;K,V\u0026gt; lastRun = e; int lastIdx = idx; // 新的位置只可能是不便或者是老的位置+老的容量。  // 遍历结束后，lastRun 后面的元素位置都是相同的  for (HashEntry\u0026lt;K,V\u0026gt; last = next; last != null; last = last.next) { int k = last.hash \u0026amp; sizeMask; if (k != lastIdx) { lastIdx = k; lastRun = last; } } // ，lastRun 后面的元素位置都是相同的，直接作为链表赋值到新位置。  newTable[lastIdx] = lastRun; // Clone remaining nodes  for (HashEntry\u0026lt;K,V\u0026gt; p = e; p != lastRun; p = p.next) { // 遍历剩余元素，头插法到指定 k 位置。  V v = p.value; int h = p.hash; int k = h \u0026amp; sizeMask; HashEntry\u0026lt;K,V\u0026gt; n = newTable[k]; newTable[k] = new HashEntry\u0026lt;K,V\u0026gt;(h, p.key, v, n); } } } } // 头插法插入新的节点  int nodeIndex = node.hash \u0026amp; sizeMask; // add the new node  node.setNext(newTable[nodeIndex]); newTable[nodeIndex] = node; table = newTable; }   有些同学可能会对最后的两个 for 循环有疑惑，这里第一个 for 是为了寻找这样一个节点，这个节点后面的所有 next 节点的新位置都是相同的。然后把这个作为一个链表赋值到新位置。第二个 for 循环是为了把剩余的元素通过头插法插入到指定位置链表。这样实现的原因可能是基于概率统计，有深入研究的同学可以发表下意见。\nget 到这里就很简单了，get 方法只需要两步即可。\n 计算得到 key 的存放位置。 遍历指定位置查找相同 key 的 value 值。  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  public V get(Object key) { Segment\u0026lt;K,V\u0026gt; s; // manually integrate access methods to reduce overhead  HashEntry\u0026lt;K,V\u0026gt;[] tab; int h = hash(key); long u = (((h \u0026gt;\u0026gt;\u0026gt; segmentShift) \u0026amp; segmentMask) \u0026lt;\u0026lt; SSHIFT) + SBASE; // 计算得到 key 的存放位置  if ((s = (Segment\u0026lt;K,V\u0026gt;)UNSAFE.getObjectVolatile(segments, u)) != null \u0026amp;\u0026amp; (tab = s.table) != null) { for (HashEntry\u0026lt;K,V\u0026gt; e = (HashEntry\u0026lt;K,V\u0026gt;) UNSAFE.getObjectVolatile (tab, ((long)(((tab.length - 1) \u0026amp; h)) \u0026lt;\u0026lt; TSHIFT) + TBASE); e != null; e = e.next) { // 如果是链表，遍历查找到相同 key 的 value。  K k; if ((k = e.key) == key || (e.hash == h \u0026amp;\u0026amp; key.equals(k))) return e.value; } } return null; }   ConcurrentHashMap 1.8 存储结构 可以发现 Java8 的 ConcurrentHashMap 相对于 Java7 来说变化比较大，不再是之前的 Segment 数组 + HashEntry 数组 + 链表，而是 Node 数组 + 链表 / 红黑树。当冲突链表达到一定长度时，链表会转换成红黑树。\n初始化 initTable 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  /** * Initializes table, using the size recorded in sizeCtl. */ private final Node\u0026lt;K,V\u0026gt;[] initTable() { Node\u0026lt;K,V\u0026gt;[] tab; int sc; while ((tab = table) == null || tab.length == 0) { ／／　如果 sizeCtl \u0026lt; 0 ,说明另外的线程执行CAS 成功，正在进行初始化。 if ((sc = sizeCtl) \u0026lt; 0) // 让出 CPU 使用权  Thread.yield(); // lost initialization race; just spin  else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) { try { if ((tab = table) == null || tab.length == 0) { int n = (sc \u0026gt; 0) ? sc : DEFAULT_CAPACITY; @SuppressWarnings(\u0026#34;unchecked\u0026#34;) Node\u0026lt;K,V\u0026gt;[] nt = (Node\u0026lt;K,V\u0026gt;[])new Node\u0026lt;?,?\u0026gt;[n]; table = tab = nt; sc = n - (n \u0026gt;\u0026gt;\u0026gt; 2); } } finally { sizeCtl = sc; } break; } } return tab; }   从源码中可以发现 ConcurrentHashMap 的初始化是通过自旋和 CAS 操作完成的。里面需要注意的是变量 sizeCtl ，它的值决定着当前的初始化状态。\n -1 说明正在初始化 -N 说明有N-1个线程正在进行扩容 表示 table 初始化大小，如果 table 没有初始化 表示 table 容量，如果 table　已经初始化。  put 直接过一遍 put 源码。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75  public V put(K key, V value) { return putVal(key, value, false); } /** Implementation for put and putIfAbsent */ final V putVal(K key, V value, boolean onlyIfAbsent) { // key 和 value 不能为空  if (key == null || value == null) throw new NullPointerException(); int hash = spread(key.hashCode()); int binCount = 0; for (Node\u0026lt;K,V\u0026gt;[] tab = table;;) { // f = 目标位置元素  Node\u0026lt;K,V\u0026gt; f; int n, i, fh;// fh 后面存放目标位置的元素 hash 值  if (tab == null || (n = tab.length) == 0) // 数组桶为空，初始化数组桶（自旋+CAS)  tab = initTable(); else if ((f = tabAt(tab, i = (n - 1) \u0026amp; hash)) == null) { // 桶内为空，CAS 放入，不加锁，成功了就直接 break 跳出  if (casTabAt(tab, i, null,new Node\u0026lt;K,V\u0026gt;(hash, key, value, null))) break; // no lock when adding to empty bin  } else if ((fh = f.hash) == MOVED) tab = helpTransfer(tab, f); else { V oldVal = null; // 使用 synchronized 加锁加入节点  synchronized (f) { if (tabAt(tab, i) == f) { // 说明是链表  if (fh \u0026gt;= 0) { binCount = 1; // 循环加入新的或者覆盖节点  for (Node\u0026lt;K,V\u0026gt; e = f;; ++binCount) { K ek; if (e.hash == hash \u0026amp;\u0026amp; ((ek = e.key) == key || (ek != null \u0026amp;\u0026amp; key.equals(ek)))) { oldVal = e.val; if (!onlyIfAbsent) e.val = value; break; } Node\u0026lt;K,V\u0026gt; pred = e; if ((e = e.next) == null) { pred.next = new Node\u0026lt;K,V\u0026gt;(hash, key, value, null); break; } } } else if (f instanceof TreeBin) { // 红黑树  Node\u0026lt;K,V\u0026gt; p; binCount = 2; if ((p = ((TreeBin\u0026lt;K,V\u0026gt;)f).putTreeVal(hash, key, value)) != null) { oldVal = p.val; if (!onlyIfAbsent) p.val = value; } } } } if (binCount != 0) { if (binCount \u0026gt;= TREEIFY_THRESHOLD) treeifyBin(tab, i); if (oldVal != null) return oldVal; break; } } } addCount(1L, binCount); return null; }    根据 key 计算出 hashcode 。 判断是否需要进行初始化。 即为当前 key 定位出的 Node，如果为空表示当前位置可以写入数据，利用 CAS 尝试写入，失败则自旋保证成功。 如果当前位置的 hashcode == MOVED == -1,则需要进行扩容。 如果都不满足，则利用 synchronized 锁写入数据。 如果数量大于 TREEIFY_THRESHOLD 则要转换为红黑树。  get get 流程比较简单，直接过一遍源码。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  public V get(Object key) { Node\u0026lt;K,V\u0026gt;[] tab; Node\u0026lt;K,V\u0026gt; e, p; int n, eh; K ek; // key 所在的 hash 位置  int h = spread(key.hashCode()); if ((tab = table) != null \u0026amp;\u0026amp; (n = tab.length) \u0026gt; 0 \u0026amp;\u0026amp; (e = tabAt(tab, (n - 1) \u0026amp; h)) != null) { // 如果指定位置元素存在，头结点hash值相同  if ((eh = e.hash) == h) { if ((ek = e.key) == key || (ek != null \u0026amp;\u0026amp; key.equals(ek))) // key hash 值相等，key值相同，直接返回元素 value  return e.val; } else if (eh \u0026lt; 0) // 头结点hash值小于0，说明正在扩容或者是红黑树，find查找  return (p = e.find(h, key)) != null ? p.val : null; while ((e = e.next) != null) { // 是链表，遍历查找  if (e.hash == h \u0026amp;\u0026amp; ((ek = e.key) == key || (ek != null \u0026amp;\u0026amp; key.equals(ek)))) return e.val; } } return null; }   总结一下 get 过程：\n 根据 hash 值计算位置。 查找到指定位置，如果头节点就是要找的，直接返回它的 value. 如果头节点 hash 值小于 0 ，说明正在扩容或者是红黑树，查找之。 如果是链表，遍历查找之。  总结：\n总的来说 ConcurrentHashMap 在 Java8 中相对于 Java7 来说变化还是挺大的，\n总结 Java7 中 ConcurrentHashMap 使用的分段锁，也就是每一个 Segment 上同时只有一个线程可以操作，每一个 Segment 都是一个类似 HashMap 数组的结构，它可以扩容，它的冲突会转化为链表。但是 Segment 的个数一但初始化就不能改变。\nJava8 中的 ConcurrentHashMap 使用的 Synchronized 锁加 CAS 的机制。结构也由 Java7 中的 Segment 数组 + HashEntry 数组 + 链表 进化成了 Node 数组 + 链表 / 红黑树，Node 是类似于一个 HashEntry 的结构。它的冲突再达到一定大小时会转化成红黑树，在冲突小于一定数量时又退回链表。\n有些同学可能对 Synchronized 的性能存在疑问，其实 Synchronized 锁自从引入锁升级策略后，性能不再是问题，有兴趣的同学可以自己了解下 Synchronized 的锁升级。\n","date":"2021-04-28T13:36:41Z","image":"https://ahao.ink/7.jpg","permalink":"https://ahao.ink/posts/concurrenthashmap%E6%BA%90%E7%A0%81-%E5%BA%95%E5%B1%82%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90/","title":"ConcurrentHashMap源码+底层数据结构分析"},{"content":"HashMap 简介 HashMap 主要用来存放键值对，它基于哈希表的 Map 接口实现，是常用的 Java 集合之一，是非线程安全的。\nHashMap 可以存储 null 的 key 和 value，但 null 作为键只能有一个，null 作为值可以有多个\nJDK1.8 之前 HashMap 由 数组+链表 组成的，数组是 HashMap 的主体，链表则是主要为了解决哈希冲突而存在的（“拉链法”解决冲突）。 JDK1.8 以后的 HashMap 在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为 8）（将链表转换成红黑树前会判断，如果当前数组的长度小于 64，那么会选择先进行数组扩容，而不是转换为红黑树）时，将链表转化为红黑树，以减少搜索时间。\nHashMap 默认的初始化大小为 16。之后每次扩充，容量变为原来的 2 倍。并且， HashMap 总是使用 2 的幂作为哈希表的大小。\n底层数据结构分析 DK1.8 之前 JDK1.8 之前 HashMap 底层是 数组和链表 结合在一起使用也就是 链表散列。\nHashMap 通过 key 的 hashCode 经过扰动函数处理过后得到 hash 值，然后通过 (n - 1) \u0026amp; hash 判断当前元素存放的位置（这里的 n 指的是数组的长度），如果当前位置存在元素的话，就判断该元素与要存入的元素的 hash 值以及 key 是否相同，如果相同的话，直接覆盖，不相同就通过拉链法解决冲突。\n所谓扰动函数指的就是 HashMap 的 hash 方法。使用 hash 方法也就是扰动函数是为了防止一些实现比较差的 hashCode() 方法 换句话说使用扰动函数之后可以减少碰撞。\nJDK 1.8 HashMap 的 hash 方法源码:\nJDK 1.8 的 hash 方法 相比于 JDK 1.7 hash 方法更加简化，但是原理不变。\n1 2 3 4 5 6 7  static final int hash(Object key) { int h; // key.hashCode()：返回散列值也就是hashcode  // ^ ：按位异或  // \u0026gt;\u0026gt;\u0026gt;:无符号右移，忽略符号位，空位都以0补齐  return (key == null) ? 0 : (h = key.hashCode()) ^ (h \u0026gt;\u0026gt;\u0026gt; 16); }   对比一下 JDK1.7 的 HashMap 的 hash 方法源码.\n1 2 3 4 5 6 7 8  static int hash(int h) { // This function ensures that hashCodes that differ only by  // constant multiples at each bit position have a bounded  // number of collisions (approximately 8 at default load factor).  h ^= (h \u0026gt;\u0026gt;\u0026gt; 20) ^ (h \u0026gt;\u0026gt;\u0026gt; 12); return h ^ (h \u0026gt;\u0026gt;\u0026gt; 7) ^ (h \u0026gt;\u0026gt;\u0026gt; 4); }   相比于 JDK1.8 的 hash 方法 ，JDK 1.7 的 hash 方法的性能会稍差一点点，因为毕竟扰动了 4 次。\n所谓 “拉链法” 就是：将链表和数组相结合。也就是说创建一个链表数组，数组中每一格就是一个链表。若遇到哈希冲突，则将冲突的值加到链表中即可。\nJDK1.8 之后 相比于之前的版本，JDK1.8 以后在解决哈希冲突时有了较大的变化。\n当链表长度大于阈值（默认为 8）时，会首先调用 treeifyBin()方法。这个方法会根据 HashMap 数组来决定是否转换为红黑树。只有当数组长度大于或者等于 64 的情况下，才会执行转换红黑树操作，以减少搜索时间。否则，就是只是执行 resize() 方法对数组扩容。相关源码这里就不贴了，重点关注 treeifyBin()方法即可！\n类的属性：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  public class HashMap\u0026lt;K,V\u0026gt; extends AbstractMap\u0026lt;K,V\u0026gt; implements Map\u0026lt;K,V\u0026gt;, Cloneable, Serializable { // 序列号  private static final long serialVersionUID = 362498820763181265L; // 默认的初始容量是16  static final int DEFAULT_INITIAL_CAPACITY = 1 \u0026lt;\u0026lt; 4; // 最大容量  static final int MAXIMUM_CAPACITY = 1 \u0026lt;\u0026lt; 30; // 默认的填充因子  static final float DEFAULT_LOAD_FACTOR = 0.75f; // 当桶(bucket)上的结点数大于这个值时会转成红黑树  static final int TREEIFY_THRESHOLD = 8; // 当桶(bucket)上的结点数小于这个值时树转链表  static final int UNTREEIFY_THRESHOLD = 6; // 桶中结构转化为红黑树对应的table的最小大小  static final int MIN_TREEIFY_CAPACITY = 64; // 存储元素的数组，总是2的幂次倍  transient Node\u0026lt;k,v\u0026gt;[] table; // 存放具体元素的集  transient Set\u0026lt;map.entry\u0026lt;k,v\u0026gt;\u0026gt; entrySet; // 存放元素的个数，注意这个不等于数组的长度。  transient int size; // 每次扩容和更改map结构的计数器  transient int modCount; // 临界值 当实际大小(容量*填充因子)超过临界值时，会进行扩容  int threshold; // 加载因子  final float loadFactor; }     loadFactor 加载因子\nloadFactor 加载因子是控制数组存放数据的疏密程度，loadFactor 越趋近于 1，那么 数组中存放的数据(entry)也就越多，也就越密，也就是会让链表的长度增加，loadFactor 越小，也就是趋近于 0，数组中存放的数据(entry)也就越少，也就越稀疏。\nloadFactor 太大导致查找元素效率低，太小导致数组的利用率低，存放的数据会很分散。loadFactor 的默认值为 0.75f 是官方给出的一个比较好的临界值。\n给定的默认容量为 16，负载因子为 0.75。Map 在使用过程中不断的往里面存放数据，当数量达到了 16 * 0.75 = 12 就需要将当前 16 的容量进行扩容，而扩容这个过程涉及到 rehash、复制数据等操作，所以非常消耗性能。\n  threshold\nthreshold = capacity * loadFactor，当 Size\u0026gt;=threshold的时候，那么就要考虑对数组的扩增了，也就是说，这个的意思就是 衡量数组是否需要扩增的一个标准。\n  Node 节点类源码:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39  // 继承自 Map.Entry\u0026lt;K,V\u0026gt; static class Node\u0026lt;K,V\u0026gt; implements Map.Entry\u0026lt;K,V\u0026gt; { final int hash;// 哈希值，存放元素到hashmap中时用来与其他元素hash值比较  final K key;//键  V value;//值  // 指向下一个节点  Node\u0026lt;K,V\u0026gt; next; Node(int hash, K key, V value, Node\u0026lt;K,V\u0026gt; next) { this.hash = hash; this.key = key; this.value = value; this.next = next; } public final K getKey() { return key; } public final V getValue() { return value; } public final String toString() { return key + \u0026#34;=\u0026#34; + value; } // 重写hashCode()方法  public final int hashCode() { return Objects.hashCode(key) ^ Objects.hashCode(value); } public final V setValue(V newValue) { V oldValue = value; value = newValue; return oldValue; } // 重写 equals() 方法  public final boolean equals(Object o) { if (o == this) return true; if (o instanceof Map.Entry) { Map.Entry\u0026lt;?,?\u0026gt; e = (Map.Entry\u0026lt;?,?\u0026gt;)o; if (Objects.equals(key, e.getKey()) \u0026amp;\u0026amp; Objects.equals(value, e.getValue())) return true; } return false; } }   树节点类源码:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  static final class TreeNode\u0026lt;K,V\u0026gt; extends LinkedHashMap.Entry\u0026lt;K,V\u0026gt; { TreeNode\u0026lt;K,V\u0026gt; parent; // 父  TreeNode\u0026lt;K,V\u0026gt; left; // 左  TreeNode\u0026lt;K,V\u0026gt; right; // 右  TreeNode\u0026lt;K,V\u0026gt; prev; // needed to unlink next upon deletion  boolean red; // 判断颜色  TreeNode(int hash, K key, V val, Node\u0026lt;K,V\u0026gt; next) { super(hash, key, val, next); } // 返回根节点  final TreeNode\u0026lt;K,V\u0026gt; root() { for (TreeNode\u0026lt;K,V\u0026gt; r = this, p;;) { if ((p = r.parent) == null) return r; r = p; }   HashMap 源码分析 构造方法 HashMap 中有四个构造方法，它们分别如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  // 默认构造函数。  public HashMap() { this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted  } // 包含另一个“Map”的构造函数  public HashMap(Map\u0026lt;? extends K, ? extends V\u0026gt; m) { this.loadFactor = DEFAULT_LOAD_FACTOR; putMapEntries(m, false);//下面会分析到这个方法  } // 指定“容量大小”的构造函数  public HashMap(int initialCapacity) { this(initialCapacity, DEFAULT_LOAD_FACTOR); } // 指定“容量大小”和“加载因子”的构造函数  public HashMap(int initialCapacity, float loadFactor) { if (initialCapacity \u0026lt; 0) throw new IllegalArgumentException(\u0026#34;Illegal initial capacity: \u0026#34; + initialCapacity); if (initialCapacity \u0026gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor \u0026lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(\u0026#34;Illegal load factor: \u0026#34; + loadFactor); this.loadFactor = loadFactor; this.threshold = tableSizeFor(initialCapacity); }   putMapEntries 方法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  final void putMapEntries(Map\u0026lt;? extends K, ? extends V\u0026gt; m, boolean evict) { int s = m.size(); if (s \u0026gt; 0) { // 判断table是否已经初始化  if (table == null) { // pre-size  // 未初始化，s为m的实际元素个数  float ft = ((float)s / loadFactor) + 1.0F; int t = ((ft \u0026lt; (float)MAXIMUM_CAPACITY) ? (int)ft : MAXIMUM_CAPACITY); // 计算得到的t大于阈值，则初始化阈值  if (t \u0026gt; threshold) threshold = tableSizeFor(t); } // 已初始化，并且m元素个数大于阈值，进行扩容处理  else if (s \u0026gt; threshold) resize(); // 将m中的所有元素添加至HashMap中  for (Map.Entry\u0026lt;? extends K, ? extends V\u0026gt; e : m.entrySet()) { K key = e.getKey(); V value = e.getValue(); putVal(hash(key), key, value, false, evict); } } }   put 方法 HashMap 只提供了 put 用于添加元素，putVal 方法只是给 put 方法调用的一个方法，并没有提供给用户使用。\n对 putVal 方法添加元素的分析如下：\n 如果定位到的数组位置没有元素 就直接插入。 如果定位到的数组位置有元素就和要插入的 key 比较，如果 key 相同就直接覆盖，如果 key 不相同，就判断 p 是否是一个树节点，如果是就调用e = ((TreeNode\u0026lt;K,V\u0026gt;)p).putTreeVal(this, tab, hash, key, value)将元素添加进入。如果不是就遍历链表插入(插入的是链表尾部)。  说明:上图有两个小问题：\n 直接覆盖之后应该就会 return，不会有后续操作。参考 JDK8 HashMap.java 658 行（issue#608  \n(opens new window)）。\n当链表长度大于阈值（默认为 8）并且 HashMap 数组长度超过 64 的时候才会执行链表转红黑树的操作，否则就只是对数组扩容。参考 HashMap 的 treeifyBin() 方法（issue#1087\n(opens new window)）。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73  public V put(K key, V value) { return putVal(hash(key), key, value, false, true); } final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) { Node\u0026lt;K,V\u0026gt;[] tab; Node\u0026lt;K,V\u0026gt; p; int n, i; // table未初始化或者长度为0，进行扩容  if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; // (n - 1) \u0026amp; hash 确定元素存放在哪个桶中，桶为空，新生成结点放入桶中(此时，这个结点是放在数组中)  if ((p = tab[i = (n - 1) \u0026amp; hash]) == null) tab[i] = newNode(hash, key, value, null); // 桶中已经存在元素  else { Node\u0026lt;K,V\u0026gt; e; K k; // 比较桶中第一个元素(数组中的结点)的hash值相等，key相等  if (p.hash == hash \u0026amp;\u0026amp; ((k = p.key) == key || (key != null \u0026amp;\u0026amp; key.equals(k)))) // 将第一个元素赋值给e，用e来记录  e = p; // hash值不相等，即key不相等；为红黑树结点  else if (p instanceof TreeNode) // 放入树中  e = ((TreeNode\u0026lt;K,V\u0026gt;)p).putTreeVal(this, tab, hash, key, value); // 为链表结点  else { // 在链表最末插入结点  for (int binCount = 0; ; ++binCount) { // 到达链表的尾部  if ((e = p.next) == null) { // 在尾部插入新结点  p.next = newNode(hash, key, value, null); // 结点数量达到阈值(默认为 8 )，执行 treeifyBin 方法  // 这个方法会根据 HashMap 数组来决定是否转换为红黑树。  // 只有当数组长度大于或者等于 64 的情况下，才会执行转换红黑树操作，以减少搜索时间。否则，就是只是对数组扩容。  if (binCount \u0026gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st  treeifyBin(tab, hash); // 跳出循环  break; } // 判断链表中结点的key值与插入的元素的key值是否相等  if (e.hash == hash \u0026amp;\u0026amp; ((k = e.key) == key || (key != null \u0026amp;\u0026amp; key.equals(k)))) // 相等，跳出循环  break; // 用于遍历桶中的链表，与前面的e = p.next组合，可以遍历链表  p = e; } } // 表示在桶中找到key值、hash值与插入元素相等的结点  if (e != null) { // 记录e的value  V oldValue = e.value; // onlyIfAbsent为false或者旧值为null  if (!onlyIfAbsent || oldValue == null) //用新值替换旧值  e.value = value; // 访问后回调  afterNodeAccess(e); // 返回旧值  return oldValue; } } // 结构性修改  ++modCount; // 实际大小大于阈值则扩容  if (++size \u0026gt; threshold) resize(); // 插入后回调  afterNodeInsertion(evict); return null; }   我们再来对比一下 JDK1.7 put 方法的代码\n对于 put 方法的分析如下：\n ① 如果定位到的数组位置没有元素 就直接插入。 ② 如果定位到的数组位置有元素，遍历以这个元素为头结点的链表，依次和插入的 key 比较，如果 key 相同就直接覆盖，不同就采用头插法插入元素。  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  public V put(K key, V value) if (table == EMPTY_TABLE) { inflateTable(threshold); } if (key == null) return putForNullKey(value); int hash = hash(key); int i = indexFor(hash, table.length); for (Entry\u0026lt;K,V\u0026gt; e = table[i]; e != null; e = e.next) { // 先遍历  Object k; if (e.hash == hash \u0026amp;\u0026amp; ((k = e.key) == key || key.equals(k))) { V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; } } modCount++; addEntry(hash, key, value, i); // 再插入  return null; }   get 方法 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  public V get(Object key) { Node\u0026lt;K,V\u0026gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value; } final Node\u0026lt;K,V\u0026gt; getNode(int hash, Object key) { Node\u0026lt;K,V\u0026gt;[] tab; Node\u0026lt;K,V\u0026gt; first, e; int n; K k; if ((tab = table) != null \u0026amp;\u0026amp; (n = tab.length) \u0026gt; 0 \u0026amp;\u0026amp; (first = tab[(n - 1) \u0026amp; hash]) != null) { // 数组元素相等  if (first.hash == hash \u0026amp;\u0026amp; // always check first node  ((k = first.key) == key || (key != null \u0026amp;\u0026amp; key.equals(k)))) return first; // 桶中不止一个节点  if ((e = first.next) != null) { // 在树中get  if (first instanceof TreeNode) return ((TreeNode\u0026lt;K,V\u0026gt;)first).getTreeNode(hash, key); // 在链表中get  do { if (e.hash == hash \u0026amp;\u0026amp; ((k = e.key) == key || (key != null \u0026amp;\u0026amp; key.equals(k)))) return e; } while ((e = e.next) != null); } } return null; }   resize 方法 进行扩容，会伴随着一次重新 hash 分配，并且会遍历 hash 表中所有的元素，是非常耗时的。在编写程序中，要尽量避免 resize。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80  final Node\u0026lt;K,V\u0026gt;[] resize() { Node\u0026lt;K,V\u0026gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap \u0026gt; 0) { // 超过最大值就不再扩充了，就只好随你碰撞去吧  if (oldCap \u0026gt;= MAXIMUM_CAPACITY) { threshold = Integer.MAX_VALUE; return oldTab; } // 没超过最大值，就扩充为原来的2倍  else if ((newCap = oldCap \u0026lt;\u0026lt; 1) \u0026lt; MAXIMUM_CAPACITY \u0026amp;\u0026amp; oldCap \u0026gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr \u0026lt;\u0026lt; 1; // double threshold  } else if (oldThr \u0026gt; 0) // initial capacity was placed in threshold  newCap = oldThr; else { // signifies using defaults  newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); } // 计算新的resize上限  if (newThr == 0) { float ft = (float)newCap * loadFactor; newThr = (newCap \u0026lt; MAXIMUM_CAPACITY \u0026amp;\u0026amp; ft \u0026lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); } threshold = newThr; @SuppressWarnings({\u0026#34;rawtypes\u0026#34;,\u0026#34;unchecked\u0026#34;}) Node\u0026lt;K,V\u0026gt;[] newTab = (Node\u0026lt;K,V\u0026gt;[])new Node[newCap]; table = newTab; if (oldTab != null) { // 把每个bucket都移动到新的buckets中  for (int j = 0; j \u0026lt; oldCap; ++j) { Node\u0026lt;K,V\u0026gt; e; if ((e = oldTab[j]) != null) { oldTab[j] = null; if (e.next == null) newTab[e.hash \u0026amp; (newCap - 1)] = e; else if (e instanceof TreeNode) ((TreeNode\u0026lt;K,V\u0026gt;)e).split(this, newTab, j, oldCap); else { Node\u0026lt;K,V\u0026gt; loHead = null, loTail = null; Node\u0026lt;K,V\u0026gt; hiHead = null, hiTail = null; Node\u0026lt;K,V\u0026gt; next; do { next = e.next; // 原索引  if ((e.hash \u0026amp; oldCap) == 0) { if (loTail == null) loHead = e; else loTail.next = e; loTail = e; } // 原索引+oldCap  else { if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; } } while ((e = next) != null); // 原索引放到bucket里  if (loTail != null) { loTail.next = null; newTab[j] = loHead; } // 原索引+oldCap放到bucket里  if (hiTail != null) { hiTail.next = null; newTab[j + oldCap] = hiHead; } } } } } return newTab; }   HashMap 常用方法测试 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71  package map; import java.util.Collection; import java.util.HashMap; import java.util.Set; public class HashMapDemo { public static void main(String[] args) { HashMap\u0026lt;String, String\u0026gt; map = new HashMap\u0026lt;String, String\u0026gt;(); // 键不能重复，值可以重复  map.put(\u0026#34;san\u0026#34;, \u0026#34;张三\u0026#34;); map.put(\u0026#34;si\u0026#34;, \u0026#34;李四\u0026#34;); map.put(\u0026#34;wu\u0026#34;, \u0026#34;王五\u0026#34;); map.put(\u0026#34;wang\u0026#34;, \u0026#34;老王\u0026#34;); map.put(\u0026#34;wang\u0026#34;, \u0026#34;老王2\u0026#34;);// 老王被覆盖  map.put(\u0026#34;lao\u0026#34;, \u0026#34;老王\u0026#34;); System.out.println(\u0026#34;-------直接输出hashmap:-------\u0026#34;); System.out.println(map); /** * 遍历HashMap */ // 1.获取Map中的所有键  System.out.println(\u0026#34;-------foreach获取Map中所有的键:------\u0026#34;); Set\u0026lt;String\u0026gt; keys = map.keySet(); for (String key : keys) { System.out.print(key+\u0026#34; \u0026#34;); } System.out.println();//换行  // 2.获取Map中所有值  System.out.println(\u0026#34;-------foreach获取Map中所有的值:------\u0026#34;); Collection\u0026lt;String\u0026gt; values = map.values(); for (String value : values) { System.out.print(value+\u0026#34; \u0026#34;); } System.out.println();//换行  // 3.得到key的值的同时得到key所对应的值  System.out.println(\u0026#34;-------得到key的值的同时得到key所对应的值:-------\u0026#34;); Set\u0026lt;String\u0026gt; keys2 = map.keySet(); for (String key : keys2) { System.out.print(key + \u0026#34;：\u0026#34; + map.get(key)+\u0026#34; \u0026#34;); } /** * 如果既要遍历key又要value，那么建议这种方式，因为如果先获取keySet然后再执行map.get(key)，map内部会执行两次遍历。 * 一次是在获取keySet的时候，一次是在遍历所有key的时候。 */ // 当我调用put(key,value)方法的时候，首先会把key和value封装到  // Entry这个静态内部类对象中，把Entry对象再添加到数组中，所以我们想获取  // map中的所有键值对，我们只要获取数组中的所有Entry对象，接下来  // 调用Entry对象中的getKey()和getValue()方法就能获取键值对了  Set\u0026lt;java.util.Map.Entry\u0026lt;String, String\u0026gt;\u0026gt; entrys = map.entrySet(); for (java.util.Map.Entry\u0026lt;String, String\u0026gt; entry : entrys) { System.out.println(entry.getKey() + \u0026#34;--\u0026#34; + entry.getValue()); } /** * HashMap其他常用方法 */ System.out.println(\u0026#34;after map.size()：\u0026#34;+map.size()); System.out.println(\u0026#34;after map.isEmpty()：\u0026#34;+map.isEmpty()); System.out.println(map.remove(\u0026#34;san\u0026#34;)); System.out.println(\u0026#34;after map.remove()：\u0026#34;+map); System.out.println(\u0026#34;after map.get(si)：\u0026#34;+map.get(\u0026#34;si\u0026#34;)); System.out.println(\u0026#34;after map.containsKey(si)：\u0026#34;+map.containsKey(\u0026#34;si\u0026#34;)); System.out.println(\u0026#34;after containsValue(李四)：\u0026#34;+map.containsValue(\u0026#34;李四\u0026#34;)); System.out.println(map.replace(\u0026#34;si\u0026#34;, \u0026#34;李四2\u0026#34;)); System.out.println(\u0026#34;after map.replace(si, 李四2):\u0026#34;+map); } }   ","date":"2021-04-19T13:36:41Z","image":"https://ahao.ink/9.jpg","permalink":"https://ahao.ink/posts/hashmap%E6%BA%90%E7%A0%81-%E5%BA%95%E5%B1%82%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90/","title":"HashMap源码+底层数据结构分析"},{"content":"ArrayList源码+扩容机制分析 ArrayList 简介 ArrayList 的底层是数组队列，相当于动态数组。与 Java 中的数组相比，它的容量能动态增长。在添加大量元素前，应用程序可以使用ensureCapacity操作来增加 ArrayList 实例的容量。这可以减少递增式再分配的数量。\nArrayList继承于 AbstractList ，实现了 List, RandomAccess, Cloneable, java.io.Serializable 这些接口。\n1 2 3 4  public class ArrayList\u0026lt;E\u0026gt; extends AbstractList\u0026lt;E\u0026gt; implements List\u0026lt;E\u0026gt;, RandomAccess, Cloneable, java.io.Serializable{ }    RandomAccess 是一个标志接口，表明实现这个这个接口的 List 集合是支持快速随机访问的。在 ArrayList 中，我们即可以通过元素的序号快速获取元素对象，这就是快速随机访问。 ArrayList 实现了 Cloneable 接口 ，即覆盖了函数clone()，能被克隆。 ArrayList 实现了 java.io.Serializable接口，这意味着ArrayList支持序列化，能通过序列化去传输。  Arraylist 和 Vector 的区别?  ArrayList 是 List 的主要实现类，底层使用 Object[ ]存储，适用于频繁的查找工作，线程不安全 ； Vector 是 List 的古老实现类，底层使用 Object[ ]存储，线程安全的。  Arraylist 与 LinkedList 区别?  是否保证线程安全： ArrayList 和 LinkedList 都是不同步的，也就是不保证线程安全； 底层数据结构： Arraylist 底层使用的是 Object 数组；LinkedList 底层使用的是 双向链表 数据结构（JDK1.6 之前为循环链表，JDK1.7 取消了循环。注意双向链表和双向循环链表的区别，下面有介绍到！） 插入和删除是否受元素位置的影响： ① ArrayList 采用数组存储，所以插入和删除元素的时间复杂度受元素位置的影响。 比如：执行add(E e)方法的时候， ArrayList 会默认在将指定的元素追加到此列表的末尾，这种情况时间复杂度就是 O(1)。但是如果要在指定位置 i 插入和删除元素的话（add(int index, E element)）时间复杂度就为 O(n-i)。因为在进行上述操作的时候集合中第 i 和第 i 个元素之后的(n-i)个元素都要执行向后位/向前移一位的操作。 ② LinkedList 采用链表存储，所以对于add(E e)方法的插入，删除元素时间复杂度不受元素位置的影响，近似 O(1)，如果是要在指定位置i插入和删除元素的话（(add(int index, E element)） 时间复杂度近似为o(n))因为需要先移动到指定位置再插入。 是否支持快速随机访问： LinkedList 不支持高效的随机元素访问，而 ArrayList 支持。快速随机访问就是通过元素的序号快速获取元素对象(对应于get(int index)方法)。 内存空间占用： ArrayList 的空间浪费主要体现在在 list 列表的结尾会预留一定的容量空间，而 LinkedList 的空间花费则体现在它的每一个元素都需要消耗比 ArrayList 更多的空间（因为要存放直接后继和直接前驱以及数据）。  ArrayList 核心源码解读 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502  package java.util; import java.util.function.Consumer; import java.util.function.Predicate; import java.util.function.UnaryOperator; public class ArrayList\u0026lt;E\u0026gt; extends AbstractList\u0026lt;E\u0026gt; implements List\u0026lt;E\u0026gt;, RandomAccess, Cloneable, java.io.Serializable { private static final long serialVersionUID = 8683452581122892189L; /** * 默认初始容量大小 */ private static final int DEFAULT_CAPACITY = 10; /** * 空数组（用于空实例）。 */ private static final Object[] EMPTY_ELEMENTDATA = {}; //用于默认大小空实例的共享空数组实例。  //我们把它从EMPTY_ELEMENTDATA数组中区分出来，以知道在添加第一个元素时容量需要增加多少。  private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = {}; /** * 保存ArrayList数据的数组 */ transient Object[] elementData; // non-private to simplify nested class access  /** * ArrayList 所包含的元素个数 */ private int size; /** * 带初始容量参数的构造函数（用户可以在创建ArrayList对象时自己指定集合的初始大小） */ public ArrayList(int initialCapacity) { if (initialCapacity \u0026gt; 0) { //如果传入的参数大于0，创建initialCapacity大小的数组  this.elementData = new Object[initialCapacity]; } else if (initialCapacity == 0) { //如果传入的参数等于0，创建空数组  this.elementData = EMPTY_ELEMENTDATA; } else { //其他情况，抛出异常  throw new IllegalArgumentException(\u0026#34;Illegal Capacity: \u0026#34;+ initialCapacity); } } /** *默认无参构造函数 *DEFAULTCAPACITY_EMPTY_ELEMENTDATA 为0.初始化为10， 也就是说初始其实是空数组 当添加第一个元素的时候数组容量才变成10 */ public ArrayList() { this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA; } /** * 构造一个包含指定集合的元素的列表，按照它们由集合的迭代器返回的顺序。 */ public ArrayList(Collection\u0026lt;? extends E\u0026gt; c) { //将指定集合转换为数组  elementData = c.toArray(); //如果elementData数组的长度不为0  if ((size = elementData.length) != 0) { // 如果elementData不是Object类型数据（c.toArray可能返回的不是Object类型的数组所以加上下面的语句用于判断）  if (elementData.getClass() != Object[].class) //将原来不是Object类型的elementData数组的内容，赋值给新的Object类型的elementData数组  elementData = Arrays.copyOf(elementData, size, Object[].class); } else { // 其他情况，用空数组代替  this.elementData = EMPTY_ELEMENTDATA; } } /** * 修改这个ArrayList实例的容量是列表的当前大小。 应用程序可以使用此操作来最小化ArrayList实例的存储。 */ public void trimToSize() { modCount++; if (size \u0026lt; elementData.length) { elementData = (size == 0) ? EMPTY_ELEMENTDATA : Arrays.copyOf(elementData, size); } } //下面是ArrayList的扩容机制 //ArrayList的扩容机制提高了性能，如果每次只扩充一个， //那么频繁的插入会导致频繁的拷贝，降低性能，而ArrayList的扩容机制避免了这种情况。  /** * 如有必要，增加此ArrayList实例的容量，以确保它至少能容纳元素的数量 * @param minCapacity 所需的最小容量 */ public void ensureCapacity(int minCapacity) { //如果是true，minExpand的值为0，如果是false,minExpand的值为10  int minExpand = (elementData != DEFAULTCAPACITY_EMPTY_ELEMENTDATA) // any size if not default element table  ? 0 // larger than default for default empty table. It\u0026#39;s already  // supposed to be at default size.  : DEFAULT_CAPACITY; //如果最小容量大于已有的最大容量  if (minCapacity \u0026gt; minExpand) { ensureExplicitCapacity(minCapacity); } } //得到最小扩容量  private void ensureCapacityInternal(int minCapacity) { if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) { // 获取“默认的容量”和“传入参数”两者之间的最大值  minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity); } ensureExplicitCapacity(minCapacity); } //判断是否需要扩容  private void ensureExplicitCapacity(int minCapacity) { modCount++; // overflow-conscious code  if (minCapacity - elementData.length \u0026gt; 0) //调用grow方法进行扩容，调用此方法代表已经开始扩容了  grow(minCapacity); } /** * 要分配的最大数组大小 */ private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8; /** * ArrayList扩容的核心方法。 */ private void grow(int minCapacity) { // oldCapacity为旧容量，newCapacity为新容量  int oldCapacity = elementData.length; //将oldCapacity 右移一位，其效果相当于oldCapacity /2，  //我们知道位运算的速度远远快于整除运算，整句运算式的结果就是将新容量更新为旧容量的1.5倍，  int newCapacity = oldCapacity + (oldCapacity \u0026gt;\u0026gt; 1); //然后检查新容量是否大于最小需要容量，若还是小于最小需要容量，那么就把最小需要容量当作数组的新容量，  if (newCapacity - minCapacity \u0026lt; 0) newCapacity = minCapacity; //再检查新容量是否超出了ArrayList所定义的最大容量，  //若超出了，则调用hugeCapacity()来比较minCapacity和 MAX_ARRAY_SIZE，  //如果minCapacity大于MAX_ARRAY_SIZE，则新容量则为Interger.MAX_VALUE，否则，新容量大小则为 MAX_ARRAY_SIZE。  if (newCapacity - MAX_ARRAY_SIZE \u0026gt; 0) newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win:  elementData = Arrays.copyOf(elementData, newCapacity); } //比较minCapacity和 MAX_ARRAY_SIZE  private static int hugeCapacity(int minCapacity) { if (minCapacity \u0026lt; 0) // overflow  throw new OutOfMemoryError(); return (minCapacity \u0026gt; MAX_ARRAY_SIZE) ? Integer.MAX_VALUE : MAX_ARRAY_SIZE; } /** *返回此列表中的元素数。 */ public int size() { return size; } /** * 如果此列表不包含元素，则返回 true 。 */ public boolean isEmpty() { //注意=和==的区别  return size == 0; } /** * 如果此列表包含指定的元素，则返回true 。 */ public boolean contains(Object o) { //indexOf()方法：返回此列表中指定元素的首次出现的索引，如果此列表不包含此元素，则为-1  return indexOf(o) \u0026gt;= 0; } /** *返回此列表中指定元素的首次出现的索引，如果此列表不包含此元素，则为-1 */ public int indexOf(Object o) { if (o == null) { for (int i = 0; i \u0026lt; size; i++) if (elementData[i]==null) return i; } else { for (int i = 0; i \u0026lt; size; i++) //equals()方法比较  if (o.equals(elementData[i])) return i; } return -1; } /** * 返回此列表中指定元素的最后一次出现的索引，如果此列表不包含元素，则返回-1。. */ public int lastIndexOf(Object o) { if (o == null) { for (int i = size-1; i \u0026gt;= 0; i--) if (elementData[i]==null) return i; } else { for (int i = size-1; i \u0026gt;= 0; i--) if (o.equals(elementData[i])) return i; } return -1; } /** * 返回此ArrayList实例的浅拷贝。 （元素本身不被复制。） */ public Object clone() { try { ArrayList\u0026lt;?\u0026gt; v = (ArrayList\u0026lt;?\u0026gt;) super.clone(); //Arrays.copyOf功能是实现数组的复制，返回复制后的数组。参数是被复制的数组和复制的长度  v.elementData = Arrays.copyOf(elementData, size); v.modCount = 0; return v; } catch (CloneNotSupportedException e) { // 这不应该发生，因为我们是可以克隆的  throw new InternalError(e); } } /** *以正确的顺序（从第一个到最后一个元素）返回一个包含此列表中所有元素的数组。 *返回的数组将是“安全的”，因为该列表不保留对它的引用。 （换句话说，这个方法必须分配一个新的数组）。 *因此，调用者可以自由地修改返回的数组。 此方法充当基于阵列和基于集合的API之间的桥梁。 */ public Object[] toArray() { return Arrays.copyOf(elementData, size); } /** * 以正确的顺序返回一个包含此列表中所有元素的数组（从第一个到最后一个元素）; *返回的数组的运行时类型是指定数组的运行时类型。 如果列表适合指定的数组，则返回其中。 *否则，将为指定数组的运行时类型和此列表的大小分配一个新数组。 *如果列表适用于指定的数组，其余空间（即数组的列表数量多于此元素），则紧跟在集合结束后的数组中的元素设置为null 。 *（这仅在调用者知道列表不包含任何空元素的情况下才能确定列表的长度。） */ @SuppressWarnings(\u0026#34;unchecked\u0026#34;) public \u0026lt;T\u0026gt; T[] toArray(T[] a) { if (a.length \u0026lt; size) // 新建一个运行时类型的数组，但是ArrayList数组的内容  return (T[]) Arrays.copyOf(elementData, size, a.getClass()); //调用System提供的arraycopy()方法实现数组之间的复制  System.arraycopy(elementData, 0, a, 0, size); if (a.length \u0026gt; size) a[size] = null; return a; } // Positional Access Operations  @SuppressWarnings(\u0026#34;unchecked\u0026#34;) E elementData(int index) { return (E) elementData[index]; } /** * 返回此列表中指定位置的元素。 */ public E get(int index) { rangeCheck(index); return elementData(index); } /** * 用指定的元素替换此列表中指定位置的元素。 */ public E set(int index, E element) { //对index进行界限检查  rangeCheck(index); E oldValue = elementData(index); elementData[index] = element; //返回原来在这个位置的元素  return oldValue; } /** * 将指定的元素追加到此列表的末尾。 */ public boolean add(E e) { ensureCapacityInternal(size + 1); // Increments modCount!!  //这里看到ArrayList添加元素的实质就相当于为数组赋值  elementData[size++] = e; return true; } /** * 在此列表中的指定位置插入指定的元素。 *先调用 rangeCheckForAdd 对index进行界限检查；然后调用 ensureCapacityInternal 方法保证capacity足够大； *再将从index开始之后的所有成员后移一个位置；将element插入index位置；最后size加1。 */ public void add(int index, E element) { rangeCheckForAdd(index); ensureCapacityInternal(size + 1); // Increments modCount!!  //arraycopy()这个实现数组之间复制的方法一定要看一下，下面就用到了arraycopy()方法实现数组自己复制自己  System.arraycopy(elementData, index, elementData, index + 1, size - index); elementData[index] = element; size++; } /** * 删除该列表中指定位置的元素。 将任何后续元素移动到左侧（从其索引中减去一个元素）。 */ public E remove(int index) { rangeCheck(index); modCount++; E oldValue = elementData(index); int numMoved = size - index - 1; if (numMoved \u0026gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--size] = null; // clear to let GC do its work  //从列表中删除的元素  return oldValue; } /** * 从列表中删除指定元素的第一个出现（如果存在）。 如果列表不包含该元素，则它不会更改。 *返回true，如果此列表包含指定的元素 */ public boolean remove(Object o) { if (o == null) { for (int index = 0; index \u0026lt; size; index++) if (elementData[index] == null) { fastRemove(index); return true; } } else { for (int index = 0; index \u0026lt; size; index++) if (o.equals(elementData[index])) { fastRemove(index); return true; } } return false; } /* * Private remove method that skips bounds checking and does not * return the value removed. */ private void fastRemove(int index) { modCount++; int numMoved = size - index - 1; if (numMoved \u0026gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--size] = null; // clear to let GC do its work  } /** * 从列表中删除所有元素。 */ public void clear() { modCount++; // 把数组中所有的元素的值设为null  for (int i = 0; i \u0026lt; size; i++) elementData[i] = null; size = 0; } /** * 按指定集合的Iterator返回的顺序将指定集合中的所有元素追加到此列表的末尾。 */ public boolean addAll(Collection\u0026lt;? extends E\u0026gt; c) { Object[] a = c.toArray(); int numNew = a.length; ensureCapacityInternal(size + numNew); // Increments modCount  System.arraycopy(a, 0, elementData, size, numNew); size += numNew; return numNew != 0; } /** * 将指定集合中的所有元素插入到此列表中，从指定的位置开始。 */ public boolean addAll(int index, Collection\u0026lt;? extends E\u0026gt; c) { rangeCheckForAdd(index); Object[] a = c.toArray(); int numNew = a.length; ensureCapacityInternal(size + numNew); // Increments modCount  int numMoved = size - index; if (numMoved \u0026gt; 0) System.arraycopy(elementData, index, elementData, index + numNew, numMoved); System.arraycopy(a, 0, elementData, index, numNew); size += numNew; return numNew != 0; } /** * 从此列表中删除所有索引为fromIndex （含）和toIndex之间的元素。 *将任何后续元素移动到左侧（减少其索引）。 */ protected void removeRange(int fromIndex, int toIndex) { modCount++; int numMoved = size - toIndex; System.arraycopy(elementData, toIndex, elementData, fromIndex, numMoved); // clear to let GC do its work  int newSize = size - (toIndex-fromIndex); for (int i = newSize; i \u0026lt; size; i++) { elementData[i] = null; } size = newSize; } /** * 检查给定的索引是否在范围内。 */ private void rangeCheck(int index) { if (index \u0026gt;= size) throw new IndexOutOfBoundsException(outOfBoundsMsg(index)); } /** * add和addAll使用的rangeCheck的一个版本 */ private void rangeCheckForAdd(int index) { if (index \u0026gt; size || index \u0026lt; 0) throw new IndexOutOfBoundsException(outOfBoundsMsg(index)); } /** * 返回IndexOutOfBoundsException细节信息 */ private String outOfBoundsMsg(int index) { return \u0026#34;Index: \u0026#34;+index+\u0026#34;, Size: \u0026#34;+size; } /** * 从此列表中删除指定集合中包含的所有元素。 */ public boolean removeAll(Collection\u0026lt;?\u0026gt; c) { Objects.requireNonNull(c); //如果此列表被修改则返回true  return batchRemove(c, false); } /** * 仅保留此列表中包含在指定集合中的元素。 *换句话说，从此列表中删除其中不包含在指定集合中的所有元素。 */ public boolean retainAll(Collection\u0026lt;?\u0026gt; c) { Objects.requireNonNull(c); return batchRemove(c, true); } /** * 从列表中的指定位置开始，返回列表中的元素（按正确顺序）的列表迭代器。 *指定的索引表示初始调用将返回的第一个元素为next 。 初始调用previous将返回指定索引减1的元素。 *返回的列表迭代器是fail-fast 。 */ public ListIterator\u0026lt;E\u0026gt; listIterator(int index) { if (index \u0026lt; 0 || index \u0026gt; size) throw new IndexOutOfBoundsException(\u0026#34;Index: \u0026#34;+index); return new ListItr(index); } /** *返回列表中的列表迭代器（按适当的顺序）。 *返回的列表迭代器是fail-fast 。 */ public ListIterator\u0026lt;E\u0026gt; listIterator() { return new ListItr(0); } /** *以正确的顺序返回该列表中的元素的迭代器。 *返回的迭代器是fail-fast 。 */ public Iterator\u0026lt;E\u0026gt; iterator() { return new Itr(); }   ArrayList 扩容机制分析 先从 ArrayList 的构造函数说起 （JDK8）ArrayList 有三种方式来初始化，构造方法源码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47  /** * 默认初始容量大小 */ private static final int DEFAULT_CAPACITY = 10; private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = {}; /** *默认构造函数，使用初始容量10构造一个空列表(无参数构造) */ public ArrayList() { this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA; } /** * 带初始容量参数的构造函数。（用户自己指定容量） */ public ArrayList(int initialCapacity) { if (initialCapacity \u0026gt; 0) {//初始容量大于0  //创建initialCapacity大小的数组  this.elementData = new Object[initialCapacity]; } else if (initialCapacity == 0) {//初始容量等于0  //创建空数组  this.elementData = EMPTY_ELEMENTDATA; } else {//初始容量小于0，抛出异常  throw new IllegalArgumentException(\u0026#34;Illegal Capacity: \u0026#34;+ initialCapacity); } } /** *构造包含指定collection元素的列表，这些元素利用该集合的迭代器按顺序返回 *如果指定的集合为null，throws NullPointerException。 */ public ArrayList(Collection\u0026lt;? extends E\u0026gt; c) { elementData = c.toArray(); if ((size = elementData.length) != 0) { // c.toArray might (incorrectly) not return Object[] (see 6260652)  if (elementData.getClass() != Object[].class) elementData = Arrays.copyOf(elementData, size, Object[].class); } else { // replace with empty array.  this.elementData = EMPTY_ELEMENTDATA; } }   细心的同学一定会发现 ：以无参数构造方法创建 ArrayList 时，实际上初始化赋值的是一个空数组。当真正对数组进行添加元素操作时，才真正分配容量。即向数组中添加第一个元素时，数组容量扩为 10。 下面在我们分析 ArrayList 扩容时会讲到这一点内容！\n 补充：JDK6 new 无参构造的 ArrayList 对象时，直接创建了长度是 10 的 Object[] 数组 elementData 。\n 一步一步分析 ArrayList 扩容机制 这里以无参构造函数创建的 ArrayList 为例分析\n先来看 add 方法 1 2 3 4 5 6 7 8 9 10  /** * 将指定的元素追加到此列表的末尾。 */ public boolean add(E e) { //添加元素之前，先调用ensureCapacityInternal方法  ensureCapacityInternal(size + 1); // Increments modCount!!  //这里看到ArrayList添加元素的实质就相当于为数组赋值  elementData[size++] = e; return true; }    注意 ：JDK11 移除了 ensureCapacityInternal() 和 ensureExplicitCapacity() 方法\n 再来看看 ensureCapacityInternal() 方法 （JDK7）可以看到 add 方法 首先调用了ensureCapacityInternal(size + 1)\n1 2 3 4 5 6 7 8 9  //得到最小扩容量  private void ensureCapacityInternal(int minCapacity) { if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) { // 获取默认的容量和传入参数的较大值  minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity); } ensureExplicitCapacity(minCapacity); }   当 要 add 进第 1 个元素时，minCapacity 为 1，在 Math.max()方法比较后，minCapacity 为 10。\n 此处和后续 JDK8 代码格式化略有不同，核心代码基本一样。\n ensureExplicitCapacity() 方法 如果调用 ensureCapacityInternal() 方法就一定会进入（执行）这个方法，下面我们来研究一下这个方法的源码！\n1 2 3 4 5 6 7 8 9  //判断是否需要扩容  private void ensureExplicitCapacity(int minCapacity) { modCount++; // overflow-conscious code  if (minCapacity - elementData.length \u0026gt; 0) //调用grow方法进行扩容，调用此方法代表已经开始扩容了  grow(minCapacity); }   我们来仔细分析一下：\n 当我们要 add 进第 1 个元素到 ArrayList 时，elementData.length 为 0 （因为还是一个空的 list），因为执行了 ensureCapacityInternal() 方法 ，所以 minCapacity 此时为 10。此时，minCapacity - elementData.length \u0026gt; 0成立，所以会进入 grow(minCapacity) 方法。 当 add 第 2 个元素时，minCapacity 为 2，此时 e lementData.length(容量)在添加第一个元素后扩容成 10 了。此时，minCapacity - elementData.length \u0026gt; 0 不成立，所以不会进入 （执行）grow(minCapacity) 方法。 添加第 3、4···到第 10 个元素时，依然不会执行 grow 方法，数组容量都为 10。  直到添加第 11 个元素，minCapacity(为 11)比 elementData.length（为 10）要大。进入 grow 方法进行扩容。\ngrow() 方法 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  /** * 要分配的最大数组大小 */ private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8; /** * ArrayList扩容的核心方法。 */ private void grow(int minCapacity) { // oldCapacity为旧容量，newCapacity为新容量  int oldCapacity = elementData.length; //将oldCapacity 右移一位，其效果相当于oldCapacity /2，  //我们知道位运算的速度远远快于整除运算，整句运算式的结果就是将新容量更新为旧容量的1.5倍，  int newCapacity = oldCapacity + (oldCapacity \u0026gt;\u0026gt; 1); //然后检查新容量是否大于最小需要容量，若还是小于最小需要容量，那么就把最小需要容量当作数组的新容量，  if (newCapacity - minCapacity \u0026lt; 0) newCapacity = minCapacity; // 如果新容量大于 MAX_ARRAY_SIZE,进入(执行) `hugeCapacity()` 方法来比较 minCapacity 和 MAX_ARRAY_SIZE，  //如果minCapacity大于最大容量，则新容量则为`Integer.MAX_VALUE`，否则，新容量大小则为 MAX_ARRAY_SIZE 即为 `Integer.MAX_VALUE - 8`。  if (newCapacity - MAX_ARRAY_SIZE \u0026gt; 0) newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win:  elementData = Arrays.copyOf(elementData, newCapacity); }   int newCapacity = oldCapacity + (oldCapacity \u0026raquo; 1),所以 ArrayList 每次扩容之后容量都会变为原来的 1.5 倍左右（oldCapacity 为偶数就是 1.5 倍，否则是 1.5 倍左右）！ 奇偶不同，比如 ：10+10/2 = 15, 33+33/2=49。如果是奇数的话会丢掉小数.\n \u0026ldquo;\u0026raquo;\u0026quot;（移位运算符）：\u0026raquo;1 右移一位相当于除 2，右移 n 位相当于除以 2 的 n 次方。这里 oldCapacity 明显右移了 1 位所以相当于 oldCapacity /2。对于大数据的 2 进制运算,位移运算符比那些普通运算符的运算要快很多,因为程序仅仅移动一下而已,不去计算,这样提高了效率,节省了资源\n 我们再来通过例子探究一下grow() 方法 ：\n 当 add 第 1 个元素时，oldCapacity 为 0，经比较后第一个 if 判断成立，newCapacity = minCapacity(为 10)。但是第二个 if 判断不会成立，即 newCapacity 不比 MAX_ARRAY_SIZE 大，则不会进入 hugeCapacity 方法。数组容量为 10，add 方法中 return true,size 增为 1。 当 add 第 11 个元素进入 grow 方法时，newCapacity 为 15，比 minCapacity（为 11）大，第一个 if 判断不成立。新容量没有大于数组最大 size，不会进入 hugeCapacity 方法。数组容量扩为 15，add 方法中 return true,size 增为 11。 以此类推······  这里补充一点比较重要，但是容易被忽视掉的知识点：\n Java 中的 length属性是针对数组说的,比如说你声明了一个数组,想知道这个数组的长度则用到了 length 这个属性. Java 中的 length() 方法是针对字符串说的,如果想看这个字符串的长度则用到 length() 这个方法. Java 中的 size() 方法是针对泛型集合说的,如果想看这个泛型有多少个元素,就调用此方法来查看!  hugeCapacity() 方法。 从上面 grow() 方法源码我们知道： 如果新容量大于 MAX_ARRAY_SIZE,进入(执行) hugeCapacity() 方法来比较 minCapacity 和 MAX_ARRAY_SIZE，如果 minCapacity 大于最大容量，则新容量则为Integer.MAX_VALUE，否则，新容量大小则为 MAX_ARRAY_SIZE 即为 Integer.MAX_VALUE - 8。\n1 2 3 4 5 6 7 8 9 10 11  private static int hugeCapacity(int minCapacity) { if (minCapacity \u0026lt; 0) // overflow  throw new OutOfMemoryError(); //对minCapacity和MAX_ARRAY_SIZE进行比较  //若minCapacity大，将Integer.MAX_VALUE作为新数组的大小  //若MAX_ARRAY_SIZE大，将MAX_ARRAY_SIZE作为新数组的大小  //MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8;  return (minCapacity \u0026gt; MAX_ARRAY_SIZE) ? Integer.MAX_VALUE : MAX_ARRAY_SIZE; }   System.arraycopy() 和 Arrays.copyOf()方法 阅读源码的话，我们就会发现 ArrayList 中大量调用了这两个方法。比如：我们上面讲的扩容操作以及add(int index, E element)、toArray() 等方法中都用到了该方法！\nSystem.arraycopy() 方法 源码：\n1 2 3 4 5 6 7 8 9 10 11 12  // 我们发现 arraycopy 是一个 native 方法,接下来我们解释一下各个参数的具体意义  /** * 复制数组 * @param src 源数组 * @param srcPos 源数组中的起始位置 * @param dest 目标数组 * @param destPos 目标数组中的起始位置 * @param length 要复制的数组元素的数量 */ public static native void arraycopy(Object src, int srcPos, Object dest, int destPos, int length);   场景：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  /** * 在此列表中的指定位置插入指定的元素。 *先调用 rangeCheckForAdd 对index进行界限检查；然后调用 ensureCapacityInternal 方法保证capacity足够大； *再将从index开始之后的所有成员后移一个位置；将element插入index位置；最后size加1。 */ public void add(int index, E element) { rangeCheckForAdd(index); ensureCapacityInternal(size + 1); // Increments modCount!!  //arraycopy()方法实现数组自己复制自己  //elementData:源数组;index:源数组中的起始位置;elementData：目标数组；index + 1：目标数组中的起始位置； size - index：要复制的数组元素的数量；  System.arraycopy(elementData, index, elementData, index + 1, size - index); elementData[index] = element; size++; }   我们写一个简单的方法测试以下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  public class ArraycopyTest { public static void main(String[] args) { // TODO Auto-generated method stub \tint[] a = new int[10]; a[0] = 0; a[1] = 1; a[2] = 2; a[3] = 3; System.arraycopy(a, 2, a, 3, 3); a[2]=99; for (int i = 0; i \u0026lt; a.length; i++) { System.out.print(a[i] + \u0026#34; \u0026#34;); } } }   结果：\n1  0 1 99 2 3 0 0 0 0 0   Arrays.copyOf()方法 源码：\n1 2 3 4 5 6 7 8  public static int[] copyOf(int[] original, int newLength) { // 申请一个新的数组  int[] copy = new int[newLength]; // 调用System.arraycopy,将源数组中的数据进行拷贝,并返回新的数组  System.arraycopy(original, 0, copy, 0, Math.min(original.length, newLength)); return copy; }   场景：\n1 2 3 4 5 6 7  /** 以正确的顺序返回一个包含此列表中所有元素的数组（从第一个到最后一个元素）; 返回的数组的运行时类型是指定数组的运行时类型。 */ public Object[] toArray() { //elementData：要复制的数组；size：要复制的长度  return Arrays.copyOf(elementData, size); }   个人觉得使用 Arrays.copyOf()方法主要是为了给原有数组扩容，测试代码如下：\n1 2 3 4 5 6 7 8 9 10 11  public class ArrayscopyOfTest { public static void main(String[] args) { int[] a = new int[3]; a[0] = 0; a[1] = 1; a[2] = 2; int[] b = Arrays.copyOf(a, 10); System.out.println(\u0026#34;b.length\u0026#34;+b.length); } }   结果：\n1  10   两者联系和区别 联系：\n看两者源代码可以发现 copyOf()内部实际调用了 System.arraycopy() 方法\n区别：\narraycopy() 需要目标数组，将原数组拷贝到你自己定义的数组里或者原数组，而且可以选择拷贝的起点和长度以及放入新数组中的位置 copyOf() 是系统自动在内部新建一个数组，并返回该数组。\nensureCapacity方法 ArrayList 源码中有一个 ensureCapacity 方法不知道大家注意到没有，这个方法 ArrayList 内部没有被调用过，所以很显然是提供给用户调用的，那么这个方法有什么作用呢？\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  /** 如有必要，增加此 ArrayList 实例的容量，以确保它至少可以容纳由minimum capacity参数指定的元素数。 * * @param minCapacity 所需的最小容量 */ public void ensureCapacity(int minCapacity) { int minExpand = (elementData != DEFAULTCAPACITY_EMPTY_ELEMENTDATA) // any size if not default element table  ? 0 // larger than default for default empty table. It\u0026#39;s already  // supposed to be at default size.  : DEFAULT_CAPACITY; if (minCapacity \u0026gt; minExpand) { ensureExplicitCapacity(minCapacity); } }   最好在 add 大量元素之前用 ensureCapacity 方法，以减少增量重新分配的次数\n我们通过下面的代码实际测试以下这个方法的效果：\n1 2 3 4 5 6 7 8 9 10 11 12 13  public class EnsureCapacityTest { public static void main(String[] args) { ArrayList\u0026lt;Object\u0026gt; list = new ArrayList\u0026lt;Object\u0026gt;(); final int N = 10000000; long startTime = System.currentTimeMillis(); for (int i = 0; i \u0026lt; N; i++) { list.add(i); } long endTime = System.currentTimeMillis(); System.out.println(\u0026#34;使用ensureCapacity方法前：\u0026#34;+(endTime - startTime)); } }   运行结果：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  使用ensureCapacity方法前：2158 public class EnsureCapacityTest { public static void main(String[] args) { ArrayList\u0026lt;Object\u0026gt; list = new ArrayList\u0026lt;Object\u0026gt;(); final int N = 10000000; list = new ArrayList\u0026lt;Object\u0026gt;(); long startTime1 = System.currentTimeMillis(); list.ensureCapacity(N); for (int i = 0; i \u0026lt; N; i++) { list.add(i); } long endTime1 = System.currentTimeMillis(); System.out.println(\u0026#34;使用ensureCapacity方法后：\u0026#34;+(endTime1 - startTime1)); } }   运行结果：\n1  使用ensureCapacity方法后：1773   通过运行结果，我们可以看出向 ArrayList 添加大量元素之前最好先使用ensureCapacity 方法，以减少增量重新分配的次数。\n总结 ArrayList的扩容：\n　扩容可分为两种情况：\n　第一种情况，当ArrayList的容量为0时，此时添加元素的话，需要扩容，三种构造方法创建的ArrayList在扩容时略有不同：\n　1.无参构造，创建ArrayList后容量为0，添加第一个元素后，容量变为10，此后若需要扩容，则正常扩容。\n　2.传容量构造，当参数为0时，创建ArrayList后容量为0，添加第一个元素后，容量为1，此时ArrayList是满的，下次添加元素时需正常扩容。\n　3.传列表构造，当列表为空时，创建ArrayList后容量为0，添加第一个元素后，容量为1，此时ArrayList是满的，下次添加元素时需正常扩容。\n　第二种情况，当ArrayList的容量大于0，并且ArrayList是满的时，此时添加元素的话，进行正常扩容，每次扩容到原来的1.5倍。\n","date":"2021-04-12T13:36:41Z","image":"https://ahao.ink/6.jpg","permalink":"https://ahao.ink/posts/arraylist%E6%BA%90%E7%A0%81-%E6%89%A9%E5%AE%B9%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/","title":"ArrayList源码+扩容机制分析"},{"content":"什么是反射？ 反射就是Reflection，Java的反射是指程序在运行期可以拿到一个对象的所有信息。\n正常情况下，如果我们要调用一个对象的方法，或者访问一个对象的字段，通常会传入对象实例：\n1 2 3 4 5 6 7 8  // Main.java import com.Person; public class Main { String getFullName(Person p) { return p.getFirstName() + \u0026#34; \u0026#34; + p.getLastName(); } }   但是，如果不能获得Person类，只有一个Object实例，比如这样：\n1 2 3  String getFullName(Object obj) { return ??? }   怎么办？有童鞋会说：强制转型啊！\n1 2 3 4  String getFullName(Object obj) { Person p = (Person) obj; return p.getFirstName() + \u0026#34; \u0026#34; + p.getLastName(); }   强制转型的时候，你会发现一个问题：编译上面的代码，仍然需要引用Person类。不然，去掉import语句，你看能不能编译通过？\n所以，反射是为了解决在运行期，对某个实例一无所知的情况下，如何调用其方法。\nClass类 除了int等基本类型外，Java的其他类型全部都是class（包括interface）。例如：\n String Object Runnable Exception \u0026hellip;  仔细思考，我们可以得出结论：class（包括interface）的本质是数据类型（Type）。无继承关系的数据类型无法赋值：\n1 2  Number n = new Double(123.456); // OK String s = new Double(123.456); // compile error!   而class是由JVM在执行过程中动态加载的。JVM在第一次读取到一种class类型时，将其加载进内存。\n每加载一种class，JVM就为其创建一个Class类型的实例，并关联起来。注意：这里的Class类型是一个名叫Class的class。它长这样：\n1 2 3  public final class Class { private Class() {} }   以String类为例，当JVM加载String类时，它首先读取String.class文件到内存，然后，为String类创建一个Class实例并关联起来：\n1  Class cls = new Class(String);   这个Class实例是JVM内部创建的，如果我们查看JDK源码，可以发现Class类的构造方法是private，只有JVM能创建Class实例，我们自己的Java程序是无法创建Class实例的。\n所以，JVM持有的每个Class实例都指向一个数据类型（class或interface）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  ┌───────────────────────────┐ │ Class Instance │──────\u0026gt; String ├───────────────────────────┤ │name = \u0026#34;java.lang.String\u0026#34; │ └───────────────────────────┘ ┌───────────────────────────┐ │ Class Instance │──────\u0026gt; Random ├───────────────────────────┤ │name = \u0026#34;java.util.Random\u0026#34; │ └───────────────────────────┘ ┌───────────────────────────┐ │ Class Instance │──────\u0026gt; Runnable ├───────────────────────────┤ │name = \u0026#34;java.lang.Runnable\u0026#34;│ └───────────────────────────┘   一个Class实例包含了该class的所有完整信息：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  ┌───────────────────────────┐ │ Class Instance │──────\u0026gt; String ├───────────────────────────┤ │name = \u0026#34;java.lang.String\u0026#34; │ ├───────────────────────────┤ │package = \u0026#34;java.lang\u0026#34; │ ├───────────────────────────┤ │super = \u0026#34;java.lang.Object\u0026#34; │ ├───────────────────────────┤ │interface = CharSequence...│ ├───────────────────────────┤ │field = value[],hash,... │ ├───────────────────────────┤ │method = indexOf()... │ └───────────────────────────┘   由于JVM为每个加载的class创建了对应的Class实例，并在实例中保存了该class的所有信息，包括类名、包名、父类、实现的接口、所有方法、字段等，因此，如果获取了某个Class实例，我们就可以通过这个Class实例获取到该实例对应的class的所有信息。\n这种通过Class实例获取class信息的方法称为反射（Reflection）。\n如何获取一个class的Class实例？有三个方法：\n方法一：直接通过一个class的静态变量class获取：\n1  Class cls = String.class;   方法二：如果我们有一个实例变量，可以通过该实例变量提供的getClass()方法获取：\n1 2  String s = \u0026#34;Hello\u0026#34;; Class cls = s.getClass();   方法三：如果知道一个class的完整类名，可以通过静态方法Class.forName()获取：\n1  Class cls = Class.forName(\u0026#34;java.lang.String\u0026#34;);   因为Class实例在JVM中是唯一的，所以，上述方法获取的Class实例是同一个实例。可以用==比较两个Class实例：\n1 2 3 4 5 6  Class cls1 = String.class; String s = \u0026#34;Hello\u0026#34;; Class cls2 = s.getClass(); boolean sameClass = cls1 == cls2; // true   注意一下Class实例比较和instanceof的差别：\n1 2 3 4 5 6 7  Integer n = new Integer(123); boolean b1 = n instanceof Integer; // true，因为n是Integer类型 boolean b2 = n instanceof Number; // true，因为n是Number类型的子类  boolean b3 = n.getClass() == Integer.class; // true，因为n.getClass()返回Integer.class boolean b4 = n.getClass() == Number.class; // false，因为Integer.class!=Number.class   用instanceof不但匹配指定类型，还匹配指定类型的子类。而用==判断class实例可以精确地判断数据类型，但不能作子类型比较。\n通常情况下，我们应该用instanceof判断数据类型，因为面向抽象编程的时候，我们不关心具体的子类型。只有在需要精确判断一个类型是不是某个class的时候，我们才使用==判断class实例。\n因为反射的目的是为了获得某个实例的信息。因此，当我们拿到某个Object实例时，我们可以通过反射获取该Object的class信息：\n1 2 3  void printObjectInfo(Object obj) { Class cls = obj.getClass(); }   要从Class实例获取获取的基本信息，参考下面的代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  public class Main { public static void main(String[] args) { printClassInfo(\u0026#34;\u0026#34;.getClass()); printClassInfo(Runnable.class); printClassInfo(java.time.Month.class); printClassInfo(String[].class); printClassInfo(int.class); } static void printClassInfo(Class cls) { System.out.println(\u0026#34;Class name: \u0026#34; + cls.getName()); System.out.println(\u0026#34;Simple name: \u0026#34; + cls.getSimpleName()); if (cls.getPackage() != null) { System.out.println(\u0026#34;Package name: \u0026#34; + cls.getPackage().getName()); } System.out.println(\u0026#34;is interface: \u0026#34; + cls.isInterface()); System.out.println(\u0026#34;is enum: \u0026#34; + cls.isEnum()); System.out.println(\u0026#34;is array: \u0026#34; + cls.isArray()); System.out.println(\u0026#34;is primitive: \u0026#34; + cls.isPrimitive()); } }   运行结果如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33  Class name: java.lang.String Simple name: String Package name: java.lang is interface: false is enum: false is array: false is primitive: false Class name: java.lang.Runnable Simple name: Runnable Package name: java.lang is interface: true is enum: false is array: false is primitive: false Class name: java.time.Month Simple name: Month Package name: java.time is interface: false is enum: true is array: false is primitive: false Class name: [Ljava.lang.String; Simple name: String[] is interface: false is enum: false is array: true is primitive: false Class name: int Simple name: int is interface: false is enum: false is array: false is primitive: true   注意到数组（例如String[]）也是一种Class，而且不同于String.class，它的类名是[Ljava.lang.String。此外，JVM为每一种基本类型如int也创建了Class，通过int.class访问。\n如果获取到了一个Class实例，我们就可以通过该Class实例来创建对应类型的实例：\n1 2 3 4  // 获取String的Class实例: Class cls = String.class; // 创建一个String实例: String s = (String) cls.newInstance();   上述代码相当于new String()。通过Class.newInstance()可以创建类实例，它的局限是：只能调用public的无参数构造方法。带参数的构造方法，或者非public的构造方法都无法通过Class.newInstance()被调用。\n动态加载 JVM在执行Java程序的时候，并不是一次性把所有用到的class全部加载到内存，而是第一次需要用到class时才加载。例如：\n1 2 3 4 5 6 7 8 9 10 11 12  // Main.java public class Main { public static void main(String[] args) { if (args.length \u0026gt; 0) { create(args[0]); } } static void create(String name) { Person p = new Person(name); } }   当执行Main.java时，由于用到了Main，因此，JVM首先会把Main.class加载到内存。然而，并不会加载Person.class，除非程序执行到create()方法，JVM发现需要加载Person类时，才会首次加载Person.class。如果没有执行create()方法，那么Person.class根本就不会被加载。\n这就是JVM动态加载class的特性。\n动态加载class的特性对于Java程序非常重要。利用JVM动态加载class的特性，我们才能在运行期根据条件加载不同的实现类。例如，Commons Logging总是优先使用Log4j，只有当Log4j不存在时，才使用JDK的logging。利用JVM动态加载特性，大致的实现代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  // Commons Logging优先使用Log4j: LogFactory factory = null; if (isClassPresent(\u0026#34;org.apache.logging.log4j.Logger\u0026#34;)) { factory = createLog4j(); } else { factory = createJdkLog(); } boolean isClassPresent(String name) { try { Class.forName(name); return true; } catch (Exception e) { return false; } }   这就是为什么我们只需要把Log4j的jar包放到classpath中，Commons Logging就会自动使用Log4j的原因。\n小结 JVM为每个加载的class及interface创建了对应的Class实例来保存class及interface的所有信息；\n获取一个class对应的Class实例后，就可以获取该class的所有信息；\n通过Class实例获取class信息的方法称为反射（Reflection）；\nJVM总是动态加载class，可以在运行期根据条件来控制加载class。\n访问字段 对任意的一个Object实例，只要我们获取了它的Class，就可以获取它的一切信息。\n我们先看看如何通过Class实例获取字段信息。Class类提供了以下几个方法来获取字段：\n Field getField(name)：根据字段名获取某个public的field（包括父类） Field getDeclaredField(name)：根据字段名获取当前类的某个field（不包括父类） Field[] getFields()：获取所有public的field（包括父类） Field[] getDeclaredFields()：获取当前类的所有field（不包括父类）  我们来看一下示例代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  // reflection public class Main { public static void main(String[] args) throws Exception { Class stdClass = Student.class; // 获取public字段\u0026#34;score\u0026#34;:  System.out.println(stdClass.getField(\u0026#34;score\u0026#34;)); // 获取继承的public字段\u0026#34;name\u0026#34;:  System.out.println(stdClass.getField(\u0026#34;name\u0026#34;)); // 获取private字段\u0026#34;grade\u0026#34;:  System.out.println(stdClass.getDeclaredField(\u0026#34;grade\u0026#34;)); } } class Student extends Person { public int score; private int grade; } class Person { public String name; }   上述代码首先获取Student的Class实例，然后，分别获取public字段、继承的public字段以及private字段，打印出的Field类似：\n1 2 3  public int Student.score public java.lang.String Person.name private int Student.grade   一个Field对象包含了一个字段的所有信息：\n getName()：返回字段名称，例如，\u0026quot;name\u0026quot;； getType()：返回字段类型，也是一个Class实例，例如，String.class； getModifiers()：返回字段的修饰符，它是一个int，不同的bit表示不同的含义。  以String类的value字段为例，它的定义是：\n1 2 3  public final class String { private final byte[] value; }   我们用反射获取该字段的信息，代码如下：\n1 2 3 4 5 6 7 8 9  Field f = String.class.getDeclaredField(\u0026#34;value\u0026#34;); f.getName(); // \u0026#34;value\u0026#34; f.getType(); // class [B 表示byte[]类型 int m = f.getModifiers(); Modifier.isFinal(m); // true Modifier.isPublic(m); // false Modifier.isProtected(m); // false Modifier.isPrivate(m); // true Modifier.isStatic(m); // false   获取字段值 利用反射拿到字段的一个Field实例只是第一步，我们还可以拿到一个实例对应的该字段的值。\n例如，对于一个Person实例，我们可以先拿到name字段对应的Field，再获取这个实例的name字段的值：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  // reflection import java.lang.reflect.Field; public class Main { public static void main(String[] args) throws Exception { Object p = new Person(\u0026#34;Xiao Ming\u0026#34;); Class c = p.getClass(); Field f = c.getDeclaredField(\u0026#34;name\u0026#34;); Object value = f.get(p); System.out.println(value); // \u0026#34;Xiao Ming\u0026#34;  } } class Person { private String name; public Person(String name) { this.name = name; } }   上述代码先获取Class实例，再获取Field实例，然后，用Field.get(Object)获取指定实例的指定字段的值。\n运行代码，如果不出意外，会得到一个IllegalAccessException，这是因为name被定义为一个private字段，正常情况下，Main类无法访问Person类的private字段。要修复错误，可以将private改为public，或者，在调用Object value = f.get(p);前，先写一句：\n1  f.setAccessible(true);   调用Field.setAccessible(true)的意思是，别管这个字段是不是public，一律允许访问。\n可以试着加上上述语句，再运行代码，就可以打印出private字段的值。\n有童鞋会问：如果使用反射可以获取private字段的值，那么类的封装还有什么意义？\n答案是正常情况下，我们总是通过p.name来访问Person的name字段，编译器会根据public、protected和private决定是否允许访问字段，这样就达到了数据封装的目的。\n而反射是一种非常规的用法，使用反射，首先代码非常繁琐，其次，它更多地是给工具或者底层框架来使用，目的是在不知道目标实例任何信息的情况下，获取特定字段的值。\n此外，setAccessible(true)可能会失败。如果JVM运行期存在SecurityManager，那么它会根据规则进行检查，有可能阻止setAccessible(true)。例如，某个SecurityManager可能不允许对java和javax开头的package的类调用setAccessible(true)，这样可以保证JVM核心库的安全。\n设置字段值 通过Field实例既然可以获取到指定实例的字段值，自然也可以设置字段的值。\n设置字段值是通过Field.set(Object, Object)实现的，其中第一个Object参数是指定的实例，第二个Object参数是待修改的值。示例代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  // reflection import java.lang.reflect.Field; public class Main { public static void main(String[] args) throws Exception { Person p = new Person(\u0026#34;Xiao Ming\u0026#34;); System.out.println(p.getName()); // \u0026#34;Xiao Ming\u0026#34;  Class c = p.getClass(); Field f = c.getDeclaredField(\u0026#34;name\u0026#34;); f.setAccessible(true); f.set(p, \u0026#34;Xiao Hong\u0026#34;); System.out.println(p.getName()); // \u0026#34;Xiao Hong\u0026#34;  } } class Person { private String name; public Person(String name) { this.name = name; } public String getName() { return this.name; } }   运行上述代码，打印的name字段从Xiao Ming变成了Xiao Hong，说明通过反射可以直接修改字段的值。\n同样的，修改非public字段，需要首先调用setAccessible(true)。\n小结 Java的反射API提供的Field类封装了字段的所有信息：\n通过Class实例的方法可以获取Field实例：getField()，getFields()，getDeclaredField()，getDeclaredFields()；\n通过Field实例可以获取字段信息：getName()，getType()，getModifiers()；\n通过Field实例可以读取或设置某个对象的字段，如果存在访问限制，要首先调用setAccessible(true)来访问非public字段。\n通过反射读写字段是一种非常规方法，它会破坏对象的封装。\n调用方法 我们已经能通过Class实例获取所有Field对象，同样的，可以通过Class实例获取所有Method信息。Class类提供了以下几个方法来获取Method：\n Method getMethod(name, Class...)：获取某个public的Method（包括父类） Method getDeclaredMethod(name, Class...)：获取当前类的某个Method（不包括父类） Method[] getMethods()：获取所有public的Method（包括父类） Method[] getDeclaredMethods()：获取当前类的所有Method（不包括父类）  我们来看一下示例代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  // reflection public class Main { public static void main(String[] args) throws Exception { Class stdClass = Student.class; // 获取public方法getScore，参数为String:  System.out.println(stdClass.getMethod(\u0026#34;getScore\u0026#34;, String.class)); // 获取继承的public方法getName，无参数:  System.out.println(stdClass.getMethod(\u0026#34;getName\u0026#34;)); // 获取private方法getGrade，参数为int:  System.out.println(stdClass.getDeclaredMethod(\u0026#34;getGrade\u0026#34;, int.class)); } } class Student extends Person { public int getScore(String type) { return 99; } private int getGrade(int year) { return 1; } } class Person { public String getName() { return \u0026#34;Person\u0026#34;; } }   上述代码首先获取Student的Class实例，然后，分别获取public方法、继承的public方法以及private方法，打印出的Method类似：\n1 2 3  public int Student.getScore(java.lang.String) public java.lang.String Person.getName() private int Student.getGrade(int)   一个Method对象包含一个方法的所有信息：\n getName()：返回方法名称，例如：\u0026quot;getScore\u0026quot;； getReturnType()：返回方法返回值类型，也是一个Class实例，例如：String.class； getParameterTypes()：返回方法的参数类型，是一个Class数组，例如：{String.class, int.class}； getModifiers()：返回方法的修饰符，它是一个int，不同的bit表示不同的含义。  调用方法 当我们获取到一个Method对象时，就可以对它进行调用。我们以下面的代码为例：\n1 2  String s = \u0026#34;Hello world\u0026#34;; String r = s.substring(6); // \u0026#34;world\u0026#34;   如果用反射来调用substring方法，需要以下代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  // reflection import java.lang.reflect.Method; public class Main { public static void main(String[] args) throws Exception { // String对象:  String s = \u0026#34;Hello world\u0026#34;; // 获取String substring(int)方法，参数为int:  Method m = String.class.getMethod(\u0026#34;substring\u0026#34;, int.class); // 在s对象上调用该方法并获取结果:  String r = (String) m.invoke(s, 6); // 打印调用结果:  System.out.println(r); } }   1  world   注意到substring()有两个重载方法，我们获取的是String substring(int)这个方法。思考一下如何获取String substring(int, int)方法。\n对Method实例调用invoke就相当于调用该方法，invoke的第一个参数是对象实例，即在哪个实例上调用该方法，后面的可变参数要与方法参数一致，否则将报错。\n调用静态方法 如果获取到的Method表示一个静态方法，调用静态方法时，由于无需指定实例对象，所以invoke方法传入的第一个参数永远为null。我们以Integer.parseInt(String)为例：\n1 2 3 4 5 6 7 8 9 10 11 12 13  // reflection import java.lang.reflect.Method; public class Main { public static void main(String[] args) throws Exception { // 获取Integer.parseInt(String)方法，参数为String:  Method m = Integer.class.getMethod(\u0026#34;parseInt\u0026#34;, String.class); // 调用该静态方法并获取结果:  Integer n = (Integer) m.invoke(null, \u0026#34;12345\u0026#34;); // 打印调用结果:  System.out.println(n); } }   1  12345   调用非public方法 和Field类似，对于非public方法，我们虽然可以通过Class.getDeclaredMethod()获取该方法实例，但直接对其调用将得到一个IllegalAccessException。为了调用非public方法，我们通过Method.setAccessible(true)允许其调用：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  // reflection import java.lang.reflect.Method; public class Main { public static void main(String[] args) throws Exception { Person p = new Person(); Method m = p.getClass().getDeclaredMethod(\u0026#34;setName\u0026#34;, String.class); m.setAccessible(true); m.invoke(p, \u0026#34;Bob\u0026#34;); System.out.println(p.name); } } class Person { String name; private void setName(String name) { this.name = name; } }   1  Bob   此外，setAccessible(true)可能会失败。如果JVM运行期存在SecurityManager，那么它会根据规则进行检查，有可能阻止setAccessible(true)。例如，某个SecurityManager可能不允许对java和javax开头的package的类调用setAccessible(true)，这样可以保证JVM核心库的安全。\n多态 我们来考察这样一种情况：一个Person类定义了hello()方法，并且它的子类Student也覆写了hello()方法，那么，从Person.class获取的Method，作用于Student实例时，调用的方法到底是哪个？\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  // reflection import java.lang.reflect.Method; public class Main { public static void main(String[] args) throws Exception { // 获取Person的hello方法:  Method h = Person.class.getMethod(\u0026#34;hello\u0026#34;); // 对Student实例调用hello方法:  h.invoke(new Student()); } } class Person { public void hello() { System.out.println(\u0026#34;Person:hello\u0026#34;); } } class Student extends Person { public void hello() { System.out.println(\u0026#34;Student:hello\u0026#34;); } }   运行上述代码，发现打印出的是Student:hello，因此，使用反射调用方法时，仍然遵循多态原则：即总是调用实际类型的覆写方法（如果存在）。上述的反射代码：\n1 2  Method m = Person.class.getMethod(\u0026#34;hello\u0026#34;); m.invoke(new Student());   实际上相当于：\n1 2  Person p = new Student(); p.hello();   小结 Java的反射API提供的Method对象封装了方法的所有信息：\n通过Class实例的方法可以获取Method实例：getMethod()，getMethods()，getDeclaredMethod()，getDeclaredMethods()；\n通过Method实例可以获取方法信息：getName()，getReturnType()，getParameterTypes()，getModifiers()；\n通过Method实例可以调用某个对象的方法：Object invoke(Object instance, Object... parameters)；\n通过设置setAccessible(true)来访问非public方法；\n通过反射调用方法时，仍然遵循多态原则。\n调用构造方法 我们通常使用new操作符创建新的实例：\n1  Person p = new Person();   如果通过反射来创建新的实例，可以调用Class提供的newInstance()方法：\n1  Person p = Person.class.newInstance();   调用Class.newInstance()的局限是，它只能调用该类的public无参数构造方法。如果构造方法带有参数，或者不是public，就无法直接通过Class.newInstance()来调用。\n为了调用任意的构造方法，Java的反射API提供了Constructor对象，它包含一个构造方法的所有信息，可以创建一个实例。Constructor对象和Method非常类似，不同之处仅在于它是一个构造方法，并且，调用结果总是返回实例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  import java.lang.reflect.Constructor; public class Main { public static void main(String[] args) throws Exception { // 获取构造方法Integer(int):  Constructor cons1 = Integer.class.getConstructor(int.class); // 调用构造方法:  Integer n1 = (Integer) cons1.newInstance(123); System.out.println(n1); // 获取构造方法Integer(String)  Constructor cons2 = Integer.class.getConstructor(String.class); Integer n2 = (Integer) cons2.newInstance(\u0026#34;456\u0026#34;); System.out.println(n2); } }   通过Class实例获取Constructor的方法如下：\n getConstructor(Class...)：获取某个public的Constructor； getDeclaredConstructor(Class...)：获取某个Constructor； getConstructors()：获取所有public的Constructor； getDeclaredConstructors()：获取所有Constructor。  注意Constructor总是当前类定义的构造方法，和父类无关，因此不存在多态的问题。\n调用非public的Constructor时，必须首先通过setAccessible(true)设置允许访问。setAccessible(true)可能会失败。\n小结 Constructor对象封装了构造方法的所有信息；\n通过Class实例的方法可以获取Constructor实例：getConstructor()，getConstructors()，getDeclaredConstructor()，getDeclaredConstructors()；\n通过Constructor实例可以创建一个实例对象：newInstance(Object... parameters)； 通过设置setAccessible(true)来访问非public构造方法。\n获取继承关系 当我们获取到某个Class对象时，实际上就获取到了一个类的类型：\n1  Class cls = String.class; // 获取到String的Class   还可以用实例的getClass()方法获取：\n1 2  String s = \u0026#34;\u0026#34;; Class cls = s.getClass(); // s是String，因此获取到String的Class   最后一种获取Class的方法是通过Class.forName(\u0026quot;\u0026quot;)，传入Class的完整类名获取：\n1  Class s = Class.forName(\u0026#34;java.lang.String\u0026#34;);   这三种方式获取的Class实例都是同一个实例，因为JVM对每个加载的Class只创建一个Class实例来表示它的类型。\n获取父类的Class 有了Class实例，我们还可以获取它的父类的Class：\n1 2 3 4 5 6 7 8 9 10 11 12  // reflection  public class Main { public static void main(String[] args) throws Exception { Class i = Integer.class; Class n = i.getSuperclass(); System.out.println(n); Class o = n.getSuperclass(); System.out.println(o); System.out.println(o.getSuperclass()); } }   运行上述代码，可以看到，Integer的父类类型是Number，Number的父类是Object，Object的父类是null。除Object外，其他任何非interface的Class都必定存在一个父类类型。\n获取interface 由于一个类可能实现一个或多个接口，通过Class我们就可以查询到实现的接口类型。例如，查询Integer实现的接口：\n1 2 3 4 5 6 7 8 9 10 11 12  // reflection import java.lang.reflect.Method; public class Main { public static void main(String[] args) throws Exception { Class s = Integer.class; Class[] is = s.getInterfaces(); for (Class i : is) { System.out.println(i); } } }   运行上述代码可知，Integer实现的接口有：\n java.lang.Comparable java.lang.constant.Constable java.lang.constant.ConstantDesc  要特别注意：getInterfaces()只返回当前类直接实现的接口类型，并不包括其父类实现的接口类型：\n1 2 3 4 5 6 7 8 9 10 11 12  // reflection import java.lang.reflect.Method; public class Main { public static void main(String[] args) throws Exception { Class s = Integer.class.getSuperclass(); Class[] is = s.getInterfaces(); for (Class i : is) { System.out.println(i); } } }   Integer的父类是Number，Number实现的接口是java.io.Serializable。\n此外，对所有interface的Class调用getSuperclass()返回的是null，获取接口的父接口要用getInterfaces()：\n1 2  System.out.println(java.io.DataInputStream.class.getSuperclass()); // java.io.FilterInputStream，因为DataInputStream继承自FilterInputStream System.out.println(java.io.Closeable.class.getSuperclass()); // null，对接口调用getSuperclass()总是返回null，获取接口的父接口要用getInterfaces()   如果一个类没有实现任何interface，那么getInterfaces()返回空数组。\n继承关系 当我们判断一个实例是否是某个类型时，正常情况下，使用instanceof操作符：\n1 2 3 4 5  Object n = Integer.valueOf(123); boolean isDouble = n instanceof Double; // false boolean isInteger = n instanceof Integer; // true boolean isNumber = n instanceof Number; // true boolean isSerializable = n instanceof java.io.Serializable; // true   如果是两个Class实例，要判断一个向上转型是否成立，可以调用isAssignableFrom()：\n1 2 3 4 5 6 7 8  // Integer i = ? Integer.class.isAssignableFrom(Integer.class); // true，因为Integer可以赋值给Integer // Number n = ? Number.class.isAssignableFrom(Integer.class); // true，因为Integer可以赋值给Number // Object o = ? Object.class.isAssignableFrom(Integer.class); // true，因为Integer可以赋值给Object // Integer i = ? Integer.class.isAssignableFrom(Number.class); // false，因为Number不能赋值给Integer   小结 通过Class对象可以获取继承关系：\n Class getSuperclass()：获取父类类型； Class[] getInterfaces()：获取当前类实现的所有接口。  通过Class对象的isAssignableFrom()方法可以判断一个向上转型是否可以实现。\n动态代理 我们来比较Java的class和interface的区别：\n 可以实例化class（非abstract）； 不能实例化interface。  所有interface类型的变量总是通过某个实例向上转型并赋值给接口类型变量的：\n1  CharSequence cs = new StringBuilder();   有没有可能不编写实现类，直接在运行期创建某个interface的实例呢？\n这是可能的，因为Java标准库提供了一种动态代理（Dynamic Proxy）的机制：可以在运行期动态创建某个interface的实例。\n什么叫运行期动态创建？听起来好像很复杂。所谓动态代理，是和静态相对应的。我们来看静态代码怎么写：\n定义接口：\n1 2 3  public interface Hello { void morning(String name); }   编写实现类：\n1 2 3 4 5  public class HelloWorld implements Hello { public void morning(String name) { System.out.println(\u0026#34;Good morning, \u0026#34; + name); } }   创建实例，转型为接口并调用：\n1 2  Hello hello = new HelloWorld(); hello.morning(\u0026#34;Bob\u0026#34;);   这种方式就是我们通常编写代码的方式。\n还有一种方式是动态代码，我们仍然先定义了接口Hello，但是我们并不去编写实现类，而是直接通过JDK提供的一个Proxy.newProxyInstance()创建了一个Hello接口对象。这种没有实现类但是在运行期动态创建了一个接口对象的方式，我们称为动态代码。JDK提供的动态创建接口对象的方式，就叫动态代理。\n一个最简单的动态代理实现如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  import java.lang.reflect.InvocationHandler; import java.lang.reflect.Method; import java.lang.reflect.Proxy; public class Main { public static void main(String[] args) { InvocationHandler handler = new InvocationHandler() { @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { System.out.println(method); if (method.getName().equals(\u0026#34;morning\u0026#34;)) { System.out.println(\u0026#34;Good morning, \u0026#34; + args[0]); } return null; } }; Hello hello = (Hello) Proxy.newProxyInstance( Hello.class.getClassLoader(), // 传入ClassLoader  new Class[] { Hello.class }, // 传入要实现的接口  handler); // 传入处理调用方法的InvocationHandler  hello.morning(\u0026#34;Bob\u0026#34;); } } interface Hello { void morning(String name); }   在运行期动态创建一个interface实例的方法如下：\n 定义一个InvocationHandler实例，它负责实现接口的方法调用； 通过Proxy.newProxyInstance()创建interface实例，它需要3个参数：  使用的ClassLoader，通常就是接口类的ClassLoader； 需要实现的接口数组，至少需要传入一个接口进去； 用来处理接口方法调用的InvocationHandler实例。   将返回的Object强制转型为接口。  动态代理实际上是JVM在运行期动态创建class字节码并加载的过程，它并没有什么黑魔法，把上面的动态代理改写为静态实现类大概长这样：\n1 2 3 4 5 6 7 8 9 10 11 12  public class HelloDynamicProxy implements Hello { InvocationHandler handler; public HelloDynamicProxy(InvocationHandler handler) { this.handler = handler; } public void morning(String name) { handler.invoke( this, Hello.class.getMethod(\u0026#34;morning\u0026#34;, String.class), new Object[] { name }); } }   其实就是JVM帮我们自动编写了一个上述类（不需要源码，可以直接生成字节码），并不存在可以直接实例化接口的黑魔法。\n小结 Java标准库提供了动态代理功能，允许在运行期动态创建一个接口的实例；\n动态代理是通过Proxy创建代理对象，然后将接口方法“代理”给InvocationHandler完成的。\n","date":"2021-04-09T13:36:41Z","image":"https://ahao.ink/2.jpg","permalink":"https://ahao.ink/posts/%E5%8F%8D%E5%B0%84%E8%AF%A6%E8%A7%A3/","title":"反射详解"},{"content":"集合判空 《阿里巴巴 Java 开发手册》的描述如下：\n 判断所有集合内部的元素是否为空，使用 isEmpty() 方法，而不是 size()==0 的方式。\n 这是因为 isEmpty() 方法的可读性更好，并且时间复杂度为 O(1)。\n绝大部分我们使用的集合的 size() 方法的时间复杂度也是 O(1)，不过，也有很多复杂度不是 O(1) 的，比如 java.util.concurrent 包下的某些集合（ConcurrentLinkedQueue 、ConcurrentHashMap\u0026hellip;）。\n下面是 ConcurrentHashMap 的 size() 方法和 isEmpty() 方法的源码。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  public int size() { long n = sumCount(); return ((n \u0026lt; 0L) ? 0 : (n \u0026gt; (long)Integer.MAX_VALUE) ? Integer.MAX_VALUE : (int)n); } final long sumCount() { CounterCell[] as = counterCells; CounterCell a; long sum = baseCount; if (as != null) { for (int i = 0; i \u0026lt; as.length; ++i) { if ((a = as[i]) != null) sum += a.value; } } return sum; } public boolean isEmpty() { return sumCount() \u0026lt;= 0L; // ignore transient negative values }   集合转 Map 《阿里巴巴 Java 开发手册》的描述如下：\n 在使用 java.util.stream.Collectors 类的 toMap() 方法转为 Map 集合时，一定要注意当 value 为 null 时会抛 NPE 异常。\n 1 2 3 4 5 6 7 8 9 10 11  class Person { private String name; private String phoneNumber; // getters and setters } List\u0026lt;Person\u0026gt; bookList = new ArrayList\u0026lt;\u0026gt;(); bookList.add(new Person(\u0026#34;jack\u0026#34;,\u0026#34;18163138123\u0026#34;)); bookList.add(new Person(\u0026#34;martin\u0026#34;,null)); // 空指针异常 bookList.stream().collect(Collectors.toMap(Person::getName, Person::getPhoneNumber));   下面我们来解释一下原因。\n首先，我们来看 java.util.stream.Collectors 类的 toMap() 方法 ，可以看到其内部调用了 Map 接口的 merge() 方法。\n1 2 3 4 5 6 7 8 9 10  public static \u0026lt;T, K, U, M extends Map\u0026lt;K, U\u0026gt;\u0026gt; Collector\u0026lt;T, ?, M\u0026gt; toMap(Function\u0026lt;? super T, ? extends K\u0026gt; keyMapper, Function\u0026lt;? super T, ? extends U\u0026gt; valueMapper, BinaryOperator\u0026lt;U\u0026gt; mergeFunction, Supplier\u0026lt;M\u0026gt; mapSupplier) { BiConsumer\u0026lt;M, T\u0026gt; accumulator = (map, element) -\u0026gt; map.merge(keyMapper.apply(element), valueMapper.apply(element), mergeFunction); return new CollectorImpl\u0026lt;\u0026gt;(mapSupplier, accumulator, mapMerger(mergeFunction), CH_ID); }   Map 接口的 merge() 方法如下，这个方法是接口中的默认实现。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  default V merge(K key, V value, BiFunction\u0026lt;? super V, ? super V, ? extends V\u0026gt; remappingFunction) { Objects.requireNonNull(remappingFunction); Objects.requireNonNull(value); V oldValue = get(key); V newValue = (oldValue == null) ? value : remappingFunction.apply(oldValue, value); if(newValue == null) { remove(key); } else { put(key, newValue); } return newValue; }   merge() 方法会先调用 Objects.requireNonNull() 方法判断 value 是否为空。\n1 2 3 4 5  public static \u0026lt;T\u0026gt; T requireNonNull(T obj) { if (obj == null) throw new NullPointerException(); return obj; }   集合遍历 《阿里巴巴 Java 开发手册》的描述如下：\n 不要在 foreach 循环里进行元素的 remove/add 操作。remove 元素请使用 Iterator 方式，如果并发操作，需要对 Iterator 对象加锁。\n 通过反编译你会发现 foreach 语法糖底层其实还是依赖 Iterator 。不过， remove/add 操作直接调用的是集合自己的方法，而不是 Iterator 的 remove/add方法\n这就导致 Iterator 莫名其妙地发现自己有元素被 remove/add ，然后，它就会抛出一个 ConcurrentModificationException 来提示用户发生了并发修改异常。这就是单线程状态下产生的 fail-fast 机制。\n fail-fast 机制 ：多个线程对 fail-fast 集合进行修改的时候，可能会抛出ConcurrentModificationException。 即使是单线程下也有可能会出现这种情况，上面已经提到过。\n Java8 开始，可以使用 Collection#removeIf()方法删除满足特定条件的元素,如\n1 2 3 4 5 6  List\u0026lt;Integer\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); for (int i = 1; i \u0026lt;= 10; ++i) { list.add(i); } list.removeIf(filter -\u0026gt; filter % 2 == 0); /* 删除list中的所有偶数 */ System.out.println(list); /* [1, 3, 5, 7, 9] */   除了上面介绍的直接使用 Iterator 进行遍历操作之外，你还可以：\n 使用普通的 for 循环 使用 fail-safe 的集合类。java.util包下面的所有的集合类都是 fail-fast 的，而java.util.concurrent包下面的所有的类都是 fail-safe 的。 \u0026hellip;\u0026hellip;  集合去重 《阿里巴巴 Java 开发手册》的描述如下：\n 可以利用 Set 元素唯一的特性，可以快速对一个集合进行去重操作，避免使用 List 的 contains() 进行遍历去重或者判断包含操作。\n 这里我们以 HashSet 和 ArrayList 为例说明。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  // Set 去重代码示例 public static \u0026lt;T\u0026gt; Set\u0026lt;T\u0026gt; removeDuplicateBySet(List\u0026lt;T\u0026gt; data) { if (CollectionUtils.isEmpty(data)) { return new HashSet\u0026lt;\u0026gt;(); } return new HashSet\u0026lt;\u0026gt;(data); } // List 去重代码示例 public static \u0026lt;T\u0026gt; List\u0026lt;T\u0026gt; removeDuplicateByList(List\u0026lt;T\u0026gt; data) { if (CollectionUtils.isEmpty(data)) { return new ArrayList\u0026lt;\u0026gt;(); } List\u0026lt;T\u0026gt; result = new ArrayList\u0026lt;\u0026gt;(data.size()); for (T current : data) { if (!result.contains(current)) { result.add(current); } } return result; }   两者的核心差别在于 contains() 方法的实现。\nHashSet 的 contains() 方法底部依赖的 HashMap 的 containsKey() 方法，时间复杂度接近于 O（1）（没有出现哈希冲突的时候为 O（1））。\n1 2 3 4  private transient HashMap\u0026lt;E,Object\u0026gt; map; public boolean contains(Object o) { return map.containsKey(o); }   我们有 N 个元素插入进 Set 中，那时间复杂度就接近是 O (n)。\nArrayList 的 contains() 方法是通过遍历所有元素的方法来做的，时间复杂度接近是 O(n)。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  public boolean contains(Object o) { return indexOf(o) \u0026gt;= 0; } public int indexOf(Object o) { if (o == null) { for (int i = 0; i \u0026lt; size; i++) if (elementData[i]==null) return i; } else { for (int i = 0; i \u0026lt; size; i++) if (o.equals(elementData[i])) return i; } return -1; }   我们的 List 有 N 个元素，那时间复杂度就接近是 O (n^2)。\n集合转数组 《阿里巴巴 Java 开发手册》的描述如下：\n 使用集合转数组的方法，必须使用集合的 toArray(T[] array)，传入的是类型完全一致、长度为 0 的空数组。\n toArray(T[] array) 方法的参数是一个泛型数组，如果 toArray 方法中没有传递任何参数的话返回的是 Object类 型数组。\n1 2 3 4 5 6 7  String [] s= new String[]{ \u0026#34;dog\u0026#34;, \u0026#34;lazy\u0026#34;, \u0026#34;a\u0026#34;, \u0026#34;over\u0026#34;, \u0026#34;jumps\u0026#34;, \u0026#34;fox\u0026#34;, \u0026#34;brown\u0026#34;, \u0026#34;quick\u0026#34;, \u0026#34;A\u0026#34; }; List\u0026lt;String\u0026gt; list = Arrays.asList(s); Collections.reverse(list); //没有指定类型的话会报错 s=list.toArray(new String[0]);   由于 JVM 优化，new String[0]作为Collection.toArray()方法的参数现在使用更好，new String[0]就是起一个模板的作用，指定了返回数组的类型，0 是为了节省空间，因为它只是为了说明返回的类型。\n数组转集合 《阿里巴巴 Java 开发手册》的描述如下：\n 使用工具类 Arrays.asList() 把数组转换成集合时，不能使用其修改集合相关的方法， 它的 add/remove/clear 方法会抛出 UnsupportedOperationException 异常。\n Arrays.asList()在平时开发中还是比较常见的，我们可以使用它将一个数组转换为一个 List 集合。\n1 2 3 4  String[] myArray = {\u0026#34;Apple\u0026#34;, \u0026#34;Banana\u0026#34;, \u0026#34;Orange\u0026#34;}; List\u0026lt;String\u0026gt; myList = Arrays.asList(myArray); //上面两个语句等价于下面一条语句 List\u0026lt;String\u0026gt; myList = Arrays.asList(\u0026#34;Apple\u0026#34;,\u0026#34;Banana\u0026#34;, \u0026#34;Orange\u0026#34;);   JDK 源码对于这个方法的说明：\n1 2 3 4 5 6 7  /** *返回由指定数组支持的固定大小的列表。此方法作为基于数组和基于集合的API之间的桥梁， * 与 Collection.toArray()结合使用。返回的List是可序列化并实现RandomAccess接口。 */ public static \u0026lt;T\u0026gt; List\u0026lt;T\u0026gt; asList(T... a) { return new ArrayList\u0026lt;\u0026gt;(a); }   下面我们来总结一下使用注意事项。\n1、Arrays.asList()是泛型方法，传递的数组必须是对象数组，而不是基本类型。\n1 2 3 4 5 6 7  int[] myArray = {1, 2, 3}; List myList = Arrays.asList(myArray); System.out.println(myList.size());//1 System.out.println(myList.get(0));//数组地址值 System.out.println(myList.get(1));//报错：ArrayIndexOutOfBoundsException int[] array = (int[]) myList.get(0); System.out.println(array[0]);//1   当传入一个原生数据类型数组时，Arrays.asList() 的真正得到的参数就不是数组中的元素，而是数组对象本身！此时 List 的唯一元素就是这个数组，这也就解释了上面的代码。\n我们使用包装类型数组就可以解决这个问题。\n1  Integer[] myArray = {1, 2, 3};   2、使用集合的修改方法: add()、remove()、clear()会抛出异常。\n1 2 3 4  List myList = Arrays.asList(1, 2, 3); myList.add(4);//运行时报错：UnsupportedOperationException myList.remove(1);//运行时报错：UnsupportedOperationException myList.clear();//运行时报错：UnsupportedOperationException   Arrays.asList() 方法返回的并不是 java.util.ArrayList ，而是 java.util.Arrays 的一个内部类,这个内部类并没有实现集合的修改方法或者说并没有重写这些方法。\n1 2  List myList = Arrays.asList(1, 2, 3); System.out.println(myList.getClass());//class java.util.Arrays$ArrayList   下图是 java.util.Arrays$ArrayList 的简易源码，我们可以看到这个类重写的方法有哪些。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40  private static class ArrayList\u0026lt;E\u0026gt; extends AbstractList\u0026lt;E\u0026gt; implements RandomAccess, java.io.Serializable { ... @Override public E get(int index) { ... } @Override public E set(int index, E element) { ... } @Override public int indexOf(Object o) { ... } @Override public boolean contains(Object o) { ... } @Override public void forEach(Consumer\u0026lt;? super E\u0026gt; action) { ... } @Override public void replaceAll(UnaryOperator\u0026lt;E\u0026gt; operator) { ... } @Override public void sort(Comparator\u0026lt;? super E\u0026gt; c) { ... } }   我们再看一下java.util.AbstractList的 add/remove/clear 方法就知道为什么会抛出 UnsupportedOperationException 了。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  public E remove(int index) { throw new UnsupportedOperationException(); } public boolean add(E e) { add(size(), e); return true; } public void add(int index, E element) { throw new UnsupportedOperationException(); } public void clear() { removeRange(0, size()); } protected void removeRange(int fromIndex, int toIndex) { ListIterator\u0026lt;E\u0026gt; it = listIterator(fromIndex); for (int i=0, n=toIndex-fromIndex; i\u0026lt;n; i++) { it.next(); it.remove(); } }   那我们如何正确的将数组转换为 ArrayList ?\n1、手动实现工具类\n1 2 3 4 5 6 7 8 9 10 11 12 13  //JDK1.5+ static \u0026lt;T\u0026gt; List\u0026lt;T\u0026gt; arrayToList(final T[] array) { final List\u0026lt;T\u0026gt; l = new ArrayList\u0026lt;T\u0026gt;(array.length); for (final T s : array) { l.add(s); } return l; } Integer [] myArray = { 1, 2, 3 }; System.out.println(arrayToList(myArray).getClass());//class java.util.ArrayList   2、最简便的方法\n1  List list = new ArrayList\u0026lt;\u0026gt;(Arrays.asList(\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;))   3、使用 Java8 的 Stream(推荐)\n1 2 3 4 5  Integer [] myArray = { 1, 2, 3 }; List myList = Arrays.stream(myArray).collect(Collectors.toList()); //基本类型也可以实现转换（依赖boxed的装箱操作） int [] myArray2 = { 1, 2, 3 }; List myList = Arrays.stream(myArray2).boxed().collect(Collectors.toList());   4、使用 Guava\n对于不可变集合，你可以使用ImmutableList类及其of与[copyOf()工厂方法：（参数不能为空）\n1 2  List\u0026lt;String\u0026gt; il = ImmutableList.of(\u0026#34;string\u0026#34;, \u0026#34;elements\u0026#34;); // from varargs List\u0026lt;String\u0026gt; il = ImmutableList.copyOf(aStringArray); // from array   对于可变集合，你可以使用Lists类及其newArrayList()工厂方法：\n1 2 3  List\u0026lt;String\u0026gt; l1 = Lists.newArrayList(anotherListOrCollection); // from collection List\u0026lt;String\u0026gt; l2 = Lists.newArrayList(aStringArray); // from array List\u0026lt;String\u0026gt; l3 = Lists.newArrayList(\u0026#34;or\u0026#34;, \u0026#34;string\u0026#34;, \u0026#34;elements\u0026#34;); // from varargs   5、使用 Apache Commons Collections\n1 2  List\u0026lt;String\u0026gt; list = new ArrayList\u0026lt;String\u0026gt;(); CollectionUtils.addAll(list, str);   6、 使用 Java9 的 List.of()方法\n1 2  Integer[] array = {1, 2, 3}; List\u0026lt;Integer\u0026gt; list = List.of(array);   ","date":"2021-04-08T13:36:41Z","image":"https://ahao.ink/16.jpg","permalink":"https://ahao.ink/posts/java%E9%9B%86%E5%90%88%E4%BD%BF%E7%94%A8%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9/","title":"Java集合使用注意事项"},{"content":"Spring AOP（面向切面） 1. 前言 大家好，本小节重点介绍一个新知识 —— AOP 。作为入门的第一小节，我们需要理解 AOP 的概念，了解 AOP 的专业术语，明白它的作用。\n那么，到底什么是 AOP ，它存在的意义是什么，在开发中扮演了一个什么样的角色呢？\n随着疑问，开始本小节的内容。\n2. 概述 2.1 AOP 的概念 AOP 并不是 Spring 框架的专属名称，它的全称是 Aspect Oriented Programming ，意为：面向切面编程。\n它是 OOP 的一个延续，通过预编译的方式和运行期间动态代理实现程序功能的统一维护的一种技术。\n名词解释：\n面向切面编程：\n其实切面是数学中的一个概念，表示只有一个点接触到球体的一个平面称呼为切面，而接触点称呼为切点。那么在 Spring 中，切面编程指的是什么呢？\n就是在程序运行某个方法的时候，不修改原始执行代码逻辑，由程序动态地执行某些额外的功能，对原有的方法做增强，这就叫做面向切面编程。\n那个被监测的执行方法，称之为切入点。\n2.2 AOP 的意义 我们明白了 AOP 的概念，它是一种编程设计模式，是一种编程技术，那么为什么在程序中使用它呢？\n Spring 框架的中心宗旨之一是非侵入性，使用 AOP 可以很方便地在某些场景实现特定的功能，通过修改配置即可以实现增加或者去除某些附加功能； AOP 设计的功能代码可以复用，代码耦合性更低，代码更加整洁； 使用 Spring 提供的 AOP ，让我们更加注重业务代码实现本身，而无需关注底层设计模式与实现方式。  3. 术语解释 3.1 Join point（连接点） 所谓连接点是指那些被拦截到的点。在 Spring 中这些点指的是方法，可以看作正在访问的，或者等待访问的那些需要被增强功能的方法。Spring 只支持方法类型的连接点。\n3.2 Pointcut（切入点） 所谓切入点是一个规则，定义了我们要对哪些 Joinpoint 进行拦截。因为在一个程序中会存在很多的类，每个类又存在很多的方法，而哪些方法会应用 AOP 对该方法做功能增强呢？\n这就需要依据我们配置的切入点规则。\n3.3 Advice（通知） 所谓通知是指拦截到 Joinpoint 之后所要做的事情就是通知。 也就是对方法做的增强功能。\n通知分类：\n 前置通知：在连接点之前运行的通知类型，它不会阻止流程进行到连接点，只是在到达连接点之前运行该通知内的行为，当然 -—— 除非它引发异常； 后置通知：在连接点正常完成后要运行的通知，正常的连接点逻辑执行完，会运行该通知，当然 —— 方法正常返回而没有引发异常； 最终通知：无论连接点执行后的结果如何，正常还是异常，都会执行的通知； 异常通知：如果连接点执行因抛出异常而退出，则执行此通知； 环绕通知：环绕通知可以在方法调用之前和之后执行自定义行为。  3.4 Target （目标） Target 指的是代理的目标对象，更通俗的解释就是：AOP 对连接点方法做增强，底层是代理模式生成连接点所在类的代理对象，那么连接点所在的类，就是被代理的类称呼为 Target。\n3.5 Aspect（切面） 切面本质是一个类，只不过是个功能类，作为整合 AOP 的切入点和通知。一般来讲，需要在 Spring 的配置文件中配置，或者通过注解来配置。\n3.6 Weaving（织入） 织入是一种动作的描述，在程序运行时将增强的功能代码也就是通知，根据通知的类型（前缀后缀等…）放到对应的位置，生成代理对象。\n3.7 Proxy（代理） 一个类被 AOP 织入增强后，产生的结果就是代理类\n4. 小结 本小节主要是 AOP 的入门介绍，那么重点给大家讲述了 AOP 的概念、意义、以及常见术语。\n当然对于初学者而言，文字描述略显苍白和枯燥，而我们本小节目的也是给大家做个铺垫，\n对一些名词做个解释和介绍，以便后续测试案例的讲解。\n","date":"2021-04-08T13:36:41Z","image":"https://ahao.ink/30.jpg","permalink":"https://ahao.ink/posts/spring-aop/","title":"Spring AOP"},{"content":"Spring DI（依赖注入）之XML配置 前言 在Spring控制反转，我们详细讲解了 控制反转，也就是对 bean 做实例化的部分。而我们知道 ，Spring 的核心功能是两个：控制反转 和 依赖注入。\n那么控制反转我们已经讲过，而依赖注入是什么呢？\n依赖注入案例 概念介绍 知识回顾\n对于依赖注入，我们在第一章第一节已经介绍过，我们回顾一下\n概念解释\n上面是我们之前对于依赖注入的一个通俗解释。那么这里再着重强调一下 IOC 控制反转与 DI 依赖注入的关系：\nIOC 控制反转是将对象实例化的动作交由了 Spring 框架， 它的作用是降低了程序的耦合，不需要我们手动的创建对象，但是程序的耦合性还是存在。\n对象中肯定会有一些其余对象的引用，那么这种引用就称呼为对象的依赖，而 DI 依赖注入其实 是 IOC 设计思想的一种表现形式。\n对于 这种属性依赖，我们无需手动赋予，也是讲赋值的动作交给 Spring ，那么这种操作就是 依赖注入。\n依赖注入方式：\n 第一种方式是通过 xml 配置的方式实现； 第二种方式是在属性或者方法上使用注解的方式实现。  那么，本章节先带大家体验下 xml 方式实现依赖注入。\n工程实现 搭建动作介绍\n 创建一个 maven 工程 导入Spring 使用的依赖 编写业务层的 Service 和持久层的 Dao java 类 编写 Spring 的配置文件  创建工程 导入依赖 省略\n可以参考之前创建过的IoC工程\njava 代码\n创建 Servcie 的接口和接口的实现类，代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  //接口代码 public interface UserService { public void deleteById(Integer id); } //实现类代码 public class UserServiceImpl implements UserService { private UserDao userDao; public UserDao getUserDao() { return userDao; } public void setUserDao(UserDao userDao) { this.userDao = userDao; } public void deleteById(Integer id) { System.out.println(\u0026#34;删除的方法执行\u0026#34;); } }   UserDao 接口和实现类代码：\n1 2 3 4 5 6 7  //dao接口代码 public interface UserDao { } //dao实现类代码 public class UserDaoImpl implements UserDao { }   代码解释： dao的接口和实现类中并没有方法，只是为了测试 作为service中的属性依赖，可以实现由 Spring 完成动态注入。\n重点来了：spring 的核心配置文件：\n配置解释：\n在上面的配置文件中：\n bean 标签是描述一个被实例化的类 而 property 则表示一类中的属性 property 标签中的属性 name 一般我们写成类中的属性名称， 实际上，起决定作用的并不是属性名，下面示例再展示 ref 表示当前的属性 是一个引用对象，而引用的是谁呢？ ref 中的值 必须是在容器中已经实例化的一个引用对象的唯一标识。 value 当前的属性可以直接赋值，所以通过 value 中，填写要赋予的数值即可  测试结果\n代码解释\n可以看到 我们得到了 service 中的类属性 Userdao 的实例，并且也 得到了 字符串属性 userName的值 zs\nproperty注入属性的解释 刚刚我们在上面的示例中 展示了xml依赖属性的注入，也是比较好理解。\n这里我们强调一下使用的注意事项：\n如果是 property 属性标签实现属性注入，那么类中必须由配置在 property 标签中 name 属性的 set 方法\n下面我们测试一下set方法的改变：\n先讲 service 中 dao 的 set 方法改造如下：\n1 2 3 4  public void setDao(UserDao userDao) { System.out.println(\u0026#34;执行了set方法 给dao属性赋值\u0026#34;); this.userDao = userDao; }   这时候代码中的set方法变成了 setDao 配置文件不变，依然是\n1  \u0026lt;property name=\u0026#34;userDao\u0026#34; ref=\u0026#34;userDao\u0026#34;\u0026gt;\u0026lt;/property\u0026gt;   我们看看会产生什么问题\n1 2 3 4 5 6 7 8  Caused by: org.springframework.beans.NotWritablePropertyException: Invalid property \u0026#39;userDao\u0026#39; of bean class [com.wyan.service.UserServiceImpl]: Bean property \u0026#39;userDao\u0026#39; is not writable or has an invalid setter method. Does the parameter type of the setter match the return type of the getter? at org.springframework.beans.BeanWrapperImpl.createNotWritablePropertyException(BeanWrapperImpl.java:247) at org.springframework.beans.AbstractNestablePropertyAccessor.processLocalProperty(AbstractNestablePropertyAccessor.java:426) at org.springframework.beans.AbstractNestablePropertyAccessor.setPropertyValue(AbstractNestablePropertyAccessor.java:278) at org.springframework.beans.AbstractNestablePropertyAccessor.setPropertyValue(AbstractNestablePropertyAccessor.java:266) at org.springframework.beans.AbstractPropertyAccessor.setPropertyValues(AbstractPropertyAccessor.java:97) at org.springframework.beans.AbstractPropertyAccessor.setPropertyValues(AbstractPropertyAccessor.java:77) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyPropertyValues(AbstractAutowireCapableBeanFactory.java:1646)   可以看到异常的堆栈信息 无效的 userDao 属性， userDao 不可以 或者 没有有效的 setter 方法提供。\n更改xml文件中的 property 标签的 name 属性 为 dao\n1  \u0026lt;property name=\u0026#34;dao\u0026#34; ref=\u0026#34;userDao\u0026#34;\u0026gt;\u0026lt;/property\u0026gt;   测试结果如下：\n所以我们说 property 中的 name 属性不一定要跟 Java类中的属性名保持一致 而是必须跟 setter 方法的名称一致\n总结： 本章节重点依赖注入的 xml 实现\n 依赖注入 实际上是 IOC 设计思想的一种具体实现 依赖注入 可以通过 xml 配置实现 ，可以通过注解实现 xml 的依赖注入 是依托于类中的 set 方法实现的。  ","date":"2021-04-08T13:36:41Z","image":"https://ahao.ink/29.png","permalink":"https://ahao.ink/posts/spring-di/","title":"Spring DI"},{"content":"Spring IoC（控制反转） 前言 通过Spring入门，我们已经可以使用 Spring 框架实现对自定义的 Java 对象管理，由 Spring 框架加载对象，实例化对象，放入容器。其实这就是 Spirng 的核心功能之 IoC，那么什么是 IoC 呢？什么又是容器呢？\n什么是 IoC？ 来自百度百科的解释 —— 控制反转（IoC）： （Inversion of Control，缩写为 IoC），是面向对象编程中的一种设计原则，可以用来降低计算机代码之间的耦合度。其中最常见的方式叫做依赖注入（Dependency Injection，简称 DI），还有一种方式叫 “依赖查找”（Dependency Lookup）。通过控制反转，对象在被创建的时候，由一个调控系统内所有对象的外界实体将其所依赖的对象的引用传递给它。也可以说，依赖被注入到对象中。\n通俗解释\n如何理解好 IoC 呢？上一个小节中，我们使用简单的语言对它做了一个描述 —— IoC 是一种设计模式。将实例化对象的控制权，由手动的 new 变成了 Spring 框架通过反射机制实例化。\n那我们来深入分析一下为什么使用 IoC 做控制反转，它到底能帮助我们做什么。 我们假设一个场景：\n我们在学习 Web 阶段的过程中，一定实现过数据的查询功能，那么这里我就举一个实例： 我们有这样几个类：\n UserServlet UserService 接口 UserServiceImpl 接口的实现类 UserDao  代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34  /* UserServlet 作为控制器 接收浏览器的请求 */ public class UserServlet extends HttpServletRequest { //用户的业务类 提供逻辑处理 用户相关的方法实现  private UserService userService; public void service(HttpServletRequest request,HttpServletResponse response){ //手动实例化UserService接口的实现类  userService = new UserServiceImpl(); List\u0026lt;User\u0026gt; list = userService.findAll(); //省略结果的跳转代码  } } /* 用户的业务接口UserService */ public interface UserService{ public List\u0026lt;User\u0026gt; findAll(); } /* UserServiceImpl 作为用户的业务实现类 实现类UserService的接口 */ public class UserServiceImpl implements UserService{ //用户的Dao  private UserDao userDao; public List\u0026lt;User\u0026gt; findAll(){ //手动实例化Dao  userDao = new UserDao(); return userDao.findAll(); } }   问题分析：\n上面的代码有什么问题吗？ 按照我们学习过的知识… 答案是没有。因为 Dao 只要数据源编写代码正确， 完全可以实现数据的增删改查 ，对吗？\n但是分析分析它我们发现：\n 代码耦合性太强 不利于程序的测试： 因为 userServlet 依赖于 userService ，而 userService 依赖于 userDao ， 那么只要是被依赖的对象，一定要实例化才行。所以我们采取在程序中硬编码，使用 new 关键字对对象做实例化。 不利于测试，因为你不能确保所有使用的依赖对象都被成功地初始化了。有的朋友很奇怪，对象实例化有什么问题吗？ 如果构造参数不满足要求，或者你的构造进行了逻辑处理，那么就有可能实例化失败； 代码也不利于扩展： 假设一下，我们花了九牛二虎之气，整理好了所有的类使用的依赖，确保不会产生问题，那么一旦后续我们的方法进行扩充，改造了构造函数，或者判断逻辑，那么是不是所有手动 new 对象的地方都需要更改？ 很明显这就不是一个优雅的设计。  解决方式：\nSpring 的 IoC 完美的解决了这一点， 对象的实例化由 Spring 框架加载实现，放到 Spring 的容器中管理，避免了我们手动的 new 对象，有需要用到对象实例依赖，直接向 Spring 容器要即可，而一旦涉及到对象的实例修改，那么 只需更改 Spring 加载实例化对象的地方，程序代码无需改动，降低了耦合，提升了扩展性。\n容器的使用 刚刚我们解释了 IoC 的作用，是对象的实例化由主动的创建变成了 Spring 的创建，并放入容器管理，那么这个容器是什么？ 概念理解: 日常生活中有很多的容器，例如：水桶、茶杯、酒瓶，那么他们都有一个特点，就是装东西。而 Spring 的容器，就是装对象的实例的。\nIoC 容器的体系结构 Spring 的容器有两个：\n BeanFactory ApplicationContext  他们两个都是接口，那么有什么区别呢？见图如下： BeanFactory 才是 Spring 容器中的顶层接口。 ApplicationContext 是它的子接口。 简而言之，BeanFactory 提供了配置框架和基本功能，并在 ApplicationContext 中增加了更多针对企业的功能。 BeanFactory 和 ApplicationContext 的区别： 创建对象的时间点不一样。 ApplicationContext：只要一读取配置文件，默认情况下就会创建对象。 BeanFactory：什么时候使用，什么时候创建对象。\nIoC 容器实例化的方式 上面已经知道 Spring 的容器是通过一个接口 org.springframework.context.ApplicationContext 表示，并负责实例化，配置和组装 Bean 对象。容器通过读取 xml 文件中的配置信息来获取关于实例化对象，配置属性等命令。 而 ApplicationContext 只是一个接口，我们通常创建 ClassPathXmlApplicationContext 的实例或者 FileSystemXmlApplicationContext 的实例。前者是从类路径中获取上下文定义文件，后者是从文件系统或 URL 中获取上下文定义文件 。例如： 代码解释： 15 行注释掉的代码是通过加载类路径下的配置文件，一般来说 Java 工程放在 src 目录下。我们使用的是 Maven 工程放在 resources 目录下。\n18 行代码是通过加载本地 D 盘目录下的文件来初始化容器， 实例化 bean 对象。\n结论 通过上面的两种方式测试，发现都可以成功初始化容器， 获取测试的 bean 对象实例。 也证明了容器的初始化可以创建 ClassPathXmlApplicationContext 也可以创建 FileSystemXmlApplicationContext 的实例。\nIoC 容器的使用实例 我们知道了加载配置文件初始化容器的方式，现在了解下容器的使用。其实对于我们而言，已经不陌生了，在Spring入门中也已经成功的从容器中获取了对象实例。 这里我们就回顾一下：\n1.容器的初始化必须先配置 xml 文件，代码回顾如下：\n1  \u0026lt;bean id=\u0026#34;user\u0026#34; class=\u0026#34;com.ahao.entity.User\u0026#34; \u0026gt;\u0026lt;/beans\u0026gt;   2.加载配置文件\n1 2  ApplicationContext context = new ClassPathXmlApplicationContext(\u0026#34;classpath:applicationContext.xml\u0026#34;);   3.调用方法\n1  context.getBean(\u0026#34;user\u0026#34;)   小结 本小节对 IoC 概念做了一个详解，同时介绍了 IoC 解决的问题，演示了 IoC 的使用实例，对于初学者来说搞清楚概念，理解作用，实践出结果，就是出色的完成了任务。\nSpring IoC （控制反转）之 xml 配置 前言 本小节目的在于带领大家熟练 xml 文件配置， 应用 xml 文件配置 IoC。\nSpring入门中我们通过一个入门工程简单地体验了一把 Spring 的使用，梳理了一下 Spring 的工作流程。\n大家有了一个初步认知，Spring 框架的工作脱离不了核心配置文件 applicationContext.xml。\n在配置文件中我们目前只用到了一个 bean 标签，它的作用是用于描述 Java 的类，让框架启动加载配置文件实例化的。\n疑问导出\n那么我们知道描述一个类有几个要素，类名、属性、构造函数 set 和 get 方法对吧？而 bean 标签如何描述一个详细的类呢？\n带着疑问… 开始本节内容。\nbean 标签中的属性介绍 核心配置文件回顾\n1  \u0026lt;bean id=\u0026#34;user\u0026#34; class=\u0026#34;com.ahao.entity.User\u0026#34; \u0026gt;\u0026lt;/bean\u0026gt;   在上面的代码中可以看到，在 bean 标签中有两个属性，一个是 id 一个是 class。那么在 bean 标签中都有哪些属性呢？\n属性列表\n   学号 姓名     id 定义的唯一标识   name 同 id 的意义一致   class 类   factory-bean 工厂对象   factory-method 工厂方法   init-method 初始化执行的方法   destroy-method 销毁执行的方法   scope 对象的作用域   lazy-init 懒加载   autowire 依赖注入   depends-on 依赖于某个实例    疑问导出\n上述属性是配置 bean 标签中可以选择的属性，当然一般来讲，我们无需配置所有，可以根据自己的需求配置需要的属性信息，那么如何选择这些属性呢？\n属性详细解释 id 和 name 标签的使用 我们目前已经知道所有被实例化后的对象都存在于 Spirng 的容器中，那么从容器中获取这些对象需要一个属性 id 对吧？那么 name 和 id 有什么关系呢？\n查看官方文档得知 Spring 的容器会给初始化的每个 bean 都定义一个或多个标识符。这些标识符在容器内必须是唯一的。一个 bean 通常只有一个标识符。而 name 和 id 都可以起到标识符的作用。\n所以在 XML 配置文件，我们一般使用 id 或者 name 属性，定义 bean 的唯一标识，这样我们才能通过定义好的唯一标识，从 Spring 的容器中获取他们。\n代码实例:\nxml 的配置文件如下：\n1 2 3 4 5 6 7 8 9  \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;beans xmlns=\u0026#34;http://www.springframework.org/schema/beans\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\u0026#34;\u0026gt; \u0026lt;bean id=\u0026#34;user\u0026#34; name=\u0026#34;user2\u0026#34; class=\u0026#34;com.ahao.entity.User\u0026#34; \u0026gt;\u0026lt;/bean\u0026gt; \u0026lt;/beans\u0026gt;   测试代码如下：\n1 2 3 4 5 6  public static void main(String[] args) { ApplicationContext context = new ClassPathXmlApplicationContext(\u0026#34;classpath:applicationContext.xml\u0026#34;); System.out.println(context.getBean(\u0026#34;user\u0026#34;)); System.out.println(context.getBean(\u0026#34;user2\u0026#34;)); }   结果如图所示：\n结论证明：\n我们通过 bean 标签中的 id 属性 user， 或者使用 bean 标签中的 name 属性 user2， 都可以得到 Spring 容器中的 user 对象的示例，而且打印的地址是同一个。我们之前说过一句，默认在容器中的实例都是单例的，在这里也得到了证明。\nclass 属性 bean 标签的定义实质上是创建一个或多个对象的方法。当 xml 文件被解析加载的时候，使用该 bean 定义封装的配置数据来创建（或获取）实际对象，而创建获取的对象是谁呢？就是通过 class 属性中定义的类的全路径来指定 。\n一般来讲 class 中的类实例化有两种方式：\n一种是反射 ，相当于我们使用的 new 关键字。这种也是我们常用的方式。当然不要忘记提供无参数的构造方法（类中默认有无参构造，但是如果自定义了有参构造，默认的无参不会提供）\n一种是工厂模式 ，需要借助于 factory-bean 和 factory-method 两个属性，这种方式不常用，我们可以了解下。\nfactorybean 和 factorymethod 属性 这两个属性主要用于工厂模式实例化 bean 的时候使用，不是很常见。工厂模式有两种，这里分别做个实例，帮助大家理解。\n静态工厂模式实例：\n1 2  \u0026lt;!--applicationContext的配置bean节点--\u0026gt; \u0026lt;bean id=\u0026#34;user\u0026#34; class=\u0026#34;com.ahao.entity.User\u0026#34; factory-method=\u0026#34;createUserInstance\u0026#34;/\u0026gt;   创建 bean 示例的 Java 工厂类：\n1 2 3 4 5 6 7 8 9 10  public class User { private static User user = new User(); private User() {} public static User createInstance() { return user; } }   解释：在定义使用静态工厂方法创建的 bean 时，class 属性指定的是被创建的类，包含静态的方法，并使用 factory-method 属性来指定工厂方法本身名称。\n普通工厂模式：\n1 2 3 4  \u0026lt;!--spring实例化工厂对象 用于创建java实例 --\u0026gt; \u0026lt;bean id=\u0026#34;beanFactory\u0026#34; class=\u0026#34;com.ahao.factory.BeanFactory\u0026#34;\u0026gt;\u0026lt;/bean\u0026gt; \u0026lt;!-- 被工厂创建的对象实例 --\u0026gt; \u0026lt;bean id=\u0026#34;user1\u0026#34; factory-bean=\u0026#34;beanFactory\u0026#34; factory-method=\u0026#34;createUser1\u0026#34;/\u0026gt;   工厂类代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  public class BeanFactory { private static User1 user1 = new User1(); private static User2 user2 = new User2(); public User1 createUser1() { return user1; } public User2 createUser2() { return user2; } }   解释：先实例化先创建各个对象示例的工厂对象到容器中，自身的 bean 标签将 class 属性保留为空，并在 factory-bean 属性中指定当前容器中的工厂 Bean 名称，再使用 factory-method 属性设置创建示例的方法名称。\ninit-method 和 destroy-method 属性的使用 这两个属性比较好理解 init-method 就是 bean 被初始化后执行的方法，destory-method 就是 bean 被销毁执行的代码。\n我们来个测试类：\n1 2 3 4 5 6 7 8 9 10 11 12 13  public class User { public User(){ System.out.println(\u0026#34;我被spring实例化了\u0026#34;); } public void initMethod(){ System.out.println(\u0026#34;user类实例化时候执行的代码\u0026#34;); } public void destoryMethod(){ System.out.println(\u0026#34;user类实例被销毁时候执行的代码\u0026#34;); } }   配置文件：\n1  \u0026lt;bean id=\u0026#34;user\u0026#34; name=\u0026#34;user2\u0026#34; class=\u0026#34;com.ahao.entity.User\u0026#34; init-method=\u0026#34;initMethod\u0026#34; destroy-method=\u0026#34;destoryMethod\u0026#34; \u0026gt;\u0026lt;/bean\u0026gt;   测试代码:\n1 2 3 4 5  public static void main(String[] args) { ApplicationContext context = new ClassPathXmlApplicationContext(\u0026#34;classpath:applicationContext.xml\u0026#34;); }   加载 Spring 的配置文件控制台打印如下：\n有个小疑问：销毁语句没打印呢？那是因为并没有调用容器的销毁方法。\n改造测试代码如下：\n1 2 3 4 5  public static void main(String[] args) { AbstractApplicationContext context = new ClassPathXmlApplicationContext(\u0026#34;classpath:applicationContext.xml\u0026#34;); context.close(); }   解释：ApplicationContext 没有 close 方法使用它的子类\n运行结果：\n其余属性作用 scope ：指定示例的作用范围，后续章节详细讲解；\nlazy-init ：表示是否为懒加载；\nautowire ：指定属性注入方式，后续章节详解；\ndepends-on： 表示是否有依赖的 bean 对象，后续依赖注入章节详细解释。\n构造函数的使用 刚刚我们详细解释了 bean 标签内部的属性，经过几个小实例以后不禁也有个问题：\n如果我们定义的类中有一些初始化的参数，并且定义好了有参数的构造，通过 xml 配置文件如何体现呢？\n实现起来非常简单，跟我来进行一个小实例：\n改造 User 类：\n这是一个普通的 Java 类对象，包含两个属性及其 get 和 set 方法，并且提供了空参构造和有参构造，为了测试方便再覆写一个 toString 方法。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  public class User { private Integer id; private String name; public User() { } public User(Integer id, String name) { this.id = id; this.name = name; } public Integer getId() { return id; } public void setId(Integer id) { this.id = id; } public String getName() { return name; } public void setName(String name) { this.name = name; } @Override public String toString() { return \u0026#34;User{\u0026#34; + \u0026#34;id=\u0026#34; + id + \u0026#34;, name=\u0026#39;\u0026#34; + name + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#39;}\u0026#39;; } }   xml 配置文件方式：\n1 2 3 4  \u0026lt;bean id=\u0026#34;user\u0026#34; class=\u0026#34;com.ahao.entity.User\u0026#34; \u0026gt; \u0026lt;constructor-arg name=\u0026#34;id\u0026#34; value=\u0026#34;1\u0026#34;\u0026gt;\u0026lt;/constructor-arg\u0026gt; \u0026lt;constructor-arg name=\u0026#34;name\u0026#34; value=\u0026#34;zs\u0026#34;\u0026gt;\u0026lt;/constructor-arg\u0026gt; \u0026lt;/bean\u0026gt;   测试结果：\n其实对于有参构造实例化对象而言，使用一个标签 constructor-arg 即可，表示构造的参数，如果有多个，可以继续添加，这里不多做演示。\n疑问导出：\n可能有同学会想，那么如果以后我们的属性需要动态更改呢？或者我们的属性不是基本类型而是另外的对象呢？ 后续在依赖注入多种属性的小节给大家讲解 。\n小结 本章节带着大家详细解释了 bean 标签的使用，那么通过本章节我们收获了哪些呢？\n 容器内部命名唯一标识可以通过 id 也可以通过 name； 实例化对象有两种方式 反射模式和工厂模式； 如果是反射模式，那么必须配置 class 属性，因为需要用 class 属性中类的全路径来实例化 bean 对象； 如果需要在类实例化初始化参数，可以使用 init 方法也可以使用有参构造。  Spring 框架模拟实现 前言 通过前面的学习，大家对于 Spring 已经有了初步的认知，我们通过案例练习，或者源码追踪，可以粗略的看到 Spring 框架初始化 bean 对象的过程，那么这个章节，我们模拟 Spring 框架的思路，来写一个类似 Spring 加载对象的案例，加深大家的印象。\n案例实现思路 步骤介绍 思路分析：\n我们通过写过的案例可以知道：\n Spring 框架的容器 是一个接口 ApplicationContext 和接口的实现类 ClassPathXmlApplicationContext 来初始化的； 在初始化容器对象的时候需要传递 xml 配置文件的位置； xml 的配置文件中主要是通过 bean 标签可以对 Java 的类进行描述：类的路径 类的标识 类的构造参数等等； 容器初始化以后需要解析 xml 配置文件的各个 bean 标签； 实例化的对象如果有参数或者构造方法，那么也需要给参数赋值；  开发准备：\n为了方便理解测试 ，我们来自定义容器的接口和实现类。\n名称改为 SpringContext 和 XmlSpringContext 区别于框架的接口和实现类。\n接口定义方法 getBean 用于获取容器内的示例，实现类定义有参构造用于接受初始化时候的配置文件路径。\n接口代码如下：\n1 2 3  public interface SpringContext { public Object getBean(String beanName); }   实现类代码如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13  public class XmlSpringContext implements SpringContext { Map\u0026lt;String,Object\u0026gt; map = new HashMap\u0026lt;String,Object\u0026gt;(); public XmlSpringContext (String filename){\t} public Object getBean(String beanName){\treturn map.get(beanName); } }   代码解释：\n map 用于存储实例化的 bean 对象 ； 有参构造方法逻辑暂时为空，下面会做实现，加载文件实例化对象在方法内部； getBean 的方法用于通过 key 获取 map 中存储的实例。  为了测试对象的实例化，我们自定义 UserService 和 UserServiceImpl 作为测试的接口对象和实现类。\n接口代码如下：\n1 2 3 4 5  public interface UserService { public void deleteById(Integer id); }   接口的实现类代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  public class UserServiceImpl implements UserService { //持久层的dao属性  private UserDao userDao; public UserDao getUserDao() { return userDao; } public void setUserDao(UserDao userDao) { this.userDao = userDao; } //实现接口的方法  public void deleteById(Integer id) { System.out.println(\u0026#34;删除的方法执行\u0026#34;); } }   代码解释：dao 的属性其实是为了模拟属性赋值，后面依赖注入章节会详细讲解。\n自定义一个 xml 文件 作为模拟框架的配置文件 ：\n1 2 3 4 5 6 7  \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;beans\u0026gt; \u0026lt;bean name=\u0026#34;userDao\u0026#34; class=\u0026#34;com.ahao.dao.UserDaoImpl\u0026#34;\u0026gt;\u0026lt;/bean\u0026gt; \u0026lt;bean name=\u0026#34;userService\u0026#34; class=\u0026#34;com.ahao.service.UserServiceImpl\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;userDao\u0026#34; ref=\u0026#34;userDao\u0026#34;\u0026gt;\u0026lt;/property\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;/beans\u0026gt;   代码解释：userDao 的 bean 需要实例化 是因为 service 用到了它的引用，所以这里多个属性 property。\n编写测试类加载文件测试：\n1 2 3 4 5 6 7 8 9 10 11 12 13  public class TestSpring { @Test public void test() { //初始化容器（读取配置文件 构建工厂） \tSpringContext context = new XmlSpringContext(\u0026#34;applicationContext.xml\u0026#34;); UserServiceImpl userService = (UserServiceImpl) context.getBean(\u0026#34;userService\u0026#34;); userService.deleteById(1); System.out.println(userService.getUserDao()); } }   代码解释：这里的目的只是测试能否获取对象调用方法，如果控制台打印证明案例成功\n容器对象的实现类构造函数具体代码 思路分析：\n  读取初始化时候传递的文件路径；\n  通过 SAXReader 解析 xml 文件的节点得到 beans 节点下对应多个 bean 节点集合；\n  每一个 bean 表示一个对象，都需要被初始化，所以需要循环遍历集合；\n  在循环遍历的过程中获取 id 属性和 class 属性，id 属性作为存入 map 的 key，class 属性用于反射实例化对象，并存储 map 的 value；\n  继续解析子节点，如果有参数，反射获取 method 执行参数赋值。\n  完整代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41  public XmlSpringContext(String filename){ // xml文件的解析器 \tSAXReader sr = new SAXReader(); try { //构建一个直接通向我们配置文件路径 的输入流 \tInputStream inputStream = this.getClass().getClassLoader().getResourceAsStream(filename); //文档模型对象 \tDocument doc = sr.read(inputStream); //获取根标签 \tElement root = doc.getRootElement(); //获取当前根标签的子标签 \tList\u0026lt;Element\u0026gt; beans = root.elements(\u0026#34;bean\u0026#34;); for(Element bean:beans){\tString key = bean.attributeValue(\u0026#34;name\u0026#34;); String value = bean.attributeValue(\u0026#34;class\u0026#34;); Class\u0026lt;?\u0026gt; myclass = Class.forName(value); //当前对象 \tObject obj = myclass.newInstance(); map.put(key, obj);\tList\u0026lt;Element\u0026gt; elements = bean.elements(\u0026#34;property\u0026#34;); if(elements.size()\u0026gt;0){ for(Element pro: elements){ String av = pro.attributeValue(\u0026#34;name\u0026#34;);//dao---\u0026gt;setDao \t//方法名 \tString methodName=\u0026#34;set\u0026#34;+(av.charAt(0)+\u0026#34;\u0026#34;).toUpperCase()+av.substring(1,av.length());\t//方法参数 \tString refvalue = pro.attributeValue(\u0026#34;ref\u0026#34;); Object refobj = map.get(refvalue);\t//根据方法名称获取方法对象Method \tMethod method = myclass.getMethod(methodName,refobj.getClass().getInterfaces()[0]);\tmethod.invoke(obj, refobj); } } } } catch (Exception e) { // TODO Auto-generated catch block \te.printStackTrace(); }\t}   测试结果\n小结 本章节带着大家模拟一下 Spirng 加载文件的过程和实例化对象的过程，当然这个过程只是模拟 Spring 的框架的思路，而并不是真正的 Spring 框架源码，实际源码远比这个要复杂的多，\n那么通过本章节我们收获哪些知识呢？\n Spring 容器类的使用 xml 配置文件的作用 反射技术的应用  Spring IoC（控制反转）之注解配置 前言 上两节，我们学习了 Spring IoC 的 xml 配置实现，整理了 xml 方式的实现步骤，并且模拟了 Spring 的容器如何加载解析 xml 配置文件，那么我们发现一点现象：\n对于 Spring 的 bean 管理而言，如果全部通过 xml 文件实现的话，配置文件的内容未免过于臃肿。因为对于一个类的实例化，就需要一个 bean 标签。\n这样的话，一个大型工程下来，有那么几百个，几千个类，Spring 的 xml 文件维护起来，成本实在太高。\n疑问导出：\nSpring 能否有更方便的方式实现 IoC 呢？Spring 提出了两种 IoC 实现方式，一种是基于配置文件，一种是基于注解形式。\n本节，我们学习下 Spring IoC 的注解形式是如何实现的。\n案例实现 步骤介绍 回顾 Spring IoC 的 xml 实现步骤：\n  使用 new 关键字对 ClassPathXmlApplicationContext 做初始化；\n  在初始化容器对象的构造传入 xml 配置文件的位置 ；\n  在配置文件中通过 bean 标签可以对类进行描述：类的路径、类的标识、类的构造参数等等。\n  注解实现 IoC 的思路分析:\n1.Spring 容器一样需要初始化；\n一样需要传入 xml 配置文件 \u0026mdash;\u0026ndash; 需要描述清楚 需要被实例化的类都有哪些；  3.xml 文件中 不需要使用 bean 标签描述被实例化的类 \u0026mdash;\u0026mdash; 使用注解实现 IoC 管理目的就是为了简化 bean 标签的配置。\n疑问导出:\n如果是 xml 文件方式实现 IoC ，加载 xml 文件的 bean 标签就已经知道，需要被实例化的对象，那么如果不使用 bean 标签描述，Spring 框架如何得知哪些类需要被容器管理呢？\n核心思想：\n开发人员无需使用 XML 来描述 bean ，而是将配置移入 Java 的类本身，通过 Spring 支持的组件扫描来实现。\n看官稍等… 马上开始我们的案例实现。\n工程实现 创建工程：\n为了区分 xml 工程，坐标名称换成 spring_an ，其实无所谓，大家自行创建即可。\n导入依赖：\n依赖的坐标跟 xml 的工程坐标一致即可，无需导入多余的依赖。\n1 2 3 4 5 6 7  \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-context\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.0.2.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt;   项目代码：\n为了测试，在工程内部创建 UserDao 的接口和 UserDao 的实现类 UserDaoImpl。\nUserDao 代码如下：\n1 2 3 4  public interface UserDao { public void saveUser(); }   UserDaoImpl 的实现类代码如下：\n1 2 3 4 5 6 7  @Repository public class UserDaoImpl implements UserDao { public void saveUser() { System.out.println(\u0026#34;执行dao的保存方法\u0026#34;); } }   注意事项： 由于我们是基于注解的方式实现对 bean 的管理，所以在实现类上面需要添加一个注解 @Repository，此注解的作用是为了 Spring 的容器启动后，需要要自动检测这些被注解的类并注册相应的 bean 实例到容器中。\nSpring 的核心配置文件：\n1 2 3 4 5 6 7 8 9 10 11 12  \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;beans xmlns=\u0026#34;http://www.springframework.org/schema/beans\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xmlns:context=\u0026#34;http://www.springframework.org/schema/context\u0026#34; xsi:schemaLocation=\u0026#34;http://www.springframework.org/schema/beans https://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context https://www.springframework.org/schema/context/spring-context.xsd\u0026#34;\u0026gt; \u0026lt;context:component-scan base-package=\u0026#34;com.ahao.dao\u0026#34;\u0026gt;\u0026lt;/context:component-scan\u0026gt; \u0026lt;/beans\u0026gt;   上面是本案例的配置文件，那么可以看出跟 xml 的配置文件有很大的区别：\n配置节点：context-component-scan 标签，这是 Spring 框架自定义的 xml 标签，通过 base-package 的属性，指明需要被自动扫描实例化的类所在位置。\n如上图所示，我们在 com.ahao.dao 下的类是需要扫描自动注入容器的。\n小细节：不是在 com.ahao.dao 下的所有类都会自动注入到容器，而是要搭配注解：比如我们的 @Repository 当然还有其余的注解，我们后面章节会详细讲解。\n测试类测试结果：\n代码解释：\n测试类其实跟 xml 的方式一模一样，我们本次测试的目的一样也是通过 Spring 容器管理注册的 bean 对象，只不过对象的实例化方式换成了注解，那么我们看到成功输出在控制台的测试语句，说明案例搭建完成。\n小结 本节带着大家使用注解的方式，实现了 Spring 对于 bean 的管理。\n那么回顾下注解开发的步骤和注意点：\n Spring 容器初始化一样需要 xml 文件，目前是 xml 文件搭配注解管理 bean 并不是纯注解开发； Spring 的 xml 配置文件中使用 context:component-scan 标签指定注册 bean 的类所在目录位置； 自定义编写的 Java 类，如果需要被自动扫描注入容器，必须搭配注解。  Spring IoC（控制反转）之常用注解 前言 上一节，我们通过注解的方式，实现了 Spring 对于 bean 的管理，那么如何实现的，我们回顾一下\n两个重要点：\n 注解实例化的类上，需要使用一个注解 @Repository； Spring 的配置文件中，需要使用组件扫描 \u0026lt;context:component-scan\u0026gt; 。  疑问导出：\n组件扫描的作用我们清楚，是为了扫描路径之下带有注解的类，但是为什么类上面的注解是 @Repository 呢？或者说，是否还有其余的注解可以实现呢？\n本节，我们一起来学习下 Spring IoC 的常用注解。\n注解的详解 在我们详细讲解注解之前，首先明确一点：\n注解配置和 xml 配置实现的功能都是一样的，只不过实现的方式不同，那么也就是说，xml 文件可以实现的，通过注解都可以完全办得到。比如实例化对象，设置属性，设置作用范围，生命周期的方法执行等等…\n注解分类介绍 按功能划分：\n 创建对象： 对应的就是在 xml 文件中配置的一个 bean 标签，可以定义 id、name、class 等属性； 注入数据： 对应的就是在 bean 标签下，使用 property 标签给类中的依赖属性赋值； 作用范围： 对应的就是设置 bean 标签的 scope 属性，不设置默认也是单例； 生命周期： 对应的就是设置 bean 标签的 init-method 和 destroy-method 方法。  创建对象的注解介绍 从 Spring 的官网得知一段话：\n @Repository 注释是针对满足的存储库（也被称为数据访问对象或 DAO）的作用，或者固定型的任何类的标记。\n 也就是说，我们上一节中使用的注解，一般用于 dao 层使用。那么，我们都知道，JAVAEE 体系结构，一般开发分为三个层级：\n 表现层： 主要作用为处理数据生成静态的页面响应给浏览器展示 ； 业务层： 主要作用为业务逻辑代码编写，数据的获取，数据的封装返回等等操作都在这里； 持久层： 主要作用为跟数据库打交道，对于数据的持久化操作等。  那么，如果是创建的表现层或者业务层代码，应该使用什么注解呢？\n好了，看一下创建对象注解的划分：\n @Component ：一般用于通用组件的类上使用的注解； @Service ： 一般用于业务层类上使用的注解； @Controller ： 一般用于控制层类上使用的注解； @Repository ：一般用于持久层类上使用的注解。  官网解释：\n Spring 提供进一步典型化注解：@Component，@Service，和 @Dao。 @Component 是任何 Spring 托管组件的通用构造型。 @Repository，@Service 和 @Controller 是 @Component 针对更特定用例的专业化（分别在持久性，服务和表示层）。\n 通俗解释：\n@Component 注解是 Spring 框架中通用的一个注解，用于组件扫描实例化对象使用， 那么其余的三个注解 @Controller ，@Service，@Repository 都是 @Component 注解的衍生注解，作用跟 @Componet 注解的作用一致。 那么意义在于， 三个注解，对应的是三个开发层级 ，一般来讲我们将 @Controller 作为表现层的使用，@Service 作为业务层的注解，@Repository 作为持久层使用的注解。我们下面通过案例演示一下。\n创建对象的注解 实例说明\n四种注解的测试，本节重点讲解创建对象使用的注解，而作用范围 scope 和生命周期的两个注解，我们放在后续对应的小节进行讲解测试。\n置于注入数据的注解，是比较重要的一个内容， 我们放在依赖注入这节详细讲解。\n创建工程省略\n我们继续使用上一节的注解工程实例即可，那么为了演示三个注解，我们分别创建三个层级对应的代码：\n 表现层的 UserController 业务层的 UserService 实现类 UserServiceImpl  持久层 dao 代码已经创建过了，这里不多解释。创建好的所有代码如下：\nUserController 代码：\n1 2 3 4 5 6 7  @Controller public class UserController { public void saveUser(){ System.out.println(\u0026#34;这是controller的执行保存..\u0026#34;); } }   UserService 和实现类代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13  public interface UserService { public void saveUser(); } @Service public class UserServiceImpl implements UserService { public void saveUser() { System.out.println(\u0026#34;执行service中的保存逻辑\u0026#34;); } }   项目结构如下：\n上面是本案例的工程以及代码结构：\n类虽然看起来很多，实际没有业务逻辑代码，只不过在各个层级使用了三个注解来注入到容器，目的是测试当 Spring 的配置文件加载扫描后，是否可以从容器中获取三种注解（@Controller @Service @Repository）注入的 bean 对象。\n Tips： Spring 的配置文件 context:component-scan 标签的扫描层级 需要包含三个包路径，例如我的工程实例代码如下：\n 1  \u0026lt;context:component-scan base-package=\u0026#34;com.ahao\u0026#34;\u0026gt;\u0026lt;/context:component-scan\u0026gt;   测试类与测试结果：\n结论：\n可以三个注解都可以将对象注入到 Spring 的容器，那么以后开发时候按照规范或者习惯，分层开发，使用对应的注解。但它并不是必须这么做，你使用任意一种都可以，只不过，代码的可读性会差。\n所以，我们一般表现层使用 @controller ，业务层使用 @service， 持久层使用 @Repository。\n至于 @Component 如果有其余的类，不属于三个层级，可以采用 @Component 作为通用组件扫描注入容器。\n注解注入规则 刚刚通过三个注解都可以完成了 bean 的实例化注入，通过测试代码也获取到了容器中的三个对象实例，那么这里不知道大家是否发现一个问题：\n我们知道，Spring 这个容器本质是个 map 集合来存储实例化后的对象。既然是个 map 集合，就应该对应的有 key 和 value。\n我们都知道 value 肯定是实例化后的 bean ，那么 key 是什么呢？\n注入规则：\n 四种注解都支持 value 的属性作为自定义的 bean id ; 如果 value 属性没有指定，那么默认以类的简单名称（类名首字母小写）作为 bean 对象的 id。  所以我们可以看到：\n当我们只使用注解没有自定义 id 的时候可以通过，每个类的首字母小写来获取对象实例，那么如果有了自定义的 id，上述代码是否继续可用呢？\n自定义 id 获取实例：\n改造类上面的注解，设置自定的 id，更改的注解如下：\n1 2 3  @Controll(\u0026#34;uc\u0026#34;) @Service(\u0026#34;us\u0026#34;) @Repository(\u0026#34;ud\u0026#34;)   测试结果：\n测试结果：\n为了区分测试结果，我在测试代码中，只修改了 controller 的获取方式，将 id 改成了 uc 。service 和 dao 并没有修改。\n从控制台打印可以看到，只有 controller 对象可以成功获取，service 和 dao 都失败了，因为我们已经使用了自定义的 id，所以容器中没有默认的以类名作为 id 的 bean 对象实例。\n小结 本章节重点讲解注解的使用：\n Spring 支持的注解有四种分类； Spring 创建对象的注解四种分类； Spring 创建对象注入容器的规则。  ","date":"2021-04-08T13:36:41Z","image":"https://ahao.ink/31.jpg","permalink":"https://ahao.ink/posts/spring-ioc/","title":"Spring IoC"},{"content":"Spring MVC 简介 Spring MVC 是 Spring Framework 提供的 Web 组件，全称是 Spring Web MVC，是目前主流的实现MVC 设计模式的框架，提供前端路由映射、视图解析等功能。\nSpring MVC 功能 MVC：Controller（控制层）、Model（模型层）、View（视图层）\n流程：Controller 接收客户端请求，调用相关业务层组件产出 Model，或业务数据并返回给Controller，Controller 再结合 View 完成业务数据的视图层渲染，并将结果响应给客户端，如下图所示：\nSpring MVC 对这套 MVC 流程进行封装，帮助开发者屏蔽底层代码，并且开放出相关接口供开发者调用，让 MVC 开发变得更加简单方便。\nSpring MVC 实现原理 核心组件  DispatcherServlet：前置控制器，负责调度其他组件的执行，可以降低不同组件之间的耦合性，是整个 Spring MVC 的核心模块。 Handler：处理器，完成具体的业务逻辑，相当于 Servlet。 HandlerMapping：DispatcherServlet 是通过 HandlerMapping 将请求映射到不同的 Handler。 HandlerInterceptor：处理器拦截器，是一个接口，如果我们需要进行一些拦截处理，可以通过实现该接口完成。 HandlerExecutionChain：处理器执行链，包括两部分内容：Handler 和HandlerInterceptor（系统会有一个默认的 HandlerInterceptor，如果需要额外拦截处理，可以添加拦截器进行设置）。 HandlerAdapter：处理器适配器，Handler 执行业务方法之前，需要进行一系列的操作包括表单的数据验证、数据类型的转换、将表单数据封装到 POJO 等，这一些列操作都是由HandlerAdapter 完成，DispatcherServlet 通过 HandlerAdapter 执行不同的Handler。 ModelAndView：封装了模型数据和视图信息，作为 Handler 的处理结果，返回给DispatcherServlet。 ViewResolver：视图解析器，DispatcherServlet 通过它将逻辑视图解析为物理视图，最终将渲染的结果响应给客户端。  工作流程 1 、客户端请求被 DispatcherServlet 接收。\n2 、根据 HandlerMapping 映射到 Handler。\n3 、生成 Handler 和 HandlerInterceptor。\n4 、Handler 和 HandlerInterceptor 以 HandlerExecutionChain 的形式一并返回给DispatcherServlet。\n5 、DispatcherServlet 通过 HandlerAdpater 调用 Handler 的方法完成业务逻辑处理。\n6 、返回一个 ModelAndView 对象给 DispatcherServlet。\n7 、DispatcherServlet 将获取的 ModelAndView 对象传给 ViewResolver 视图解析器，将逻辑视图解析成物理视图。\n8 、ViewResolver 返回一个 View 给 DispatcherServlet。\n9 、DispatcherServlet 根据 View 进行视图渲染（将模型数据填充到视图中）。\n10 、DispatcherServlet 将渲染之后的视图响应给客户端。\nSpring MVC 具体使用 1 、创建 Maven 工程，并引入pom.xml。\n1 2 3 4 5  \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-webmvc\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.2.3.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt;   2 、在 web.xml 中配置 Spring MVC 的 DispatcherServlet。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  \u0026lt;web-app\u0026gt; \u0026lt;display-name\u0026gt;Archetype Created Web Application\u0026lt;/display-name\u0026gt; \u0026lt;servlet\u0026gt; \u0026lt;servlet-name\u0026gt;springmvc\u0026lt;/servlet-name\u0026gt; \u0026lt;servlet-class\u0026gt;org.springframework.web.servlet.DispatcherServlet\u0026lt;/servlet-class\u0026gt; \u0026lt;init-param\u0026gt; \u0026lt;param-name\u0026gt;contextConfigLocation\u0026lt;/param-name\u0026gt; \u0026lt;param-value\u0026gt;classpath:springmvc.xml\u0026lt;/param-value\u0026gt; \u0026lt;/init-param\u0026gt; \u0026lt;/servlet\u0026gt; \u0026lt;servlet-mapping\u0026gt; \u0026lt;servlet-name\u0026gt;springmvc\u0026lt;/servlet-name\u0026gt; \u0026lt;url-pattern\u0026gt;/\u0026lt;/url-pattern\u0026gt; \u0026lt;/servlet-mapping\u0026gt; \u0026lt;web-app\u0026gt;   3 、springmvc.xml\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;beans xmlns=\u0026#34;http://www.springframework.org/schema/beans\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xmlns:context=\u0026#34;http://www.springframework.org/schema/context\u0026#34; xmlns:mvc=\u0026#34;http://www.springframework.org/schema/mvc\u0026#34; xsi:schemaLocation=\u0026#34;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc-3.2.xsd\u0026#34;\u0026gt; \u0026lt;!-- 配置自动扫描 --\u0026gt; \u0026lt;context:component-scan base-package=\u0026#34;com.ahao\u0026#34;\u0026gt;\u0026lt;/context:component- scan\u0026gt; \u0026lt;!-- 视图解析器 --\u0026gt; \u0026lt;bean class=\u0026#34;org.springframework.web.servlet.view.InternalResourceViewResolver\u0026#34;\u0026gt; \u0026lt;!-- 前缀 --\u0026gt; \u0026lt;property name=\u0026#34;prefix\u0026#34; value=\u0026#34;/\u0026#34;\u0026gt;\u0026lt;/property\u0026gt; \u0026lt;!-- 后缀 --\u0026gt; \u0026lt;property name=\u0026#34;suffix\u0026#34; value=\u0026#34;.jsp\u0026#34;\u0026gt;\u0026lt;/property\u0026gt; \u0026lt;/bean\u0026gt;   4 、创建 Handler\n1 2 3 4 5 6 7 8 9 10 11 12  package com.ahao.controller; import org.springframework.stereotype.Controller; import org.springframework.web.bind.annotation.RequestMapping; @Controller public class HelloHandler { @RequestMapping(\u0026#34;/index\u0026#34;) public String index(){ System.out.println(\u0026#34;接收到了请求\u0026#34;); //返回逻辑视图  return \u0026#34;index\u0026#34;; }   流程梳理 1 、DispatcherServlet 接收到 URL 请求 index，结合 @RequestMapping(\u0026quot;/index\u0026quot;) 注解将该请求交给index 业务方法进行处理。\n2 、执行 index 业务方法，控制台打印日志，并且返回 \u0026ldquo;index\u0026rdquo; 字符串（逻辑视图）。\n3 、结合 springmvc.xml 中的视图解析器配置，找到目标资源：/index.jsp，即根目录下的 index.jsp 文件，将该 JSP 资源返回给客户端完成响应。\nSpring MVC 环境搭建成功。\nSpring MVC 常用注解 @RequestMapping Spring MVC 通过 @RequestMapping 注解将 URL 请求与业务方法进行映射，在控制器的类定义处以及方法定义处都可以添加 @RequestMapping ，在类定义处添加相当于多了一层访问路径。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  package com.southwind.controller; import org.springframework.stereotype.Controller; import org.springframework.web.bind.annotation.RequestMapping; @Controller @RequestMapping(\u0026#34;/hello\u0026#34;) public class HelloHandler { @RequestMapping(\u0026#34;/index\u0026#34;) public String index(){ System.out.println(\u0026#34;接收到了请求\u0026#34;); //返回逻辑视图 \treturn \u0026#34;index\u0026#34;; } }   http://localhost:8080/hello/index\n@RequestMapping 常用参数\n  value：指定 URL 请求的实际地址，是 @RequestMapping 的默认值\n1 2 3 4 5 6  @RequestMapping(\u0026#34;/index\u0026#34;) public String index(){ System.out.println(\u0026#34;接收到了请求\u0026#34;); //返回逻辑视图 \treturn \u0026#34;index\u0026#34;; }     等同于\n  添加value\n1 2 3 4 5 6  @RequestMapping(value=\u0026#34;/index\u0026#34;) public String index(){ System.out.println(\u0026#34;接收到了请求\u0026#34;); //返回逻辑视图  return \u0026#34;index\u0026#34;; }     method：指定请求的 method 类型，包括 GET、POST、PUT、DELETE 等。\n1 2 3 4 5 6  @RequestMapping(value = \u0026#34;/index\u0026#34;,method = RequestMethod.POST) public String index(){ System.out.println(\u0026#34;接收到了请求\u0026#34;); //返回逻辑视图  return \u0026#34;index\u0026#34;; }     上述代码表示只有 POST 请求可以访问该方法，若使用其他请求访问，直接抛出异常，比如 Get。\n  params：指定 request 请求中必须包含的参数值，若不包含，无法调用该方法。\n1 2 3 4 5 6 7  @RequestMapping(value = \u0026#34;/index\u0026#34;,method = RequestMethod.POST,params = {\u0026#34;id=1\u0026#34;,\u0026#34;name=tom\u0026#34;}) public String index(){ System.out.println(\u0026#34;接收到了请求\u0026#34;); //返回逻辑视图  return \u0026#34;index\u0026#34;; }   上述代码表示 request 请求中必须包含 name 和 id 两个参数，并且 id 的值必须为 1 ，name 的值必须 为 tom，才可调用，否则抛出 400 异常。\n  参数绑定 params 是对 URL 请求参数进行限制，不满足条件的 URL 无法访问该方法，需要在业务方法中获取URL 的参数值。\n1 、在业务方法定义时声明参数列表。\n2 、给参数列表添加 @RequestParam 注解进行绑定。\n1 2 3 4 5 6 7  @RequestMapping(value = \u0026#34;/index\u0026#34;,method = RequestMethod.POST) public String index(@RequestParam(\u0026#34;num\u0026#34;) Integer id,@RequestParam(\u0026#34;str\u0026#34;) String name){ System.out.println(\u0026#34;接收到了请求,参数是：id=\u0026#34;+id+\u0026#34;,name=\u0026#34;+name); //返回逻辑视图  return \u0026#34;index\u0026#34;; }   Spring MVC 可以自动完成数据类型转换，该工作是由 HandlerAdapter 来完成的。\n支持 RESTful 风格 传统的 URL：localhost:8080/hello/index?id=1\u0026amp;name=tom\nRESTful URL：localhost:8080/hello/index/1/tom\n1 2 3 4 5 6  @RequestMapping(\u0026#34;/restful/{id}/{name}\u0026#34;) public String restful(@PathVariable(\u0026#34;id\u0026#34;) Integer id,@PathVariable(\u0026#34;name\u0026#34;) String name){ System.out.println(id+\u0026#34;-\u0026#34;+name); return \u0026#34;index\u0026#34;; }   将参数列表的注解改为 @PathVariable(\u0026ldquo;id\u0026rdquo;) 即可。\n映射 Cookie 1 2 3 4 5  @RequestMapping(\u0026#34;/cookie\u0026#34;) public String getCookie(@CookieValue(\u0026#34;JSESSIONID\u0026#34;) String sessionId){ System.out.println(sessionId); return \u0026#34;index\u0026#34;; }   使用 POJO 绑定参数 Spring MVC 会根据请求参数名和 POJO 属性名进行匹配，自动为该对象填充属性值，并且支持属性级联。\n如果出现中文乱码，可以通过配置过滤器来解决，在 web.xml 中添加配置即可。\n1 2 3 4 5 6 7 8 9 10 11 12 13  \u0026lt;filter\u0026gt; \u0026lt;filter-name\u0026gt;encodingFilter\u0026lt;/filter-name\u0026gt; \u0026lt;filter-class\u0026gt;org.springframework.web.filter.CharacterEncodingFilter\u0026lt;/filter-class\u0026gt; \u0026lt;init-param\u0026gt; \u0026lt;param-name\u0026gt;encoding\u0026lt;/param-name\u0026gt; \u0026lt;param-value\u0026gt;UTF-8\u0026lt;/param-value\u0026gt; \u0026lt;/init-param\u0026gt; \u0026lt;/filter\u0026gt; \u0026lt;filter-mapping\u0026gt; \u0026lt;filter-name\u0026gt;encodingFilter\u0026lt;/filter-name\u0026gt; \u0026lt;url-pattern\u0026gt;/*\u0026lt;/url-pattern\u0026gt; \u0026lt;/filter-mapping\u0026gt;   Address.java\n1 2 3 4 5 6 7  package com.ahao.entity; import lombok.Data; @Data public class Address { private Integer code; private String value; }   User.java\n1 2 3 4 5 6 7 8  package com.ahao.entity; import lombok.Data; @Data public class User { private Integer id; private String name; private Address address; }   addUser.jsp\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44  \u0026lt;%@ page contentType=\u0026#34;text/html;charset=UTF-8\u0026#34; language=\u0026#34;java\u0026#34; %\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;Title\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;form action=\u0026#34;/hello/add\u0026#34; method=\u0026#34;post\u0026#34;\u0026gt; \u0026lt;table\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;编号：\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;id\u0026#34; /\u0026gt; \u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;姓名：\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;name\u0026#34; /\u0026gt; \u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;地址编号：\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;address.code\u0026#34; /\u0026gt; \u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;地址信息：\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;address.value\u0026#34; /\u0026gt; \u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt; \u0026lt;input type=\u0026#34;submit\u0026#34; value=\u0026#34;提交\u0026#34; /\u0026gt; \u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/table\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;   handler\n1 2 3 4 5  RequestMapping(value = \u0026#34;/add\u0026#34;,method = RequestMethod.POST) public String add(User user){ System.out.println(user); return \u0026#34;index\u0026#34;; }   ","date":"2021-04-08T13:36:41Z","image":"https://ahao.ink/32.jpg","permalink":"https://ahao.ink/posts/spring-mvc/","title":"Spring MVC"},{"content":"Spring 简介 前言 “Spring 真的那么有用吗？”\n首先 Spring 可谓是大名鼎鼎，如雷贯耳。而关于 Spring 的文章、书籍、教程更是数不胜数。可以说 Spring 贯穿我们的整个职业生涯，是框架界的常青树。那么我们这个专题专门来聊一聊： 到底 Spring 是什么，它的特点优势是什么，我们项目的开发为什么选择 Spring，它能帮助我们解决哪些问题？\n带着疑问，开始我们的专题。\nSpring 概述 先搞清楚 Spring 的概念： 官网定义：\nSpring 框架为任何类型的部署平台上的基于 Java 的现代企业应用程序提供了全面的编程和配置模型。\nSpring 的一个关键元素是在应用程序级别的基础架构支持：Spring 专注于企业应用程序的 “管道”，以便团队可以专注于应用程序级别的业务逻辑，而不必与特定的部署环境建立不必要的联系。\n通俗解释：\n简单来说：Spring 是一个免费开源框架，为了简化企业级项目开发，提供全面的开发部署解决方案。\n疑问导出：\n看到这儿，我们明白了一件事：Spring 是帮助我们开发项目的，使用起来很方便。\n那么问题来了：Spring 为了简化项目开发到底做了哪些事情？\n知识入门 Spring 核心功能 Spring 到底如何简化我们的项目开发呢？首先，来了解下 Spring 的体系结构。\nSpring 的体系结构介绍 结构图阐释：\n 左上角勾画出负责持久层的部分，是 Spring 对数据持久化，事务管理，支持的功能框架。大家听过的 SpringDataJpa 就是其中的一种； 右上角勾画出是负责表现层的部分，是 Spring 对于表现层数据的处理部分的支持，比如：大家听说过的 SpirngMVC 就是其中的一种； 最底部的负责测试的部分 是 Spring 对于项目的测试 提供了完整的一个测试环境支持； 而中间的两部分 是我们大家常常俗称的 Spring 框架。  疑问导出：\n看到这里大家可能会明白一点， Spring 其实是一个 “大家族”。从表现层、业务层、持久层，它都有对应的支持，而我们在框架学习的部分其实主要是使用了它中间的两个部分的核心功能。\n那么，Spring 核心功能到底是什么呢？\nSpring 的核心功能 大家对于使用 Spring 框架开发项目已经司空见惯了… 但是对于它的功能或者作用，描述出来总是差点什么，那么现在咱们详细聊一聊它的核心功能。\n核心功能：\n 控制反转（IoC）： 简单理解 IoC 是一种设计模式，将实例化对象的控制权 由手动的 new 变成了 Spring 框架通过反射机制实例化； 依赖注入（DI）： 首先理解依赖，程序运行的需要可以称之为依赖。由于 Spring 框架通过反射技术实例化了对象，并将对象的实例存入在容器进行管理。那么如果一个类中的属性为某个其余的类，属性无需手动赋值，通过 spring 的配置文件，或者 Spring 提供的注解，通过 spring 框架可以实现直接注入属性； 面向切面编程 （AOP）： 何谓切面，切面是数学中的一个概念，表示只有一个点接触到球体的一个平面称呼为切面，而接触点称呼为切点。那么在 Spring 中，切面编程指的就是在程序运行某个方法的时候，不修改原始执行代码逻辑，由程序动态地执行某些额外的功能，对原有的方法做增强，这就叫做面向切面编程，那个被监测的执行方法，称呼为切入点。  知识小结：\nSpring 是分层的 Java SE/EE 应用 轻量级开源框架，以 IoC（Inverse of Control：控制反转）和 AOP（Aspect Oriented Programming：面向切面编程）为内核，提供了展现层 Spring MVC 和持久层 Spring JDBC 以及业务层事务管理等众多的企业级应用技术，还能整合开源世界众多 著名的第三方框架和类库， 是使用最多的 Java EE 企业应用开源框架。\n使用 Spring 的意义在于：对于 bean 对象的实例管理更加方便，代码编写更加优雅，降低代码的耦合性，提升代码的扩展性。\nSpring 的优势 Spring 的概念和功能了解以后，下面谈谈它的优势在哪\n Spring 简化项目开发 ： Spring 灵活全面的扩展功能，使我们开发项目如鱼得水 。通过 Spring 提供的 IoC 容器，可以将对象间的依赖关系交由 Spring 进行控制，避免硬编码所造成的过度程序耦合。用户也不必再为单例模式类、属性文件解析等这些很底层的需求编写代码，可以更专注于上层的应用； Spring 的面向切面编程 ：Spirng 框架的 AOP 面向切面编程，极大地提高了程序的扩展性，支持开发人员实现对程序的自定义增强。同时可以方便地使用 Spring 提供的事务管理； 面向接口编程： 面向接口编程 降低代码的耦合性，同时也提高了代码的扩展性； 测试方便：对于测试的支持 有很多的组件实现； 方便集成第三方框架 Spring 可以降低各种框架的使用难度，提供了对各种优秀框架（Struts、Hibernate、Hessian、Quartz 等）的直接支持。  小结 本节主要对于 Spring 框架做了入门介绍，通过本节的学习，我们应该知道以下几点：\n Spring 框架的概念； Spring 框架的意义； Spring 框架的体系结构； Spring 框架的核心功能； Spring 框架的优势；  Spring 工程的搭建 前言 “Spring 的工程如何创建？”\n在上一节中我们通过 Spring 的简介，了解了 Spring 的概念、体系结构、与它的核心功能。那么本章带你体验一下 Spring 的项目开发和我们之前搭建过的开发项目有哪些不同。\nSpring 框架版本介绍与依赖引入 版本历史 Spring 诞生到现在经历太多的历史版本，有的已经消失在历史长河中了… 我们选择最新的版本给大家进行案例讲解。\n 5.2.x 是最新的生产线（通常于 2019 年 9 月下旬提供）； 5.1.x 是之前的生产线（自 2018 年 9 月以来），一直得到积极支持，直到 2020 年底； 5.0.x 于 2019 年第二季度进入 EOL 阶段。出于对 5.0.x 用户的礼貌，我们将在 2020 年 1 月之前提供主动维护，并在 2020 年底之前提供安全补丁（如果需要）； 4.3.x 是第四代的最后一个功能分支。它具有延长的维护期限，直到 2020 年 1 月，并且安全补丁甚至超过了这一点。4.3.x 将于 2020 年 12 月 31 日达到其正式停产（停产）； 截至 2016 年 12 月 31 日，3.2.x 属于产品停产（寿命终止）。该产品线中没有计划进一步的维护版本和安全补丁。请尽快迁移到 4.3 或 5.x。  我们建议从 Maven Central 升级到最新的 Spring Framework 5.2.x 版本。\n以上是官网列出 Spring 的历史版本介绍，我们采用的是 5.2.2 版本，对应的 jdk 最少是 jdk 1.8 ，我相信大家的 jdk 一般来讲都是满足要求的。\nSpring 框架源码下载 下载方式：\n 下载源码文件 。 Spring 的源码下载地址 ： https://github.com/spring-projects/spring-framework/releases 第二种是使用 maven 的坐标方式 。 maven 的 pom 文件坐标。  1 2 3 4 5  \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-context\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.2.2.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt;   工程创建 准备好依赖之后 废话不多说，我们开始撸代码 。\n使用 IDEA 创建 Web 工程 开发工具选择 idea ，创建 Maven 的 jar 工程即可。因为涉及不到浏览器的请求，所以无需创建 web 工程。\n创建 Maven 工程 。\n补全坐标信息。\n继续下一步 finish 完成创建即可。\n引入项目使用的坐标依赖 将准备好的坐标信息粘贴到工程下 pom 文件中 。 看下图：\n编写 Spring 框架使用的配置文件 坐标有了之后，说明我们的工程中已经引入了 Spring 框架的依赖。点开左侧的 External Libraries 查看一下 。\n那么看到上面的 jar 包列表，表示 Spring 框架中的基本依赖我们已经成功引入。接下来：既然我们使用的是框架，框架是一个半成品，已经封装好了很多功能提供我们使用，而我们如何让他们工作呢？ 这里需要一个和 Spirng 框架通信的桥梁 —Spring 框架的核心配置文件。\n小提示： 文件的名称可以随便起，一般习惯使用 applicationContext.xml。 文件的位置放在哪里呢？ maven 工程需要放在 src 下面的 resources 下面，如下图：\n那么配置文件是空的，不要着急。到底应该配置什么，不是自己臆想猜测的。 如果你已经下载了源码，那么解压缩它，打开 docs\\spring-framework-reference 目录，打开 core.html 查看官方文档， 下图： 将上面的实例配置信息拷贝到我们的配置文件中，它只是给了最基本的配置头信息，内容部分 针对 bean 做初始化的部分 需要我们自行填充 。\n1 2 3 4 5 6 7 8  \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;beans xmlns=\u0026#34;http://www.springframework.org/schema/beans\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\u0026#34;\u0026gt; \u0026lt;/beans\u0026gt;   编写代码测试 准备好工程后，编写我们的代码。\n编写接口和接口的实现类 代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12  //接口的代码 public interface UserService { public void saveUser(); } //实现类的代码 public class UserServiceImpl implements UserService { public void saveUser() { System.out.println(\u0026#34;service的save方法执行了\u0026#34;); } }   补充 Spring 的配置文件 配置文件的目的是将我们自定义的实现类交给 Spring 的容器管理。因为 Spring 框架核心功能之一就是 IoC 控制反转，目的是将对象实例化的动作交给容器。还记得第一节介绍的吗？不记得了？走你，剩下的我们继续。最终 Spring 的配置文件如下:\n1 2 3 4 5 6 7 8 9 10 11  \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;beans xmlns=\u0026#34;http://www.springframework.org/schema/beans\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xmlns:util=\u0026#34;http://www.springframework.org/schema/util\u0026#34; xsi:schemaLocation=\u0026#34; http://www.springframework.org/schema/beans https://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/util https://www.springframework.org/schema/util/spring-util.xsd\u0026#34;\u0026gt; \u0026lt;!-- 此标签的作用 是实例化UserServiceImpl类的实例 交给 Spring 容器 --\u0026gt; \u0026lt;bean id=\u0026#34;userService\u0026#34; class=\u0026#34;com.wyan.service.impl.UserServiceImpl\u0026#34;\u0026gt;\u0026lt;/bean\u0026gt; \u0026lt;/beans\u0026gt;   测试结果 从容器中获取对象实例，调用提供的方法\n1 2 3 4 5 6 7 8 9  public class DemoTest { public static void main(String[] args) { ApplicationContext context = new ClassPathXmlApplicationContext(\u0026#34;classpath:applicationContext.xml\u0026#34;); UserService service = (UserService) context.getBean(\u0026#34;userService\u0026#34;); service.saveUser(); } }   解释：\n ApplicationContext 是 Spring 框架提供的一个接口，目前只需要知道它是作为存储实例化 bean 对象的容器即可。下一节我们会细讲。 context.getBean () 方法是通过配置文件中声明的 bean 标签 id 属性获取容器内的实例。  最终结果如下： 可以看到控制台打印输出 证明确实从容器中获取到了 userService 的实例。入门就是如此简单…\n小结 技术之路很简单 一是思路步骤清晰，二就是代码的熟练度。 先理清入门示例的步骤 ：\n 创建 Maven 工程； 导入 Spring 的依赖； 编写 Spring 的配置文件； 编写测试的代码。  Spring 工程执行过程 前言 Spring 框架是如何工作的？\n本节目的在于帮助大家理解 Spring 框架底层干了什么事情。\n在上一节中我们通过一个入门工程简单地体验了一把 Spring 的使用。\n我们发现，通过构造一个 ClassPathXmlApplicationContext 对象，加载项目的 applicationContext.xml 文件，确实可以实例化对象。\n疑问导出\n而脑海中不禁有一个想法… Spring 如何初始化对象的实例的？我们又如何从容器中获取得到对象的实例的呢？\n带着疑问… 开启本节的源码和原理之旅。\n容器初始化 回顾代码：\n1 2 3 4 5 6  public static void main(String[] args) { ApplicationContext context = new ClassPathXmlApplicationContext(\u0026#34;applicationContext.xml\u0026#34;); UserService service = (UserService) context.getBean(\u0026#34;userService\u0026#34;); service.saveUser(); }   在上面的代码中可以得知 Spring 的容器是 ApplicationContext，那么它到底是什么东西呢？先跟我一起追踪一下它的角色。 官方文档 通俗解释\n简单翻译过来就是 ApplicationContext 是一个接口，是 BeanFactory 这个接口的子接口，它扩展了 BeanFactory 这个接口，提供了额外附加的功能。 而 BeanFactory 是管理 bean 对象的容器的根接口，大家了解下就好，我们是针对它的子接口 ClassPathXmlApplicationContext 做的实例化，目的是加载项目中的 Spring 的配置文件，使 Spring 来管理我们定义的 bean 对象。\n疑问导出 那么我们的问题是…ClassPathXmlApplicationContext 对象实例化之后，干了哪些事情呢？\n容器初始化执行动作 applicationContext 实例化执行代码逻辑 。 我们追踪下源码，发现 ClassPathXmlApplicationContext 初始化的时候，它做了一系列的事情。源码如下：\n代码解释：\n 是初始化 ClassPathXmlApplicationContext 对象执行的有参构造； 加载项目下的 xml 配置文件； 调用 refresh 刷新容器的方法 bean 的实例化就在这个方法中。  继续跟踪：\n容器初始化 bean 对象动作 下面是从源码中粘贴的部分代码\n步骤阐述：\n 1 的位置：是准备刷新，那么 Spring 只是设置刷新的标记，加载了外部的 properties 属性文件； 2 的位置：是准备 bean 工厂对象； 3 的位置：这一步骤就加载了配置文件中的所有 bean 标签，但是并没有对他们进行实例化； 4 的位置：完成此上下文的 bean 工厂的初始化，初始化所有剩余的单例 bean。（Spring 中默认加载的 bean 就是单例模式后面生命周期会讲） 最后的位置：完成容器的刷新，也就是所有的 bean 初始化完成。  1 2 3 4 5 6 7 8  //这里粘贴一部分初始化代码的逻辑 帮助大家理解 \t// Instantiate all remaining (non-lazy-init) singletons. \tbeanFactory.preInstantiateSingletons(); // Trigger initialization of all non-lazy singleton beans... \t//所有非懒加载的单例bean的触发器初始化。。。 \tfor (String beanName : beanNames) { ...//省略循环的代码 \t}   OK 上面就是加载配置文件后 Spring 框架做的所有事情，当然实际底层涉及的东西 更多，但是我们没有必要深究，毕竟我们是理解过程，不是追求实现。\n疑问导出：\n我们整理了 Spring 初始化 bean 对象的过程，那么如果容器中确实存在了 bean 的实例，我们是如何获取得到的呢？\n容器中获取对象的过程 还是先看下我们获取容器对象的代码：\n1 2 3 4 5 6  public static void main(String[] args) { ApplicationContext context = new ClassPathXmlApplicationContext(\u0026#34;classpath:applicationContext.xml\u0026#34;); UserService service = (UserService) context.getBean(\u0026#34;userService\u0026#34;); service.saveUser(); }   代码分析：\ncontext.getBean 的方法是通过 bean 标签里的 id 来从容器中获取，那么我们看下源码 ： 在父类 AbstractApplicationContext 中有对 getBean 方法的实现。\n1 2 3 4 5  @Override public Object getBean(String name) throws BeansException { assertBeanFactoryActive(); return getBeanFactory().getBean(name); }   追踪父类方法 最终通过我们层层追踪，我们在 AbstractAutowireCapableBeanFactory 中发现这样的一段代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  protected Object doCreateBean(final String beanName, final RootBeanDefinition mbd, final @Nullable Object[] args) throws BeanCreationException { //... \t//省略大量方法内部代码  //... \t// Initialize the bean instance. \tObject exposedObject = bean; try { //给实例中的属性赋值 \tpopulateBean(beanName, mbd, instanceWrapper); //真实实例化对象 \texposedObject = initializeBean(beanName, exposedObject, mbd); } //...  //继续省略大量方法  //... \t// Register bean as disposable. \ttry { //将实例化后的对象放入容器中 \tregisterDisposableBeanIfNecessary(beanName, bean, mbd); } catch (BeanDefinitionValidationException ex) { throw new BeanCreationException( mbd.getResourceDescription(), beanName, \u0026#34;Invalid destruction signature\u0026#34;, ex); } //返回实例化后的对象实例 \treturn exposedObject; }   上面源码中我们可以看到： 对象实例的获取好像是在获取的时候执行的 doCreateBean，那么之前记载的 xml 文件不是实例过了吗？稍微解释下：加载文件时候的实例化操作，其实是实例化了一个 Spring 框架提供的对象，作用是对于我们 bean 对象做描述，这里才是真实的实例化动作。我们再看看 registerDisposableBeanIfNecessary 这个方法做的是什么。\n1 2 3 4 5  public void registerDisposableBean(String beanName, DisposableBean bean) { synchronized (this.disposableBeans) { this.disposableBeans.put(beanName, bean); } }   结论： 一切真相大白。它其实就是一个 map 集合 ，这个 map 集合的 key 就是我们定义的 bean 的 id 或者 bean 的 name ，那么值就是对象的实例。\n小结 本节带着大家梳理了一下 Spring 初始化 bean 和获取 bean 的流程：\n Spring 框架通过 ResourceLoader 加载项目的 xml 配置文件； 读取 xml 的配置信息 变成对象存储，但未实例化； 通过 bean 工厂处理器对 bean 做实例化，存储到一个 map 集合中默认是单例； 获取对象 通过 xml 文件中 bean 的 id 从 map 集合中通过 get (key) 获取。  ","date":"2021-04-08T13:36:41Z","image":"https://ahao.ink/28.jpg","permalink":"https://ahao.ink/posts/spring-%E5%85%A5%E9%97%A8/","title":"Spring 入门"},{"content":"线程池原理 为什么要使用线程池 使用线程池主要有以下三个原因：\n 创建/销毁线程需要消耗系统资源，线程池可以复用已创建的线程。 控制并发的数量。并发数量过多，可能会导致资源消耗过多，从而造成服务器崩溃。（主要原因） 可以对线程做统一管理。  线程池的原理 Java中的线程池顶层接口是Executor接口，ThreadPoolExecutor是这个接口的实现类。\n我们先看看ThreadPoolExecutor类。\nThreadPoolExecutor提供的构造方法 一共有四个构造方法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  // 五个参数的构造函数 public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue\u0026lt;Runnable\u0026gt; workQueue) // 六个参数的构造函数-1 public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue\u0026lt;Runnable\u0026gt; workQueue, ThreadFactory threadFactory) // 六个参数的构造函数-2 public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue\u0026lt;Runnable\u0026gt; workQueue, RejectedExecutionHandler handler) // 七个参数的构造函数 public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue\u0026lt;Runnable\u0026gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler)   涉及到5~7个参数，我们先看看必须的5个参数是什么意思：\n  int corePoolSize：该线程池中核心线程数最大值\n 核心线程：线程池中有两类线程，核心线程和非核心线程。核心线程默认情况下会一直存在于线程池中，即使这个核心线程什么都不干（铁饭碗），而非核心线程如果长时间的闲置，就会被销毁（临时工）。\n   int maximumPoolSize：该线程池中线程总数最大值 。\n 该值等于核心线程数量 + 非核心线程数量。\n   long keepAliveTime：非核心线程闲置超时时长。\n 非核心线程如果处于闲置状态超过该值，就会被销毁。如果设置allowCoreThreadTimeOut(true)，则会也作用于核心线程。\n   TimeUnit unit：keepAliveTime的单位。\n  TimeUnit是一个枚举类型 ，包括以下属性：\n NANOSECONDS ： 1微毫秒 = 1微秒 / 1000 MICROSECONDS ： 1微秒 = 1毫秒 / 1000 MILLISECONDS ： 1毫秒 = 1秒 /1000 SECONDS ： 秒 MINUTES ： 分 HOURS ： 小时 DAYS ： 天\n   BlockingQueue workQueue：阻塞队列，维护着等待执行的Runnable任务对象。\n常用的几个阻塞队列：\n  LinkedBlockingQueue\n链式阻塞队列，底层数据结构是链表，默认大小是Integer.MAX_VALUE，也可以指定大小。\n  ArrayBlockingQueue\n数组阻塞队列，底层数据结构是数组，需要指定队列的大小。\n  SynchronousQueue\n同步队列，内部容量为0，每个put操作必须等待一个take操作，反之亦然。\n  DelayQueue\n延迟队列，该队列中的元素只有当其指定的延迟时间到了，才能够从队列中获取到该元素 。\n     我们将在下一章中重点介绍各种阻塞队列\n 好了，介绍完5个必须的参数之后，还有两个非必须的参数。\n  ThreadFactory threadFactory\n创建线程的工厂 ，用于批量创建线程，统一在创建线程时设置一些参数，如是否守护线程、线程的优先级等。如果不指定，会新建一个默认的线程工厂。\n  1 2 3 4 5 6 7 8 9 10 11 12 13 14  static class DefaultThreadFactory implements ThreadFactory { // 省略属性  // 构造函数  DefaultThreadFactory() { SecurityManager s = System.getSecurityManager(); group = (s != null) ? s.getThreadGroup() : Thread.currentThread().getThreadGroup(); namePrefix = \u0026#34;pool-\u0026#34; + poolNumber.getAndIncrement() + \u0026#34;-thread-\u0026#34;; } // 省略 }     RejectedExecutionHandler handler\n拒绝处理策略，线程数量大于最大线程数就会采用拒绝处理策略，四种拒绝处理的策略为 ：\n ThreadPoolExecutor.AbortPolicy：默认拒绝处理策略，丢弃任务并抛出RejectedExecutionException异常。 ThreadPoolExecutor.DiscardPolicy：丢弃新来的任务，但是不抛出异常。 ThreadPoolExecutor.DiscardOldestPolicy：丢弃队列头部（最旧的）的任务，然后重新尝试执行程序（如果再次失败，重复此过程）。 ThreadPoolExecutor.CallerRunsPolicy：由调用线程处理该任务。    ThreadPoolExecutor的策略 线程池本身有一个调度线程，这个线程就是用于管理布控整个线程池里的各种任务和事务，例如创建线程、销毁线程、任务队列管理、线程队列管理等等。\n故线程池也有自己的状态。ThreadPoolExecutor类中使用了一些final int常量变量来表示线程池的状态 ，分别为RUNNING、SHUTDOWN、STOP、TIDYING 、TERMINATED。\n1 2 3 4 5 6  // runState is stored in the high-order bits private static final int RUNNING = -1 \u0026lt;\u0026lt; COUNT_BITS; private static final int SHUTDOWN = 0 \u0026lt;\u0026lt; COUNT_BITS; private static final int STOP = 1 \u0026lt;\u0026lt; COUNT_BITS; private static final int TIDYING = 2 \u0026lt;\u0026lt; COUNT_BITS; private static final int TERMINATED = 3 \u0026lt;\u0026lt; COUNT_BITS;     线程池创建后处于RUNNING状态。\n  调用shutdown()方法后处于SHUTDOWN状态，线程池不能接受新的任务，清除一些空闲worker,会等待阻塞队列的任务完成。\n  调用shutdownNow()方法后处于STOP状态，线程池不能接受新的任务，中断所有线程，阻塞队列中没有被执行的任务全部丢弃。此时，poolsize=0,阻塞队列的size也为0。\n  当所有的任务已终止，ctl记录的”任务数量”为0，线程池会变为TIDYING状态。接着会执行terminated()函数。\n ThreadPoolExecutor中有一个控制状态的属性叫ctl，它是一个AtomicInteger类型的变量。线程池状态就是通过AtomicInteger类型的成员变量ctl来获取的。\n获取的ctl值传入runStateOf方法，与~CAPACITY位与运算(CAPACITY是低29位全1的int变量)。\n~CAPACITY在这里相当于掩码，用来获取ctl的高3位，表示线程池状态；而另外的低29位用于表示工作线程数\n   线程池处在TIDYING状态时，执行完terminated()方法之后，就会由 TIDYING -\u0026gt; TERMINATED， 线程池被设置为TERMINATED状态。\n  线程池主要的任务处理流程 处理任务的核心方法是execute，我们看看 JDK 1.8 源码中ThreadPoolExecutor是如何处理线程任务的：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  // JDK 1.8 public void execute(Runnable command) { if (command == null) throw new NullPointerException(); int c = ctl.get(); // 1.当前线程数小于corePoolSize,则调用addWorker创建核心线程执行任务  if (workerCountOf(c) \u0026lt; corePoolSize) { if (addWorker(command, true)) return; c = ctl.get(); } // 2.如果不小于corePoolSize，则将任务添加到workQueue队列。  if (isRunning(c) \u0026amp;\u0026amp; workQueue.offer(command)) { int recheck = ctl.get(); // 2.1 如果isRunning返回false(状态检查)，则remove这个任务，然后执行拒绝策略。  if (! isRunning(recheck) \u0026amp;\u0026amp; remove(command)) reject(command); // 2.2 线程池处于running状态，但是没有线程，则创建线程  else if (workerCountOf(recheck) == 0) addWorker(null, false); } // 3.如果放入workQueue失败，则创建非核心线程执行任务，  // 如果这时创建非核心线程失败(当前线程总数不小于maximumPoolSize时)，就会执行拒绝策略。  else if (!addWorker(command, false)) reject(command); }   ctl.get()是获取线程池状态，用int类型表示。第二步中，入队前进行了一次isRunning判断，入队之后，又进行了一次isRunning判断。\n为什么要二次检查线程池的状态?\n在多线程的环境下，线程池的状态是时刻发生变化的。很有可能刚获取线程池状态后线程池状态就改变了。判断是否将command加入workqueue是线程池之前的状态。倘若没有二次检查，万一线程池处于非RUNNING状态（在多线程环境下很有可能发生），那么command永远不会执行。\n总结一下处理流程\n 线程总数量 \u0026lt; corePoolSize，无论线程是否空闲，都会新建一个核心线程执行任务（让核心线程数量快速达到corePoolSize，在核心线程数量 \u0026lt; corePoolSize时）。注意，这一步需要获得全局锁。 线程总数量 \u0026gt;= corePoolSize时，新来的线程任务会进入任务队列中等待，然后空闲的核心线程会依次去缓存队列中取任务来执行（体现了线程复用）。 当缓存队列满了，说明这个时候任务已经多到爆棚，需要一些“临时工”来执行这些任务了。于是会创建非核心线程去执行这个任务。注意，这一步需要获得全局锁。 缓存队列满了， 且总线程数达到了maximumPoolSize，则会采取上面提到的拒绝策略进行处理。  整个过程如图所示：\nThreadPoolExecutor如何做到线程复用的？ 我们知道，一个线程在创建的时候会指定一个线程任务，当执行完这个线程任务之后，线程自动销毁。但是线程池却可以复用线程，即一个线程执行完线程任务后不销毁，继续执行另外的线程任务。那么，线程池如何做到线程复用呢？\n原来，ThreadPoolExecutor在创建线程时，会将线程封装成工作线程worker,并放入工作线程组中，然后这个worker反复从阻塞队列中拿任务去执行。话不多说，我们继续看看源码（一定要仔细看，前后有联系）\n这里的addWorker方法是在上面提到的execute方法里面调用的，先看看上半部分：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  // ThreadPoolExecutor.addWorker方法源码上半部分 private boolean addWorker(Runnable firstTask, boolean core) { retry: for (;;) { int c = ctl.get(); int rs = runStateOf(c); // Check if queue empty only if necessary.  if (rs \u0026gt;= SHUTDOWN \u0026amp;\u0026amp; ! (rs == SHUTDOWN \u0026amp;\u0026amp; firstTask == null \u0026amp;\u0026amp; ! workQueue.isEmpty())) return false; for (;;) { int wc = workerCountOf(c); if (wc \u0026gt;= CAPACITY || // 1.如果core是ture,证明需要创建的线程为核心线程，则先判断当前线程是否大于核心线程  // 如果core是false,证明需要创建的是非核心线程，则先判断当前线程数是否大于总线程数  // 如果不小于，则返回false  wc \u0026gt;= (core ? corePoolSize : maximumPoolSize)) return false; if (compareAndIncrementWorkerCount(c)) break retry; c = ctl.get(); // Re-read ctl  if (runStateOf(c) != rs) continue retry; // else CAS failed due to workerCount change; retry inner loop  } }   上半部分主要是判断线程数量是否超出阈值，超过了就返回false。我们继续看下半部分:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44  // ThreadPoolExecutor.addWorker方法源码下半部分  boolean workerStarted = false; boolean workerAdded = false; Worker w = null; try { // 1.创建一个worker对象  w = new Worker(firstTask); // 2.实例化一个Thread对象  final Thread t = w.thread; if (t != null) { // 3.线程池全局锁  final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { // Recheck while holding lock.  // Back out on ThreadFactory failure or if  // shut down before lock acquired.  int rs = runStateOf(ctl.get()); if (rs \u0026lt; SHUTDOWN || (rs == SHUTDOWN \u0026amp;\u0026amp; firstTask == null)) { if (t.isAlive()) // precheck that t is startable  throw new IllegalThreadStateException(); workers.add(w); int s = workers.size(); if (s \u0026gt; largestPoolSize) largestPoolSize = s; workerAdded = true; } } finally { mainLock.unlock(); } if (workerAdded) { // 4.启动这个线程  t.start(); workerStarted = true; } } } finally { if (! workerStarted) addWorkerFailed(w); } return workerStarted; }   创建worker对象，并初始化一个Thread对象，然后启动这个线程对象。\n我们接着看看Worker类，仅展示部分源码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  // Worker类部分源码 private final class Worker extends AbstractQueuedSynchronizer implements Runnable{ final Thread thread; Runnable firstTask; Worker(Runnable firstTask) { setState(-1); // inhibit interrupts until runWorker  this.firstTask = firstTask; this.thread = getThreadFactory().newThread(this); } public void run() { runWorker(this); } //其余代码略... }   Worker类实现了Runnable接口，所以Worker也是一个线程任务。在构造方法中，创建了一个线程，线程的任务就是自己。故addWorker方法调用addWorker方法源码下半部分中的第4步t.start，会触发Worker类的run方法被JVM调用。\n我们再看看runWorker的逻辑：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52  // Worker.runWorker方法源代码 final void runWorker(Worker w) { Thread wt = Thread.currentThread(); Runnable task = w.firstTask; w.firstTask = null; // 1.线程启动之后，通过unlock方法释放锁  w.unlock(); // allow interrupts  boolean completedAbruptly = true; try { // 2.Worker执行firstTask或从workQueue中获取任务，如果getTask方法不返回null,循环不退出  while (task != null || (task = getTask()) != null) { // 2.1进行加锁操作，保证thread不被其他线程中断（除非线程池被中断）  w.lock(); // If pool is stopping, ensure thread is interrupted;  // if not, ensure thread is not interrupted. This  // requires a recheck in second case to deal with  // shutdownNow race while clearing interrupt  // 2.2检查线程池状态，倘若线程池处于中断状态，当前线程将中断。  if ((runStateAtLeast(ctl.get(), STOP) || (Thread.interrupted() \u0026amp;\u0026amp; runStateAtLeast(ctl.get(), STOP))) \u0026amp;\u0026amp; !wt.isInterrupted()) wt.interrupt(); try { // 2.3执行beforeExecute  beforeExecute(wt, task); Throwable thrown = null; try { // 2.4执行任务  task.run(); } catch (RuntimeException x) { thrown = x; throw x; } catch (Error x) { thrown = x; throw x; } catch (Throwable x) { thrown = x; throw new Error(x); } finally { // 2.5执行afterExecute方法  afterExecute(task, thrown); } } finally { task = null; w.completedTasks++; // 2.6解锁操作  w.unlock(); } } completedAbruptly = false; } finally { processWorkerExit(w, completedAbruptly); } }   首先去执行创建这个worker时就有的任务，当执行完这个任务后，worker的生命周期并没有结束，在while循环中，worker会不断地调用getTask方法从阻塞队列中获取任务然后调用task.run()执行任务,从而达到复用线程的目的。只要getTask方法不返回null,此线程就不会退出。\n当然，核心线程池中创建的线程想要拿到阻塞队列中的任务，先要判断线程池的状态，如果STOP或者TERMINATED，返回null。\n最后看看getTask方法的实现:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48  // Worker.getTask方法源码 private Runnable getTask() { boolean timedOut = false; // Did the last poll() time out?  for (;;) { int c = ctl.get(); int rs = runStateOf(c); // Check if queue empty only if necessary.  if (rs \u0026gt;= SHUTDOWN \u0026amp;\u0026amp; (rs \u0026gt;= STOP || workQueue.isEmpty())) { decrementWorkerCount(); return null; } int wc = workerCountOf(c); // Are workers subject to culling?  // 1.allowCoreThreadTimeOut变量默认是false,核心线程即使空闲也不会被销毁  // 如果为true,核心线程在keepAliveTime内仍空闲则会被销毁。  boolean timed = allowCoreThreadTimeOut || wc \u0026gt; corePoolSize; // 2.如果运行线程数超过了最大线程数，但是缓存队列已经空了，这时递减worker数量。 　// 如果有设置允许线程超时或者线程数量超过了核心线程数量，  // 并且线程在规定时间内均未poll到任务且队列为空则递减worker数量  if ((wc \u0026gt; maximumPoolSize || (timed \u0026amp;\u0026amp; timedOut)) \u0026amp;\u0026amp; (wc \u0026gt; 1 || workQueue.isEmpty())) { if (compareAndDecrementWorkerCount(c)) return null; continue; } try { // 3.如果timed为true(想想哪些情况下timed为true),则会调用workQueue的poll方法获取任务.  // 超时时间是keepAliveTime。如果超过keepAliveTime时长，  // poll返回了null，上边提到的while循序就会退出，线程也就执行完了。  // 如果timed为false（allowCoreThreadTimeOut为falsefalse  // 且wc \u0026gt; corePoolSize为false），则会调用workQueue的take方法阻塞在当前。  // 队列中有任务加入时，线程被唤醒，take方法返回任务，并执行。  Runnable r = timed ? workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) : workQueue.take(); if (r != null) return r; timedOut = true; } catch (InterruptedException retry) { timedOut = false; } } }   核心线程的会一直卡在workQueue.take方法，被阻塞并挂起，不会占用CPU资源，直到拿到Runnable 然后返回（当然如果allowCoreThreadTimeOut设置为true,那么核心线程就会去调用poll方法，因为poll可能会返回null,所以这时候核心线程满足超时条件也会被销毁）。\n非核心线程会workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) ，如果超时还没有拿到，下一次循环判断compareAndDecrementWorkerCount就会返回null,Worker对象的run()方法循环体的判断为null,任务结束，然后线程被系统回收 。\n源码解析完毕，你理解的源码是否和图中的处理流程一致？如果不一致，那么就多看两遍吧，加油。\n四种常见的线程池 Executors类中提供的几个静态方法来创建线程池。大家到了这一步，如果看懂了前面讲的ThreadPoolExecutor构造方法中各种参数的意义，那么一看到Executors类中提供的线程池的源码就应该知道这个线程池是干嘛的。\nnewCachedThreadPool 1 2 3 4 5  public static ExecutorService newCachedThreadPool() { return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue\u0026lt;Runnable\u0026gt;()); }   CacheThreadPool的运行流程如下：\n 提交任务进线程池。 因为corePoolSize为0的关系，不创建核心线程，线程池最大为Integer.MAX_VALUE。 尝试将任务添加到SynchronousQueue队列。 如果SynchronousQueue入列成功，等待被当前运行的线程空闲后拉取执行。如果当前没有空闲线程，那么就创建一个非核心线程，然后从SynchronousQueue拉取任务并在当前线程执行。 如果SynchronousQueue已有任务在等待，入列操作将会阻塞。  当需要执行很多短时间的任务时，CacheThreadPool的线程复用率比较高， 会显著的提高性能。而且线程60s后会回收，意味着即使没有任务进来，CacheThreadPool并不会占用很多资源。\nnewFixedThreadPool 1 2 3 4 5  public static ExecutorService newFixedThreadPool(int nThreads) { return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue\u0026lt;Runnable\u0026gt;()); }   核心线程数量和总线程数量相等，都是传入的参数nThreads，所以只能创建核心线程，不能创建非核心线程。因为LinkedBlockingQueue的默认大小是Integer.MAX_VALUE，故如果核心线程空闲，则交给核心线程处理；如果核心线程不空闲，则入列等待，直到核心线程空闲。\n与CachedThreadPool的区别：\n 因为 corePoolSize == maximumPoolSize ，所以FixedThreadPool只会创建核心线程。 而CachedThreadPool因为corePoolSize=0，所以只会创建非核心线程。 在 getTask() 方法，如果队列里没有任务可取，线程会一直阻塞在 LinkedBlockingQueue.take() ，线程不会被回收。 CachedThreadPool会在60s后收回。 由于线程不会被回收，会一直卡在阻塞，所以没有任务的情况下， FixedThreadPool占用资源更多。 都几乎不会触发拒绝策略，但是原理不同。FixedThreadPool是因为阻塞队列可以很大（最大为Integer最大值），故几乎不会触发拒绝策略；CachedThreadPool是因为线程池很大（最大为Integer最大值），几乎不会导致线程数量大于最大线程数，故几乎不会触发拒绝策略。  newSingleThreadExecutor 1 2 3 4 5 6  public static ExecutorService newSingleThreadExecutor() { return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue\u0026lt;Runnable\u0026gt;())); }   有且仅有一个核心线程（ corePoolSize == maximumPoolSize=1），使用了LinkedBlockingQueue（容量很大），所以，不会创建非核心线程。所有任务按照先来先执行的顺序执行。如果这个唯一的线程不空闲，那么新来的任务会存储在任务队列里等待执行。\nnewScheduledThreadPool 创建一个定长线程池，支持定时及周期性任务执行。\n1 2 3 4 5 6 7 8 9 10  public static ScheduledExecutorService newScheduledThreadPool(int corePoolSize) { return new ScheduledThreadPoolExecutor(corePoolSize); } //ScheduledThreadPoolExecutor(): public ScheduledThreadPoolExecutor(int corePoolSize) { super(corePoolSize, Integer.MAX_VALUE, DEFAULT_KEEPALIVE_MILLIS, MILLISECONDS, new DelayedWorkQueue()); }   四种常见的线程池基本够我们使用了，但是《阿里巴巴开发手册》不建议我们直接使用Executors类中的线程池，而是通过ThreadPoolExecutor的方式，这样的处理方式让写的同学需要更加明确线程池的运行规则，规避资源耗尽的风险。\n但如果你及团队本身对线程池非常熟悉，又确定业务规模不会大到资源耗尽的程度（比如线程数量或任务队列长度可能达到Integer.MAX_VALUE）时，其实是可以使用JDK提供的这几个接口的，它能让我们的代码具有更强的可读性。\n阻塞队列 阻塞队列的由来 我们假设一种场景，生产者一直生产资源，消费者一直消费资源，资源存储在一个缓冲池中，生产者将生产的资源存进缓冲池中，消费者从缓冲池中拿到资源进行消费，这就是大名鼎鼎的生产者-消费者模式。\n该模式能够简化开发过程，一方面消除了生产者类与消费者类之间的代码依赖性，另一方面将生产数据的过程与使用数据的过程解耦简化负载。\n我们自己coding实现这个模式的时候，因为需要让多个线程操作共享变量（即资源），所以很容易引发线程安全问题，造成重复消费和死锁，尤其是生产者和消费者存在多个的情况。另外，当缓冲池空了，我们需要阻塞消费者，唤醒生产者；当缓冲池满了，我们需要阻塞生产者，唤醒消费者，这些个等待-唤醒逻辑都需要自己实现。（这块不明白的同学，可以看最下方结语部分的链接）\n这么容易出错的事情，JDK当然帮我们做啦，这就是阻塞队列(BlockingQueue)，你只管往里面存、取就行，而不用担心多线程环境下存、取共享变量的线程安全问题。\n BlockingQueue是Java util.concurrent包下重要的数据结构，区别于普通的队列，BlockingQueue提供了线程安全的队列访问方式，并发包下很多高级同步类的实现都是基于BlockingQueue实现的。\n BlockingQueue一般用于生产者-消费者模式，生产者是往队列里添加元素的线程，消费者是从队列里拿元素的线程。BlockingQueue就是存放元素的容器。\nBlockingQueue的操作方法 阻塞队列提供了四组不同的方法用于插入、移除、检查元素：\n   方法\\处理方式 抛出异常 返回特殊值 一直阻塞 超时退出     插入方法 add(e) offer(e) put(e) offer(e,time,unit)   移除方法 remove() poll() take() poll(time,unit)   检查方法 element() peek() - -     抛出异常：如果试图的操作无法立即执行，抛异常。当阻塞队列满时候，再往队列里插入元素，会抛出IllegalStateException(“Queue full”)异常。当队列为空时，从队列里获取元素时会抛出NoSuchElementException异常 。 返回特殊值：如果试图的操作无法立即执行，返回一个特殊值，通常是true / false。 一直阻塞：如果试图的操作无法立即执行，则一直阻塞或者响应中断。 超时退出：如果试图的操作无法立即执行，该方法调用将会发生阻塞，直到能够执行，但等待时间不会超过给定值。返回一个特定值以告知该操作是否成功，通常是 true / false。  注意之处\n 不能往阻塞队列中插入null,会抛出空指针异常。 可以访问阻塞队列中的任意元素，调用remove(o)可以将队列之中的特定对象移除，但并不高效，尽量避免使用。  BlockingQueue的实现类 ArrayBlockingQueue 由数组结构组成的有界阻塞队列。内部结构是数组，故具有数组的特性。\n1 2 3  public ArrayBlockingQueue(int capacity, boolean fair){ //..省略代码 }   可以初始化队列大小， 且一旦初始化不能改变。构造方法中的fair表示控制对象的内部锁是否采用公平锁，默认是非公平锁。\nLinkedBlockingQueue 由链表结构组成的有界阻塞队列。内部结构是链表，具有链表的特性。默认队列的大小是Integer.MAX_VALUE，也可以指定大小。此队列按照先进先出的原则对元素进行排序。\nDelayQueue 1 2 3  该队列中的元素只有当其指定的延迟时间到了，才能够从队列中获取到该元素 。注入其中的元素必须实现 java.util.concurrent.Delayed 接口。 DelayQueue是一个没有大小限制的队列，因此往队列中插入数据的操作（生产者）永远不会被阻塞，而只有获取数据的操作（消费者）才会被阻塞。   PriorityBlockingQueue 1  基于优先级的无界阻塞队列（优先级的判断通过构造函数传入的Compator对象来决定），内部控制线程同步的锁采用的是非公平锁。    网上大部分博客上PriorityBlockingQueue为公平锁，其实是不对的，查阅源码（感谢github:ambition0802同学的指出）：\n 1 2 3 4 5  public PriorityBlockingQueue(int initialCapacity, Comparator\u0026lt;? super E\u0026gt; comparator) { this.lock = new ReentrantLock(); //默认构造方法-非公平锁  ...//其余代码略  }   SynchronousQueue 这个队列比较特殊，没有任何内部容量，甚至连一个队列的容量都没有。并且每个 put 必须等待一个 take，反之亦然。\n需要区别容量为1的ArrayBlockingQueue、LinkedBlockingQueue。\n以下方法的返回值，可以帮助理解这个队列：\n iterator() 永远返回空，因为里面没有东西 peek() 永远返回null put() 往queue放进去一个element以后就一直wait直到有其他thread进来把这个element取走。 offer() 往queue里放一个element后立即返回，如果碰巧这个element被另一个thread取走了，offer方法返回true，认为offer成功；否则返回false。 take() 取出并且remove掉queue里的element，取不到东西他会一直等。 poll() 取出并且remove掉queue里的element，只有到碰巧另外一个线程正在往queue里offer数据或者put数据的时候，该方法才会取到东西。否则立即返回null。 isEmpty() 永远返回true remove()\u0026amp;removeAll() 永远返回false  注意\nPriorityBlockingQueue不会阻塞数据生产者（因为队列是无界的），而只会在没有可消费的数据时，阻塞数据的消费者。因此使用的时候要特别注意，生产者生产数据的速度绝对不能快于消费者消费数据的速度，否则时间一长，会最终耗尽所有的可用堆内存空间。对于使用默认大小的LinkedBlockingQueue也是一样的。\n阻塞队列的原理 阻塞队列的原理很简单，利用了Lock锁的多条件（Condition）阻塞控制。接下来我们分析ArrayBlockingQueue JDK 1.8 的源码。\n首先是构造器，除了初始化队列的大小和是否是公平锁之外，还对同一个锁（lock）初始化了两个监视器，分别是notEmpty和notFull。这两个监视器的作用目前可以简单理解为标记分组，当该线程是put操作时，给他加上监视器notFull,标记这个线程是一个生产者；当线程是take操作时，给他加上监视器notEmpty，标记这个线程是消费者。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  //数据元素数组 final Object[] items; //下一个待取出元素索引 int takeIndex; //下一个待添加元素索引 int putIndex; //元素个数 int count; //内部锁 final ReentrantLock lock; //消费者监视器 private final Condition notEmpty; //生产者监视器 private final Condition notFull; public ArrayBlockingQueue(int capacity, boolean fair) { //..省略其他代码  lock = new ReentrantLock(fair); notEmpty = lock.newCondition(); notFull = lock.newCondition(); }   put操作的源码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  public void put(E e) throws InterruptedException { checkNotNull(e); final ReentrantLock lock = this.lock; // 1.自旋拿锁  lock.lockInterruptibly(); try { // 2.判断队列是否满了  while (count == items.length) // 2.1如果满了，阻塞该线程，并标记为notFull线程，  // 等待notFull的唤醒，唤醒之后继续执行while循环。  notFull.await(); // 3.如果没有满，则进入队列  enqueue(e); } finally { lock.unlock(); } } private void enqueue(E x) { // assert lock.getHoldCount() == 1;  // assert items[putIndex] == null;  final Object[] items = this.items; items[putIndex] = x; if (++putIndex == items.length) putIndex = 0; count++; // 4 唤醒一个等待的线程  notEmpty.signal(); }   总结put的流程：\n 所有执行put操作的线程竞争lock锁，拿到了lock锁的线程进入下一步，没有拿到lock锁的线程自旋竞争锁。 判断阻塞队列是否满了，如果满了，则调用await方法阻塞这个线程，并标记为notFull（生产者）线程，同时释放lock锁,等待被消费者线程唤醒。 如果没有满，则调用enqueue方法将元素put进阻塞队列。注意这一步的线程还有一种情况是第二步中阻塞的线程被唤醒且又拿到了lock锁的线程。 唤醒一个标记为notEmpty（消费者）的线程。  take操作的源码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  public E take() throws InterruptedException { final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try { while (count == 0) notEmpty.await(); return dequeue(); } finally { lock.unlock(); } } private E dequeue() { // assert lock.getHoldCount() == 1;  // assert items[takeIndex] != null;  final Object[] items = this.items; @SuppressWarnings(\u0026#34;unchecked\u0026#34;) E x = (E) items[takeIndex]; items[takeIndex] = null; if (++takeIndex == items.length) takeIndex = 0; count--; if (itrs != null) itrs.elementDequeued(); notFull.signal(); return x; }   take操作和put操作的流程是类似的，总结一下take操作的流程：\n 所有执行take操作的线程竞争lock锁，拿到了lock锁的线程进入下一步，没有拿到lock锁的线程自旋竞争锁。 判断阻塞队列是否为空，如果是空，则调用await方法阻塞这个线程，并标记为notEmpty（消费者）线程，同时释放lock锁,等待被生产者线程唤醒。 如果没有空，则调用dequeue方法。注意这一步的线程还有一种情况是第二步中阻塞的线程被唤醒且又拿到了lock锁的线程。 唤醒一个标记为notFull（生产者）的线程。  注意\n put和take操作都需要先获取锁，没有获取到锁的线程会被挡在第一道大门之外自旋拿锁，直到获取到锁。 就算拿到锁了之后，也不一定会顺利进行put/take操作，需要判断队列是否可用（是否满/空），如果不可用，则会被阻塞，并释放锁。 在第2点被阻塞的线程会被唤醒，但是在唤醒之后，依然需要拿到锁才能继续往下执行，否则，自旋拿锁，拿到锁了再while判断队列是否可用（这也是为什么不用if判断，而使用while判断的原因）。  示例和使用场景 生产者-消费者模型 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51  public class Test { private int queueSize = 10; private ArrayBlockingQueue\u0026lt;Integer\u0026gt; queue = new ArrayBlockingQueue\u0026lt;Integer\u0026gt;(queueSize); public static void main(String[] args) { Test test = new Test(); Producer producer = test.new Producer(); Consumer consumer = test.new Consumer(); producer.start(); consumer.start(); } class Consumer extends Thread{ @Override public void run() { consume(); } private void consume() { while(true){ try { queue.take(); System.out.println(\u0026#34;从队列取走一个元素，队列剩余\u0026#34;+queue.size()+\u0026#34;个元素\u0026#34;); } catch (InterruptedException e) { e.printStackTrace(); } } } } class Producer extends Thread{ @Override public void run() { produce(); } private void produce() { while(true){ try { queue.put(1); System.out.println(\u0026#34;向队列取中插入一个元素，队列剩余空间：\u0026#34;+(queueSize-queue.size())); } catch (InterruptedException e) { e.printStackTrace(); } } } } }   下面是这个例子的输出片段：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  从队列取走一个元素，队列剩余0个元素 从队列取走一个元素，队列剩余0个元素 向队列取中插入一个元素，队列剩余空间：9 向队列取中插入一个元素，队列剩余空间：9 向队列取中插入一个元素，队列剩余空间：9 向队列取中插入一个元素，队列剩余空间：8 向队列取中插入一个元素，队列剩余空间：7 向队列取中插入一个元素，队列剩余空间：6 向队列取中插入一个元素，队列剩余空间：5 向队列取中插入一个元素，队列剩余空间：4 向队列取中插入一个元素，队列剩余空间：3 向队列取中插入一个元素，队列剩余空间：2 向队列取中插入一个元素，队列剩余空间：1 向队列取中插入一个元素，队列剩余空间：0 从队列取走一个元素，队列剩余1个元素 从队列取走一个元素，队列剩余9个元素   注意，这个例子中的输出结果看起来可能有问题，比如有几行在插入一个元素之后，队列的剩余空间不变。这是由于System.out.println语句没有锁。考虑到这样的情况：线程1在执行完put/take操作后立即失去CPU时间片，然后切换到线程2执行put/take操作，执行完毕后回到线程1的System.out.println语句并输出，发现这个时候阻塞队列的size已经被线程2改变了，所以这个时候输出的size并不是当时线程1执行完put/take操作之后阻塞队列的size，但可以确保的是size不会超过10个。实际上使用阻塞队列是没有问题的。\n线程池中使用阻塞队列 1 2 3 4 5 6 7 8  public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue\u0026lt;Runnable\u0026gt; workQueue) { this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, Executors.defaultThreadFactory(), defaultHandler); }   Java中的线程池就是使用阻塞队列实现的，我们在了解阻塞队列之后，无论是使用Executors类中已经提供的线程池，还是自己通过ThreadPoolExecutor实现线程池，都会更加得心应手，想要了解线程池的同学，可以看：线程池原理。\n 注：上面提到了生产者-消费者模式，大家可以参考生产者-消费者模型，可以更好的理解阻塞队列。\n 锁接口和类 前面我们介绍了Java原生的锁——基于对象的锁，它一般是配合synchronized关键字来使用的。实际上，Java在java.util.concurrent.locks包下，还为我们提供了几个关于锁的类和接口。它们有更强大的功能或更高的性能。\nsynchronized的不足之处 我们先来看看synchronized有什么不足之处。\n 如果临界区是只读操作，其实可以多线程一起执行，但使用synchronized的话，同一时间只能有一个线程执行。 synchronized无法知道线程有没有成功获取到锁 使用synchronized，如果临界区因为IO或者sleep方法等原因阻塞了，而当前线程又没有释放锁，就会导致所有线程等待。  而这些都是locks包下的锁可以解决的。\n锁的几种分类 锁可以根据以下几种方式来进行分类，下面我们逐一介绍。\n可重入锁和非可重入锁 所谓重入锁，顾名思义。就是支持重新进入的锁，也就是说这个锁支持一个线程对资源重复加锁。\nsynchronized关键字就是使用的重入锁。比如说，你在一个synchronized实例方法里面调用另一个本实例的synchronized实例方法，它可以重新进入这个锁，不会出现任何异常。\n如果我们自己在继承AQS实现同步器的时候，没有考虑到占有锁的线程再次获取锁的场景，可能就会导致线程阻塞，那这个就是一个“非可重入锁”。\nReentrantLock的中文意思就是可重入锁。也是本文后续要介绍的重点类。\n公平锁与非公平锁 这里的“公平”，其实通俗意义来说就是“先来后到”，也就是FIFO。如果对一个锁来说，先对锁获取请求的线程一定会先被满足，后对锁获取请求的线程后被满足，那这个锁就是公平的。反之，那就是不公平的。\n一般情况下，非公平锁能提升一定的效率。但是非公平锁可能会发生线程饥饿（有一些线程长时间得不到锁）的情况。所以要根据实际的需求来选择非公平锁和公平锁。\nReentrantLock支持非公平锁和公平锁两种。\n读写锁和排它锁 我们前面讲到的synchronized用的锁和ReentrantLock，其实都是“排它锁”。也就是说，这些锁在同一时刻只允许一个线程进行访问。\n而读写锁可以在同一时刻允许多个读线程访问。Java提供了ReentrantReadWriteLock类作为读写锁的默认实现，内部维护了两个锁：一个读锁，一个写锁。通过分离读锁和写锁，使得在“读多写少”的环境下，大大地提高了性能。\n 注意，即使用读写锁，在写线程访问时，所有的读线程和其它写线程均被阻塞。\n 可见，只是synchronized是远远不能满足多样化的业务对锁的要求的。接下来我们介绍一下JDK中有关锁的一些接口和类。\nJDK中有关锁的一些接口和类 众所周知，JDK中关于并发的类大多都在java.util.concurrent（以下简称juc）包下。而juc.locks包看名字就知道，是提供了一些并发锁的工具类的。前面我们介绍的AQS（AbstractQueuedSynchronizer）就是在这个包下。下面分别介绍一下这个包下的类和接口以及它们之间的关系。\n抽象类AQS/AQLS/AOS 这三个抽象类有一定的关系，所以这里放到一起讲。\n首先我们看AQS（AbstractQueuedSynchronizer），之前专门有章节介绍这个类，它是在JDK 1.5 发布的，提供了一个“队列同步器”的基本功能实现。而AQS里面的“资源”是用一个int类型的数据来表示的，有时候我们的业务需求资源的数量超出了int的范围，所以在JDK 1.6 中，多了一个AQLS（AbstractQueuedLongSynchronizer）。它的代码跟AQS几乎一样，只是把资源的类型变成了long类型。\nAQS和AQLS都继承了一个类叫AOS（AbstractOwnableSynchronizer）。这个类也是在JDK 1.6 中出现的。这个类只有几行简单的代码。从源码类上的注释可以知道，它是用于表示锁与持有者之间的关系（独占模式）。可以看一下它的主要方法：\n1 2 3 4 5 6 7 8 9 10 11 12  // 独占模式，锁的持有者 private transient Thread exclusiveOwnerThread; // 设置锁持有者 protected final void setExclusiveOwnerThread(Thread t) { exclusiveOwnerThread = t; } // 获取锁的持有线程 protected final Thread getExclusiveOwnerThread() { return exclusiveOwnerThread; }   接口Condition/Lock/ReadWriteLock juc.locks包下共有三个接口：Condition、Lock、ReadWriteLock。其中，Lock和ReadWriteLock从名字就可以看得出来，分别是锁和读写锁的意思。Lock接口里面有一些获取锁和释放锁的方法声明，而ReadWriteLock里面只有两个方法，分别返回“读锁”和“写锁”：\n1 2 3 4  public interface ReadWriteLock { Lock readLock(); Lock writeLock(); }   Lock接口中有一个方法是可以获得一个Condition:\n1  Condition newCondition();   之前我们提到了每个对象都可以用继承自Object的wait/notify方法来实现等待/通知机制。而Condition接口也提供了类似Object监视器的方法，通过与Lock配合来实现等待/通知模式。\n那为什么既然有Object的监视器方法了，还要用Condition呢？这里有一个二者简单的对比：\n   对比项 Object监视器 Condition     前置条件 获取对象的锁 调用Lock.lock获取锁，调用Lock.newCondition获取Condition对象   调用方式 直接调用，比如object.notify() 直接调用，比如condition.await()   等待队列的个数 一个 多个   当前线程释放锁进入等待状态 支持 支持   当前线程释放锁进入等待状态，在等待状态中不中断 不支持 支持   当前线程释放锁并进入超时等待状态 支持 支持   当前线程释放锁并进入等待状态直到将来的某个时间 不支持 支持   唤醒等待队列中的一个线程 支持 支持   唤醒等待队列中的全部线程 支持 支持    Condition和Object的wait/notify基本相似。其中，Condition的await方法对应的是Object的wait方法，而Condition的signal/signalAll方法则对应Object的notify/notifyAll()。但Condition类似于Object的等待/通知机制的加强版。我们来看看主要的方法：\n   方法名称 描述     await() 当前线程进入等待状态直到被通知（signal）或者中断；当前线程进入运行状态并从await()方法返回的场景包括：（1）其他线程调用相同Condition对象的signal/signalAll方法，并且当前线程被唤醒；（2）其他线程调用interrupt方法中断当前线程；   awaitUninterruptibly() 当前线程进入等待状态直到被通知，在此过程中对中断信号不敏感，不支持中断当前线程   awaitNanos(long) 当前线程进入等待状态，直到被通知、中断或者超时。如果返回值小于等于0，可以认定就是超时了   awaitUntil(Date) 当前线程进入等待状态，直到被通知、中断或者超时。如果没到指定时间被通知，则返回true，否则返回false   signal() 唤醒一个等待在Condition上的线程，被唤醒的线程在方法返回前必须获得与Condition对象关联的锁   signalAll() 唤醒所有等待在Condition上的线程，能够从await()等方法返回的线程必须先获得与Condition对象关联的锁    ReentrantLock ReentrantLock是一个非抽象类，它是Lock接口的JDK默认实现，实现了锁的基本功能。从名字上看，它是一个”可重入“锁，从源码上看，它内部有一个抽象类Sync，是继承了AQS，自己实现的一个同步器。同时，ReentrantLock内部有两个非抽象类NonfairSync和FairSync，它们都继承了Sync。从名字上看得出，分别是”非公平同步器“和”公平同步器“的意思。这意味着ReentrantLock可以支持”公平锁“和”非公平锁“。\n通过看这两个同步器的源码可以发现，它们的实现都是”独占“的。都调用了AOS的setExclusiveOwnerThread方法，所以ReentrantLock的锁是”独占“的，也就是说，它的锁都是”排他锁“，不能共享。\n在ReentrantLock的构造方法里，可以传入一个boolean类型的参数，来指定它是否是一个公平锁，默认情况下是非公平的。这个参数一旦实例化后就不能修改，只能通过isFair()方法来查看。\nReentrantReadWriteLock 这个类也是一个非抽象类，它是ReadWriteLock接口的JDK默认实现。它与ReentrantLock的功能类似，同样是可重入的，支持非公平锁和公平锁。不同的是，它还支持”读写锁“。\nReentrantReadWriteLock内部的结构大概是这样：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38  // 内部结构 private final ReentrantReadWriteLock.ReadLock readerLock; private final ReentrantReadWriteLock.WriteLock writerLock; final Sync sync; abstract static class Sync extends AbstractQueuedSynchronizer { // 具体实现 } static final class NonfairSync extends Sync { // 具体实现 } static final class FairSync extends Sync { // 具体实现 } public static class ReadLock implements Lock, java.io.Serializable { private final Sync sync; protected ReadLock(ReentrantReadWriteLock lock) { sync = lock.sync; } // 具体实现 } public static class WriteLock implements Lock, java.io.Serializable { private final Sync sync; protected WriteLock(ReentrantReadWriteLock lock) { sync = lock.sync; } // 具体实现 } // 构造方法，初始化两个锁 public ReentrantReadWriteLock(boolean fair) { sync = fair ? new FairSync() : new NonfairSync(); readerLock = new ReadLock(this); writerLock = new WriteLock(this); } // 获取读锁和写锁的方法 public ReentrantReadWriteLock.WriteLock writeLock() { return writerLock; } public ReentrantReadWriteLock.ReadLock readLock() { return readerLock; }   可以看到，它同样是内部维护了两个同步器。且维护了两个Lock的实现类ReadLock和WriteLock。从源码可以发现，这两个内部类用的是外部类的同步器。\nReentrantReadWriteLock实现了读写锁，但它有一个小弊端，就是在“写”操作的时候，其它线程不能写也不能读。我们称这种现象为“写饥饿”，将在后文的StampedLock类继续讨论这个问题。\nStampedLock StampedLock类是在Java 8 才发布的，也是Doug Lea大神所写，有人号称它为锁的性能之王。它没有实现Lock接口和ReadWriteLock接口，但它其实是实现了“读写锁”的功能，并且性能比ReentrantReadWriteLock更高。StampedLock还把读锁分为了“乐观读锁”和“悲观读锁”两种。\n前面提到了ReentrantReadWriteLock会发生“写饥饿”的现象，但StampedLock不会。它是怎么做到的呢？它的核心思想在于，在读的时候如果发生了写，应该通过重试的方式来获取新的值，而不应该阻塞写操作。这种模式也就是典型的无锁编程思想，和CAS自旋的思想一样。这种操作方式决定了StampedLock在读线程非常多而写线程非常少的场景下非常适用，同时还避免了写饥饿情况的发生。\n这里篇幅有限，就不介绍StampedLock的源码了，只是分析一下官方提供的用法（在JDK源码类声明的上方或Javadoc里可以找到）。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55  class Point { private double x, y; private final StampedLock sl = new StampedLock(); // 写锁的使用  void move(double deltaX, double deltaY) { long stamp = sl.writeLock(); // 获取写锁  try { x += deltaX; y += deltaY; } finally { sl.unlockWrite(stamp); // 释放写锁  } } // 乐观读锁的使用  double distanceFromOrigin() { long stamp = sl.tryOptimisticRead(); // 获取乐观读锁  double currentX = x, currentY = y; if (!sl.validate(stamp)) { // //检查乐观读锁后是否有其他写锁发生，有则返回false  stamp = sl.readLock(); // 获取一个悲观读锁  try { currentX = x; currentY = y; } finally { sl.unlockRead(stamp); // 释放悲观读锁  } } return Math.sqrt(currentX * currentX + currentY * currentY); } // 悲观读锁以及读锁升级写锁的使用  void moveIfAtOrigin(double newX, double newY) { long stamp = sl.readLock(); // 悲观读锁  try { while (x == 0.0 \u0026amp;\u0026amp; y == 0.0) { // 读锁尝试转换为写锁：转换成功后相当于获取了写锁，转换失败相当于有写锁被占用  long ws = sl.tryConvertToWriteLock(stamp); if (ws != 0L) { // 如果转换成功  stamp = ws; // 读锁的票据更新为写锁的  x = newX; y = newY; break; } else { // 如果转换失败  sl.unlockRead(stamp); // 释放读锁  stamp = sl.writeLock(); // 强制获取写锁  } } } finally { sl.unlock(stamp); // 释放所有锁  } } }    乐观读锁的意思就是先假定在这个锁获取期间，共享变量不会被改变，既然假定不会被改变，那就不需要上锁。在获取乐观读锁之后进行了一些操作，然后又调用了validate方法，这个方法就是用来验证tryOptimisticRead之后，是否有写操作执行过，如果有，则获取一个悲观读锁，这里的悲观读锁和ReentrantReadWriteLock中的读锁类似，也是个共享锁。\n 可以看到，StampedLock获取锁会返回一个long类型的变量，释放锁的时候再把这个变量传进去。简单看看源码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  // 用于操作state后获取stamp的值 private static final int LG_READERS = 7; private static final long RUNIT = 1L; //0000 0000 0001 private static final long WBIT = 1L \u0026lt;\u0026lt; LG_READERS; //0000 1000 0000 private static final long RBITS = WBIT - 1L; //0000 0111 1111 private static final long RFULL = RBITS - 1L; //0000 0111 1110 private static final long ABITS = RBITS | WBIT; //0000 1111 1111 private static final long SBITS = ~RBITS; //1111 1000 0000  // 初始化时state的值 private static final long ORIGIN = WBIT \u0026lt;\u0026lt; 1; //0001 0000 0000  // 锁共享变量state private transient volatile long state; // 读锁溢出时用来存储多出的读锁 private transient int readerOverflow;   StampedLock用这个long类型的变量的前7位（LG_READERS）来表示读锁，每获取一个悲观读锁，就加1（RUNIT），每释放一个悲观读锁，就减1。而悲观读锁最多只能装128个（7位限制），很容易溢出，所以用一个int类型的变量来存储溢出的悲观读锁。\n写锁用state变量剩下的位来表示，每次获取一个写锁，就加0000 1000 0000（WBIT）。需要注意的是，写锁在释放的时候，并不是减WBIT，而是再加WBIT。这是为了让每次写锁都留下痕迹，解决CAS中的ABA问题，也为乐观锁检查变化validate方法提供基础。\n乐观读锁就比较简单了，并没有真正改变state的值，而是在获取锁的时候记录state的写状态，在操作完成后去检查state的写状态部分是否发生变化，上文提到了，每次写锁都会留下痕迹，也是为了这里乐观锁检查变化提供方便。\n总的来说，StampedLock的性能是非常优异的，基本上可以取代ReentrantReadWriteLock的作用。\n并发容器集合 同步容器与并发容器 我们知道在java.util包下提供了一些容器类，而Vector和Hashtable是线程安全的容器类，但是这些容器实现同步的方式是通过对方法加锁(sychronized)方式实现的，这样读写均需要锁操作，导致性能低下。\n而即使是Vector这样线程安全的类，在面对多线程下的复合操作的时候也是需要通过客户端加锁的方式保证原子性。如下面例子说明:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  public class TestVector { private Vector\u0026lt;String\u0026gt; vector; //方法一  public Object getLast(Vector vector) { int lastIndex = vector.size() - 1; return vector.get(lastIndex); } //方法二  public void deleteLast(Vector vector) { int lastIndex = vector.size() - 1; vector.remove(lastIndex); } //方法三  public Object getLastSysnchronized(Vector vector) { synchronized(vector){ int lastIndex = vector.size() - 1; return vector.get(lastIndex); } } //方法四  public void deleteLastSysnchronized(Vector vector) { synchronized (vector){ int lastIndex = vector.size() - 1; vector.remove(lastIndex); } } }   如果方法一和方法二为一个组合的话。那么当方法一获取到了vector的size之后，方法二已经执行完毕，这样就导致程序的错误。\n如果方法三与方法四组合的话。通过锁机制保证了在vector上的操作的原子性。\n并发容器是Java 5 提供的在多线程编程下用于代替同步容器，针对不同的应用场景进行设计，提高容器的并发访问性，同时定义了线程安全的复合操作。\n并发容器类介绍 整体架构(列举常用的容器类)\n其中，阻塞队列（BlockingQueue）在有介绍，CopyOnWrite容器（CopyOnWritexxx）在有介绍，这里不做过多介绍。\n下面分别介绍一些常用的并发容器类和接口，因篇幅原因，这里只介绍这些类的用途和基本的原理，不做过多的源码解析。\n并发Map ConcurrentMap接口 ConcurrentMap接口继承了Map接口，在Map接口的基础上又定义了四个方法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  public interface ConcurrentMap\u0026lt;K, V\u0026gt; extends Map\u0026lt;K, V\u0026gt; { //插入元素  V putIfAbsent(K key, V value); //移除元素  boolean remove(Object key, Object value); //替换元素  boolean replace(K key, V oldValue, V newValue); //替换元素  V replace(K key, V value); }   **putIfAbsent：**与原有put方法不同的是，putIfAbsent方法中如果插入的key相同，则不替换原有的value值；\n**remove：**与原有remove方法不同的是，新remove方法中增加了对value的判断，如果要删除的key-value不能与Map中原有的key-value对应上，则不会删除该元素;\n**replace(K,V,V)：**增加了对value值的判断，如果key-oldValue能与Map中原有的key-value对应上，才进行替换操作；\n**replace(K,V)：**与上面的replace不同的是，此replace不会对Map中原有的key-value进行比较，如果key存在则直接替换；\nConcurrentHashMap类 ConcurrentHashMap同HashMap一样也是基于散列表的map，但是它提供了一种与Hashtable完全不同的加锁策略，提供更高效的并发性和伸缩性。\nConcurrentHashMap在JDK 1.7 和JDK 1.8中有一些区别。这里我们分开介绍一下。\nJDK 1.7\nConcurrentHashMap在JDK 1.7中，提供了一种粒度更细的加锁机制来实现在多线程下更高的性能，这种机制叫分段锁(Lock Striping)。\n提供的优点是：在并发环境下将实现更高的吞吐量，而在单线程环境下只损失非常小的性能。\n可以这样理解分段锁，就是将数据分段，对每一段数据分配一把锁。当一个线程占用锁访问其中一个段数据的时候，其他段的数据也能被其他线程访问。\n有些方法需要跨段，比如size()、isEmpty()、containsValue()，它们可能需要锁定整个表而不仅仅是某个段，这需要按顺序锁定所有段，操作完毕后，又按顺序释放所有段的锁。如下图：\nConcurrentHashMap是由Segment数组结构和HashEntry数组结构组成。Segment是一种可重入锁ReentrantLock，HashEntry则用于存储键值对数据。\n一个ConcurrentHashMap里包含一个Segment数组，Segment的结构和HashMap类似，是一种数组和链表结构， 一个Segment里包含一个HashEntry数组，每个HashEntry是一个链表结构的元素， 每个Segment守护着一个HashEntry数组里的元素，当对HashEntry数组的数据进行修改时，必须首先获得它对应的Segment锁。\nJDK 1.8\n而在JDK 1.8中，ConcurrentHashMap主要做了两个优化：\n 同HashMap一样，链表也会在长度达到8的时候转化为红黑树，这样可以提升大量冲突时候的查询效率； 以某个位置的头结点（链表的头结点或红黑树的root结点）为锁，配合自旋+CAS避免不必要的锁开销，进一步提升并发性能。  ConcurrentNavigableMap接口与ConcurrentSkipListMap类 ConcurrentNavigableMap接口继承了NavigableMap接口，这个接口提供了针对给定搜索目标返回最接近匹配项的导航方法。\nConcurrentNavigableMap接口的主要实现类是ConcurrentSkipListMap类。从名字上来看，它的底层使用的是跳表（SkipList）的数据结构。关于跳表的数据结构这里不做太多介绍，它是一种”空间换时间“的数据结构，可以使用CAS来保证并发安全性。\n并发Queue JDK并没有提供线程安全的List类，因为对List来说，很难去开发一个通用并且没有并发瓶颈的线程安全的List。因为即使简单的读操作，拿contains() 这样一个操作来说，很难想到搜索的时候如何避免锁住整个list。\n所以退一步，JDK提供了对队列和双端队列的线程安全的类：ConcurrentLinkedQueue和ConcurrentLinkedDeque。因为队列相对于List来说，有更多的限制。这两个类是使用CAS来实现线程安全的。\n并发Set JDK提供了ConcurrentSkipListSet，是线程安全的有序的集合。底层是使用ConcurrentSkipListMap实现。\n谷歌的guava框架实现了一个线程安全的ConcurrentHashSet：\n1  Set\u0026lt;String\u0026gt; s = Sets.newConcurrentHashSet();   CopyOnWrite容器 什么是CopyOnWrite容器 在说到CopyOnWrite容器之前我们先来谈谈什么是CopyOnWrite机制，CopyOnWrite是计算机设计领域中的一种优化策略，也是一种在并发场景下常用的设计思想——写入时复制思想。\n那什么是写入时复制思想呢？就是当有多个调用者同时去请求一个资源数据的时候，有一个调用者出于某些原因需要对当前的数据源进行修改，这个时候系统将会复制一个当前数据源的副本给调用者修改。\nCopyOnWrite容器即写时复制的容器,当我们往一个容器中添加元素的时候，不直接往容器中添加，而是将当前容器进行copy，复制出来一个新的容器，然后向新容器中添加我们需要的元素，最后将原容器的引用指向新容器。\n这样做的好处在于，我们可以在并发的场景下对容器进行\u0026quot;读操作\u0026quot;而不需要\u0026quot;加锁\u0026quot;，从而达到读写分离的目的。从JDK 1.5 开始Java并发包里提供了两个使用CopyOnWrite机制实现的并发容器 ，分别是CopyOnWriteArrayList和CopyOnWriteArraySet 。我们着重给大家介绍一下CopyOnWriteArrayList。\nCopyOnWriteArrayList 优点： CopyOnWriteArrayList经常被用于“读多写少”的并发场景，是因为CopyOnWriteArrayList无需任何同步措施，大大增强了读的性能。在Java中遍历线程非安全的List(如：ArrayList和 LinkedList)的时候，若中途有别的线程对List容器进行修改，那么会抛出ConcurrentModificationException异常。CopyOnWriteArrayList由于其\u0026quot;读写分离\u0026quot;，遍历和修改操作分别作用在不同的List容器，所以在使用迭代器遍历的时候，则不会抛出异常。\n缺点： 第一个缺点是CopyOnWriteArrayList每次执行写操作都会将原容器进行拷贝一份，数据量大的时候，内存会存在较大的压力，可能会引起频繁Full GC（ZGC因为没有使用Full GC）。比如这些对象占用的内存200M左右，那么再写入100M数据进去，内存就会多占用300M。\n第二个缺点是CopyOnWriteArrayList由于实现的原因，写和读分别作用在不同新老容器上，在写操作执行过程中，读不会阻塞，但读取到的却是老容器的数据。\n现在我们来看一下CopyOnWriteArrayList的add操作源码，它的逻辑很清晰，就是先把原容器进行copy，然后在新的副本上进行“写操作”，最后再切换引用，在此过程中是加了锁的。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  public boolean add(E e) { // ReentrantLock加锁，保证线程安全  final ReentrantLock lock = this.lock; lock.lock(); try { Object[] elements = getArray(); int len = elements.length; // 拷贝原容器，长度为原容器长度加一  Object[] newElements = Arrays.copyOf(elements, len + 1); // 在新副本上执行添加操作  newElements[len] = e; // 将原容器引用指向新副本  setArray(newElements); return true; } finally { // 解锁  lock.unlock(); } }   我们再来看一下remove操作的源码，remove的逻辑是将要remove元素之外的其他元素拷贝到新的副本中，然后再将原容器的引用指向新的副本中，因为remove操作也是“写操作”所以也是要加锁的。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  public E remove(int index) { // 加锁  final ReentrantLock lock = this.lock; lock.lock(); try { Object[] elements = getArray(); int len = elements.length; E oldValue = get(elements, index); int numMoved = len - index - 1; if (numMoved == 0) // 如果要删除的是列表末端数据，拷贝前len-1个数据到新副本上，再切换引用  setArray(Arrays.copyOf(elements, len - 1)); else { // 否则，将要删除元素之外的其他元素拷贝到新副本中，并切换引用  Object[] newElements = new Object[len - 1]; System.arraycopy(elements, 0, newElements, 0, index); System.arraycopy(elements, index + 1, newElements, index, numMoved); setArray(newElements); } return oldValue; } finally { // 解锁  lock.unlock(); } }   我们再来看看CopyOnWriteArrayList效率最高的读操作的源码\n1 2 3 4 5 6  public E get(int index) { return get(getArray(), index); } private E get(Object[] a, int index) { return (E) a[index]; }   由上可见“读操作”是没有加锁，直接读取。\nCopyOnWrite的业务中实现 接下来，我们结合具体业务场景来实现一个CopyOnWriteMap的并发容器并且使用它。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  import java.util.Collection; import java.util.Map; import java.util.Set; public class CopyOnWriteMap\u0026lt;K, V\u0026gt; implements Map\u0026lt;K, V\u0026gt;, Cloneable { private volatile Map\u0026lt;K, V\u0026gt; internalMap; public CopyOnWriteMap() { internalMap = new HashMap\u0026lt;K, V\u0026gt;(); } public V put(K key, V value) { synchronized (this) { Map\u0026lt;K, V\u0026gt; newMap = new HashMap\u0026lt;K, V\u0026gt;(internalMap); V val = newMap.put(key, value); internalMap = newMap; return val; } } public V get(Object key) { return internalMap.get(key); } public void putAll(Map\u0026lt;? extends K, ? extends V\u0026gt; newData) { synchronized (this) { Map\u0026lt;K, V\u0026gt; newMap = new HashMap\u0026lt;K, V\u0026gt;(internalMap); newMap.putAll(newData); internalMap = newMap; } } }   上面就是参考CopyOnWriteArrayList实现的CopyOnWriteMap，我们可以用这个容器来做什么呢？结合我们之前说的CopyOnWrite的复制思想，它最适用于“读多写少”的并发场景。\n**场景：**假如我们有一个搜索的网站需要屏蔽一些“关键字”，“黑名单”每晚定时更新，每当用户搜索的时候，“黑名单”中的关键字不会出现在搜索结果当中，并且提示用户敏感字。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  // 黑名单服务 public class BlackListServiceImpl { //　减少扩容开销。根据实际需要，初始化CopyOnWriteMap的大小，避免写时CopyOnWriteMap扩容的开销。  private static CopyOnWriteMap\u0026lt;String, Boolean\u0026gt; blackListMap = new CopyOnWriteMap\u0026lt;String, Boolean\u0026gt;(1000); public static boolean isBlackList(String id) { return blackListMap.get(id) == null ? false : true; } public static void addBlackList(String id) { blackListMap.put(id, Boolean.TRUE); } /** * 批量添加黑名单 * (使用批量添加。因为每次添加，容器每次都会进行复制，所以减少添加次数，可以减少容器的复制次数。 * 如使用上面代码里的addBlackList方法) * @param ids */ public static void addBlackList(Map\u0026lt;String,Boolean\u0026gt; ids) { blackListMap.putAll(ids); } }   这里需要各位小伙伴特别特别注意一个问题，此处的场景是每晚凌晨“黑名单”定时更新，原因是CopyOnWrite容器有数据一致性的问题，它只能保证最终数据一致性。\n所以如果我们希望写入的数据马上能准确地读取，请不要使用CopyOnWrite容器。\n通信工具类 JDK中提供了一些工具类以供开发者使用。这样的话我们在遇到一些常见的应用场景时就可以使用这些工具类，而不用自己再重复造轮子了。\n它们都在java.util.concurrent包下。先总体概括一下都有哪些工具类，它们有什么作用，然后再分别介绍它们的主要使用方法和原理。\n   类 作用     Semaphore 限制线程的数量   Exchanger 两个线程交换数据   CountDownLatch 线程等待直到计数器减为0时开始工作   CyclicBarrier 作用跟CountDownLatch类似，但是可以重复使用   Phaser 增强的CyclicBarrier    下面分别介绍这几个类。\nSemaphore Semaphore介绍 Semaphore翻译过来是信号的意思。顾名思义，这个工具类提供的功能就是多个线程彼此“打信号”。而这个“信号”是一个int类型的数据，也可以看成是一种“资源”。\n可以在构造函数中传入初始资源总数，以及是否使用“公平”的同步器。默认情况下，是非公平的。\n1 2 3 4 5 6 7 8  // 默认情况下使用非公平 public Semaphore(int permits) { sync = new NonfairSync(permits); } public Semaphore(int permits, boolean fair) { sync = fair ? new FairSync(permits) : new NonfairSync(permits); }   最主要的方法是acquire方法和release方法。acquire()方法会申请一个permit，而release方法会释放一个permit。当然，你也可以申请多个acquire(int permits)或者释放多个release(int permits)。\n每次acquire，permits就会减少一个或者多个。如果减少到了0，再有其他线程来acquire，那就要阻塞这个线程直到有其它线程release permit为止。\nSemaphore案例 Semaphore往往用于资源有限的场景中，去限制线程的数量。举个例子，我想限制同时只能有3个线程在工作：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36  public class SemaphoreDemo { static class MyThread implements Runnable { private int value; private Semaphore semaphore; public MyThread(int value, Semaphore semaphore) { this.value = value; this.semaphore = semaphore; } @Override public void run() { try { semaphore.acquire(); // 获取permit  System.out.println(String.format(\u0026#34;当前线程是%d, 还剩%d个资源，还有%d个线程在等待\u0026#34;, value, semaphore.availablePermits(), semaphore.getQueueLength())); // 睡眠随机时间，打乱释放顺序  Random random =new Random(); Thread.sleep(random.nextInt(1000)); System.out.println(String.format(\u0026#34;线程%d释放了资源\u0026#34;, value)); } catch (InterruptedException e) { e.printStackTrace(); } finally{ semaphore.release(); // 释放permit  } } } public static void main(String[] args) { Semaphore semaphore = new Semaphore(3); for (int i = 0; i \u0026lt; 10; i++) { new Thread(new MyThread(i, semaphore)).start(); } } }   输出：\n 当前线程是1, 还剩2个资源，还有0个线程在等待 当前线程是0, 还剩1个资源，还有0个线程在等待 当前线程是6, 还剩0个资源，还有0个线程在等待 线程6释放了资源 当前线程是2, 还剩0个资源，还有6个线程在等待 线程2释放了资源 当前线程是4, 还剩0个资源，还有5个线程在等待 线程0释放了资源 当前线程是7, 还剩0个资源，还有4个线程在等待 线程1释放了资源 当前线程是8, 还剩0个资源，还有3个线程在等待 线程7释放了资源 当前线程是5, 还剩0个资源，还有2个线程在等待 线程4释放了资源 当前线程是3, 还剩0个资源，还有1个线程在等待 线程8释放了资源 当前线程是9, 还剩0个资源，还有0个线程在等待 线程9释放了资源 线程5释放了资源 线程3释放了资源\n 可以看到，在这次运行中，最开始是1, 0, 6这三个线程获得了资源，而其它线程进入了等待队列。然后当某个线程释放资源后，就会有等待队列中的线程获得资源。\n当然，Semaphore默认的acquire方法是会让线程进入等待队列，且会抛出中断异常。但它还有一些方法可以忽略中断或不进入阻塞队列：\n1 2 3 4 5 6 7 8 9 10  // 忽略中断 public void acquireUninterruptibly() public void acquireUninterruptibly(int permits) // 不进入等待队列，底层使用CAS public boolean tryAcquire public boolean tryAcquire(int permits) public boolean tryAcquire(int permits, long timeout, TimeUnit unit) throws InterruptedException public boolean tryAcquire(long timeout, TimeUnit unit)   Semaphore原理 Semaphore内部有一个继承了AQS的同步器Sync，重写了tryAcquireShared方法。在这个方法里，会去尝试获取资源。\n如果获取失败（想要的资源数量小于目前已有的资源数量），就会返回一个负数（代表尝试获取资源失败）。然后当前线程就会进入AQS的等待队列。\nExchanger Exchanger类用于两个线程交换数据。它支持泛型，也就是说你可以在两个线程之间传送任何数据。先来一个案例看看如何使用，比如两个线程之间想要传送字符串：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  public class ExchangerDemo { public static void main(String[] args) throws InterruptedException { Exchanger\u0026lt;String\u0026gt; exchanger = new Exchanger\u0026lt;\u0026gt;(); new Thread(() -\u0026gt; { try { System.out.println(\u0026#34;这是线程A，得到了另一个线程的数据：\u0026#34; + exchanger.exchange(\u0026#34;这是来自线程A的数据\u0026#34;)); } catch (InterruptedException e) { e.printStackTrace(); } }).start(); System.out.println(\u0026#34;这个时候线程A是阻塞的，在等待线程B的数据\u0026#34;); Thread.sleep(1000); new Thread(() -\u0026gt; { try { System.out.println(\u0026#34;这是线程B，得到了另一个线程的数据：\u0026#34; + exchanger.exchange(\u0026#34;这是来自线程B的数据\u0026#34;)); } catch (InterruptedException e) { e.printStackTrace(); } }).start(); } }   输出：\n 这个时候线程A是阻塞的，在等待线程B的数据 这是线程B，得到了另一个线程的数据：这是来自线程A的数据 这是线程A，得到了另一个线程的数据：这是来自线程B的数据\n 可以看到，当一个线程调用exchange方法后，它是处于阻塞状态的，只有当另一个线程也调用了exchange方法，它才会继续向下执行。看源码可以发现它是使用park/unpark来实现等待状态的切换的，但是在使用park/unpark方法之前，使用了CAS检查，估计是为了提高性能。\nExchanger一般用于两个线程之间更方便地在内存中交换数据，因为其支持泛型，所以我们可以传输任何的数据，比如IO流或者IO缓存。根据JDK里面的注释的说法，可以总结为一下特性：\n 此类提供对外的操作是同步的； 用于成对出现的线程之间交换数据； 可以视作双向的同步队列； 可应用于基因算法、流水线设计等场景。  Exchanger类还有一个有超时参数的方法，如果在指定时间内没有另一个线程调用exchange，就会抛出一个超时异常。\n1  public V exchange(V x, long timeout, TimeUnit unit)   那么问题来了，Exchanger只能是两个线程交换数据吗？那三个调用同一个实例的exchange方法会发生什么呢？答案是只有前两个线程会交换数据，第三个线程会进入阻塞状态。\n需要注意的是，exchange是可以重复使用的。也就是说。两个线程可以使用Exchanger在内存中不断地再交换数据。\nCountDownLatch CountDownLatch介绍 先来解读一下CountDownLatch这个类名字的意义。CountDown代表计数递减，Latch是“门闩”的意思。也有人把它称为“屏障”。而CountDownLatch这个类的作用也很贴合这个名字的意义，假设某个线程在执行任务之前，需要等待其它线程完成一些前置任务，必须等所有的前置任务都完成，才能开始执行本线程的任务。\nCountDownLatch的方法也很简单，如下：\n1 2 3 4 5 6 7  // 构造方法： public CountDownLatch(int count) public void await() // 等待 public boolean await(long timeout, TimeUnit unit) // 超时等待 public void countDown() // count - 1 public long getCount() // 获取当前还有多少count   CountDownLatch案例 我们知道，玩游戏的时候，在游戏真正开始之前，一般会等待一些前置任务完成，比如“加载地图数据”，“加载人物模型”，“加载背景音乐”等等。只有当所有的东西都加载完成后，玩家才能真正进入游戏。下面我们就来模拟一下这个demo。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47  public class CountDownLatchDemo { // 定义前置任务线程  static class PreTaskThread implements Runnable { private String task; private CountDownLatch countDownLatch; public PreTaskThread(String task, CountDownLatch countDownLatch) { this.task = task; this.countDownLatch = countDownLatch; } @Override public void run() { try { Random random = new Random(); Thread.sleep(random.nextInt(1000)); System.out.println(task + \u0026#34; - 任务完成\u0026#34;); countDownLatch.countDown(); } catch (InterruptedException e) { e.printStackTrace(); } } } public static void main(String[] args) { // 假设有三个模块需要加载  CountDownLatch countDownLatch = new CountDownLatch(3); // 主任务  new Thread(() -\u0026gt; { try { System.out.println(\u0026#34;等待数据加载...\u0026#34;); System.out.println(String.format(\u0026#34;还有%d个前置任务\u0026#34;, countDownLatch.getCount())); countDownLatch.await(); System.out.println(\u0026#34;数据加载完成，正式开始游戏！\u0026#34;); } catch (InterruptedException e) { e.printStackTrace(); } }).start(); // 前置任务  new Thread(new PreTaskThread(\u0026#34;加载地图数据\u0026#34;, countDownLatch)).start(); new Thread(new PreTaskThread(\u0026#34;加载人物模型\u0026#34;, countDownLatch)).start(); new Thread(new PreTaskThread(\u0026#34;加载背景音乐\u0026#34;, countDownLatch)).start(); } }   输出：\n 等待数据加载\u0026hellip; 还有3个前置任务 加载人物模型 - 任务完成 加载背景音乐 - 任务完成 加载地图数据 - 任务完成 数据加载完成，正式开始游戏！\n CountDownLatch原理 其实CountDownLatch类的原理挺简单的，内部同样是一个继承了AQS的实现类Sync，且实现起来还很简单，可能是JDK里面AQS的子类中最简单的实现了，有兴趣的读者可以去看看这个内部类的源码。\n需要注意的是构造器中的计数值（count）实际上就是闭锁需要等待的线程数量。这个值只能被设置一次，而且CountDownLatch没有提供任何机制去重新设置这个计数值。\nCyclicBarrier CyclicBarrier介绍 CyclicBarrirer从名字上来理解是“循环的屏障”的意思。前面提到了CountDownLatch一旦计数值count被降为0后，就不能再重新设置了，它只能起一次“屏障”的作用。而CyclicBarrier拥有CountDownLatch的所有功能，还可以使用reset()方法重置屏障。\nCyclicBarrier Barrier被破坏 如果参与者（线程）在等待的过程中，Barrier被破坏，就会抛出BrokenBarrierException。可以用isBroken()方法检测Barrier是否被破坏。\n 如果有线程已经处于等待状态，调用reset方法会导致已经在等待的线程出现BrokenBarrierException异常。并且由于出现了BrokenBarrierException，将会导致始终无法等待。 如果在等待的过程中，线程被中断，会抛出InterruptedException异常，并且这个异常会传播到其他所有的线程。 如果在执行屏障操作过程中发生异常，则该异常将传播到当前线程中，其他线程会抛出BrokenBarrierException，屏障被损坏。 如果超出指定的等待时间，当前线程会抛出 TimeoutException 异常，其他线程会抛出BrokenBarrierException异常。  CyclicBarrier案例 我们同样用玩游戏的例子。如果玩一个游戏有多个“关卡”，那使用CountDownLatch显然不太合适，那需要为每个关卡都创建一个实例。那我们可以使用CyclicBarrier来实现每个关卡的数据加载等待功能。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38  public class CyclicBarrierDemo { static class PreTaskThread implements Runnable { private String task; private CyclicBarrier cyclicBarrier; public PreTaskThread(String task, CyclicBarrier cyclicBarrier) { this.task = task; this.cyclicBarrier = cyclicBarrier; } @Override public void run() { // 假设总共三个关卡  for (int i = 1; i \u0026lt; 4; i++) { try { Random random = new Random(); Thread.sleep(random.nextInt(1000)); System.out.println(String.format(\u0026#34;关卡%d的任务%s完成\u0026#34;, i, task)); cyclicBarrier.await(); } catch (InterruptedException | BrokenBarrierException e) { e.printStackTrace(); } cyclicBarrier.reset(); // 重置屏障  } } } public static void main(String[] args) { CyclicBarrier cyclicBarrier = new CyclicBarrier(3, () -\u0026gt; { System.out.println(\u0026#34;本关卡所有前置任务完成，开始游戏...\u0026#34;); }); new Thread(new PreTaskThread(\u0026#34;加载地图数据\u0026#34;, cyclicBarrier)).start(); new Thread(new PreTaskThread(\u0026#34;加载人物模型\u0026#34;, cyclicBarrier)).start(); new Thread(new PreTaskThread(\u0026#34;加载背景音乐\u0026#34;, cyclicBarrier)).start(); } }   输出：\n 关卡1的任务加载地图数据完成 关卡1的任务加载背景音乐完成 关卡1的任务加载人物模型完成 本关卡所有前置任务完成，开始游戏\u0026hellip; 关卡2的任务加载地图数据完成 关卡2的任务加载背景音乐完成 关卡2的任务加载人物模型完成 本关卡所有前置任务完成，开始游戏\u0026hellip; 关卡3的任务加载人物模型完成 关卡3的任务加载地图数据完成 关卡3的任务加载背景音乐完成 本关卡所有前置任务完成，开始游戏\u0026hellip;\n 注意这里跟CountDownLatch的代码有一些不同。CyclicBarrier没有分为await()和countDown()，而是只有单独的一个await()方法。\n一旦调用await()方法的线程数量等于构造方法中传入的任务总量（这里是3），就代表达到屏障了。CyclicBarrier允许我们在达到屏障的时候可以执行一个任务，可以在构造方法传入一个Runnable类型的对象。上述案例就是在达到屏障时，输出“本关卡所有前置任务完成，开始游戏\u0026hellip;”。\n1 2 3 4 5 6 7  // 构造方法 public CyclicBarrier(int parties) { this(parties, null); } public CyclicBarrier(int parties, Runnable barrierAction) { // 具体实现 }   CyclicBarrier原理 CyclicBarrier虽说功能与CountDownLatch类似，但是实现原理却完全不同，CyclicBarrier内部使用的是Lock + Condition实现的等待/通知模式。详情可以查看这个方法的源码：\n1  private int dowait(boolean timed, long nanos)   Phaser Phaser介绍 Phaser这个单词是“移相器，相位器”的意思（好吧，笔者并不懂这是什么玩意，下方资料来自百度百科）。这个类是从JDK 1.7 中出现的。\n 移相器（Phaser）能够对波的相位进行调整的一种装置。任何传输介质对在其中传导的波动都会引入相移，这是早期模拟移相器的原理；现代电子技术发展后利用A/D、D/A转换实现了数字移相，顾名思义，它是一种不连续的移相技术，但特点是移相精度高。 移相器在雷达、导弹姿态控制、加速器、通信、仪器仪表甚至于音乐等领域都有着广泛的应用\n Phaser类有点复杂，这里只介绍一些基本的用法和知识点。详情可以查看JDK文档，文档里有这个类非常详尽的介绍。\n前面我们介绍了CyclicBarrier，可以发现它在构造方法里传入“任务总量”parties之后，就不能修改这个值了，并且每次调用await()方法也只能消耗一个parties计数。但Phaser可以动态地调整任务总量！\n名词解释：\n party：对应一个线程，数量可以通过register或者构造参数传入; arrive：对应一个party的状态，初始时是unarrived，当调用arriveAndAwaitAdvance()或者 arriveAndDeregister()进入arrive状态，可以通过getUnarrivedParties()获取当前未到达的数量; register：注册一个party，每一阶段必须所有注册的party都到达才能进入下一阶段; deRegister：减少一个party。 phase：阶段，当所有注册的party都arrive之后，将会调用Phaser的onAdvance()方法来判断是否要进入下一阶段。  Phaser终止的两种途径，Phaser维护的线程执行完毕或者onAdvance()返回true 此外Phaser还能维护一个树状的层级关系，构造的时候new Phaser(parentPhaser)，对于Task执行时间短的场景（竞争激烈），也就是说有大量的party, 那可以把每个Phaser的任务量设置较小，多个Phaser共同继承一个父Phaser。\n Phasers with large numbers of parties that would otherwise experience heavy synchronization contention costs may instead be set up so that groups of sub-phasers share a common parent. This may greatly increase throughput even though it incurs greater per-operation overhead.\n翻译：如果有大量的party，那许多线程可能同步的竞争成本比较高。所以可以拆分成多个子Phaser共享一个共同的父Phaser。这可能会大大增加吞吐量，即使它会带来更多的每次操作开销。\n Phaser案例 还是游戏的案例。假设我们游戏有三个关卡，但只有第一个关卡有新手教程，需要加载新手教程模块。但后面的第二个关卡和第三个关卡都不需要。我们可以用Phaser来做这个需求。\n代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53  public class PhaserDemo { static class PreTaskThread implements Runnable { private String task; private Phaser phaser; public PreTaskThread(String task, Phaser phaser) { this.task = task; this.phaser = phaser; } @Override public void run() { for (int i = 1; i \u0026lt; 4; i++) { try { // 第二次关卡起不加载NPC，跳过  if (i \u0026gt;= 2 \u0026amp;\u0026amp; \u0026#34;加载新手教程\u0026#34;.equals(task)) { continue; } Random random = new Random(); Thread.sleep(random.nextInt(1000)); System.out.println(String.format(\u0026#34;关卡%d，需要加载%d个模块，当前模块【%s】\u0026#34;, i, phaser.getRegisteredParties(), task)); // 从第二个关卡起，不加载NPC  if (i == 1 \u0026amp;\u0026amp; \u0026#34;加载新手教程\u0026#34;.equals(task)) { System.out.println(\u0026#34;下次关卡移除加载【新手教程】模块\u0026#34;); phaser.arriveAndDeregister(); // 移除一个模块  } else { phaser.arriveAndAwaitAdvance(); } } catch (InterruptedException e) { e.printStackTrace(); } } } } public static void main(String[] args) { Phaser phaser = new Phaser(4) { @Override protected boolean onAdvance(int phase, int registeredParties) { System.out.println(String.format(\u0026#34;第%d次关卡准备完成\u0026#34;, phase + 1)); return phase == 3 || registeredParties == 0; } }; new Thread(new PreTaskThread(\u0026#34;加载地图数据\u0026#34;, phaser)).start(); new Thread(new PreTaskThread(\u0026#34;加载人物模型\u0026#34;, phaser)).start(); new Thread(new PreTaskThread(\u0026#34;加载背景音乐\u0026#34;, phaser)).start(); new Thread(new PreTaskThread(\u0026#34;加载新手教程\u0026#34;, phaser)).start(); } }   输出：\n 关卡1，需要加载4个模块，当前模块【加载背景音乐】 关卡1，需要加载4个模块，当前模块【加载新手教程】 下次关卡移除加载【新手教程】模块 关卡1，需要加载3个模块，当前模块【加载地图数据】 关卡1，需要加载3个模块，当前模块【加载人物模型】 第1次关卡准备完成 关卡2，需要加载3个模块，当前模块【加载地图数据】 关卡2，需要加载3个模块，当前模块【加载背景音乐】 关卡2，需要加载3个模块，当前模块【加载人物模型】 第2次关卡准备完成 关卡3，需要加载3个模块，当前模块【加载人物模型】 关卡3，需要加载3个模块，当前模块【加载地图数据】 关卡3，需要加载3个模块，当前模块【加载背景音乐】 第3次关卡准备完成\n 这里要注意关卡1的输出，在“加载新手教程”线程中调用了arriveAndDeregister()减少一个party之后，后面的线程使用getRegisteredParties()得到的是已经被修改后的parties了。但是当前这个阶段(phase)，仍然是需要4个parties都arrive才触发屏障的。从下一个阶段开始，才需要3个parties都arrive就触发屏障。\n另外Phaser类用来控制某个阶段的线程数量很有用，但它并在意这个阶段具体有哪些线程arrive，只要达到它当前阶段的parties值，就触发屏障。所以我这里的案例虽然制定了特定的线程（加载新手教程）来更直观地表述Phaser的功能，但是其实Phaser是没有分辨具体是哪个线程的功能的，它在意的只是数量，这一点需要读者注意。\nPhaser原理 Phaser类的原理相比起来要复杂得多。它内部使用了两个基于Fork-Join框架的原子类辅助：\n1 2 3 4 5 6  private final AtomicReference\u0026lt;QNode\u0026gt; evenQ; private final AtomicReference\u0026lt;QNode\u0026gt; oddQ; static final class QNode implements ForkJoinPool.ManagedBlocker { // 实现代码 }   有兴趣的读者可以去看看JDK源代码，这里不做过多叙述。\n总的来说，CountDownLatch，CyclicBarrier，Phaser是一个比一个强大，但也一个比一个复杂。根据自己的业务需求合理选择即可。\nFork/Join框架 什么是Fork/Join Fork/Join框架是一个实现了ExecutorService接口的多线程处理器，它专为那些可以通过递归分解成更细小的任务而设计，最大化的利用多核处理器来提高应用程序的性能。\n与其他ExecutorService相关的实现相同的是，Fork/Join框架会将任务分配给线程池中的线程。而与之不同的是，Fork/Join框架在执行任务时使用了工作窃取算法。\nfork在英文里有分叉的意思，join在英文里连接、结合的意思。顾名思义，fork就是要使一个大任务分解成若干个小任务，而join就是最后将各个小任务的结果结合起来得到大任务的结果。\nFork/Join的运行流程大致如下所示：\n需要注意的是，图里的次级子任务可以一直分下去，一直分到子任务足够小为止。用伪代码来表示如下：\n1 2 3 4 5 6 7 8  solve(任务): if(任务已经划分到足够小): 顺序执行任务 else: for(划分任务得到子任务) solve(子任务) 结合所有子任务的结果到上一层循环 return 最终结合的结果   通过上面伪代码可以看出，我们通过递归嵌套的计算得到最终结果，这里有体现分而治之(divide and conquer) 的算法思想。\n工作窃取算法 工作窃取算法指的是在多线程执行不同任务队列的过程中，某个线程执行完自己队列的任务后从其他线程的任务队列里窃取任务来执行。\n工作窃取流程如下图所示：\n值得注意的是，当一个线程窃取另一个线程的时候，为了减少两个任务线程之间的竞争，我们通常使用双端队列来存储任务。被窃取的任务线程都从双端队列的头部拿任务执行，而窃取其他任务的线程从双端队列的尾部执行任务。\n另外，当一个线程在窃取任务时要是没有其他可用的任务了，这个线程会进入阻塞状态以等待再次“工作”。\nFork/Join的具体实现 前面我们说Fork/Join框架简单来讲就是对任务的分割与子任务的合并，所以要实现这个框架，先得有任务。在Fork/Join框架里提供了抽象类ForkJoinTask来实现任务。\nForkJoinTask ForkJoinTask是一个类似普通线程的实体，但是比普通线程轻量得多。\nfork()方法:使用线程池中的空闲线程异步提交任务\n1 2 3 4 5 6 7 8 9 10 11 12 13  // 本文所有代码都引自Java 8 public final ForkJoinTask\u0026lt;V\u0026gt; fork() { Thread t; // ForkJoinWorkerThread是执行ForkJoinTask的专有线程，由ForkJoinPool管理  // 先判断当前线程是否是ForkJoin专有线程，如果是，则将任务push到当前线程所负责的队列里去  if ((t = Thread.currentThread()) instanceof ForkJoinWorkerThread) ((ForkJoinWorkerThread)t).workQueue.push(this); else // 如果不是则将线程加入队列  // 没有显式创建ForkJoinPool的时候走这里，提交任务到默认的common线程池中  ForkJoinPool.common.externalPush(this); return this; }   其实fork()只做了一件事，那就是把任务推入当前工作线程的工作队列里。\njoin()方法：等待处理任务的线程处理完毕，获得返回值。\n来看下join()的源码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  public final V join() { int s; // doJoin()方法来获取当前任务的执行状态  if ((s = doJoin() \u0026amp; DONE_MASK) != NORMAL) // 任务异常，抛出异常  reportException(s); // 任务正常完成，获取返回值  return getRawResult(); } /** * doJoin()方法用来返回当前任务的执行状态 **/ private int doJoin() { int s; Thread t; ForkJoinWorkerThread wt; ForkJoinPool.WorkQueue w; // 先判断任务是否执行完毕，执行完毕直接返回结果（执行状态）  return (s = status) \u0026lt; 0 ? s : // 如果没有执行完毕，先判断是否是ForkJoinWorkThread线程  ((t = Thread.currentThread()) instanceof ForkJoinWorkerThread) ? // 如果是，先判断任务是否处于工作队列顶端（意味着下一个就执行它）  // tryUnpush()方法判断任务是否处于当前工作队列顶端，是返回true  // doExec()方法执行任务  (w = (wt = (ForkJoinWorkerThread)t).workQueue). // 如果是处于顶端并且任务执行完毕，返回结果  tryUnpush(this) \u0026amp;\u0026amp; (s = doExec()) \u0026lt; 0 ? s : // 如果不在顶端或者在顶端却没未执行完毕，那就调用awitJoin()执行任务  // awaitJoin()：使用自旋使任务执行完成，返回结果  wt.pool.awaitJoin(w, this, 0L) : // 如果不是ForkJoinWorkThread线程，执行externalAwaitDone()返回任务结果  externalAwaitDone(); }   我们在之前介绍过说Thread.join()会使线程阻塞，而ForkJoinPool.join()会使线程免于阻塞，下面是ForkJoinPool.join()的流程图：\nRecursiveAction和RecursiveTask\n通常情况下，在创建任务的时候我们一般不直接继承ForkJoinTask，而是继承它的子类RecursiveAction和RecursiveTask。\n两个都是ForkJoinTask的子类，RecursiveAction可以看做是无返回值的ForkJoinTask，RecursiveTask是有返回值的ForkJoinTask。\n此外，两个子类都有执行主要计算的方法compute()，当然，RecursiveAction的compute()返回void，RecursiveTask的compute()有具体的返回值。\nForkJoinPool ForkJoinPool是用于执行ForkJoinTask任务的执行（线程）池。\nForkJoinPool管理着执行池中的线程和任务队列，此外，执行池是否还接受任务，显示线程的运行状态也是在这里处理。\n我们来大致看下ForkJoinPool的源码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  @sun.misc.Contended public class ForkJoinPool extends AbstractExecutorService { // 任务队列  volatile WorkQueue[] workQueues; // 线程的运行状态  volatile int runState; // 创建ForkJoinWorkerThread的默认工厂，可以通过构造函数重写  public static final ForkJoinWorkerThreadFactory defaultForkJoinWorkerThreadFactory; // 公用的线程池，其运行状态不受shutdown()和shutdownNow()的影响  static final ForkJoinPool common; // 私有构造方法，没有任何安全检查和参数校验，由makeCommonPool直接调用  // 其他构造方法都是源自于此方法  // parallelism: 并行度，  // 默认调用java.lang.Runtime.availableProcessors() 方法返回可用处理器的数量  private ForkJoinPool(int parallelism, ForkJoinWorkerThreadFactory factory, // 工作线程工厂  UncaughtExceptionHandler handler, // 拒绝任务的handler  int mode, // 同步模式  String workerNamePrefix) { // 线程名prefix  this.workerNamePrefix = workerNamePrefix; this.factory = factory; this.ueh = handler; this.config = (parallelism \u0026amp; SMASK) | mode; long np = (long)(-parallelism); // offset ctl counts  this.ctl = ((np \u0026lt;\u0026lt; AC_SHIFT) \u0026amp; AC_MASK) | ((np \u0026lt;\u0026lt; TC_SHIFT) \u0026amp; TC_MASK); } }   WorkQueue 双端队列，ForkJoinTask存放在这里。\n当工作线程在处理自己的工作队列时，会从队列首取任务来执行（FIFO）；如果是窃取其他队列的任务时，窃取的任务位于所属任务队列的队尾（LIFO）。\nForkJoinPool与传统线程池最显著的区别就是它维护了一个工作队列数组（volatile WorkQueue[] workQueues，ForkJoinPool中的每个工作线程都维护着一个工作队列）。\nrunState ForkJoinPool的运行状态。SHUTDOWN状态用负数表示，其他用2的幂次表示。\nFork/Join的使用 上面我们说ForkJoinPool负责管理线程和任务，ForkJoinTask实现fork和join操作，所以要使用Fork/Join框架就离不开这两个类了，只是在实际开发中我们常用ForkJoinTask的子类RecursiveTask 和RecursiveAction来替代ForkJoinTask。\n下面我们用一个计算斐波那契数列第n项的例子来看一下Fork/Join的使用：\n 斐波那契数列数列是一个线性递推数列，从第三项开始，每一项的值都等于前两项之和：\n1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89······\n如果设f(n）为该数列的第n项（n∈N*），那么有：f(n) = f(n-1) + f(n-2)。\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43  public class FibonacciTest { class Fibonacci extends RecursiveTask\u0026lt;Integer\u0026gt; { int n; public Fibonacci(int n) { this.n = n; } // 主要的实现逻辑都在compute()里  @Override protected Integer compute() { // 这里先假设 n \u0026gt;= 0  if (n \u0026lt;= 1) { return n; } else { // f(n-1)  Fibonacci f1 = new Fibonacci(n - 1); f1.fork(); // f(n-2)  Fibonacci f2 = new Fibonacci(n - 2); f2.fork(); // f(n) = f(n-1) + f(n-2)  return f1.join() + f2.join(); } } } @Test public void testFib() throws ExecutionException, InterruptedException { ForkJoinPool forkJoinPool = new ForkJoinPool(); System.out.println(\u0026#34;CPU核数：\u0026#34; + Runtime.getRuntime().availableProcessors()); long start = System.currentTimeMillis(); Fibonacci fibonacci = new Fibonacci(40); Future\u0026lt;Integer\u0026gt; future = forkJoinPool.submit(fibonacci); System.out.println(future.get()); long end = System.currentTimeMillis(); System.out.println(String.format(\u0026#34;耗时：%d millis\u0026#34;, end - start)); } }   上面例子在本机的输出：\n1 2 3  CPU核数：4 计算结果：102334155 耗时：9490 millis   需要注意的是，上述计算时间复杂度为O(2^n)，随着n的增长计算效率会越来越低，这也是上面的例子中n不敢取太大的原因。\n此外，也并不是所有的任务都适合Fork/Join框架，比如上面的例子任务划分过于细小反而体现不出效率，下面我们试试用普通的递归来求f(n)的值，看看是不是要比使用Fork/Join快：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  // 普通递归，复杂度为O(2^n) public int plainRecursion(int n) { if (n == 1 || n == 2) { return 1; } else { return plainRecursion(n -1) + plainRecursion(n - 2); } } @Test public void testPlain() { long start = System.currentTimeMillis(); int result = plainRecursion(40); long end = System.currentTimeMillis(); System.out.println(\u0026#34;计算结果:\u0026#34; + result); System.out.println(String.format(\u0026#34;耗时：%d millis\u0026#34;, end -start)); }   普通递归的例子输出：\n1 2  计算结果:102334155 耗时：436 millis   通过输出可以很明显的看出来，使用普通递归的效率都要比使用Fork/Join框架要高很多。\n这里我们再用另一种思路来计算：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  // 通过循环来计算，复杂度为O(n) private int computeFibonacci(int n) { // 假设n \u0026gt;= 0  if (n \u0026lt;= 1) { return n; } else { int first = 1; int second = 1; int third = 0; for (int i = 3; i \u0026lt;= n; i ++) { // 第三个数是前两个数之和  third = first + second; // 前两个数右移  first = second; second = third; } return third; } } @Test public void testComputeFibonacci() { long start = System.currentTimeMillis(); int result = computeFibonacci(40); long end = System.currentTimeMillis(); System.out.println(\u0026#34;计算结果:\u0026#34; + result); System.out.println(String.format(\u0026#34;耗时：%d millis\u0026#34;, end -start)); }   上面例子在笔者所用电脑的输出为：\n1 2  计算结果:102334155 耗时：0 millis   这里耗时为0不代表没有耗时，是表明这里计算的耗时几乎可以忽略不计，大家可以在自己的电脑试试，即使是n取大很多量级的数据（注意int溢出的问题）耗时也是很短的，或者可以用System.nanoTime()统计纳秒的时间。\n为什么在这里普通的递归或循环效率更快呢？因为Fork/Join是使用多个线程协作来计算的，所以会有线程通信和线程切换的开销。\n如果要计算的任务比较简单（比如我们案例中的斐波那契数列），那当然是直接使用单线程会更快一些。但如果要计算的东西比较复杂，计算机又是多核的情况下，就可以充分利用多核CPU来提高计算速度。\n另外，Java 8 Stream的并行操作底层就是用到了Fork/Join框架，下一章我们将从源码及案例两方面介绍Java 8 Stream的并行操作。\nJava 8 Stream并行计算原理 Java 8 Stream简介 从Java 8 开始，我们可以使用Stream接口以及lambda表达式进行“流式计算”。它可以让我们对集合的操作更加简洁、更加可读、更加高效。\nStream接口有非常多用于集合计算的方法，比如判空操作empty、过滤操作filter、求最max值、查找操作findFirst和findAny等等。\nStream单线程串行计算 Stream接口默认是使用串行的方式，也就是说在一个线程里执行。下面举一个例子：\n1 2 3 4 5 6 7 8 9 10 11  public class StreamDemo { public static void main(String[] args) { Stream.of(1, 2, 3, 4, 5, 6, 7, 8, 9) .reduce((a, b) -\u0026gt; { System.out.println(String.format(\u0026#34;%s: %d + %d = %d\u0026#34;, Thread.currentThread().getName(), a, b, a + b)); return a + b; }) .ifPresent(System.out::println); } }   我们来理解一下这个方法。首先我们用整数1~9创建了一个Stream。这里的Stream.of(T\u0026hellip; values)方法是Stream接口的一个静态方法，其底层调用的是Arrays.stream(T[] array)方法。\n然后我们使用了reduce方法来计算这个集合的累加和。reduce方法这里做的是：从前两个元素开始，进行某种操作（我这里进行的是加法操作）后，返回一个结果，然后再拿这个结果跟第三个元素执行同样的操作，以此类推，直到最后的一个元素。\n我们来打印一下当前这个reduce操作的线程以及它们被操作的元素和返回的结果以及最后所有reduce方法的结果，也就代表的是数字1到9的累加和。\n main: 1 + 2 = 3 main: 3 + 3 = 6 main: 6 + 4 = 10 main: 10 + 5 = 15 main: 15 + 6 = 21 main: 21 + 7 = 28 main: 28 + 8 = 36 main: 36 + 9 = 45 45\n 可以看到，默认情况下，它是在一个单线程运行的，也就是main线程。然后每次reduce操作都是串行起来的，首先计算前两个数字的和，然后再往后依次计算。\nStream多线程并行计算 我们思考上面一个例子，是不是一定要在单线程里进行串行地计算呢？假如我的计算机是一个多核计算机，我们在理论上能否利用多核来进行并行计算，提高计算效率呢？\n当然可以，比如我们在计算前两个元素1 + 2 = 3的时候，其实我们也可以同时在另一个核计算 3 + 4 = 7。然后等它们都计算完成之后，再计算 3 + 7 = 10的操作。\n是不是很熟悉这样的操作手法？没错，它就是ForkJoin框架的思想。下面小小地修改一下上面的代码，增加一行代码，使Stream使用多线程来并行计算：\n1 2 3 4 5 6 7 8 9 10 11 12  public class StreamParallelDemo { public static void main(String[] args) { Stream.of(1, 2, 3, 4, 5, 6, 7, 8, 9) .parallel() .reduce((a, b) -\u0026gt; { System.out.println(String.format(\u0026#34;%s: %d + %d = %d\u0026#34;, Thread.currentThread().getName(), a, b, a + b)); return a + b; }) .ifPresent(System.out::println); } }   可以看到，与上一个案例的代码只有一点点区别，就是在reduce方法被调用之前，调用了parallel()方法。下面来看看这个方法的输出：\n ForkJoinPool.commonPool-worker-1: 3 + 4 = 7 ForkJoinPool.commonPool-worker-4: 8 + 9 = 17 ForkJoinPool.commonPool-worker-2: 5 + 6 = 11 ForkJoinPool.commonPool-worker-3: 1 + 2 = 3 ForkJoinPool.commonPool-worker-4: 7 + 17 = 24 ForkJoinPool.commonPool-worker-4: 11 + 24 = 35 ForkJoinPool.commonPool-worker-3: 3 + 7 = 10 ForkJoinPool.commonPool-worker-3: 10 + 35 = 45 45\n 可以很明显地看到，它使用的线程是ForkJoinPool里面的commonPool里面的worker线程。并且它们是并行计算的，并不是串行计算的。但由于Fork/Join框架的作用，它最终能很好的协调计算结果，使得计算结果完全正确。\n如果我们用Fork/Join代码去实现这样一个功能，那无疑是非常复杂的。但Java8提供了并行式的流式计算，大大简化了我们的代码量，使得我们只需要写很少很简单的代码就可以利用计算机底层的多核资源。\n从源码看Stream并行计算原理 上面我们通过在控制台输出线程的名字，看到了Stream的并行计算底层其实是使用的Fork/Join框架。那它到底是在哪使用Fork/Join的呢？我们从源码上来解析一下上述案例。\nStream.of方法就不说了，它只是生成一个简单的Stream。先来看看parallel()方法的源码。这里由于我的数据是int类型的，所以它其实是使用的BaseStream接口的parallel()方法。而BaseStream接口的JDK唯一实现类是一个叫AbstractPipeline的类。下面我们来看看这个类的parallel()方法的代码：\n1 2 3 4  public final S parallel() { sourceStage.parallel = true; return (S) this; }   这个方法很简单，就是把一个标识sourceStage.parallel设置为true。然后返回实例本身。\n接着我们再来看reduce这个方法的内部实现。\nStream.reduce()方法的具体实现是交给了ReferencePipeline这个抽象类，它是继承了AbstractPipeline这个类的:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  // ReferencePipeline抽象类的reduce方法 @Override public final Optional\u0026lt;P_OUT\u0026gt; reduce(BinaryOperator\u0026lt;P_OUT\u0026gt; accumulator) { // 调用evaluate方法  return evaluate(ReduceOps.makeRef(accumulator)); } final \u0026lt;R\u0026gt; R evaluate(TerminalOp\u0026lt;E_OUT, R\u0026gt; terminalOp) { assert getOutputShape() == terminalOp.inputShape(); if (linkedOrConsumed) throw new IllegalStateException(MSG_STREAM_LINKED); linkedOrConsumed = true; return isParallel() // 调用isParallel()判断是否使用并行模式  ? terminalOp.evaluateParallel(this, sourceSpliterator(terminalOp.getOpFlags())) : terminalOp.evaluateSequential(this, sourceSpliterator(terminalOp.getOpFlags())); } @Override public final boolean isParallel() { // 根据之前在parallel()方法设置的那个flag来判断。  return sourceStage.parallel; }   从它的源码可以知道，reduce方法调用了evaluate方法，而evaluate方法会先去检查当前的flag，是否使用并行模式，如果是则会调用evaluateParallel方法执行并行计算，否则，会调用evaluateSequential方法执行串行计算。\n这里我们再看看TerminalOp（注意这里是字母l O，而不是数字1 0）接口的evaluateParallel方法。TerminalOp接口的实现类有这样几个内部类：\n java.util.stream.FindOps.FindOp java.util.stream.ForEachOps.ForEachOp java.util.stream.MatchOps.MatchOp java.util.stream.ReduceOps.ReduceOp  可以看到，对应的是Stream的几种主要的计算操作。我们这里的示例代码使用的是reduce计算，那我们就看看ReduceOp类的这个方法的源码：\n1 2 3 4 5 6  // java.util.stream.ReduceOps.ReduceOp.evaluateParallel @Override public \u0026lt;P_IN\u0026gt; R evaluateParallel(PipelineHelper\u0026lt;T\u0026gt; helper, Spliterator\u0026lt;P_IN\u0026gt; spliterator) { return new ReduceTask\u0026lt;\u0026gt;(this, helper, spliterator).invoke().get(); }   evaluateParallel方法创建了一个新的ReduceTask实例，并且调用了invoke()方法后再调用get()方法，然后返回这个结果。那这个ReduceTask是什么呢？它的invoke方法内部又是什么呢？\n追溯源码我们可以发现，ReduceTask类是ReduceOps类的一个内部类，它继承了AbstractTask类，而AbstractTask类又继承了CountedCompleter类，而CountedCompleter类又继承了ForkJoinTask类！\n它们的继承关系如下：\n ReduceTask -\u0026gt; AbstractTask -\u0026gt; CountedCompleter -\u0026gt; ForkJoinTask\n 这里的ReduceTask的invoke方法，其实是调用的ForkJoinTask的invoke方法，中间三层继承并没有覆盖这个方法的实现。\n所以这就从源码层面解释了Stream并行的底层原理是使用了Fork/Join框架。\n需要注意的是，一个Java进程的Stream并行计算任务默认共享同一个线程池，如果随意的使用并行特性可能会导致方法的吞吐量下降。我们可以通过下面这种方式来让你的某个并行Stream使用自定义的ForkJoin线程池：\n1 2 3  ForkJoinPool customThreadPool = new ForkJoinPool(4); long actualTotal = customThreadPool .submit(() -\u0026gt; roster.parallelStream().reduce(0, Integer::sum)).get();   Stream并行计算的性能提升 我们可以在本地测试一下如果在多核情况下，Stream并行计算会给我们的程序带来多大的效率上的提升。用以下示例代码来计算一千万个随机数的和：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  public class StreamParallelDemo { public static void main(String[] args) { System.out.println(String.format(\u0026#34;本计算机的核数：%d\u0026#34;, Runtime.getRuntime().availableProcessors())); // 产生100w个随机数(1 ~ 100)，组成列表  Random random = new Random(); List\u0026lt;Integer\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(1000_0000); for (int i = 0; i \u0026lt; 1000_0000; i++) { list.add(random.nextInt(100)); } long prevTime = getCurrentTime(); list.stream().reduce((a, b) -\u0026gt; a + b).ifPresent(System.out::println); System.out.println(String.format(\u0026#34;单线程计算耗时：%d\u0026#34;, getCurrentTime() - prevTime)); prevTime = getCurrentTime(); list.stream().parallel().reduce((a, b) -\u0026gt; a + b).ifPresent(System.out::println); System.out.println(String.format(\u0026#34;多线程计算耗时：%d\u0026#34;, getCurrentTime() - prevTime)); } private static long getCurrentTime() { return System.currentTimeMillis(); } }   输出：\n 本计算机的核数：8 495156156 单线程计算耗时：223 495156156 多线程计算耗时：95\n 所以在多核的情况下，使用Stream的并行计算确实比串行计算能带来很大效率上的提升，并且也能保证结果计算完全准确。\n本文一直在强调的“多核”的情况。其实可以看到，我的本地电脑有8核，但并行计算耗时并不是单线程计算耗时除以8，因为线程的创建、销毁以及维护线程上下文的切换等等都有一定的开销。所以如果你的服务器并不是多核服务器，那也没必要用Stream的并行计算。因为在单核的情况下，往往Stream的串行计算比并行计算更快，因为它不需要线程切换的开销。\n计划任务 自JDK 1.5 开始，JDK提供了ScheduledThreadPoolExecutor类用于计划任务（又称定时任务），这个类有两个用途：\n 在给定的延迟之后运行任务 周期性重复执行任务  在这之前，是使用Timer类来完成定时任务的，但是Timer有缺陷：\n Timer是单线程模式； 如果在执行任务期间某个TimerTask耗时较久，那么就会影响其它任务的调度； Timer的任务调度是基于绝对时间的，对系统时间敏感； Timer不会捕获执行TimerTask时所抛出的异常，由于Timer是单线程，所以一旦出现异常，则线程就会终止，其他任务也得不到执行。  所以JDK 1.5之后，大家就摒弃Timer,使用ScheduledThreadPoolExecutor吧。\n使用案例 假设我有一个需求，指定时间给大家发送消息。那么我们会将消息（包含发送时间）存储在数据库中，然后想用一个定时任务，每隔1秒检查数据库在当前时间有没有需要发送的消息，那这个计划任务怎么写？下面是一个Demo:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  public class ThreadPool { private static final ScheduledExecutorService executor = new ScheduledThreadPoolExecutor(1, Executors.defaultThreadFactory()); private static SimpleDateFormat df = new SimpleDateFormat(\u0026#34;yyyy-MM-dd HH:mm:ss\u0026#34;); public static void main(String[] args){ // 新建一个固定延迟时间的计划任务  executor.scheduleWithFixedDelay(new Runnable() { @Override public void run() { if (haveMsgAtCurrentTime()) { System.out.println(df.format(new Date())); System.out.println(\u0026#34;大家注意了，我要发消息了\u0026#34;); } } }, 1, 1, TimeUnit.SECONDS); } public static boolean haveMsgAtCurrentTime(){ //查询数据库，有没有当前时间需要发送的消息  //这里省略实现，直接返回true  return true; } }   下面截取前面的输出（这个demo会一直运行下去）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  2019-01-23 16:16:48 大家注意了，我要发消息了 2019-01-23 16:16:49 大家注意了，我要发消息了 2019-01-23 16:16:50 大家注意了，我要发消息了 2019-01-23 16:16:51 大家注意了，我要发消息了 2019-01-23 16:16:52 大家注意了，我要发消息了 2019-01-23 16:16:53 大家注意了，我要发消息了 2019-01-23 16:16:54 大家注意了，我要发消息了 2019-01-23 16:16:55 大家注意了，我要发消息了   这就是ScheduledThreadPoolExecutor的一个简单运用，想要知道奥秘，接下来的东西需要仔细的看哦。\n类结构 1 2 3 4 5 6 7 8 9  public class ScheduledThreadPoolExecutor extends ThreadPoolExecutor implements ScheduledExecutorService { public ScheduledThreadPoolExecutor(int corePoolSize,ThreadFactory threadFactory) { super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS, new DelayedWorkQueue(), threadFactory); } //…… }   ScheduledThreadPoolExecutor继承了ThreadPoolExecutor，实现了ScheduledExecutorService。 线程池在之前的章节介绍过了，我们先看看ScheduledExecutorService。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  public interface ScheduledExecutorService extends ExecutorService { public ScheduledFuture\u0026lt;?\u0026gt; schedule(Runnable command,long delay, TimeUnit unit); public \u0026lt;V\u0026gt; ScheduledFuture\u0026lt;V\u0026gt; schedule(Callable\u0026lt;V\u0026gt; callable,long delay, TimeUnit unit); public ScheduledFuture\u0026lt;?\u0026gt; scheduleAtFixedRate(Runnable command, long initialDelay, long period, TimeUnit unit); public ScheduledFuture\u0026lt;?\u0026gt; scheduleWithFixedDelay(Runnable command, long initialDelay, long delay, TimeUnit unit); }   ScheduledExecutorService实现了ExecutorService ,并增加若干定时相关的接口。 前两个方法用于单次调度执行任务，区别是有没有返回值。\n重点理解一下后面两个方法：\n  scheduleAtFixedRate\n该方法在initialDelay时长后第一次执行任务，以后每隔period时长，再次执行任务。注意，period是从任务开始执行算起的。开始执行任务后，定时器每隔period时长检查该任务是否完成，如果完成则再次启动任务，否则等该任务结束后才再次启动任务。\n  scheduleWithFixDelay\n该方法在initialDelay时长后第一次执行任务，以后每当任务执行完成后，等待delay时长，再次执行任务。\n  主要方法介绍 schedule 1 2 3 4 5 6 7 8 9 10 11  // delay时长后执行任务command，该任务只执行一次 public ScheduledFuture\u0026lt;?\u0026gt; schedule(Runnable command, long delay, TimeUnit unit) { if (command == null || unit == null) throw new NullPointerException(); // 这里的decorateTask方法仅仅返回第二个参数  RunnableScheduledFuture\u0026lt;?\u0026gt; t = decorateTask(command, new ScheduledFutureTask\u0026lt;Void\u0026gt;(command, null, triggerTime(delay,unit))); // 延时或者周期执行任务的主要方法,稍后统一说明  delayedExecute(t); return t; }   我们先看看里面涉及到的几个类和接口ScheduledFuture、 RunnableScheduledFuture、 ScheduledFutureTask的关系：\n我们先看看这几个接口和类：\nDelayed接口 1 2 3 4 5  // 继承Comparable接口，表示该类对象支持排序 public interface Delayed extends Comparable\u0026lt;Delayed\u0026gt; { // 返回该对象剩余时延  long getDelay(TimeUnit unit); }   Delayed接口很简单，继承了Comparable接口，表示对象是可以比较排序的。\nScheduledFuture接口 1 2 3  // 仅仅继承了Delayed和Future接口，自己没有任何代码 public interface ScheduledFuture\u0026lt;V\u0026gt; extends Delayed, Future\u0026lt;V\u0026gt; { }   没有添加其他方法。\nRunnableScheduledFuture接口 1 2 3 4  public interface RunnableScheduledFuture\u0026lt;V\u0026gt; extends RunnableFuture\u0026lt;V\u0026gt;, ScheduledFuture\u0026lt;V\u0026gt; { // 是否是周期任务，周期任务可被调度运行多次，非周期任务只被运行一次  boolean isPeriodic(); }   ScheduledFutureTask类 回到schecule方法中，它创建了一个ScheduledFutureTask的对象，由上面的关系图可知，ScheduledFutureTask直接或者间接实现了很多接口，一起看看ScheduledFutureTask里面的实现方法吧。\n构造方法\n1 2 3 4 5 6 7 8 9 10  ScheduledFutureTask(Runnable r, V result, long ns, long period) { // 调用父类FutureTask的构造方法  super(r, result); // time表示任务下次执行的时间  this.time = ns; // 周期任务，正数表示按照固定速率，负数表示按照固定时延,0表示不是周期任务  this.period = period; // 任务的编号  this.sequenceNumber = sequencer.getAndIncrement(); }   Delayed接口的实现\n1 2 3 4  // 实现Delayed接口的getDelay方法，返回任务开始执行的剩余时间 public long getDelay(TimeUnit unit) { return unit.convert(time - now(), TimeUnit.NANOSECONDS); }   Comparable接口的实现\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  // Comparable接口的compareTo方法，比较两个任务的”大小”。 public int compareTo(Delayed other) { if (other == this) return 0; if (other instanceof ScheduledFutureTask) { ScheduledFutureTask\u0026lt;?\u0026gt; x = (ScheduledFutureTask\u0026lt;?\u0026gt;)other; long diff = time - x.time; // 小于0，说明当前任务的执行时间点早于other，要排在延时队列other的前面  if (diff \u0026lt; 0) return -1; // 大于0，说明当前任务的执行时间点晚于other，要排在延时队列other的后面  else if (diff \u0026gt; 0) return 1; // 如果两个任务的执行时间点一样，比较两个任务的编号，编号小的排在队列前面，编号大的排在队列后面  else if (sequenceNumber \u0026lt; x.sequenceNumber) return -1; else return 1; } // 如果任务类型不是ScheduledFutureTask，通过getDelay方法比较  long d = (getDelay(TimeUnit.NANOSECONDS) - other.getDelay(TimeUnit.NANOSECONDS)); return (d == 0) ? 0 : ((d \u0026lt; 0) ? -1 : 1); }   setNextRunTime\n1 2 3 4 5 6 7 8 9 10 11 12  // 任务执行完后，设置下次执行的时间 private void setNextRunTime() { long p = period; // p \u0026gt; 0，说明是固定速率运行的任务  // 在原来任务开始执行时间的基础上加上p即可  if (p \u0026gt; 0) time += p; // p \u0026lt; 0，说明是固定时延运行的任务，  // 下次执行时间在当前时间(任务执行完成的时间)的基础上加上-p的时间  else time = triggerTime(-p); }   Runnable接口实现\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  public void run() { boolean periodic = isPeriodic(); // 如果当前状态下不能执行任务，则取消任务  if (!canRunInCurrentRunState(periodic)) cancel(false); // 不是周期性任务，执行一次任务即可，调用父类的run方法  else if (!periodic) ScheduledFutureTask.super.run(); // 是周期性任务，调用FutureTask的runAndReset方法，方法执行完成后  // 重新设置任务下一次执行的时间，并将该任务重新入队，等待再次被调度  else if (ScheduledFutureTask.super.runAndReset()) { setNextRunTime(); reExecutePeriodic(outerTask); } }   总结一下run方法的执行过程：\n 如果当前线程池运行状态不可以执行任务，取消该任务，然后直接返回，否则执行步骤2； 如果不是周期性任务，调用FutureTask中的run方法执行，会设置执行结果，然后直接返回，否则执行步骤3； 如果是周期性任务，调用FutureTask中的runAndReset方法执行，不会设置执行结果，然后直接返回，否则执行步骤4和步骤5； 计算下次执行该任务的具体时间； 重复执行任务。  runAndReset方法是为任务多次执行而设计的。runAndReset方法执行完任务后不会设置任务的执行结果，也不会去更新任务的状态，维持任务的状态为初始状态（NEW状态），这也是该方法和FutureTask的run方法的区别。\nscheduledAtFixedRate 我们看一下代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  // 注意，固定速率和固定时延，传入的参数都是Runnable，也就是说这种定时任务是没有返回值的 public ScheduledFuture\u0026lt;?\u0026gt; scheduleAtFixedRate(Runnable command, long initialDelay, long period, TimeUnit unit) { if (command == null || unit == null) throw new NullPointerException(); if (period \u0026lt;= 0) throw new IllegalArgumentException(); // 创建一个有初始延时和固定周期的任务  ScheduledFutureTask\u0026lt;Void\u0026gt; sft = new ScheduledFutureTask\u0026lt;Void\u0026gt;(command, null, triggerTime(initialDelay, unit), unit.toNanos(period)); RunnableScheduledFuture\u0026lt;Void\u0026gt; t = decorateTask(command, sft); // outerTask表示将会重新入队的任务  sft.outerTask = t; // 稍后说明  delayedExecute(t); return t; }   scheduleAtFixedRate这个方法和schedule类似，不同点是scheduleAtFixedRate方法内部创建的是ScheduledFutureTask，带有初始延时和固定周期的任务 。\nscheduledAtFixedDelay FixedDelay也是通过ScheduledFutureTask体现的，唯一不同的地方在于创建的ScheduledFutureTask不同 。这里不再展示源码。\ndelayedExecute 前面讲到的schedule、scheduleAtFixedRate和scheduleAtFixedDelay最后都调用了delayedExecute方法，该方法是定时任务执行的主要方法。 一起来看看源码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  private void delayedExecute(RunnableScheduledFuture\u0026lt;?\u0026gt; task) { // 线程池已经关闭，调用拒绝执行处理器处理  if (isShutdown()) reject(task); else { // 将任务加入到等待队列  super.getQueue().add(task); // 线程池已经关闭，且当前状态不能运行该任务，将该任务从等待队列移除并取消该任务  if (isShutdown() \u0026amp;\u0026amp; !canRunInCurrentRunState(task.isPeriodic()) \u0026amp;\u0026amp; remove(task)) task.cancel(false); else // 增加一个worker，就算corePoolSize=0也要增加一个worker  ensurePrestart(); } }   delayedExecute方法的逻辑也很简单，主要就是将任务添加到等待队列，然后调用ensurePrestart方法。\n1 2 3 4 5 6 7  void ensurePrestart() { int wc = workerCountOf(ctl.get()); if (wc \u0026lt; corePoolSize) addWorker(null, true); else if (wc == 0) addWorker(null, false); }   ensurePrestart方法主要是调用了addWorker，线程池中的工作线程是通过该方法来启动并执行任务的。 具体可以查看前面讲的线程池章节。\n对于ScheduledThreadPoolExecutor，worker添加到线程池后会在等待队列上等待获取任务，这点是和ThreadPoolExecutor一致的。但是worker是怎么从等待队列取定时任务的？\n因为ScheduledThreadPoolExecutor使用了DelayedWorkQueue保存等待的任务，该等待队列队首应该保存的是最近将要执行的任务，如果队首任务的开始执行时间还未到，worker也应该继续等待。\nDelayedWorkQueue ScheduledThreadPoolExecutor使用了DelayedWorkQueue保存等待的任务。\n该等待队列队首应该保存的是最近将要执行的任务，所以worker只关心队首任务即可，如果队首任务的开始执行时间还未到，worker也应该继续等待。\nDelayedWorkQueue是一个无界优先队列，使用数组存储，底层是使用堆结构来实现优先队列的功能。我们先看看DelayedWorkQueue的声明和成员变量：\n1 2 3 4 5 6 7 8 9 10 11 12 13  static class DelayedWorkQueue extends AbstractQueue\u0026lt;Runnable\u0026gt; implements BlockingQueue\u0026lt;Runnable\u0026gt; { // 队列初始容量  private static final int INITIAL_CAPACITY = 16; // 数组用来存储定时任务，通过数组实现堆排序  private RunnableScheduledFuture[] queue = new RunnableScheduledFuture[INITIAL_CAPACITY]; // 当前在队首等待的线程  private Thread leader = null; // 锁和监视器，用于leader线程  private final ReentrantLock lock = new ReentrantLock(); private final Condition available = lock.newCondition(); // 其他代码，略 }   当一个线程成为leader，它只要等待队首任务的delay时间即可，其他线程会无条件等待。leader取到任务返回前要通知其他线程，直到有线程成为新的leader。每当队首的定时任务被其他更早需要执行的任务替换时，leader设置为null，其他等待的线程（被当前leader通知）和当前的leader重新竞争成为leader。\n同时，定义了锁lock和监视器available用于线程竞争成为leader。\n当一个新的任务成为队首，或者需要有新的线程成为leader时，available监视器上的线程将会被通知，然后竞争成为leader线程。 有些类似于生产者-消费者模式。\n接下来看看DelayedWorkQueue中几个比较重要的方法\ntake 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43  public RunnableScheduledFuture take() throws InterruptedException { final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try { for (;;) { // 取堆顶的任务，堆顶是最近要执行的任务  RunnableScheduledFuture first = queue[0]; // 堆顶为空，线程要在条件available上等待  if (first == null) available.await(); else { // 堆顶任务还要多长时间才能执行  long delay = first.getDelay(TimeUnit.NANOSECONDS); // 堆顶任务已经可以执行了，finishPoll会重新调整堆，使其满足最小堆特性，该方法设置任务在  // 堆中的index为-1并返回该任务  if (delay \u0026lt;= 0) return finishPoll(first); // 如果leader不为空，说明已经有线程成为leader并等待堆顶任务  // 到达执行时间，此时，其他线程都需要在available条件上等待  else if (leader != null) available.await(); else { // leader为空，当前线程成为新的leader  Thread thisThread = Thread.currentThread(); leader = thisThread; try { // 当前线程已经成为leader了，只需要等待堆顶任务到达执行时间即可  available.awaitNanos(delay); } finally { // 返回堆顶元素之前将leader设置为空  if (leader == thisThread) leader = null; } } } } } finally { // 通知其他在available条件等待的线程，这些线程可以去竞争成为新的leader  if (leader == null \u0026amp;\u0026amp; queue[0] != null) available.signal(); lock.unlock(); } }   take方法是什么时候调用的呢？在线程池的章节中，介绍了getTask方法，工作线程会循环地从workQueue中取任务。但计划任务却不同，因为如果一旦getTask方法取出了任务就开始执行了，而这时可能还没有到执行的时间，所以在take方法中，要保证只有在到指定的执行时间的时候任务才可以被取走。\n总结一下流程：\n 如果堆顶元素为空，在available条件上等待。 如果堆顶任务的执行时间已到，将堆顶元素替换为堆的最后一个元素并调整堆使其满足最小堆特性，同时设置任务在堆中索引为-1，返回该任务。 如果leader不为空，说明已经有线程成为leader了，其他线程都要在available监视器上等待。 如果leader为空，当前线程成为新的leader，并等待直到堆顶任务执行时间到达。 take方法返回之前，将leader设置为空，并通知其他线程。  再来说一下leader的作用，这里的leader是为了减少不必要的定时等待，当一个线程成为leader时，它只等待下一个节点的时间间隔，但其它线程无限期等待。 leader线程必须在从take()或poll()返回之前signal其它线程，除非其他线程成为了leader。\n举例来说，如果没有leader，那么在执行take时，都要执行available.awaitNanos(delay)，假设当前线程执行了该段代码，这时还没有signal，第二个线程也执行了该段代码，则第二个线程也要被阻塞。但只有一个线程返回队首任务，其他的线程在awaitNanos(delay)之后，继续执行for循环，因为队首任务已经被返回了，所以这个时候的for循环拿到的队首任务是新的，又需要重新判断时间，又要继续阻塞。\n所以，为了不让多个线程频繁的做无用的定时等待，这里增加了leader，如果leader不为空，则说明队列中第一个节点已经在等待出队，这时其它的线程会一直阻塞，减少了无用的阻塞（注意，在finally中调用了signal()来唤醒一个线程，而不是signalAll()）。\noffer 该方法往队列插入一个值，返回是否成功插入 。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  public boolean offer(Runnable x) { if (x == null) throw new NullPointerException(); RunnableScheduledFuture e = (RunnableScheduledFuture)x; final ReentrantLock lock = this.lock; lock.lock(); try { int i = size; // 队列元素已经大于等于数组的长度，需要扩容，新堆的容量是原来堆容量的1.5倍  if (i \u0026gt;= queue.length) grow(); // 堆中元素增加1  size = i + 1; // 调整堆  if (i == 0) { queue[0] = e; setIndex(e, 0); } else { // 调整堆，使的满足最小堆，比较大小的方式就是上文提到的compareTo方法  siftUp(i, e); } if (queue[0] == e) { leader = null; // 通知其他在available条件上等待的线程，这些线程可以竞争成为新的leader  available.signal(); } } finally { lock.unlock(); } return true; }   在堆中插入了一个节点，这个时候堆有可能不满足最小堆的定义，siftUp用于将堆调整为最小堆，这属于数据结构的基本内容，本文不做介绍。\n总结 内部使用优化的DelayQueue来实现，由于使用队列来实现定时器，有出入队调整堆等操作，所以定时并不是非常非常精确。\n","date":"2021-04-07T13:36:41Z","image":"https://ahao.ink/14.jpg","permalink":"https://ahao.ink/posts/java%E5%B9%B6%E5%8F%91-jdk%E5%B7%A5%E5%85%B7%E7%AF%87/","title":"Java并发 JDK工具篇"},{"content":"Java内存模型基础知识 并发编程模型的两个关键问题  线程间如何通信？即：线程之间以何种机制来交换信息 线程间如何同步？即：线程以何种机制来控制不同线程间操作发生的相对顺序  有两种并发模型可以解决这两个问题：\n 消息传递并发模型 共享内存并发模型  这两种模型之间的区别如下表所示：\n在Java中，使用的是共享内存并发模型。\nJava内存模型的抽象结构 运行时内存的划分 先谈一下运行时数据区，下面这张图相信大家一点都不陌生：\n对于每一个线程来说，栈都是私有的，而堆是共有的。\n也就是说在栈中的变量（局部变量、方法定义参数、异常处理器参数）不会在线程之间共享，也就不会有内存可见性（下文会说到）的问题，也不受内存模型的影响。而在堆中的变量是共享的，本文称为共享变量。\n所以，内存可见性是针对的共享变量。\n既然堆是共享的，为什么在堆中会有内存不可见问题？ 这是因为现代计算机为了高效，往往会在高速缓存区中缓存共享变量，因为cpu访问缓存区比访问内存要快得多。\n 线程之间的共享变量存在主内存中，每个线程都有一个私有的本地内存，存储了该线程以读、写共享变量的副本。本地内存是Java内存模型的一个抽象概念，并不真实存在。它涵盖了缓存、写缓冲区、寄存器等。\n Java线程之间的通信由Java内存模型（简称JMM）控制，从抽象的角度来说，JMM定义了线程和主内存之间的抽象关系。JMM的抽象示意图如图所示：\n从图中可以看出：\n 所有的共享变量都存在主内存中。 每个线程都保存了一份该线程使用到的共享变量的副本。 如果线程A与线程B之间要通信的话，必须经历下面2个步骤：  线程A将本地内存A中更新过的共享变量刷新到主内存中去。 线程B到主内存中去读取线程A之前已经更新过的共享变量。    所以，线程A无法直接访问线程B的工作内存，线程间通信必须经过主内存。\n注意，根据JMM的规定，线程对共享变量的所有操作都必须在自己的本地内存中进行，不能直接从主内存中读取。\n所以线程B并不是直接去主内存中读取共享变量的值，而是先在本地内存B中找到这个共享变量，发现这个共享变量已经被更新了，然后本地内存B去主内存中读取这个共享变量的新值，并拷贝到本地内存B中，最后线程B再读取本地内存B中的新值。\n那么怎么知道这个共享变量的被其他线程更新了呢？这就是JMM的功劳了，也是JMM存在的必要性之一。JMM通过控制主内存与每个线程的本地内存之间的交互，来提供内存可见性保证。\n Java中的volatile关键字可以保证多线程操作共享变量的可见性以及禁止指令重排序，synchronized关键字不仅保证可见性，同时也保证了原子性（互斥性）。在更底层，JMM通过内存屏障来实现内存的可见性以及禁止重排序。为了程序员的方便理解，提出了happens-before，它更加的简单易懂，从而避免了程序员为了理解内存可见性而去学习复杂的重排序规则以及这些规则的具体实现方法。这里涉及到的所有内容后面都会有专门的章节介绍。\n JMM与Java内存区域划分的区别与联系 上面两小节分别提到了JMM和Java运行时内存区域的划分，这两者既有差别又有联系：\n  区别\n两者是不同的概念层次。JMM是抽象的，他是用来描述一组规则，通过这个规则来控制各个变量的访问方式，围绕原子性、有序性、可见性等展开的。而Java运行时内存的划分是具体的，是JVM运行Java程序时，必要的内存划分。\n  联系\n都存在私有数据区域和共享数据区域。一般来说，JMM中的主内存属于共享数据区域，他是包含了堆和方法区；同样，JMM中的本地内存属于私有数据区域，包含了程序计数器、本地方法栈、虚拟机栈。\n  实际上，他们表达的是同一种含义，这里不做区分。\n重排序与happens-before 什么是重排序？ 计算机在执行程序时，为了提高性能，编译器和处理器常常会对指令做重排。\n为什么指令重排序可以提高性能？\n简单地说，每一个指令都会包含多个步骤，每个步骤可能使用不同的硬件。因此，流水线技术产生了，它的原理是指令1还没有执行完，就可以开始执行指令2，而不用等到指令1执行结束之后再执行指令2，这样就大大提高了效率。\n但是，流水线技术最害怕中断，恢复中断的代价是比较大的，所以我们要想尽办法不让流水线中断。指令重排就是减少中断的一种技术。\n我们分析一下下面这个代码的执行情况：\n1 2  a = b + c; d = e - f ;   先加载b、c（注意，即有可能先加载b，也有可能先加载c），但是在执行add(b,c)的时候，需要等待b、c装载结束才能继续执行，也就是增加了停顿，那么后面的指令也会依次有停顿,这降低了计算机的执行效率。\n为了减少这个停顿，我们可以先加载e和f,然后再去加载add(b,c),这样做对程序（串行）是没有影响的,但却减少了停顿。既然add(b,c)需要停顿，那还不如去做一些有意义的事情。\n综上所述，指令重排对于提高CPU处理性能十分必要。虽然由此带来了乱序的问题，但是这点牺牲是值得的。\n指令重排一般分为以下三种：\n  编译器优化重排\n编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。\n  指令并行重排\n现代处理器采用了指令级并行技术来将多条指令重叠执行。如果不存在数据依赖性(即后一个执行的语句无需依赖前面执行的语句的结果)，处理器可以改变语句对应的机器指令的执行顺序。\n  内存系统重排\n由于处理器使用缓存和读写缓存冲区，这使得加载(load)和存储(store)操作看上去可能是在乱序执行，因为三级缓存的存在，导致内存与缓存的数据同步存在时间差。\n  指令重排可以保证串行语义一致，但是没有义务保证多线程间的语义也一致。所以在多线程下，指令重排序可能会导致一些问题。\n顺序一致性模型与JMM的保证 顺序一致性模型是一个理论参考模型，内存模型在设计的时候都会以顺序一致性内存模型作为参考。\n数据竞争与顺序一致性 当程序未正确同步的时候，就可能存在数据竞争。\n 数据竞争：在一个线程中写一个变量，在另一个线程读同一个变量，并且写和读没有通过同步来排序。\n 如果程序中包含了数据竞争，那么运行的结果往往充满了不确定性，比如读发生在了写之前，可能就会读到错误的值；如果一个线程程序能够正确同步，那么就不存在数据竞争。\nJava内存模型（JMM）对于正确同步多线程程序的内存一致性做了以下保证：\n 如果程序是正确同步的，程序的执行将具有顺序一致性。 即程序的执行结果和该程序在顺序一致性模型中执行的结果相同。\n 这里的同步包括了使用volatile、final、synchronized等关键字来实现多线程下的同步。\n如果程序员没有正确使用volatile、final、synchronized，那么即便是使用了同步（单线程下的同步），JMM也不会有内存可见性的保证，可能会导致你的程序出错，并且具有不可重现性，很难排查。\n所以如何正确使用volatile、final、synchronized，是程序员应该去了解的。后面会有专门的章节介绍这几个关键字的内存语义及使用。\n顺序一致性模型 顺序一致性内存模型是一个理想化的理论参考模型，它为程序员提供了极强的内存可见性保证。\n顺序一致性模型有两大特性：\n 一个线程中的所有操作必须按照程序的顺序（即Java代码的顺序）来执行。 不管程序是否同步，所有线程都只能看到一个单一的操作执行顺序。即在顺序一致性模型中，每个操作必须是原子性的，且立刻对所有线程可见。  为了理解这两个特性，我们举个例子，假设有两个线程A和B并发执行，线程A有3个操作，他们在程序中的顺序是A1-\u0026gt;A2-\u0026gt;A3，线程B也有3个操作，B1-\u0026gt;B2-\u0026gt;B3。\n假设正确使用了同步，A线程的3个操作执行后释放锁，B线程获取同一个锁。那么在顺序一致性模型中的执行效果如下所示：\n操作的执行整体上有序，并且两个线程都只能看到这个执行顺序。\n假设没有使用同步，那么在顺序一致性模型中的执行效果如下所示：\n操作的执行整体上无序，但是两个线程都只能看到这个执行顺序。之所以可以得到这个保证，是因为顺序一致性模型中的每个操作必须立即对任意线程可见。\n但是JMM没有这样的保证。\n比如，在当前线程把写过的数据缓存在本地内存中，在没有刷新到主内存之前，这个写操作仅对当前线程可见；从其他线程的角度来观察，这个写操作根本没有被当前线程所执行。只有当前线程把本地内存中写过的数据刷新到主内存之后，这个写操作才对其他线程可见。在这种情况下，当前线程和其他线程看到的执行顺序是不一样的。\nJMM中同步程序的顺序一致性效果 在顺序一致性模型中，所有操作完全按照程序的顺序串行执行。但是JMM中，临界区内（同步块或同步方法中）的代码可以发生重排序（但不允许临界区内的代码“逃逸”到临界区之外，因为会破坏锁的内存语义）。\n虽然线程A在临界区做了重排序，但是因为锁的特性，线程B无法观察到线程A在临界区的重排序。这种重排序既提高了执行效率，又没有改变程序的执行结果。\n同时，JMM会在退出临界区和进入临界区做特殊的处理，使得在临界区内程序获得与顺序一致性模型相同的内存视图。\n由此可见，JMM的具体实现方针是：在不改变（正确同步的）程序执行结果的前提下，尽量为编译期和处理器的优化打开方便之门。\nJMM中未同步程序的顺序一致性效果 对于未同步的多线程程序，JMM只提供最小安全性：线程读取到的值，要么是之前某个线程写入的值，要么是默认值，不会无中生有。\n为了实现这个安全性，JVM在堆上分配对象时，首先会对内存空间清零，然后才会在上面分配对象（这两个操作是同步的）。\nJMM没有保证未同步程序的执行结果与该程序在顺序一致性中执行结果一致。因为如果要保证执行结果一致，那么JMM需要禁止大量的优化，对程序的执行性能会产生很大的影响。\n未同步程序在JMM和顺序一致性内存模型中的执行特性有如下差异：\n 顺序一致性保证单线程内的操作会按程序的顺序执行；JMM不保证单线程内的操作会按程序的顺序执行。（因为重排序，但是JMM保证单线程下的重排序不影响执行结果） 顺序一致性模型保证所有线程只能看到一致的操作执行顺序，而JMM不保证所有线程能看到一致的操作执行顺序。（因为JMM不保证所有操作立即可见） 顺序一致性模型保证对所有的内存读写操作都具有原子性，而JMM不保证对64位的long型和double型变量的写操作具有原子性。  happens-before 什么是happens-before? 一方面，程序员需要JMM提供一个强的内存模型来编写代码；另一方面，编译器和处理器希望JMM对它们的束缚越少越好，这样它们就可以最可能多的做优化来提高性能，希望的是一个弱的内存模型。\nJMM考虑了这两种需求，并且找到了平衡点，对编译器和处理器来说，只要不改变程序的执行结果（单线程程序和正确同步了的多线程程序），编译器和处理器怎么优化都行。\n而对于程序员，JMM提供了happens-before规则（JSR-133规范），满足了程序员的需求——**简单易懂，并且提供了足够强的内存可见性保证。**换言之，程序员只要遵循happens-before规则，那他写的程序就能保证在JMM中具有强的内存可见性。\nJMM使用happens-before的概念来定制两个操作之间的执行顺序。这两个操作可以在一个线程以内，也可以是不同的线程之间。因此，JMM可以通过happens-before关系向程序员提供跨线程的内存可见性保证。\nhappens-before关系的定义如下：\n 如果一个操作happens-before另一个操作，那么第一个操作的执行结果将对第二个操作可见，而且第一个操作的执行顺序排在第二个操作之前。 两个操作之间存在happens-before关系，并不意味着Java平台的具体实现必须要按照happens-before关系指定的顺序来执行。如果重排序之后的执行结果，与按happens-before关系来执行的结果一致，那么JMM也允许这样的重排序。  happens-before关系本质上和as-if-serial语义是一回事。\nas-if-serial语义保证单线程内重排序后的执行结果和程序代码本身应有的结果是一致的，happens-before关系保证正确同步的多线程程序的执行结果不被重排序改变。\n总之，如果操作A happens-before操作B，那么操作A在内存上所做的操作对操作B都是可见的，不管它们在不在一个线程。\n天然的happens-before关系 在Java中，有以下天然的happens-before关系：\n 程序顺序规则：一个线程中的每一个操作，happens-before于该线程中的任意后续操作。 监视器锁规则：对一个锁的解锁，happens-before于随后对这个锁的加锁。 volatile变量规则：对一个volatile域的写，happens-before于任意后续对这个volatile域的读。 传递性：如果A happens-before B，且B happens-before C，那么A happens-before C。 start规则：如果线程A执行操作ThreadB.start()启动线程B，那么A线程的ThreadB.start（）操作happens-before于线程B中的任意操作、 join规则：如果线程A执行操作ThreadB.join（）并成功返回，那么线程B中的任意操作happens-before于线程A从ThreadB.join()操作成功返回。  举例：\n1 2 3 4  int a = 1; // A操作 int b = 2; // B操作 int sum = a + b;// C 操作 System.out.println(sum);   根据以上介绍的happens-before规则，假如只有一个线程，那么不难得出：\n1 2 3  1\u0026gt; A happens-before B 2\u0026gt; B happens-before C 3\u0026gt; A happens-before C   注意，真正在执行指令的时候，其实JVM有可能对操作A \u0026amp; B进行重排序，因为无论先执行A还是B，他们都对对方是可见的，并且不影响执行结果。\n如果这里发生了重排序，这在视觉上违背了happens-before原则，但是JMM是允许这样的重排序的。\n所以，我们只关心happens-before规则，不用关心JVM到底是怎样执行的。只要确定操作A happens-before操作B就行了。\n重排序有两类，JMM对这两类重排序有不同的策略：\n 会改变程序执行结果的重排序，比如 A -\u0026gt; C，JMM要求编译器和处理器都禁止这种重排序。 不会改变程序执行结果的重排序，比如 A -\u0026gt; B，JMM对编译器和处理器不做要求，允许这种重排序。  volatile 几个基本概念 在介绍volatile之前，我们先回顾及介绍几个基本的概念。\n内存可见性 在Java内存模型那一章我们介绍了JMM有一个主内存，每个线程有自己私有的工作内存，工作内存中保存了一些变量在主内存的拷贝。\n内存可见性，指的是线程之间的可见性，当一个线程修改了共享变量时，另一个线程可以读取到这个修改后的值。\n重排序 为优化程序性能，对原有的指令执行顺序进行优化重新排序。重排序可能发生在多个阶段，比如编译重排序、CPU重排序等。\nhappens-before规则 是一个给程序员使用的规则，只要程序员在写代码的时候遵循happens-before规则，JVM就能保证指令在多线程之间的顺序性符合程序员的预期。\nvolatile的内存语义 在Java中，volatile关键字有特殊的内存语义。volatile主要有以下两个功能：\n 保证变量的内存可见性 禁止volatile变量与普通变量重排序（JSR133提出，Java 5 开始才有这个“增强的volatile内存语义”）  内存可见性 以一段示例代码开始：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  public class VolatileExample { int a = 0; volatile boolean flag = false; public void writer() { a = 1; // step 1  flag = true; // step 2  } public void reader() { if (flag) { // step 3  System.out.println(a); // step 4  } } }   在这段代码里，我们使用volatile关键字修饰了一个boolean类型的变量flag。\n所谓内存可见性，指的是当一个线程对volatile修饰的变量进行写操作（比如step 2）时，JMM会立即把该线程对应的本地内存中的共享变量的值刷新到主内存；当一个线程对volatile修饰的变量进行读操作（比如step 3）时，JMM会把立即该线程对应的本地内存置为无效，从主内存中读取共享变量的值。\n 在这一点上，volatile与锁具有相同的内存效果，volatile变量的写和锁的释放具有相同的内存语义，volatile变量的读和锁的获取具有相同的内存语义。\n 假设在时间线上，线程A先执行方法writer方法，线程B后执行reader方法。那必然会有下图：\n而如果flag变量没有用volatile修饰，在step 2，线程A的本地内存里面的变量就不会立即更新到主内存，那随后线程B也同样不会去主内存拿最新的值，仍然使用线程B本地内存缓存的变量的值a = 0，flag = false。\n禁止重排序 在JSR-133之前的旧的Java内存模型中，是允许volatile变量与普通变量重排序的。那上面的案例中，可能就会被重排序成下列时序来执行：\n 线程A写volatile变量，step 2，设置flag为true； 线程B读同一个volatile，step 3，读取到flag为true； 线程B读普通变量，step 4，读取到 a = 0； 线程A修改普通变量，step 1，设置 a = 1；  可见，如果volatile变量与普通变量发生了重排序，虽然volatile变量能保证内存可见性，也可能导致普通变量读取错误。\n所以在旧的内存模型中，volatile的写-读就不能与锁的释放-获取具有相同的内存语义了。为了提供一种比锁更轻量级的线程间的通信机制，JSR-133专家组决定增强volatile的内存语义：严格限制编译器和处理器对volatile变量与普通变量的重排序。\n编译器还好说，JVM是怎么还能限制处理器的重排序的呢？它是通过内存屏障来实现的。\n什么是内存屏障？硬件层面，内存屏障分两种：读屏障（Load Barrier）和写屏障（Store Barrier）。内存屏障有两个作用：\n 阻止屏障两侧的指令重排序； 强制把写缓冲区/高速缓存中的脏数据等写回主内存，或者让缓存中相应的数据失效。   注意这里的缓存主要指的是CPU缓存，如L1，L2等\n 编译器在生成字节码时，会在指令序列中插入内存屏障来禁止特定类型的处理器重排序。编译器选择了一个比较保守的JMM内存屏障插入策略，这样可以保证在任何处理器平台，任何程序中都能得到正确的volatile内存语义。这个策略是：\n 在每个volatile写操作前插入一个StoreStore屏障； 在每个volatile写操作后插入一个StoreLoad屏障； 在每个volatile读操作后插入一个LoadLoad屏障； 在每个volatile读操作后再插入一个LoadStore屏障。  大概示意图是这个样子：\n 再逐个解释一下这几个屏障。注：下述Load代表读操作，Store代表写操作\nLoadLoad屏障：对于这样的语句Load1; LoadLoad; Load2，在Load2及后续读取操作要读取的数据被访问前，保证Load1要读取的数据被读取完毕。 StoreStore屏障：对于这样的语句Store1; StoreStore; Store2，在Store2及后续写入操作执行前，这个屏障会把Store1强制刷新到内存，保证Store1的写入操作对其它处理器可见。 LoadStore屏障：对于这样的语句Load1; LoadStore; Store2，在Store2及后续写入操作被刷出前，保证Load1要读取的数据被读取完毕。 StoreLoad屏障：对于这样的语句Store1; StoreLoad; Load2，在Load2及后续所有读取操作执行前，保证Store1的写入对所有处理器可见。它的开销是四种屏障中最大的（冲刷写缓冲器，清空无效化队列）。在大多数处理器的实现中，这个屏障是个万能屏障，兼具其它三种内存屏障的功能\n 对于连续多个volatile变量读或者连续多个volatile变量写，编译器做了一定的优化来提高性能，比如：\n 第一个volatile读;\nLoadLoad屏障；\n第二个volatile读；\nLoadStore屏障\n 再介绍一下volatile与普通变量的重排序规则:\n 如果第一个操作是volatile读，那无论第二个操作是什么，都不能重排序； 如果第二个操作是volatile写，那无论第一个操作是什么，都不能重排序； 如果第一个操作是volatile写，第二个操作是volatile读，那不能重排序。  举个例子，我们在案例中step 1，是普通变量的写，step 2是volatile变量的写，那符合第2个规则，这两个steps不能重排序。而step 3是volatile变量读，step 4是普通变量读，符合第1个规则，同样不能重排序。\n但如果是下列情况：第一个操作是普通变量读，第二个操作是volatile变量读，那是可以重排序的：\n1 2 3 4 5 6 7  // 声明变量 int a = 0; // 声明普通变量 volatile boolean flag = false; // 声明volatile变量  // 以下两个变量的读操作是可以重排序的 int i = a; // 普通变量读 boolean j = flag; // volatile变量读   volatile的用途 从volatile的内存语义上来看，volatile可以保证内存可见性且禁止重排序。\n在保证内存可见性这一点上，volatile有着与锁相同的内存语义，所以可以作为一个“轻量级”的锁来使用。但由于volatile仅仅保证对单个volatile变量的读/写具有原子性，而锁可以保证整个临界区代码的执行具有原子性。所以在功能上，锁比volatile更强大；在性能上，volatile更有优势。\n在禁止重排序这一点上，volatile也是非常有用的。比如我们熟悉的单例模式，其中有一种实现方式是“双重锁检查”，比如这样的代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  public class Singleton { private static Singleton instance; // 不使用volatile关键字  // 双重锁检验  public static Singleton getInstance() { if (instance == null) { // 第7行  synchronized (Singleton.class) { if (instance == null) { instance = new Singleton(); // 第10行  } } } return instance; } }   如果这里的变量声明不使用volatile关键字，是可能会发生错误的。它可能会被重排序：\n1 2 3 4 5 6 7 8 9 10 11  instance = new Singleton(); // 第10行  // 可以分解为以下三个步骤 1 memory=allocate();// 分配内存 相当于c的malloc 2 ctorInstanc(memory) //初始化对象 3 s=memory //设置s指向刚分配的地址  // 上述三个步骤可能会被重排序为 1-3-2，也就是： 1 memory=allocate();// 分配内存 相当于c的malloc 3 s=memory //设置s指向刚分配的地址 2 ctorInstanc(memory) //初始化对象   而一旦假设发生了这样的重排序，比如线程A在第10行执行了步骤1和步骤3，但是步骤2还没有执行完。这个时候另一个线程B执行到了第7行，它会判定instance不为空，然后直接返回了一个未初始化完成的instance！\n所以JSR-133对volatile做了增强后，volatile的禁止重排序功能还是非常有用的。\nsynchronized与锁 这篇文章我们来聊一聊Java多线程里面的“锁”。\n首先需要明确的一点是：Java多线程的锁都是基于对象的，Java中的每一个对象都可以作为一个锁。\n还有一点需要注意的是，我们常听到的类锁其实也是对象锁。\nJava类只有一个Class对象（可以有多个实例对象，多个实例共享这个Class对象），而Class对象也是特殊的Java对象。所以我们常说的类锁，其实就是Class对象的锁。\nSynchronized关键字 说到锁，我们通常会谈到synchronized这个关键字。它翻译成中文就是“同步”的意思。\n我们通常使用synchronized关键字来给一段代码或一个方法上锁。它通常有以下三种形式：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  // 关键字在实例方法上，锁为当前实例 public synchronized void instanceLock() { // code } // 关键字在静态方法上，锁为当前Class对象 public static synchronized void classLock() { // code } // 关键字在代码块上，锁为括号里面的对象 public void blockLock() { Object o = new Object(); synchronized (o) { // code  } }   我们这里介绍一下“临界区”的概念。所谓“临界区”，指的是某一块代码区域，它同一时刻只能由一个线程执行。在上面的例子中，如果synchronized关键字在方法上，那临界区就是整个方法内部。而如果是使用synchronized代码块，那临界区就指的是代码块内部的区域。\n通过上面的例子我们可以看到，下面这两个写法其实是等价的作用：\n1 2 3 4 5 6 7 8 9 10 11  // 关键字在实例方法上，锁为当前实例 public synchronized void instanceLock() { // code } // 关键字在代码块上，锁为括号里面的对象 public void blockLock() { synchronized (this) { // code  } }   同理，下面这两个方法也应该是等价的：\n1 2 3 4 5 6 7 8 9 10 11  // 关键字在静态方法上，锁为当前Class对象 public static synchronized void classLock() { // code } // 关键字在代码块上，锁为括号里面的对象 public void blockLock() { synchronized (this.getClass()) { // code  } }   几种锁 Java 6 为了减少获得锁和释放锁带来的性能消耗，引入了“偏向锁”和“轻量级锁“。在Java 6 以前，所有的锁都是”重量级“锁。所以在Java 6 及其以后，一个对象其实有四种锁状态，它们级别由低到高依次是：\n 无锁状态 偏向锁状态 轻量级锁状态 重量级锁状态  无锁就是没有对资源进行锁定，任何线程都可以尝试去修改它，无锁在这里不再细讲。\n几种锁会随着竞争情况逐渐升级，锁的升级很容易发生，但是锁降级发生的条件会比较苛刻，锁降级发生在Stop The World期间，当JVM进入安全点的时候，会检查是否有闲置的锁，然后进行降级。\n 关于锁降级有两点说明：\n1.不同于大部分文章说锁不能降级，实际上HotSpot JVM 是支持锁降级的，文末有链接。\n2.上面提到的Stop The World期间，以及安全点，这些知识是属于JVM的知识范畴，本文不做细讲。\n 下面分别介绍这几种锁以及它们之间的升级。\nJava对象头 前面我们提到，Java的锁都是基于对象的。首先我们来看看一个对象的“锁”的信息是存放在什么地方的。\n每个Java对象都有对象头。如果是非数组类型，则用2个字宽来存储对象头，如果是数组，则会用3个字宽来存储对象头。在32位处理器中，一个字宽是32位；在64位虚拟机中，一个字宽是64位。对象头的内容如下表：\n   长度 内容 说明     32/64bit Mark Word 存储对象的hashCode或锁信息等   32/64bit Class Metadata Address 存储到对象类型数据的指针   32/64bit Array length 数组的长度（如果是数组）    我们主要来看看Mark Word的格式：\n   锁状态 29 bit 或 61 bit 1 bit 是否是偏向锁？ 2 bit 锁标志位     无锁  0 01   偏向锁 线程ID 1 01   轻量级锁 指向栈中锁记录的指针 此时这一位不用于标识偏向锁 00   重量级锁 指向互斥量（重量级锁）的指针 此时这一位不用于标识偏向锁 10   GC标记  此时这一位不用于标识偏向锁 11    可以看到，当对象状态为偏向锁时，Mark Word存储的是偏向的线程ID；当状态为轻量级锁时，Mark Word存储的是指向线程栈中Lock Record的指针；当状态为重量级锁时，Mark Word为指向堆中的monitor对象的指针。\n偏向锁 Hotspot的作者经过以往的研究发现大多数情况下锁不仅不存在多线程竞争，而且总是由同一线程多次获得，于是引入了偏向锁。\n偏向锁会偏向于第一个访问锁的线程，如果在接下来的运行过程中，该锁没有被其他的线程访问，则持有偏向锁的线程将永远不需要触发同步。也就是说，偏向锁在资源无竞争情况下消除了同步语句，连CAS操作都不做了，提高了程序的运行性能。\n 大白话就是对锁置个变量，如果发现为true，代表资源无竞争，则无需再走各种加锁/解锁流程。如果为false，代表存在其他线程竞争资源，那么就会走后面的流程。\n 实现原理 一个线程在第一次进入同步块时，会在对象头和栈帧中的锁记录里存储锁的偏向的线程ID。当下次该线程进入这个同步块时，会去检查锁的Mark Word里面是不是放的自己的线程ID。\n如果是，表明该线程已经获得了锁，以后该线程在进入和退出同步块时不需要花费CAS操作来加锁和解锁 ；如果不是，就代表有另一个线程来竞争这个偏向锁。这个时候会尝试使用CAS来替换Mark Word里面的线程ID为新线程的ID，这个时候要分两种情况：\n 成功，表示之前的线程不存在了， Mark Word里面的线程ID为新线程的ID，锁不会升级，仍然为偏向锁； 失败，表示之前的线程仍然存在，那么暂停之前的线程，设置偏向锁标识为0，并设置锁标志位为00，升级为轻量级锁，会按照轻量级锁的方式进行竞争锁。   CAS: Compare and Swap\n比较并设置。用于在硬件层面上提供原子性操作。在 Intel 处理器中，比较并交换通过指令cmpxchg实现。 比较是否和给定的数值一致，如果一致则修改，不一致则不修改。\n 线程竞争偏向锁的过程如下：\n图中涉及到了lock record指针指向当前堆栈中的最近一个lock record，是轻量级锁按照先来先服务的模式进行了轻量级锁的加锁。\n撤销偏向锁 偏向锁使用了一种等到竞争出现才释放锁的机制，所以当其他线程尝试竞争偏向锁时， 持有偏向锁的线程才会释放锁。\n偏向锁升级成轻量级锁时，会暂停拥有偏向锁的线程，重置偏向锁标识，这个过程看起来容易，实则开销还是很大的，大概的过程如下：\n 在一个安全点（在这个时间点上没有字节码正在执行）停止拥有锁的线程。 遍历线程栈，如果存在锁记录的话，需要修复锁记录和Mark Word，使其变成无锁状态。 唤醒被停止的线程，将当前锁升级成轻量级锁。  所以，如果应用程序里所有的锁通常处于竞争状态，那么偏向锁就会是一种累赘，对于这种情况，我们可以一开始就把偏向锁这个默认功能给关闭：\n1  -XX:UseBiasedLocking=false。   下面这个经典的图总结了偏向锁的获得和撤销：\n轻量级锁 多个线程在不同时段获取同一把锁，即不存在锁竞争的情况，也就没有线程阻塞。针对这种情况，JVM采用轻量级锁来避免线程的阻塞与唤醒。\n轻量级锁的加锁 JVM会为每个线程在当前线程的栈帧中创建用于存储锁记录的空间，我们称为Displaced Mark Word。如果一个线程获得锁的时候发现是轻量级锁，会把锁的Mark Word复制到自己的Displaced Mark Word里面。\n然后线程尝试用CAS将锁的Mark Word替换为指向锁记录的指针。如果成功，当前线程获得锁，如果失败，表示Mark Word已经被替换成了其他线程的锁记录，说明在与其它线程竞争锁，当前线程就尝试使用自旋来获取锁。\n 自旋：不断尝试去获取锁，一般用循环来实现。\n 自旋是需要消耗CPU的，如果一直获取不到锁的话，那该线程就一直处在自旋状态，白白浪费CPU资源。解决这个问题最简单的办法就是指定自旋的次数，例如让其循环10次，如果还没获取到锁就进入阻塞状态。\n但是JDK采用了更聪明的方式——适应性自旋，简单来说就是线程如果自旋成功了，则下次自旋的次数会更多，如果自旋失败了，则自旋的次数就会减少。\n自旋也不是一直进行下去的，如果自旋到一定程度（和JVM、操作系统相关），依然没有获取到锁，称为自旋失败，那么这个线程会阻塞。同时这个锁就会升级成重量级锁。\n轻量级锁的释放：\n在释放锁时，当前线程会使用CAS操作将Displaced Mark Word的内容复制回锁的Mark Word里面。如果没有发生竞争，那么这个复制的操作会成功。如果有其他线程因为自旋多次导致轻量级锁升级成了重量级锁，那么CAS操作会失败，此时会释放锁并唤醒被阻塞的线程。\n一张图说明加锁和释放锁的过程：\n重量级锁 重量级锁依赖于操作系统的互斥量（mutex） 实现的，而操作系统中线程间状态的转换需要相对比较长的时间，所以重量级锁效率很低，但被阻塞的线程不会消耗CPU。\n前面说到，每一个对象都可以当做一个锁，当多个线程同时请求某个对象锁时，对象锁会设置几种状态用来区分请求的线程：\n1 2 3 4 5 6  Contention List：所有请求锁的线程将被首先放置到该竞争队列 Entry List：Contention List中那些有资格成为候选人的线程被移到Entry List Wait Set：那些调用wait方法被阻塞的线程被放置到Wait Set OnDeck：任何时刻最多只能有一个线程正在竞争锁，该线程称为OnDeck Owner：获得锁的线程称为Owner !Owner：释放锁的线程   当一个线程尝试获得锁时，如果该锁已经被占用，则会将该线程封装成一个ObjectWaiter对象插入到Contention List的队列的队首，然后调用park函数挂起当前线程。\n当线程释放锁时，会从Contention List或EntryList中挑选一个线程唤醒，被选中的线程叫做Heir presumptive即假定继承人，假定继承人被唤醒后会尝试获得锁，但synchronized是非公平的，所以假定继承人不一定能获得锁。这是因为对于重量级锁，线程先自旋尝试获得锁，这样做的目的是为了减少执行操作系统同步操作带来的开销。如果自旋不成功再进入等待队列。这对那些已经在等待队列中的线程来说，稍微显得不公平，还有一个不公平的地方是自旋线程可能会抢占了Ready线程的锁。\n如果线程获得锁后调用Object.wait方法，则会将线程加入到WaitSet中，当被Object.notify唤醒后，会将线程从WaitSet移动到Contention List或EntryList中去。需要注意的是，当调用一个锁对象的wait或notify方法时，如当前锁的状态是偏向锁或轻量级锁则会先膨胀成重量级锁。\n总结锁的升级流程 每一个线程在准备获取共享资源时： 第一步，检查MarkWord里面是不是放的自己的ThreadId ,如果是，表示当前线程是处于 “偏向锁” 。\n第二步，如果MarkWord不是自己的ThreadId，锁升级，这时候，用CAS来执行切换，新的线程根据MarkWord里面现有的ThreadId，通知之前线程暂停，之前线程将Markword的内容置为空。\n第三步，两个线程都把锁对象的HashCode复制到自己新建的用于存储锁的记录空间，接着开始通过CAS操作， 把锁对象的MarKword的内容修改为自己新建的记录空间的地址的方式竞争MarkWord。\n第四步，第三步中成功执行CAS的获得资源，失败的则进入自旋 。\n第五步，自旋的线程在自旋过程中，成功获得资源(即之前获的资源的线程执行完成并释放了共享资源)，则整个状态依然处于 轻量级锁的状态，如果自旋失败 。\n第六步，进入重量级锁的状态，这个时候，自旋的线程进行阻塞，等待之前线程执行完成并唤醒自己。\n各种锁的优缺点对比 下表来自《Java并发编程的艺术》：\n   锁 优点 缺点 适用场景     偏向锁 加锁和解锁不需要额外的消耗，和执行非同步方法比仅存在纳秒级的差距。 如果线程间存在锁竞争，会带来额外的锁撤销的消耗。 适用于只有一个线程访问同步块场景。   轻量级锁 竞争的线程不会阻塞，提高了程序的响应速度。 如果始终得不到锁竞争的线程使用自旋会消耗CPU。 追求响应时间。同步块执行速度非常快。   重量级锁 线程竞争不使用自旋，不会消耗CPU。 线程阻塞，响应时间缓慢。 追求吞吐量。同步块执行时间较长。    CAS与原子操作 乐观锁与悲观锁的概念 锁可以从不同的角度分类。其中，乐观锁和悲观锁是一种分类方式。\n悲观锁：\n悲观锁就是我们常说的锁。对于悲观锁来说，它总是认为每次访问共享资源时会发生冲突，所以必须对每次数据操作加上锁，以保证临界区的程序同一时间只能有一个线程在执行。\n乐观锁：\n乐观锁又称为“无锁”，顾名思义，它是乐观派。乐观锁总是假设对共享资源的访问没有冲突，线程可以不停地执行，无需加锁也无需等待。而一旦多个线程发生冲突，乐观锁通常是使用一种称为CAS的技术来保证线程执行的安全性。\n由于无锁操作中没有锁的存在，因此不可能出现死锁的情况，也就是说乐观锁天生免疫死锁。\n乐观锁多用于“读多写少“的环境，避免频繁加锁影响性能；而悲观锁多用于”写多读少“的环境，避免频繁失败和重试影响性能。\nCAS的概念 CAS的全称是：比较并交换（Compare And Swap）。在CAS中，有这样三个值：\n V：要更新的变量(var) E：预期值(expected) N：新值(new)  比较并交换的过程如下：\n判断V是否等于E，如果等于，将V的值设置为N；如果不等，说明已经有其它线程更新了V，则当前线程放弃更新，什么都不做。\n所以这里的预期值E本质上指的是“旧值”。\n我们以一个简单的例子来解释这个过程：\n 如果有一个多个线程共享的变量i原本等于5，我现在在线程A中，想把它设置为新的值6; 我们使用CAS来做这个事情； 首先我们用i去与5对比，发现它等于5，说明没有被其它线程改过，那我就把它设置为新的值6，此次CAS成功，i的值被设置成了6； 如果不等于5，说明i被其它线程改过了（比如现在i的值为2），那么我就什么也不做，此次CAS失败，i的值仍然为2。  在这个例子中，i就是V，5就是E，6就是N。\n那有没有可能我在判断了i为5之后，正准备更新它的新值的时候，被其它线程更改了i的值呢？\n不会的。因为CAS是一种原子操作，它是一种系统原语，是一条CPU的原子指令，从CPU层面保证它的原子性\n当多个线程同时使用CAS操作一个变量时，只有一个会胜出，并成功更新，其余均会失败，但失败的线程并不会被挂起，仅是被告知失败，并且允许再次尝试，当然也允许失败的线程放弃操作。\nJava实现CAS的原理 - Unsafe类 前面提到，CAS是一种原子操作。那么Java是怎样来使用CAS的呢？我们知道，在Java中，如果一个方法是native的，那Java就不负责具体实现它，而是交给底层的JVM使用c或者c++去实现。\n在Java中，有一个Unsafe类，它在sun.misc包中。它里面是一些native方法，其中就有几个关于CAS的：\n1 2 3  boolean compareAndSwapObject(Object o, long offset,Object expected, Object x); boolean compareAndSwapInt(Object o, long offset,int expected,int x); boolean compareAndSwapLong(Object o, long offset,long expected,long x);   当然，他们都是public native的。\nUnsafe中对CAS的实现是C++写的，它的具体实现和操作系统、CPU都有关系。\nLinux的X86下主要是通过cmpxchgl这个指令在CPU级完成CAS操作的，但在多处理器情况下必须使用lock指令加锁来完成。当然不同的操作系统和处理器的实现会有所不同，大家可以自行了解。\n当然，Unsafe类里面还有其它方法用于不同的用途。比如支持线程挂起和恢复的park和unpark， LockSupport类底层就是调用了这两个方法。还有支持反射操作的allocateInstance()方法。\n原子操作-AtomicInteger类源码简析 上面介绍了Unsafe类的几个支持CAS的方法。那Java具体是如何使用这几个方法来实现原子操作的呢？\nJDK提供了一些用于原子操作的类，在java.util.concurrent.atomic包下面。在JDK 11中，有如下17个类：\n从名字就可以看得出来这些类大概的用途：\n 原子更新基本类型 原子更新数组 原子更新引用 原子更新字段（属性）  这里我们以AtomicInteger类的getAndAdd(int delta)方法为例，来看看Java是如何实现原子操作的。\n先看看这个方法的源码：\n1 2 3  public final int getAndAdd(int delta) { return U.getAndAddInt(this, VALUE, delta); }   这里的U其实就是一个Unsafe对象：\n1  private static final jdk.internal.misc.Unsafe U = jdk.internal.misc.Unsafe.getUnsafe();   所以其实AtomicInteger类的getAndAdd(int delta)方法是调用Unsafe类的方法来实现的：\n1 2 3 4 5 6 7 8  @HotSpotIntrinsicCandidate public final int getAndAddInt(Object o, long offset, int delta) { int v; do { v = getIntVolatile(o, offset); } while (!weakCompareAndSetInt(o, offset, v, v + delta)); return v; }    注：这个方法是在JDK 1.8才新增的。在JDK1.8之前，AtomicInteger源码实现有所不同，是基于for死循环的，有兴趣的读者可以自行了解一下。\n 我们来一步步解析这段源码。首先，对象o是this，也就是一个AtomicInteger对象。然后offset是一个常量VALUE。这个常量是在AtomicInteger类中声明的：\n1  private static final long VALUE = U.objectFieldOffset(AtomicInteger.class, \u0026#34;value\u0026#34;);   同样是调用的Unsafe的方法。从方法名字上来看，是得到了一个对象字段偏移量。\n 用于获取某个字段相对Java对象的“起始地址”的偏移量。\n一个java对象可以看成是一段内存，各个字段都得按照一定的顺序放在这段内存里，同时考虑到对齐要求，可能这些字段不是连续放置的，\n用这个方法能准确地告诉你某个字段相对于对象的起始内存地址的字节偏移量，因为是相对偏移量，所以它其实跟某个具体对象又没什么太大关系，跟class的定义和虚拟机的内存模型的实现细节更相关。\n 继续看源码。前面我们讲到，CAS是“无锁”的基础，它允许更新失败。所以经常会与while循环搭配，在失败后不断去重试。\n这里声明了一个v，也就是要返回的值。从getAndAddInt来看，它返回的应该是原来的值，而新的值的v + delta。\n这里使用的是do-while循环。这种循环不多见，它的目的是保证循环体内的语句至少会被执行一遍。这样才能保证return 的值v是我们期望的值。\n循环体的条件是一个CAS方法：\n1 2 3 4 5 6 7 8 9  public final boolean weakCompareAndSetInt(Object o, long offset, int expected, int x) { return compareAndSetInt(o, offset, expected, x); } public final native boolean compareAndSetInt(Object o, long offset, int expected, int x);   可以看到，最终其实是调用的我们之前说到了CAS native方法。那为什么要经过一层weakCompareAndSetInt呢？从JDK源码上看不出来什么。在JDK 8及之前的版本，这两个方法是一样的。\n 而在JDK 9开始，这两个方法上面增加了@HotSpotIntrinsicCandidate注解。这个注解允许HotSpot VM自己来写汇编或IR编译器来实现该方法以提供性能。也就是说虽然外面看到的在JDK9中weakCompareAndSet和compareAndSet底层依旧是调用了一样的代码，但是不排除HotSpot VM会手动来实现weakCompareAndSet真正含义的功能的可能性。\n 根据本文第一篇参考文章（文末链接），它跟volatile有关。\n简单来说，weakCompareAndSet操作仅保留了volatile自身变量的特性，而除去了happens-before规则带来的内存语义。也就是说，weakCompareAndSet**无法保证处理操作目标的volatile变量外的其他变量的执行顺序( 编译器和处理器为了优化程序性能而对指令序列进行重新排序 )，同时也无法保证这些变量的可见性。**这在一定程度上可以提高性能。\n再回到循环条件上来，可以看到它是在不断尝试去用CAS更新。如果更新失败，就继续重试。那为什么要把获取“旧值”v的操作放到循环体内呢？其实这也很好理解。前面我们说了，CAS如果旧值V不等于预期值E，它就会更新失败。说明旧的值发生了变化。那我们当然需要返回的是被其他线程改变之后的旧值了，因此放在了do循环体内。\nCAS实现原子操作的三大问题 这里介绍一下CAS实现原子操作的三大问题及其解决方案。\nABA问题 所谓ABA问题，就是一个值原来是A，变成了B，又变回了A。这个时候使用CAS是检查不出变化的，但实际上却被更新了两次。\nABA问题的解决思路是在变量前面追加上版本号或者时间戳。从JDK 1.5开始，JDK的atomic包里提供了一个类AtomicStampedReference类来解决ABA问题。\n这个类的compareAndSet方法的作用是首先检查当前引用是否等于预期引用，并且检查当前标志是否等于预期标志，如果二者都相等，才使用CAS设置为新的值和标志。\n1 2 3 4 5 6 7 8 9 10 11 12  public boolean compareAndSet(V expectedReference, V newReference, int expectedStamp, int newStamp) { Pair\u0026lt;V\u0026gt; current = pair; return expectedReference == current.reference \u0026amp;\u0026amp; expectedStamp == current.stamp \u0026amp;\u0026amp; ((newReference == current.reference \u0026amp;\u0026amp; newStamp == current.stamp) || casPair(current, Pair.of(newReference, newStamp))); }   循环时间长开销大 CAS多与自旋结合。如果自旋CAS长时间不成功，会占用大量的CPU资源。\n解决思路是让JVM支持处理器提供的pause指令。\npause指令能让自旋失败时cpu睡眠一小段时间再继续自旋，从而使得读操作的频率低很多,为解决内存顺序冲突而导致的CPU流水线重排的代价也会小很多。\n只能保证一个共享变量的原子操作 这个问题你可能已经知道怎么解决了。有两种解决方案：\n 使用JDK 1.5开始就提供的AtomicReference类保证对象之间的原子性，把多个变量放到一个对象里面进行CAS操作； 使用锁。锁内的临界区代码可以保证只有当前线程能操作。  AQS AQS简介 AQS是AbstractQueuedSynchronizer的简称，即抽象队列同步器，从字面意思上理解:\n 抽象：抽象类，只实现一些主要逻辑，有些方法由子类实现； 队列：使用先进先出（FIFO）队列存储数据； 同步：实现了同步的功能。  那AQS有什么用呢？AQS是一个用来构建锁和同步器的框架，使用AQS能简单且高效地构造出应用广泛的同步器，比如我们提到的ReentrantLock，Semaphore，ReentrantReadWriteLock，SynchronousQueue，FutureTask等等皆是基于AQS的。\n当然，我们自己也能利用AQS非常轻松容易地构造出符合我们自己需求的同步器，只要子类实现它的几个protected方法就可以了，在下文会有详细的介绍。\nAQS的数据结构 AQS内部使用了一个volatile的变量state来作为资源的标识。同时定义了几个获取和改变state的protected方法，子类可以覆盖这些方法来实现自己的逻辑：\n1 2 3  getState() setState() compareAndSetState()   这三种叫做均是原子操作，其中compareAndSetState的实现依赖于Unsafe的compareAndSwapInt()方法。\n而AQS类本身实现的是一些排队和阻塞的机制，比如具体线程等待队列的维护（如获取资源失败入队/唤醒出队等）。它内部使用了一个先进先出（FIFO）的双端队列，并使用了两个指针head和tail用于标识队列的头部和尾部。其数据结构如图：\n但它并不是直接储存线程，而是储存拥有线程的Node节点。\n资源共享模式 资源有两种共享模式，或者说两种同步方式：\n 独占模式（Exclusive）：资源是独占的，一次只能一个线程获取。如ReentrantLock。 共享模式（Share）：同时可以被多个线程获取，具体的资源个数可以通过参数指定。如Semaphore/CountDownLatch。  一般情况下，子类只需要根据需求实现其中一种模式，当然也有同时实现两种模式的同步类，如ReadWriteLock。\nAQS中关于这两种资源共享模式的定义源码（均在内部类Node中）。我们来看看Node的结构：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42  static final class Node { // 标记一个结点（对应的线程）在共享模式下等待  static final Node SHARED = new Node(); // 标记一个结点（对应的线程）在独占模式下等待  static final Node EXCLUSIVE = null; // waitStatus的值，表示该结点（对应的线程）已被取消  static final int CANCELLED = 1; // waitStatus的值，表示后继结点（对应的线程）需要被唤醒  static final int SIGNAL = -1; // waitStatus的值，表示该结点（对应的线程）在等待某一条件  static final int CONDITION = -2; /*waitStatus的值，表示有资源可用，新head结点需要继续唤醒后继结点（共享模式下，多线程并发释放资源，而head唤醒其后继结点后，需要把多出来的资源留给后面的结点；设置新的head结点时，会继续唤醒其后继结点）*/ static final int PROPAGATE = -3; // 等待状态，取值范围，-3，-2，-1，0，1  volatile int waitStatus; volatile Node prev; // 前驱结点  volatile Node next; // 后继结点  volatile Thread thread; // 结点对应的线程  Node nextWaiter; // 等待队列里下一个等待条件的结点  // 判断共享模式的方法  final boolean isShared() { return nextWaiter == SHARED; } Node(Thread thread, Node mode) { // Used by addWaiter  this.nextWaiter = mode; this.thread = thread; } // 其它方法忽略，可以参考具体的源码 } // AQS里面的addWaiter私有方法 private Node addWaiter(Node mode) { // 使用了Node的这个构造函数  Node node = new Node(Thread.currentThread(), mode); // 其它代码省略 }    注意：通过Node我们可以实现两个队列，一是通过prev和next实现CLH队列(线程同步队列,双向队列)，二是nextWaiter实现Condition条件上的等待线程队列(单向队列)，这个Condition主要用在ReentrantLock类中。\n AQS的主要方法源码解析 AQS的设计是基于模板方法模式的，它有一些方法必须要子类去实现的，它们主要有：\n isHeldExclusively()：该线程是否正在独占资源。只有用到condition才需要去实现它。 tryAcquire(int)：独占方式。尝试获取资源，成功则返回true，失败则返回false。 tryRelease(int)：独占方式。尝试释放资源，成功则返回true，失败则返回false。 tryAcquireShared(int)：共享方式。尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。 tryReleaseShared(int)：共享方式。尝试释放资源，如果释放后允许唤醒后续等待结点返回true，否则返回false。  这些方法虽然都是protected方法，但是它们并没有在AQS具体实现，而是直接抛出异常（这里不使用抽象方法的目的是：避免强迫子类中把所有的抽象方法都实现一遍，减少无用功，这样子类只需要实现自己关心的抽象方法即可，比如 Semaphore 只需要实现 tryAcquire 方法而不用实现其余不需要用到的模版方法）：\n1 2 3  protected boolean tryAcquire(int arg) { throw new UnsupportedOperationException(); }   而AQS实现了一系列主要的逻辑。下面我们从源码来分析一下获取和释放资源的主要逻辑：\n获取资源 获取资源的入口是acquire(int arg)方法。arg是要获取的资源的个数，在独占模式下始终为1。我们先来看看这个方法的逻辑：\n1 2 3 4 5  public final void acquire(int arg) { if (!tryAcquire(arg) \u0026amp;\u0026amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); }   首先调用tryAcquire(arg)尝试去获取资源。前面提到了这个方法是在子类具体实现的。\n如果获取资源失败，就通过addWaiter(Node.EXCLUSIVE)方法把这个线程插入到等待队列中。其中传入的参数代表要插入的Node是独占式的。这个方法的具体实现：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34  private Node addWaiter(Node mode) { // 生成该线程对应的Node节点  Node node = new Node(Thread.currentThread(), mode); // 将Node插入队列中  Node pred = tail; if (pred != null) { node.prev = pred; // 使用CAS尝试，如果成功就返回  if (compareAndSetTail(pred, node)) { pred.next = node; return node; } } // 如果等待队列为空或者上述CAS失败，再自旋CAS插入  enq(node); return node; } // 自旋CAS插入等待队列 private Node enq(final Node node) { for (;;) { Node t = tail; if (t == null) { // Must initialize  if (compareAndSetHead(new Node())) tail = head; } else { node.prev = t; if (compareAndSetTail(t, node)) { t.next = node; return t; } } } }    上面的两个函数比较好理解，就是在队列的尾部插入新的Node节点，但是需要注意的是由于AQS中会存在多个线程同时争夺资源的情况，因此肯定会出现多个线程同时插入节点的操作，在这里是通过CAS自旋的方式保证了操作的线程安全性。\n OK，现在回到最开始的aquire(int arg)方法。现在通过addWaiter方法，已经把一个Node放到等待队列尾部了。而处于等待队列的结点是从头结点一个一个去获取资源的。具体的实现我们来看看acquireQueued方法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  final boolean acquireQueued(final Node node, int arg) { boolean failed = true; try { boolean interrupted = false; // 自旋  for (;;) { final Node p = node.predecessor(); // 如果node的前驱结点p是head，表示node是第二个结点，就可以尝试去获取资源了  if (p == head \u0026amp;\u0026amp; tryAcquire(arg)) { // 拿到资源后，将head指向该结点。  // 所以head所指的结点，就是当前获取到资源的那个结点或null。  setHead(node); p.next = null; // help GC  failed = false; return interrupted; } // 如果自己可以休息了，就进入waiting状态，直到被unpark()  if (shouldParkAfterFailedAcquire(p, node) \u0026amp;\u0026amp; parkAndCheckInterrupt()) interrupted = true; } } finally { if (failed) cancelAcquire(node); } }    这里parkAndCheckInterrupt方法内部使用到了LockSupport.park(this)，顺便简单介绍一下park。\nLockSupport类是Java 6 引入的一个类，提供了基本的线程同步原语。LockSupport实际上是调用了Unsafe类里的函数，归结到Unsafe里，只有两个函数：\n park(boolean isAbsolute, long time)：阻塞当前线程 unpark(Thread jthread)：使给定的线程停止阻塞   所以结点进入等待队列后，是调用park使它进入阻塞状态的。只有头结点的线程是处于活跃状态的。\n当然，获取资源的方法除了acquire外，还有以下三个：\n acquireInterruptibly：申请可中断的资源（独占模式） acquireShared：申请共享模式的资源 acquireSharedInterruptibly：申请可中断的资源（共享模式）   可中断的意思是，在线程中断时可能会抛出InterruptedException\n 总结起来的一个流程图：\n释放资源 释放资源相比于获取资源来说，会简单许多。在AQS中只有一小段实现。源码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  public final boolean release(int arg) { if (tryRelease(arg)) { Node h = head; if (h != null \u0026amp;\u0026amp; h.waitStatus != 0) unparkSuccessor(h); return true; } return false; } private void unparkSuccessor(Node node) { // 如果状态是负数，尝试把它设置为0  int ws = node.waitStatus; if (ws \u0026lt; 0) compareAndSetWaitStatus(node, ws, 0); // 得到头结点的后继结点head.next  Node s = node.next; // 如果这个后继结点为空或者状态大于0  // 通过前面的定义我们知道，大于0只有一种可能，就是这个结点已被取消  if (s == null || s.waitStatus \u0026gt; 0) { s = null; // 等待队列中所有还有用的结点，都向前移动  for (Node t = tail; t != null \u0026amp;\u0026amp; t != node; t = t.prev) if (t.waitStatus \u0026lt;= 0) s = t; } // 如果后继结点不为空，  if (s != null) LockSupport.unpark(s.thread); }   ","date":"2021-04-06T13:36:41Z","image":"https://ahao.ink/13.jpg","permalink":"https://ahao.ink/posts/java%E5%B9%B6%E5%8F%91-%E5%8E%9F%E7%90%86%E7%AF%87/","title":"Java并发 原理篇"},{"content":"进程与线程的基本概念 进程产生的背景 最初的计算机只能接受一些特定的指令，用户每输入一个指令，计算机就做出一个操作。当用户在思考或者输入时，计算机就在等待。这样效率非常低下，在很多时候，计算机都处在等待状态。\n批处理操作系统\n后来有了批处理操作系统,把一系列需要操作的指令写下来，形成一个清单，一次性交给计算机。用户将多个需要执行的程序写在磁带上，然后交由计算机去读取并逐个执行这些程序，并将输出结果写在另一个磁带上。\n批处理操作系统在一定程度上提高了计算机的效率，但是由于批处理操作系统的指令运行方式仍然是串行的，内存中始终只有一个程序在运行，后面的程序需要等待前面的程序执行完成后才能开始执行，而前面的程序有时会由于I/O操作、网络等原因阻塞，所以批处理操作效率也不高。\n进程的提出\n人们对于计算机的性能要求越来越高，现有的批处理操作系统并不能满足人们的需求，而批处理操作系统的瓶颈在于内存中只存在一个程序，那么内存中能不能存在多个程序呢？这是人们亟待解决的问题。\n于是，科学家们提出了进程的概念。\n进程就是应用程序在内存中分配的空间，也就是正在运行的程序，各个进程之间互不干扰。同时进程保存着程序每一个时刻运行的状态。\n 程序：用某种编程语言(java、python等)编写，能够完成一定任务或者功能的代码集合,是指令和数据的有序集合，是一段静态代码。\n 此时，CPU采用时间片轮转的方式运行进程：CPU为每个进程分配一个时间段，称作它的时间片。如果在时间片结束时进程还在运行，则暂停这个进程的运行，并且CPU分配给另一个进程（这个过程叫做上下文切换）。如果进程在时间片结束前阻塞或结束，则CPU立即进行切换，不用等待时间片用完。\n 当进程暂停时，它会保存当前进程的状态（进程标识，进程使用的资源等），在下一次切换回来时根据之前保存的状态进行恢复，接着继续执行。\n 使用进程+CPU时间片轮转方式的操作系统，在宏观上看起来同一时间段执行多个任务，换句话说，进程让操作系统的并发成为了可能。虽然并发从宏观上看有多个任务在执行，但在事实上，对于单核CPU来说，任意具体时刻都只有一个任务在占用CPU资源。\n对操作系统的要求进一步提高\n虽然进程的出现，使得操作系统的性能大大提升，但是随着时间的推移，人们并不满足一个进程在一段时间只能做一件事情，如果一个进程有多个子任务时，只能逐个得执行这些子任务，很影响效率。\n 比如杀毒软件在检测用户电脑时，如果在某一项检测中卡住了，那么后面的检测项也会受到影响。或者说当你使用杀毒软件中的扫描病毒功能时，在扫描病毒结束之前，无法使用杀毒软件中清理垃圾的功能，这显然无法满足人们的要求。\n 线程的提出\n那么能不能让这些子任务同时执行呢？于是人们又提出了线程的概念，让一个线程执行一个子任务，这样一个进程就包含了多个线程，每个线程负责一个单独的子任务。\n 使用线程之后，事情就变得简单多了。当用户使用扫描病毒功能时，就让扫描病毒这个线程去执行。同时，如果用户又使用清理垃圾功能，那么可以先暂停扫描病毒线程，先响应用户的清理垃圾的操作，让清理垃圾这个线程去执行。响应完后再切换回来，接着执行扫描病毒线程。\n注意：操作系统是如何分配时间片给每一个线程的，涉及到线程的调度策略，有兴趣的同学可以看一下《操作系统》，本文不做深入详解。\n 总之，进程和线程的提出极大的提高了操作系统的性能。进程让操作系统的并发性成为了可能，而线程让进程的内部并发成为了可能。\n多进程的方式也可以实现并发，为什么我们要使用多线程？\n多进程方式确实可以实现并发，但使用多线程，有以下几个好处：\n 进程间的通信比较复杂，而线程间的通信比较简单，通常情况下，我们需要使用共享资源，这些资源在线程间的通信比较容易。 进程是重量级的，而线程是轻量级的，故多线程方式的系统开销更小。  进程和线程的区别\n进程是一个独立的运行环境，而线程是在进程中执行的一个任务。他们两个本质的区别是是否单独占有内存地址空间及其它系统资源（比如I/O）：\n 进程单独占有一定的内存地址空间，所以进程间存在内存隔离，数据是分开的，数据共享复杂但是同步简单，各个进程之间互不干扰；而线程共享所属进程占有的内存地址空间和资源，数据共享简单，但是同步复杂。 进程单独占有一定的内存地址空间，一个进程出现问题不会影响其他进程，不影响主程序的稳定性，可靠性高；一个线程崩溃可能影响整个程序的稳定性，可靠性较低。 进程单独占有一定的内存地址空间，进程的创建和销毁不仅需要保存寄存器和栈信息，还需要资源的分配回收以及页调度，开销较大；线程只需要保存寄存器和栈信息，开销较小。  另外一个重要区别是，进程是操作系统进行资源分配的基本单位，而线程是操作系统进行调度的基本单位，即CPU分配时间的单位 。\n上下文切换 上下文切换（有时也称做进程切换或任务切换）是指 CPU 从一个进程（或线程）切换到另一个进程（或线程）。上下文是指某一时间点 CPU 寄存器和程序计数器的内容。\n 寄存器是cpu内部的少量的速度很快的闪存，通常存储和访问计算过程的中间值提高计算机程序的运行速度。\n程序计数器是一个专用的寄存器，用于表明指令序列中 CPU 正在执行的位置，存的值为正在执行的指令的位置或者下一个将要被执行的指令的位置，具体实现依赖于特定的系统。\n举例说明 线程A - B\n1.先挂起线程A，将其在cpu中的状态保存在内存中。\n2.在内存中检索下一个线程B的上下文并将其在 CPU 的寄存器中恢复,执行B线程。\n3.当B执行完，根据程序计数器中指向的位置恢复线程A。\n CPU通过为每个线程分配CPU时间片来实现多线程机制。CPU通过时间片分配算法来循环执行任务，当前任务执行一个时间片后会切换到下一个任务。\n但是，在切换前会保存上一个任务的状态，以便下次切换回这个任务时，可以再加载这个任务的状态。所以任务从保存到再加载的过程就是一次上下文切换。\n上下文切换通常是计算密集型的，意味着此操作会消耗大量的 CPU 时间，故线程也不是越多越好。如何减少系统中上下文切换次数，是提升多线程性能的一个重点课题。\nJava多线程入门类和接口 Thread类和Runnable接口 上一章我们了解了操作系统中多线程的基本概念。那么在Java中，我们是如何使用多线程的呢？\n首先，我们需要有一个“线程”类。JDK提供了Thread类和Runnable接口来让我们实现自己的“线程”类。\n 继承Thread类，并重写run方法； 实现Runnable接口的run方法；  继承Thread类 先学会怎么用，再学原理。首先我们来看看怎么用Thread和Runnable来写一个Java多线程程序。\n首先是继承Thread类：\n1 2 3 4 5 6 7 8 9 10 11 12 13  public class Demo { public static class MyThread extends Thread { @Override public void run() { System.out.println(\u0026#34;MyThread\u0026#34;); } } public static void main(String[] args) { Thread myThread = new MyThread(); myThread.start(); } }   注意要调用start()方法后，该线程才算启动！\n 我们在程序里面调用了start()方法后，虚拟机会先为我们创建一个线程，然后等到这个线程第一次得到时间片时再调用run()方法。\n注意不可多次调用start()方法。在第一次调用start()方法后，再次调用start()方法会抛出IllegalThreadStateException异常。\n 实现Runnable接口 接着我们来看一下Runnable接口(JDK 1.8 +)：\n1 2 3 4  @FunctionalInterface public interface Runnable { public abstract void run(); }   可以看到Runnable是一个函数式接口，这意味着我们可以使用Java 8的函数式编程来简化代码。\n示例代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  public class Demo { public static class MyThread implements Runnable { @Override public void run() { System.out.println(\u0026#34;MyThread\u0026#34;); } } public static void main(String[] args) { new Thread(new MyThread()).start(); // Java 8 函数式编程，可以省略MyThread类  new Thread(() -\u0026gt; { System.out.println(\u0026#34;Java 8 匿名内部类\u0026#34;); }).start(); } }   Thread类构造方法 Thread类是一个Runnable接口的实现类，我们来看看Thread类的源码。\n查看Thread类的构造方法，发现其实是简单调用一个私有的init方法来实现初始化。init的方法签名：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  // Thread类源码  // 片段1 - init方法 private void init(ThreadGroup g, Runnable target, String name, long stackSize, AccessControlContext acc, boolean inheritThreadLocals) // 片段2 - 构造函数调用init方法 public Thread(Runnable target) { init(null, target, \u0026#34;Thread-\u0026#34; + nextThreadNum(), 0); } // 片段3 - 使用在init方法里初始化AccessControlContext类型的私有属性 this.inheritedAccessControlContext = acc != null ? acc : AccessController.getContext(); // 片段4 - 两个对用于支持ThreadLocal的私有属性 ThreadLocal.ThreadLocalMap threadLocals = null; ThreadLocal.ThreadLocalMap inheritableThreadLocals = null;   我们挨个来解释一下init方法的这些参数：\n  g：线程组，指定这个线程是在哪个线程组下；\n  target：指定要执行的任务；\n  name：线程的名字，多个线程的名字是可以重复的。如果不指定名字，见片段2；\n  acc：见片段3，用于初始化私有变量inheritedAccessControlContext。\n 这个变量有点神奇。它是一个私有变量，但是在Thread类里只有init方法对它进行初始化，在exit方法把它设为null。其它没有任何地方使用它。一般我们是不会使用它的，那什么时候会使用到这个变量呢？可以参考这个stackoverflow的问题：Restrict permissions to threads which execute third party software；\n   inheritThreadLocals：可继承的ThreadLocal，见片段4，Thread类里面有两个私有属性来支持ThreadLocal，我们会在后面的章节介绍ThreadLocal的概念。\n  实际情况下，我们大多是直接调用下面两个构造方法：\n1 2  Thread(Runnable target) Thread(Runnable target, String name)   Thread类的几个常用方法 这里介绍一下Thread类的几个常用的方法：\n currentThread()：静态方法，返回对当前正在执行的线程对象的引用； start()：开始执行线程的方法，java虚拟机会调用线程内的run()方法； yield()：yield在英语里有放弃的意思，同样，这里的yield()指的是当前线程愿意让出对当前处理器的占用。这里需要注意的是，就算当前线程调用了yield()方法，程序在调度的时候，也还有可能继续运行这个线程的； sleep()：静态方法，使当前线程睡眠一段时间； join()：使当前线程等待另一个线程执行完毕之后再继续执行，内部调用的是Object类的wait方法实现的；  Thread类与Runnable接口的比较： 实现一个自定义的线程类，可以有继承Thread类或者实现Runnable接口这两种方式，它们之间有什么优劣呢？\n 由于Java“单继承，多实现”的特性，Runnable接口使用起来比Thread更灵活。 Runnable接口出现更符合面向对象，将线程单独进行对象的封装。 Runnable接口出现，降低了线程对象和线程任务的耦合性。 如果使用线程时不需要使用Thread类的诸多方法，显然使用Runnable接口更为轻量。  所以，我们通常优先使用“实现Runnable接口”这种方式来自定义线程类。\nCallable、Future与FutureTask 通常来说，我们使用Runnable和Thread来创建一个新的线程。但是它们有一个弊端，就是run方法是没有返回值的。而有时候我们希望开启一个线程去执行一个任务，并且这个任务执行完成后有一个返回值。\nJDK提供了Callable接口与Future接口为我们解决这个问题，这也是所谓的“异步”模型。\nCallable接口 Callable与Runnable类似，同样是只有一个抽象方法的函数式接口。不同的是，Callable提供的方法是有返回值的，而且支持泛型。\n1 2 3 4  @FunctionalInterface public interface Callable\u0026lt;V\u0026gt; { V call() throws Exception; }   那一般是怎么使用Callable的呢？Callable一般是配合线程池工具ExecutorService来使用的。我们会在后续章节解释线程池的使用。这里只介绍ExecutorService可以使用submit方法来让一个Callable接口执行。它会返回一个Future，我们后续的程序可以通过这个Future的get方法得到结果。\n这里可以看一个简单的使用demo：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  // 自定义Callable class Task implements Callable\u0026lt;Integer\u0026gt;{ @Override public Integer call() throws Exception { // 模拟计算需要一秒  Thread.sleep(1000); return 2; } public static void main(String args[]) throws Exception { // 使用  ExecutorService executor = Executors.newCachedThreadPool(); Task task = new Task(); Future\u0026lt;Integer\u0026gt; result = executor.submit(task); // 注意调用get方法会阻塞当前线程，直到得到结果。  // 所以实际编码中建议使用可以设置超时时间的重载get方法。  System.out.println(result.get()); } }   输出结果：\n1  2   Future接口 Future接口只有几个比较简单的方法：\n1 2 3 4 5 6 7 8  public abstract interface Future\u0026lt;V\u0026gt; { public abstract boolean cancel(boolean paramBoolean); public abstract boolean isCancelled(); public abstract boolean isDone(); public abstract V get() throws InterruptedException, ExecutionException; public abstract V get(long paramLong, TimeUnit paramTimeUnit) throws InterruptedException, ExecutionException, TimeoutException; }   cancel方法是试图取消一个线程的执行。\n注意是试图取消，并不一定能取消成功。因为任务可能已完成、已取消、或者一些其它因素不能取消，存在取消失败的可能。boolean类型的返回值是“是否取消成功”的意思。参数paramBoolean表示是否采用中断的方式取消线程执行。\n所以有时候，为了让任务有能够取消的功能，就使用Callable来代替Runnable。如果为了可取消性而使用 Future但又不提供可用的结果，则可以声明 Future\u0026lt;?\u0026gt;形式类型、并返回 null作为底层任务的结果。\nFutureTask类 上面介绍了Future接口。这个接口有一个实现类叫FutureTask。FutureTask是实现的RunnableFuture接口的，而RunnableFuture接口同时继承了Runnable接口和Future接口：\n1 2 3 4 5 6 7  public interface RunnableFuture\u0026lt;V\u0026gt; extends Runnable, Future\u0026lt;V\u0026gt; { /** * Sets this Future to the result of its computation * unless it has been cancelled. */ void run(); }   那FutureTask类有什么用？为什么要有一个FutureTask类？前面说到了Future只是一个接口，而它里面的cancel，get，isDone等方法要自己实现起来都是非常复杂的。所以JDK提供了一个FutureTask类来供我们使用。\n示例代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  // 自定义Callable，与上面一样 class Task implements Callable\u0026lt;Integer\u0026gt;{ @Override public Integer call() throws Exception { // 模拟计算需要一秒  Thread.sleep(1000); return 2; } public static void main(String args[]) throws Exception { // 使用  ExecutorService executor = Executors.newCachedThreadPool(); FutureTask\u0026lt;Integer\u0026gt; futureTask = new FutureTask\u0026lt;\u0026gt;(new Task()); executor.submit(futureTask); System.out.println(futureTask.get()); } }   使用上与第一个Demo有一点小的区别。首先，调用submit方法是没有返回值的。这里实际上是调用的submit(Runnable task)方法，而上面的Demo，调用的是submit(Callable\u0026lt;T\u0026gt; task)方法。\n然后，这里是使用FutureTask直接取get取值，而上面的Demo是通过submit方法返回的Future去取值。\n在很多高并发的环境下，有可能Callable和FutureTask会创建多次。FutureTask能够在高并发环境下确保任务只执行一次。这块有兴趣的同学可以参看FutureTask源码。\nFutureTask的几个状态 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  /** * * state可能的状态转变路径如下： * NEW -\u0026gt; COMPLETING -\u0026gt; NORMAL * NEW -\u0026gt; COMPLETING -\u0026gt; EXCEPTIONAL * NEW -\u0026gt; CANCELLED * NEW -\u0026gt; INTERRUPTING -\u0026gt; INTERRUPTED */ private volatile int state; private static final int NEW = 0; private static final int COMPLETING = 1; private static final int NORMAL = 2; private static final int EXCEPTIONAL = 3; private static final int CANCELLED = 4; private static final int INTERRUPTING = 5; private static final int INTERRUPTED = 6;    state表示任务的运行状态，初始状态为NEW。运行状态只会在set、setException、cancel方法中终止。COMPLETING、INTERRUPTING是任务完成后的瞬时状态。\n 以上就是Java多线程几个基本的类和接口的介绍。可以打开JDK看看源码，体会这几个类的设计思路和用途吧！\n线程组和线程优先级 线程组(ThreadGroup) Java中用ThreadGroup来表示线程组，我们可以使用线程组对线程进行批量控制。\nThreadGroup和Thread的关系就如同他们的字面意思一样简单粗暴，每个Thread必然存在于一个ThreadGroup中，Thread不能独立于ThreadGroup存在。执行main()方法线程的名字是main，如果在new Thread时没有显式指定，那么默认将父线程（当前执行new Thread的线程）线程组设置为自己的线程组。\n示例代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  public class Demo { public static void main(String[] args) { Thread testThread = new Thread(() -\u0026gt; { System.out.println(\u0026#34;testThread当前线程组名字：\u0026#34; + Thread.currentThread().getThreadGroup().getName()); System.out.println(\u0026#34;testThread线程名字：\u0026#34; + Thread.currentThread().getName()); }); testThread.start(); System.out.println(\u0026#34;执行main所在线程的线程组名字： \u0026#34; + Thread.currentThread().getThreadGroup().getName()); System.out.println(\u0026#34;执行main方法线程名字：\u0026#34; + Thread.currentThread().getName()); } }   输出结果：\n1 2 3 4  执行main所在线程的线程组名字： main 执行main方法线程名字：main testThread当前线程组名字：main testThread线程名字：Thread-0   ThreadGroup管理着它下面的Thread，ThreadGroup是一个标准的向下引用的树状结构，这样设计的原因是防止\u0026quot;上级\u0026quot;线程被\u0026quot;下级\u0026quot;线程引用而无法有效地被GC回收。\n线程的优先级 Java中线程优先级可以指定，范围是1~10。但是并不是所有的操作系统都支持10级优先级的划分（比如有些操作系统只支持3级划分：低，中，高），Java只是给操作系统一个优先级的参考值，线程最终在操作系统的优先级是多少还是由操作系统决定。\nJava默认的线程优先级为5，线程的执行顺序由调度程序来决定，线程的优先级会在线程被调用之前设定。\n通常情况下，高优先级的线程将会比低优先级的线程有更高的几率得到执行。我们使用方法Thread类的setPriority()实例方法来设定线程的优先级。\n1 2 3 4 5 6 7 8 9  public class Demo { public static void main(String[] args) { Thread a = new Thread(); System.out.println(\u0026#34;我是默认线程优先级：\u0026#34;+a.getPriority()); Thread b = new Thread(); b.setPriority(10); System.out.println(\u0026#34;我是设置过的线程优先级：\u0026#34;+b.getPriority()); } }   输出结果：\n1 2  我是默认线程优先级：5 我是设置过的线程优先级：10   既然有1-10的级别来设定了线程的优先级，这时候可能有些读者会问，那么我是不是可以在业务实现的时候，采用这种方法来指定一些线程执行的先后顺序？\n对于这个问题，我们的答案是:No!\nJava中的优先级来说不是特别的可靠，Java程序中对线程所设置的优先级只是给操作系统一个建议，操作系统不一定会采纳。而真正的调用顺序，是由操作系统的线程调度算法决定的。\n我们通过代码来验证一下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  public class Demo { public static class T1 extends Thread { @Override public void run() { super.run(); System.out.println(String.format(\u0026#34;当前执行的线程是：%s，优先级：%d\u0026#34;, Thread.currentThread().getName(), Thread.currentThread().getPriority())); } } public static void main(String[] args) { IntStream.range(1, 10).forEach(i -\u0026gt; { Thread thread = new Thread(new T1()); thread.setPriority(i); thread.start(); }); } }   某次输出：\n1 2 3 4 5 6 7 8 9  当前执行的线程是：Thread-17，优先级：9 当前执行的线程是：Thread-1，优先级：1 当前执行的线程是：Thread-13，优先级：7 当前执行的线程是：Thread-11，优先级：6 当前执行的线程是：Thread-15，优先级：8 当前执行的线程是：Thread-7，优先级：4 当前执行的线程是：Thread-9，优先级：5 当前执行的线程是：Thread-3，优先级：2 当前执行的线程是：Thread-5，优先级：3   Java提供一个线程调度器来监视和控制处于RUNNABLE状态的线程。线程的调度策略采用抢占式，优先级高的线程比优先级低的线程会有更大的几率优先执行。在优先级相同的情况下，按照“先到先得”的原则。每个Java程序都有一个默认的主线程，就是通过JVM启动的第一个线程main线程。\n还有一种线程称为守护线程（Daemon），守护线程默认的优先级比较低。\n 如果某线程是守护线程，那如果所有的非守护线程都结束了，这个守护线程也会自动结束。\n应用场景是：当所有非守护线程结束时，结束其余的子线程（守护线程）自动关闭，就免去了还要继续关闭子线程的麻烦。\n一个线程默认是非守护线程，可以通过Thread类的setDaemon(boolean on)来设置。\n 在之前，我们有谈到一个线程必然存在于一个线程组中，那么当线程和线程组的优先级不一致的时候将会怎样呢？我们用下面的案例来验证一下：\n1 2 3 4 5 6 7 8  public static void main(String[] args) { ThreadGroup threadGroup = new ThreadGroup(\u0026#34;t1\u0026#34;); threadGroup.setMaxPriority(6); Thread thread = new Thread(threadGroup,\u0026#34;thread\u0026#34;); thread.setPriority(9); System.out.println(\u0026#34;我是线程组的优先级\u0026#34;+threadGroup.getMaxPriority()); System.out.println(\u0026#34;我是线程的优先级\u0026#34;+thread.getPriority()); }   输出：\n 我是线程组的优先级6 我是线程的优先级6\n 所以，如果某个线程优先级大于线程所在线程组的最大优先级，那么该线程的优先级将会失效，取而代之的是线程组的最大优先级。\n线程组的常用方法及数据结构 线程组的常用方法 获取当前的线程组名字\n1  Thread.currentThread().getThreadGroup().getName()   复制线程组\n1 2 3 4 5  // 获取当前的线程组 ThreadGroup threadGroup = Thread.currentThread().getThreadGroup(); // 复制一个线程组到一个线程数组（获取Thread信息） Thread[] threads = new Thread[threadGroup.activeCount()]; threadGroup.enumerate(threads);   线程组统一异常处理\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  package com.func.axc.threadgroup; public class ThreadGroupDemo { public static void main(String[] args) { ThreadGroup threadGroup1 = new ThreadGroup(\u0026#34;group1\u0026#34;) { // 继承ThreadGroup并重新定义以下方法  // 在线程成员抛出unchecked exception  // 会执行此方法  public void uncaughtException(Thread t, Throwable e) { System.out.println(t.getName() + \u0026#34;: \u0026#34; + e.getMessage()); } }; // 这个线程是threadGroup1的一员  Thread thread1 = new Thread(threadGroup1, new Runnable() { public void run() { // 抛出unchecked异常  throw new RuntimeException(\u0026#34;测试异常\u0026#34;); } }); thread1.start(); } }   线程组的数据结构 线程组还可以包含其他的线程组，不仅仅是线程。\n首先看看 ThreadGroup源码中的成员变量\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  public class ThreadGroup implements Thread.UncaughtExceptionHandler { private final ThreadGroup parent; // 父亲ThreadGroup  String name; // ThreadGroupr 的名称  int maxPriority; // 线程最大优先级  boolean destroyed; // 是否被销毁  boolean daemon; // 是否守护线程  boolean vmAllowSuspension; // 是否可以中断  int nUnstartedThreads = 0; // 还未启动的线程  int nthreads; // ThreadGroup中线程数目  Thread threads[]; // ThreadGroup中的线程  int ngroups; // 线程组数目  ThreadGroup groups[]; // 线程组数组 }   然后看看构造函数：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  // 私有构造函数 private ThreadGroup() { this.name = \u0026#34;system\u0026#34;; this.maxPriority = Thread.MAX_PRIORITY; this.parent = null; } // 默认是以当前ThreadGroup传入作为parent ThreadGroup，新线程组的父线程组是目前正在运行线程的线程组。 public ThreadGroup(String name) { this(Thread.currentThread().getThreadGroup(), name); } // 构造函数 public ThreadGroup(ThreadGroup parent, String name) { this(checkParentAccess(parent), parent, name); } // 私有构造函数，主要的构造函数 private ThreadGroup(Void unused, ThreadGroup parent, String name) { this.name = name; this.maxPriority = parent.maxPriority; this.daemon = parent.daemon; this.vmAllowSuspension = parent.vmAllowSuspension; this.parent = parent; parent.add(this); }   第三个构造函数里调用了checkParentAccess方法，这里看看这个方法的源码：\n1 2 3 4 5 6 7 8 9 10 11 12 13  // 检查parent ThreadGroup private static Void checkParentAccess(ThreadGroup parent) { parent.checkAccess(); return null; } // 判断当前运行的线程是否具有修改线程组的权限 public final void checkAccess() { SecurityManager security = System.getSecurityManager(); if (security != null) { security.checkAccess(this); } }    这里涉及到SecurityManager这个类，它是Java的安全管理器，它允许应用程序在执行一个可能不安全或敏感的操作前确定该操作是什么，以及是否是在允许执行该操作的安全上下文中执行它。应用程序可以允许或不允许该操作。\n比如引入了第三方类库，但是并不能保证它的安全性。\n其实Thread类也有一个checkAccess()方法，不过是用来当前运行的线程是否有权限修改被调用的这个线程实例。（Determines if the currently running thread has permission to modify this thread.）\n 总结来说，线程组是一个树状的结构，每个线程组下面可以有多个线程或者线程组。线程组可以起到统一控制线程的优先级和检查线程的权限的作用。\nJava线程的状态及主要转化方法 操作系统中的线程状态转换 首先我们来看看操作系统中的线程状态转换。\n 在现在的操作系统中，线程是被视为轻量级进程的，所以操作系统线程的状态其实和操作系统进程的状态是一致的。\n 操作系统线程主要有以下三个状态：\n 就绪状态(ready)：线程正在等待使用CPU，经调度程序调用之后可进入running状态。 执行状态(running)：线程正在使用CPU。 等待状态(waiting): 线程经过等待事件的调用或者正在等待其他资源（如I/O）。  Java线程的6个状态 1 2 3 4 5 6 7 8 9  // Thread.State 源码 public enum State { NEW, RUNNABLE, BLOCKED, WAITING, TIMED_WAITING, TERMINATED; }   NEW 处于NEW状态的线程此时尚未启动。这里的尚未启动指的是还没调用Thread实例的start()方法。\n1 2 3 4  private void testStateNew() { Thread thread = new Thread(() -\u0026gt; {}); System.out.println(thread.getState()); // 输出 NEW }   从上面可以看出，只是创建了线程而并没有调用start()方法，此时线程处于NEW状态。\n关于start()的两个引申问题\n 反复调用同一个线程的start()方法是否可行？ 假如一个线程执行完毕（此时处于TERMINATED状态），再次调用这个线程的start()方法是否可行？  要分析这两个问题，我们先来看看start()的源码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  public synchronized void start() { if (threadStatus != 0) throw new IllegalThreadStateException(); group.add(this); boolean started = false; try { start0(); started = true; } finally { try { if (!started) { group.threadStartFailed(this); } } catch (Throwable ignore) { } } }   我们可以看到，在start()内部，这里有一个threadStatus的变量。如果它不等于0，调用start()是会直接抛出异常的。\n我们接着往下看，有一个native的start0()方法。这个方法里并没有对threadStatus的处理。到了这里我们仿佛就拿这个threadStatus没辙了，我们通过debug的方式再看一下:\n1 2 3 4 5 6  @Test public void testStartMethod() { Thread thread = new Thread(() -\u0026gt; {}); thread.start(); // 第一次调用  thread.start(); // 第二次调用 }   我是在start()方法内部的最开始打的断点，叙述下在我这里打断点看到的结果：\n 第一次调用时threadStatus的值是0。 第二次调用时threadStatus的值不为0。  查看当前线程状态的源码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  // Thread.getState方法源码： public State getState() { // get current thread state  return sun.misc.VM.toThreadState(threadStatus); } // sun.misc.VM 源码： public static State toThreadState(int var0) { if ((var0 \u0026amp; 4) != 0) { return State.RUNNABLE; } else if ((var0 \u0026amp; 1024) != 0) { return State.BLOCKED; } else if ((var0 \u0026amp; 16) != 0) { return State.WAITING; } else if ((var0 \u0026amp; 32) != 0) { return State.TIMED_WAITING; } else if ((var0 \u0026amp; 2) != 0) { return State.TERMINATED; } else { return (var0 \u0026amp; 1) == 0 ? State.NEW : State.RUNNABLE; } }   所以，我们结合上面的源码可以得到引申的两个问题的结果：\n 两个问题的答案都是不可行，在调用一次start()之后，threadStatus的值会改变（threadStatus !=0），此时再次调用start()方法会抛出IllegalThreadStateException异常。\n比如，threadStatus为2代表当前线程状态为TERMINATED。\n RUNNABLE 表示当前线程正在运行中。处于RUNNABLE状态的线程在Java虚拟机中运行，也有可能在等待CPU分配资源。\nJava中线程的RUNNABLE状态\n看了操作系统线程的几个状态之后我们来看看Thread源码里对RUNNABLE状态的定义：\n1 2 3 4 5 6  /** * Thread state for a runnable thread. A thread in the runnable * state is executing in the Java virtual machine but it may * be waiting for other resources from the operating system * such as processor. */    Java线程的RUNNABLE状态其实是包括了传统操作系统线程的ready和running两个状态的。\n BLOCKED 阻塞状态。处于BLOCKED状态的线程正等待锁的释放以进入同步区。\n我们用BLOCKED状态举个生活中的例子：\n 假如今天你下班后准备去食堂吃饭。你来到食堂仅有的一个窗口，发现前面已经有个人在窗口前了，此时你必须得等前面的人从窗口离开才行。 假设你是线程t2，你前面的那个人是线程t1。此时t1占有了锁（食堂唯一的窗口），t2正在等待锁的释放，所以此时t2就处于BLOCKED状态。\n WAITING 等待状态。处于等待状态的线程变成RUNNABLE状态需要其他线程唤醒。\n调用如下3个方法会使线程进入等待状态：\n Object.wait()：使当前线程处于等待状态直到另一个线程唤醒它； Thread.join()：等待线程执行完毕，底层调用的是Object实例的wait方法； LockSupport.park()：除非获得调用许可，否则禁用当前线程进行线程调度。  我们延续上面的例子继续解释一下WAITING状态：\n 你等了好几分钟现在终于轮到你了，突然你们有一个“不懂事”的经理突然来了。你看到他你就有一种不祥的预感，果然，他是来找你的。\n他把你拉到一旁叫你待会儿再吃饭，说他下午要去作报告，赶紧来找你了解一下项目的情况。你心里虽然有一万个不愿意但是你还是从食堂窗口走开了。\n此时，假设你还是线程t2，你的经理是线程t1。虽然你此时都占有锁（窗口）了，“不速之客”来了你还是得释放掉锁。此时你t2的状态就是WAITING。然后经理t1获得锁，进入RUNNABLE状态。\n要是经理t1不主动唤醒你t2（notify、notifyAll..），可以说你t2只能一直等待了。\n TIMED_WAITING 超时等待状态。线程等待一个具体的时间，时间到后会被自动唤醒。\n调用如下方法会使线程进入超时等待状态：\n Thread.sleep(long millis)：使当前线程睡眠指定时间； Object.wait(long timeout)：线程休眠指定时间，等待期间可以通过notify()/notifyAll()唤醒； Thread.join(long millis)：等待当前线程最多执行millis毫秒，如果millis为0，则会一直执行； LockSupport.parkNanos(long nanos)： 除非获得调用许可，否则禁用当前线程进行线程调度指定时间； LockSupport.parkUntil(long deadline)：同上，也是禁止线程进行调度指定时间；  我们继续延续上面的例子来解释一下TIMED_WAITING状态：\n 到了第二天中午，又到了饭点，你还是到了窗口前。\n突然间想起你的同事叫你等他一起，他说让你等他十分钟他改个bug。\n好吧，你说那你就等等吧，你就离开了窗口。很快十分钟过去了，你见他还没来，你想都等了这么久了还不来，那你还是先去吃饭好了。\n这时你还是线程t1，你改bug的同事是线程t2。t2让t1等待了指定时间，此时t1等待期间就属于TIMED_WATING状态。\nt1等待10分钟后，就自动唤醒，拥有了去争夺锁的资格。\n TERMINATED 终止状态。此时线程已执行完毕。\n线程状态的转换 根据上面关于线程状态的介绍我们可以得到下面的线程状态转换图：\nBLOCKED与RUNNABLE状态的转换 我们在上面说到：处于BLOCKED状态的线程是因为在等待锁的释放。假如这里有两个线程a和b，a线程提前获得了锁并且暂未释放锁，此时b就处于BLOCKED状态。我们先来看一个例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  @Test public void blockedTest() { Thread a = new Thread(new Runnable() { @Override public void run() { testMethod(); } }, \u0026#34;a\u0026#34;); Thread b = new Thread(new Runnable() { @Override public void run() { testMethod(); } }, \u0026#34;b\u0026#34;); a.start(); b.start(); System.out.println(a.getName() + \u0026#34;:\u0026#34; + a.getState()); // 输出？  System.out.println(b.getName() + \u0026#34;:\u0026#34; + b.getState()); // 输出？ } // 同步方法争夺锁 private synchronized void testMethod() { try { Thread.sleep(2000L); } catch (InterruptedException e) { e.printStackTrace(); } }   初看之下，大家可能会觉得线程a会先调用同步方法，同步方法内又调用了Thread.sleep()方法，必然会输出TIMED_WAITING，而线程b因为等待线程a释放锁所以必然会输出BLOCKED。\n其实不然，有两点需要值得大家注意，一是在测试方法blockedTest()内还有一个main线程，二是启动线程后执行run方法还是需要消耗一定时间的。\n 测试方法的main线程只保证了a，b两个线程调用start()方法（转化为RUNNABLE状态），如果CPU执行效率高一点，还没等两个线程真正开始争夺锁，就已经打印此时两个线程的状态（RUNNABLE）了。\n当然，如果CPU执行效率低一点，其中某个线程也是可能打印出BLOCKED状态的（此时两个线程已经开始争夺锁了）。\n 这时你可能又会问了，要是我想要打印出BLOCKED状态我该怎么处理呢？BLOCKED状态的产生需要两个线程争夺锁才行。那我们处理下测试方法里的main线程就可以了，让它“休息一会儿”，调用一下Thread.sleep()方法。\n这里需要注意的是main线程休息的时间，要保证在线程争夺锁的时间内，不要等到前一个线程锁都释放了你再去争夺锁，此时还是得不到BLOCKED状态的。\n我们把上面的测试方法blockedTest()改动一下：\n1 2 3 4 5 6 7 8  public void blockedTest() throws InterruptedException { ······ a.start(); Thread.sleep(1000L); // 需要注意这里main线程休眠了1000毫秒，而testMethod()里休眠了2000毫秒  b.start(); System.out.println(a.getName() + \u0026#34;:\u0026#34; + a.getState()); // 输出？  System.out.println(b.getName() + \u0026#34;:\u0026#34; + b.getState()); // 输出？ }   在这个例子中两个线程的状态转换如下\n a的状态转换过程：RUNNABLE（a.start()） -\u0026gt; TIMED_WATING（Thread.sleep()）-\u0026gt;RUNABLE（sleep()时间到）-\u0026gt;BLOCKED(未抢到锁) -\u0026gt; TERMINATED b的状态转换过程：RUNNABLE（b.start()) -\u0026gt; BLOCKED(未抢到锁) -\u0026gt;TERMINATED   斜体表示可能出现的状态， 大家可以在自己的电脑上多试几次看看输出。同样，这里的输出也可能有多钟结果。\n WAITING状态与RUNNABLE状态的转换 根据转换图我们知道有3个方法可以使线程从RUNNABLE状态转为WAITING状态。我们主要介绍下Object.wait()和Thread.join()。\nObject.wait()\n 调用wait()方法前线程必须持有对象的锁。\n线程调用wait()方法时，会释放当前的锁，直到有其他线程调用notify()/notifyAll()方法唤醒等待锁的线程。\n需要注意的是，其他线程调用notify()方法只会唤醒单个等待锁的线程，如有有多个线程都在等待这个锁的话不一定会唤醒到之前调用wait()方法的线程。\n同样，调用notifyAll()方法唤醒所有等待锁的线程之后，也不一定会马上把时间片分给刚才放弃锁的那个线程，具体要看系统的调度。\n Thread.join()\n 调用join()方法，会一直等待这个线程执行完毕（转换为TERMINATED状态）。\n 我们再把上面的例子线程启动那里改变一下：\n1 2 3 4 5 6 7 8  public void blockedTest() { ······ a.start(); a.join(); b.start(); System.out.println(a.getName() + \u0026#34;:\u0026#34; + a.getState()); // 输出 TERMINATED  System.out.println(b.getName() + \u0026#34;:\u0026#34; + b.getState()); }   要是没有调用join方法，main线程不管a线程是否执行完毕都会继续往下走。\na线程启动之后马上调用了join方法，这里main线程就会等到a线程执行完毕，所以这里a线程打印的状态固定是TERMINATED。\n至于b线程的状态，有可能打印RUNNABLE（尚未进入同步方法），也有可能打印TIMED_WAITING（进入了同步方法）。\nTIMED_WAITING与RUNNABLE状态转换 TIMED_WAITING与WAITING状态类似，只是TIMED_WAITING状态等待的时间是指定的。\nThread.sleep(long)\n 使当前线程睡眠指定时间。需要注意这里的“睡眠”只是暂时使线程停止执行，并不会释放锁。时间到后，线程会重新进入RUNNABLE状态。\n Object.wait(long)\n wait(long)方法使线程进入TIMED_WAITING状态。这里的wait(long)方法与无参方法wait()相同的地方是，都可以通过其他线程调用notify()或notifyAll()方法来唤醒。\n不同的地方是，有参方法wait(long)就算其他线程不来唤醒它，经过指定时间long之后它会自动唤醒，拥有去争夺锁的资格。\n Thread.join(long)\n join(long)使当前线程执行指定时间，并且使线程进入TIMED_WAITING状态。\n我们再来改一改刚才的示例:\n1 2 3 4 5 6 7 8  public void blockedTest() { ······ a.start(); a.join(1000L); b.start(); System.out.println(a.getName() + \u0026#34;:\u0026#34; + a.getState()); // 输出 TIEMD_WAITING  System.out.println(b.getName() + \u0026#34;:\u0026#34; + b.getState()); }   这里调用a.join(1000L)，因为是指定了具体a线程执行的时间的，并且执行时间是小于a线程sleep的时间，所以a线程状态输出TIMED_WAITING。\n b线程状态仍然不固定（RUNNABLE或BLOCKED）。\n线程中断  在某些情况下，我们在线程启动后发现并不需要它继续执行下去时，需要中断线程。目前在Java里还没有安全直接的方法来停止线程，但是Java提供了线程中断机制来处理需要中断线程的情况。\n线程中断机制是一种协作机制。需要注意，通过中断操作并不能直接终止一个线程，而是通知需要被中断的线程自行处理。\n 简单介绍下Thread类里提供的关于线程中断的几个方法：\n Thread.interrupt()：中断线程。这里的中断线程并不会立即停止线程，而是设置线程的中断状态为true（默认是flase）； Thread.interrupted()：测试当前线程是否被中断。线程的中断状态受这个方法的影响，意思是调用一次使线程中断状态设置为true，连续调用两次会使得这个线程的中断状态重新转为false； Thread.isInterrupted()：测试当前线程是否被中断。与上面方法不同的是调用这个方法并不会影响线程的中断状态。   在线程中断机制里，当其他线程通知需要被中断的线程后，线程中断的状态被设置为true，但是具体被要求中断的线程要怎么处理，完全由被中断线程自己而定，可以在合适的实际处理中断请求，也可以完全不处理继续执行下去。\n Java线程间的通信 合理的使用Java多线程可以更好地利用服务器资源。一般来讲，线程内部有自己私有的线程上下文，互不干扰。但是当我们需要多个线程之间相互协作的时候，就需要我们掌握Java线程的通信方式。本文将介绍Java线程之间的几种通信原理。\n锁与同步 在Java中，锁的概念都是基于对象的，所以我们又经常称它为对象锁。线程和锁的关系，我们可以用婚姻关系来理解。一个锁同一时间只能被一个线程持有。也就是说，一个锁如果和一个线程“结婚”（持有），那其他线程如果需要得到这个锁，就得等这个线程和这个锁“离婚”（释放）。\n在我们的线程之间，有一个同步的概念。什么是同步呢，假如我们现在有2位正在抄暑假作业答案的同学：线程A和线程B。当他们正在抄的时候，老师突然来修改了一些答案，可能A和B最后写出的暑假作业就不一样。我们为了A,B能写出2本相同的暑假作业，我们就需要让老师先修改答案，然后A，B同学再抄。或者A，B同学先抄完，老师再修改答案。这就是线程A，线程B的线程同步。\n可以解释为：线程同步是线程之间按照一定的顺序执行。\n为了达到线程同步，我们可以使用锁来实现它。\n我们先来看看一个无锁的程序：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  public class NoneLock { static class ThreadA implements Runnable { @Override public void run() { for (int i = 0; i \u0026lt; 100; i++) { System.out.println(\u0026#34;Thread A \u0026#34; + i); } } } static class ThreadB implements Runnable { @Override public void run() { for (int i = 0; i \u0026lt; 100; i++) { System.out.println(\u0026#34;Thread B \u0026#34; + i); } } } public static void main(String[] args) { new Thread(new ThreadA()).start(); new Thread(new ThreadB()).start(); } }   执行这个程序，你会在控制台看到，线程A和线程B各自独立工作，输出自己的打印值。如下是我的电脑上某一次运行的结果。每一次运行结果都会不一样。\n1 2 3 4 5 6 7 8 9  .... Thread A 48 Thread A 49 Thread B 0 Thread A 50 Thread B 1 Thread A 51 Thread A 52 ....   那我现在有一个需求，我想等A先执行完之后，再由B去执行，怎么办呢？最简单的方式就是使用一个“对象锁”：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  public class ObjectLock { private static Object lock = new Object(); static class ThreadA implements Runnable { @Override public void run() { synchronized (lock) { for (int i = 0; i \u0026lt; 100; i++) { System.out.println(\u0026#34;Thread A \u0026#34; + i); } } } } static class ThreadB implements Runnable { @Override public void run() { synchronized (lock) { for (int i = 0; i \u0026lt; 100; i++) { System.out.println(\u0026#34;Thread B \u0026#34; + i); } } } } public static void main(String[] args) throws InterruptedException { new Thread(new ThreadA()).start(); Thread.sleep(10); new Thread(new ThreadB()).start(); } }   这里声明了一个名字为lock的对象锁。我们在ThreadA和ThreadB内需要同步的代码块里，都是用synchronized关键字加上了同一个对象锁lock。\n上文我们说到了，根据线程和锁的关系，同一时间只有一个线程持有一个锁，那么线程B就会等线程A执行完成后释放lock，线程B才能获得锁lock。\n 这里在主线程里使用sleep方法睡眠了10毫秒，是为了防止线程B先得到锁。因为如果同时start，线程A和线程B都是出于就绪状态，操作系统可能会先让B运行。这样就会先输出B的内容，然后B执行完成之后自动释放锁，线程A再执行。\n 等待/通知机制 上面一种基于“锁”的方式，线程需要不断地去尝试获得锁，如果失败了，再继续尝试。这可能会耗费服务器资源。\n而等待/通知机制是另一种方式。\nJava多线程的等待/通知机制是基于Object类的wait()方法和notify(), notifyAll()方法来实现的。\n notify()方法会随机叫醒一个正在等待的线程，而notifyAll()会叫醒所有正在等待的线程。\n 前面我们讲到，一个锁同一时刻只能被一个线程持有。而假如线程A现在持有了一个锁lock并开始执行，它可以使用lock.wait()让自己进入等待状态。这个时候，lock这个锁是被释放了的。\n这时，线程B获得了lock这个锁并开始执行，它可以在某一时刻，使用lock.notify()，通知之前持有lock锁并进入等待状态的线程A，说“线程A你不用等了，可以往下执行了”。\n 需要注意的是，这个时候线程B并没有释放锁lock，除非线程B这个时候使用lock.wait()释放锁，或者线程B执行结束自行释放锁，线程A才能得到lock锁。\n 我们用代码来实现一下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57  public class WaitAndNotify { private static Object lock = new Object(); static class ThreadA implements Runnable { @Override public void run() { synchronized (lock) { for (int i = 0; i \u0026lt; 5; i++) { try { System.out.println(\u0026#34;ThreadA: \u0026#34; + i); lock.notify(); lock.wait(); } catch (InterruptedException e) { e.printStackTrace(); } } lock.notify(); } } } static class ThreadB implements Runnable { @Override public void run() { synchronized (lock) { for (int i = 0; i \u0026lt; 5; i++) { try { System.out.println(\u0026#34;ThreadB: \u0026#34; + i); lock.notify(); lock.wait(); } catch (InterruptedException e) { e.printStackTrace(); } } lock.notify(); } } } public static void main(String[] args) throws InterruptedException { new Thread(new ThreadA()).start(); Thread.sleep(1000); new Thread(new ThreadB()).start(); } } // 输出： ThreadA: 0 ThreadB: 0 ThreadA: 1 ThreadB: 1 ThreadA: 2 ThreadB: 2 ThreadA: 3 ThreadB: 3 ThreadA: 4 ThreadB: 4   在这个Demo里，线程A和线程B首先打印出自己需要的东西，然后使用notify()方法叫醒另一个正在等待的线程，然后自己使用wait()方法陷入等待并释放lock锁。\n 需要注意的是等待/通知机制使用的是使用同一个对象锁，如果你两个线程使用的是不同的对象锁，那它们之间是不能用等待/通知机制通信的。\n 信号量 JDK提供了一个类似于“信号量”功能的类Semaphore。但本文不是要介绍这个类，而是介绍一种基于volatile关键字的自己实现的信号量通信。\n后面会有专门的章节介绍volatile关键字，这里只是做一个简单的介绍。\n volatile关键字能够保证内存的可见性，如果用volatile关键字声明了一个变量，在一个线程里面改变了这个变量的值，那其它线程是立马可见更改后的值的。\n 比如我现在有一个需求，我想让线程A输出0，然后线程B输出1，再然后线程A输出2…以此类推。我应该怎样实现呢？\n代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40  public class Signal { private static volatile int signal = 0; static class ThreadA implements Runnable { @Override public void run() { while (signal \u0026lt; 5) { if (signal % 2 == 0) { System.out.println(\u0026#34;threadA: \u0026#34; + signal); signal++; } } } } static class ThreadB implements Runnable { @Override public void run() { while (signal \u0026lt; 5) { if (signal % 2 == 1) { System.out.println(\u0026#34;threadB: \u0026#34; + signal); signal = signal + 1; } } } } public static void main(String[] args) throws InterruptedException { new Thread(new ThreadA()).start(); Thread.sleep(1000); new Thread(new ThreadB()).start(); } } // 输出： threadA: 0 threadB: 1 threadA: 2 threadB: 3 threadA: 4   我们可以看到，使用了一个volatile变量signal来实现了“信号量”的模型。这里需要注意的是，volatile变量需要进行原子操作。\n需要注意的是，signal++并不是一个原子操作，所以我们在实际开发中，会根据需要使用synchronized给它“上锁”，或者是使用AtomicInteger等原子类。并且上面的程序也并不是线程安全的，因为执行while语句后，可能当前线程就暂停等待时间片了，等线程醒来，可能signal已经大于等于5了。\n 这种实现方式并不一定高效，本例只是演示信号量\n 信号量的应用场景： 假如在一个停车场中，车位是我们的公共资源，线程就如同车辆，而看门的管理员就是起的“信号量”的作用。\n因为在这种场景下，多个线程（超过2个）需要相互合作，我们用简单的“锁”和“等待通知机制”就不那么方便了。这个时候就可以用到信号量。\n其实JDK中提供的很多多线程通信工具类都是基于信号量模型的。我们会在后面第三篇的文章中介绍一些常用的通信工具类。\n管道 管道是基于“管道流”的通信方式。JDK提供了PipedWriter、 PipedReader、 PipedOutputStream、 PipedInputStream。其中，前面两个是基于字符的，后面两个是基于字节流的。\n这里的示例代码使用的是基于字符的：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63  public class Pipe { static class ReaderThread implements Runnable { private PipedReader reader; public ReaderThread(PipedReader reader) { this.reader = reader; } @Override public void run() { System.out.println(\u0026#34;this is reader\u0026#34;); int receive = 0; try { while ((receive = reader.read()) != -1) { System.out.print((char)receive); } } catch (IOException e) { e.printStackTrace(); } } } static class WriterThread implements Runnable { private PipedWriter writer; public WriterThread(PipedWriter writer) { this.writer = writer; } @Override public void run() { System.out.println(\u0026#34;this is writer\u0026#34;); int receive = 0; try { writer.write(\u0026#34;test\u0026#34;); } catch (IOException e) { e.printStackTrace(); } finally { try { writer.close(); } catch (IOException e) { e.printStackTrace(); } } } } public static void main(String[] args) throws IOException, InterruptedException { PipedWriter writer = new PipedWriter(); PipedReader reader = new PipedReader(); writer.connect(reader); // 这里注意一定要连接，才能通信  new Thread(new ReaderThread(reader)).start(); Thread.sleep(1000); new Thread(new WriterThread(writer)).start(); } } // 输出： this is reader this is writer test   我们通过线程的构造函数，传入了PipedWrite和PipedReader对象。可以简单分析一下这个示例代码的执行流程：\n 线程ReaderThread开始执行， 线程ReaderThread使用管道reader.read()进入”阻塞“， 线程WriterThread开始执行， 线程WriterThread用writer.write(\u0026ldquo;test\u0026rdquo;)往管道写入字符串， 线程WriterThread使用writer.close()结束管道写入，并执行完毕， 线程ReaderThread接受到管道输出的字符串并打印， 线程ReaderThread执行完毕。  管道通信的应用场景： 这个很好理解。使用管道多半与I/O流相关。当我们一个线程需要先另一个线程发送一个信息（比如字符串）或者文件等等时，就需要使用管道通信了。\n其它通信相关 以上介绍了一些线程间通信的基本原理和方法。除此以外，还有一些与线程通信相关的知识点，这里一并介绍。\njoin方法 join()方法是Thread类的一个实例方法。它的作用是让当前线程陷入“等待”状态，等join的这个线程执行完成后，再继续执行当前线程。\n有时候，主线程创建并启动了子线程，如果子线程中需要进行大量的耗时运算，主线程往往将早于子线程结束之前结束。\n如果主线程想等待子线程执行完毕后，获得子线程中的处理完的某个数据，就要用到join方法了。\n示例代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  public class Join { static class ThreadA implements Runnable { @Override public void run() { try { System.out.println(\u0026#34;我是子线程，我先睡一秒\u0026#34;); Thread.sleep(1000); System.out.println(\u0026#34;我是子线程，我睡完了一秒\u0026#34;); } catch (InterruptedException e) { e.printStackTrace(); } } } public static void main(String[] args) throws InterruptedException { Thread thread = new Thread(new ThreadA()); thread.start(); thread.join(); System.out.println(\u0026#34;如果不加join方法，我会先被打出来，加了就不一样了\u0026#34;); } }    注意join()方法有两个重载方法，一个是join(long)， 一个是join(long, int)。\n实际上，通过源码你会发现，join()方法及其重载方法底层都是利用了wait(long)这个方法。\n对于join(long, int)，通过查看源码(JDK 1.8)发现，底层并没有精确到纳秒，而是对第二个参数做了简单的判断和处理。\n sleep方法 sleep方法是Thread类的一个静态方法。它的作用是让当前线程睡眠一段时间。它有这样两个方法：\n Thread.sleep(long) Thread.sleep(long, int)   同样，查看源码(JDK 1.8)发现，第二个方法貌似只对第二个参数做了简单的处理，没有精确到纳秒。实际上还是调用的第一个方法。\n 这里需要强调一下：**sleep方法是不会释放当前的锁的，而wait方法会。**这也是最常见的一个多线程面试题。\n它们还有这些区别：\n wait可以指定时间，也可以不指定；而sleep必须指定时间。 wait释放cpu资源，同时释放锁；sleep释放cpu资源，但是不释放锁，所以易死锁。 wait必须放在同步块或同步方法中，而sleep可以再任意位置  ThreadLocal类 ThreadLocal是一个本地线程副本变量工具类。内部是一个弱引用的Map来维护。这里不详细介绍它的原理，而是只是介绍它的使用，以后有独立章节来介绍ThreadLocal类的原理。\n有些朋友称ThreadLocal为线程本地变量或线程本地存储。严格来说，ThreadLocal类并不属于多线程间的通信，而是让每个线程有自己”独立“的变量，线程之间互不影响。它为每个线程都创建一个副本，每个线程可以访问自己内部的副本变量。\nThreadLocal类最常用的就是set方法和get方法。示例代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49  public class ThreadLocalDemo { static class ThreadA implements Runnable { private ThreadLocal\u0026lt;String\u0026gt; threadLocal; public ThreadA(ThreadLocal\u0026lt;String\u0026gt; threadLocal) { this.threadLocal = threadLocal; } @Override public void run() { threadLocal.set(\u0026#34;A\u0026#34;); try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(\u0026#34;ThreadA输出：\u0026#34; + threadLocal.get()); } static class ThreadB implements Runnable { private ThreadLocal\u0026lt;String\u0026gt; threadLocal; public ThreadB(ThreadLocal\u0026lt;String\u0026gt; threadLocal) { this.threadLocal = threadLocal; } @Override public void run() { threadLocal.set(\u0026#34;B\u0026#34;); try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(\u0026#34;ThreadB输出：\u0026#34; + threadLocal.get()); } } public static void main(String[] args) { ThreadLocal\u0026lt;String\u0026gt; threadLocal = new ThreadLocal\u0026lt;\u0026gt;(); new Thread(new ThreadA(threadLocal)).start(); new Thread(new ThreadB(threadLocal)).start(); } } } // 输出： ThreadA输出：A ThreadB输出：B   可以看到，虽然两个线程使用的同一个ThreadLocal实例（通过构造方法传入），但是它们各自可以存取自己当前线程的一个值。\n那ThreadLocal有什么作用呢？如果只是单纯的想要线程隔离，在每个线程中声明一个私有变量就好了呀，为什么要使用ThreadLocal？\n如果开发者希望将类的某个静态变量（user ID或者transaction ID）与线程状态关联，则可以考虑使用ThreadLocal。\n最常见的ThreadLocal使用场景为用来解决数据库连接、Session管理等。数据库连接和Session管理涉及多个复杂对象的初始化和关闭。如果在每个线程中声明一些私有变量来进行操作，那这个线程就变得不那么“轻量”了，需要频繁的创建和关闭连接。\nInheritableThreadLocal InheritableThreadLocal类与ThreadLocal类稍有不同，Inheritable是继承的意思。它不仅仅是当前线程可以存取副本值，而且它的子线程也可以存取这个副本值。\n","date":"2021-04-05T13:36:41Z","image":"https://ahao.ink/12.jpg","permalink":"https://ahao.ink/posts/java%E5%B9%B6%E5%8F%91-%E5%9F%BA%E7%A1%80%E7%AF%87/","title":"Java并发 基础篇"},{"content":"Java体系 Java 基础 1、跨平台 2、面向对象编程语言 3、分布式计算\nJava 的运行机制  编程 Java 程序 编译 Java 文件 JVM 读取字节码文件运行程序  Java的三大体系  Java SE(J2SE) Java ME(J2ME) Java EE(J2EE)  配置 Java 环境 JRE、JDK JRE：Java Runtime Environment Java 运行环境 JDK：Java Devlopment Kit Java 开发工具包\n开发  编译  1  javac HelloWorld.java    运行  1  java HelloWorld   Java IDE NetBeans、Eclipse、IDEA\n代码规范  强制性代码规范，必须执行的  1、Java 程序的文件名与类名必须一致，若不一致，无法通过编译。 2、main 方法是程序的入口，方法的定义必须严格按照格式书写。 3、类是组织 Java 代码结构的，类中的方法是执行具体业务的。\n 非强制性代码规范，建议按照此方式编写代码  1、一行只写一条语句。 2、在 1 的基础上，还要注意代码缩进。\n基本概念 安装 Java 环境  编写 Java 代码 编译 Java 代码，成为字节码文件 16 进制 javac 文件名（带后缀） 让 JVM 执行字节码文件，运行程序 java 文件名（不带后缀）  IDE：集成开发环境 Eclipse、IDEA\n注释 注释就是用通俗易懂的语言对代码进行描述解释，方便自己和他人阅读。\n 单行注释：  1  //注释内容    多行注释：  1 2 3 4  /*注释内容 注释内容 注释内容 */    文档注释：  1 2 3 4  /**注释内容 *注释内容 *注释内容 */   关键字 Java 语言预先定义好的，有指定意义的标识符，组成程序的基本元素。\n   abstract 表示抽象     boolean 基本数据类型   break 跳出循环   byte 基本数据类型   case 与 switch 搭配使用   catch 与 try 搭配使用，表示捕获异常   char 基本数据类型   class 表示一个类   continue 跳出循环   do 与 while 搭配使用，表示循环   double 基本数据类型   else 与 if 搭配，流程控制   enum 枚举类型   extends 继承   final 修饰常量   float 基本数据类型   if 流程控制   implements 实现接口   import 引入某个类   int 基本数据类型   interface 表示接口   long 基本数据类型   native 表示本地方法   new 创建对象   package 表示包   private 私有   public 共有   return 返回值   short 基本数据类型   static 表示静态   super 表示父类   switch 与 case 搭配使用   synchronized 线程同步   this 表示当前实例   throw 抛出异常   throws 方法中主动抛出异常   try 与 catch 搭配使用   void 表示方法没有返回值   volatile 保证线程读取到最新值   while 表示循环    变量  数据类型 变量名 变量值  1  基本数据类型`+`引用数据类型   使用变量 1、声明变量的数据类型和变量名（包含数字、字母、下划线、$，不能包含空格、运算符，不能用关键字命名，不能以数字开头），大小写可以混用，首单词应该小写，后续单词的首字母大写。 userId、studentName （驼峰式命名法） 2、给内存空间赋值，该值就是变量值。\nJava 的数据类型  基本数据类型  byte、int、short、long、float、double、char、boolean\n 数值类型（整数、小数）\n byte 1 个字节 (8位)\nshort 2 个字节（16位）\nint 4 个字节（32位）\nlong 8 个字节（64位） float 4 个字节（32位） 单精度浮点型 double 8 个字节（64位）双精度浮点型\n 非数值类型（文本）\n char 2 个字节（16位） boolean 1 个字节(8位)、判断逻辑是否成立 true 1/false 0\n 引用数据类型  数据类型转换  自动转换  Java 可以自动对某些数据类型进行自动转换。\n规则：只能由低字节向高字节进行转换，反之则不行。\nbyte-\u0026gt;short-\u0026gt;int-\u0026gt;long-\u0026gt;float-\u0026gt;double\n 强制类型转换  Java 无法自动转换的数据类型，开发者可以通过强制手段进行转换。\n一般来讲强制类型转换可能会造成精度损失。\n1 2  double num = 10.0; int num2 = (int)num;   运算符  赋值运算符  数据类型 变量名 = 数值/变量;\n1 2 3 4 5 6 7 8 9 10  //1、创建变量用来记录张三的体重 double weight1 = 70.5; //2、创建变量表示李四的体重 double weight2 = 60.5; System.out.println(\u0026#34;交换之前：张三的体重是\u0026#34;+weight1+\u0026#34;,李四的体重是\u0026#34;+weight2); System.out.println(\u0026#34;进行交换\u0026#34;); double temp = weight1; weight1 = weight2; weight2 = temp; System.out.println(\u0026#34;交换之后：张三的体重是\u0026#34;+weight1+\u0026#34;,李四的体重是\u0026#34;+weight2);     算术运算符\n 基本算术运算符 +、-、*、/、%、++、– 变量1 + 变量2 变量1 - 变量2 变量1 * 变量2 变量1 / 变量2 变量1 % 变量2 变量++、++变量 变量–、\u0026ndash;变量 变量++：先操作，再运算。 ++变量：先运算，再操作。 复合算术运算符 +=、-=、*=、/=、%= 变量1 += 变量2：先求出变量1和变量2之和，再把计算结果赋值给变量1，变量1 = 变量1 + 变量2    关系运算符\n==、!=、\u0026gt;、\u0026lt;、\u0026gt;=、\u0026lt;=\n  逻辑运算符\n  逻辑运算符只能用于 boolean 类型的数据运算，判断 boolean 数据之间的逻辑关系，与、或、非。 \u0026amp;（与）、｜（或）、!（非）、\u0026amp;\u0026amp;（短路与）、||（短路或） 参与逻辑运算符的变量都是 boolean 的。\n1、变量1 \u0026amp; 变量2：只有当变量 1 和变量 2 都为 true，结果为 true，否则为 false。 【A \u0026amp; B AB都会执行】 2、变量1 ｜ 变量2：变量 1 和变量 2 只要有一个为 true，结果为 true，否则为 false。【A | B AB都会执行】 3、!变量1：若变量 1 为 true，结果为 false，若变量 1 为 false，结果为 true。 4、变量1 \u0026amp;\u0026amp; 变量2：只有当变量 1 和变量 2 都为 true，结果为 true，否则为 false。 【A \u0026amp;\u0026amp; B 若A为false，B不执行】 5、变量1 || 变量2：变量 1 和变量 2 只要有一个为 true，结果为 true，否则为 false。【A || B 若A为true，B不执行】\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  int num1 = 10; int num2 = 11; System.out.println((++num1==num2)||(num1++==num2)); System.out.println(num1); int num1 = 10; int num2 = 11; System.out.println((++num1==num2)|(num1++==num2)); System.out.println(num1); int num1 = 10; int num2 = 11; System.out.println((num1++==num2)\u0026amp;(++num1==num2)); System.out.println(num1); int num1 = 10; int num2 = 11; System.out.println((num1++==num2)\u0026amp;\u0026amp;(++num1==num2)); System.out.println(num1);   条件运算符 三元运算符、三目运算符、三元表达式\n根据不同的条件给同一个变量赋不同的值，变量 = 条件?值1:值2.\n位运算符  十进制和二进制的转换   十进制转二进制：\n目标数除以2，若能除尽，该位记做0，若除不尽，该位记做1，再对商继续除以2，以此类推，直到商为0，然后把每一位的结果反序组合就是对应的二进制。\n 10：1010\n17：10001\n 二进制转十进制：\n从目标数的最后侧起，本位的数值乘以本位的权重，权重就是2的第几位的位数减一次方，将每一位的值进行相加，得到的结果就是对应的十进制。\n 位运算符：\n \u0026amp;（按位与） ｜（按位或） ^（按位异或） \u0026laquo;（左移）、\u0026raquo;（右移）   变量1 \u0026amp; 变量2：先把变量 1 和变量 2 转为二进制，每一位的数字一一对应，进行比较判断，若都为 1，则该位记做 1，否则记做 0。\n  变量1 |变量2：先把变量 1 和变量 2 转为二进制，每一位的数字一一对应，进行比较判断，只要有一个为 1，则该位记做 1，否则记做 0。\n  变量1 ^ 变量2：先把变量 1 和变量 2 转为二进制，每一位的数字一一对应，进行比较判断，相同记做 0，不同记做 1。\n  变量1 \u0026laquo; 变量2：变量1乘以2的变量2次方\n 2 \u0026laquo; 3 : 2 * 8 = 16\n 变量1 \u0026raquo; 变量2：变量1除以2的变量2次方\n 2 \u0026raquo; 3：2/8 = 0\n运算符的优先级 !\u0026gt;算术运算符\u0026gt;关系运算符\u0026gt;逻辑运算符(\u0026amp;\u0026amp;\u0026gt;||)\n流程控制 选择流程控制  if else  用来判断某个条件是否成立，然后执行不同的逻辑运算。\n基本语法：\n1 2 3 4 5  if(判断条件){ //条件成立的代码 }else{ //条件不成立的代码 }    多重 if   173 M\n173～178 L\n178 XL\n  if 后面必须跟条件 else 后面不能跟条件 else 后面可以根据{}，也可以跟 if  循环流程控制  switch-case  与 if 不同的是，switch-case 只能完成等值判断，而无法完成判断大小。 如果是判断两个值是否相等，可以使用 switch-case，如果比较两个值的大小关系，则不能使用 switch-case。 switch 支持 int、short、byte、char、枚举、String 类型，不支持 boolean 类型。 基本语法\n1 2 3 4 5 6 7 8 9 10 11 12  switch(变量){ case 值1: //业务代码  break； case 值2: //业务代码  breka; ... default: //业务代码  break; }   case 判断变量是否等于某个值，default 表示所有的 case 都不成立的情况下所执行的代码。\n 1 奖励 2000 2 奖励 1000 3 奖励 500 否则没有奖励  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  public static void main(String[] args) { int placing = 1; if(placing == 1) { System.out.println(\u0026#34;奖励2000元\u0026#34;); }else { if(placing == 2) { System.out.println(\u0026#34;奖励1000元\u0026#34;); }else { if(placing == 3) { System.out.println(\u0026#34;奖励500元\u0026#34;); }else{ System.out.println(\u0026#34;没有奖励\u0026#34;); } } } switch(placing) { case 1: System.out.println(\u0026#34;奖励2000元\u0026#34;); break; case 2: System.out.println(\u0026#34;奖励1000元\u0026#34;); break; case 3: System.out.println(\u0026#34;奖励500元\u0026#34;); break; default: System.out.println(\u0026#34;没有奖励\u0026#34;); break; } }   循环 for、while、do-while、foreach 循环四要素：\n 初始化循环变量 循环条件 循环体 更新循环变量  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66  while 初始化循环变量 while(循环条件){ 循环体 更新循环变量 } //初始化循环变量 int num = 0; //循环条件 while(num \u0026lt; 10) { //循环体  System.out.println(\u0026#34;Hello World\u0026#34;); //更新循环变量  num++; } int num = 0; String flag = \u0026#34;y\u0026#34;; while(flag.equals(\u0026#34;y\u0026#34;)) { System.out.print(\u0026#34;请输入学生学号：\u0026#34;); Scanner scanner = new Scanner(System.in); int id = scanner.nextInt(); switch(id) { case 1: System.out.println(\u0026#34;张三的成绩是96\u0026#34;); break; case 2: System.out.println(\u0026#34;李四的成绩是91\u0026#34;); break; case 3: System.out.println(\u0026#34;王五的成绩是89\u0026#34;); break; default: System.out.println(\u0026#34;请输入正确的学号\u0026#34;); break; } System.out.print(\u0026#34;是否继续？y/n\u0026#34;); flag = scanner.next(); } System.out.println(\u0026#34;感谢使用学生成绩查询系统\u0026#34;); do-while //初始化循环变量  int num = 0; do { //循环体  System.out.println(\u0026#34;Hello World\u0026#34;); //更新循环变量  num++; }while(num\u0026lt;10); //循环条件 Scanner scanner = new Scanner(System.in); String result = \u0026#34;\u0026#34;; do { System.out.println(\u0026#34;张三参加体能测试，跑1000米\u0026#34;); System.out.print(\u0026#34;是否合格？y/n\u0026#34;); result = scanner.next(); }while(result.equals(\u0026#34;n\u0026#34;)); System.out.println(\u0026#34;合格，通过测试\u0026#34;); for for(初始化循环变量;循环条件;更新循环变量){ 循环体 } for(int num = 0;num \u0026lt; 10;num++) { System.out.println(\u0026#34;Hello World\u0026#34;); }   while、do-while、for 3种循环的区别\n 相同点：都遵循循环四要素，初始化循环变量、循环条件、循环体、更新循环变量。 不同点：  while 和 do-while 适用于循环次数不确定的业务场景；for 适用于循环次数确定的场景。 while 和 for 都是先判断循环条件，再执行循环体；do-while 先执行循环体，再判断循环条件。    分别使用 while、do-while、for 循环输出 10 以内的所有奇数。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  //while循环 int num = 0; while(num \u0026lt;= 10) { if(num%2!=0) { System.out.println(num); } num++; } //do-while循环 int num = 0; do { if(num%2!=0) { System.out.println(num); } num++; }while(num \u0026lt;= 10); //for循环 for(int num = 0;num \u0026lt;= 10;num++) { if(num%2!=0) { System.out.println(num); } } 1234567891011121314151617181920212223   for 循环只适用于循环次数确定的场景下(for 也可以适用于循环次数不确定的场景，只不过一般不会用这种方式进行开发)，while 和 do-while 循环次数确定或者不确定都可以使用。\n1 2 3 4 5 6 7  String result = \u0026#34;n\u0026#34;; for(;result.equals(\u0026#34;n\u0026#34;);) { System.out.println(\u0026#34;张三参加体能测试，跑1000米\u0026#34;); System.out.print(\u0026#34;是否合格？y/n\u0026#34;); result = scanner.next(); } System.out.println(\u0026#34;合格，通过测试\u0026#34;);   数组 数组 数组就是一种可以存储大量数据类型相同的变量的数据结构，数组就是一个具有相同数据类型的数据集合。 数组中的数据必须是同一种数据类型的。\n数组的基本要素  数组名称 数组元素 元素下标 数据类型  数组本身就是一个变量，数组名称就是变量名，数组中保存的每一个数据都会有一个下标（从 0 开始）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  //声明数组 int[] array; //分配内存空间 array = new int[6]; //给数组赋值 array[0] = 1; array[1] = 2; array[2] = 3; array[3] = 4; array[4] = 5; array[5] = 6; int[] array2 = {1,2,3,4,5,6}; int[] array3 = new int[]{1,2,3,4,5,6};   数组常见的错误  数据类型不匹配。 边声明边赋值的方式，代码必须写在同一行，不能换行。 数组下标越界。  数组的常用操作及方法  求数组的最大值 求数组的最小值 在数组的指定位置插入数据 对数组进行排序  二维数组 二维数组简单理解即一维数组中保存的值是另外一个一维数组。 变量、数据类型、流程控制、循环、数组。 用户管理系统\n 查询用户：将系统中保存的全部用户信息在控制台打印输出。 添加用户：向系统中添加新的用户信息，如果添加的用户已经存在，给出提示信息。 删除用户：输入用户名，进行删除操作，若输入的用户名不存在，给出提示信息。 账号冻结：输入用户名，进行冻结操作，若输入的用户名不存在或者该用户已经被冻结，给出相应提示。 账号解冻：输入用户名，进行解封操作，若输入的用户名不存在或者该用户状态正常，给出相应提示。 退出系统：跳出循环，给出提示信息。  面向对象程序 面向对象 面向对象编程思想：将程序模块化的思想。\n 什么是面向对象？  面向对象编程思想诞生之前，程序开发采用的是面向过程的结构化编程方式，是一种面向功能划分的软件结构。 最小粒度细化到方法这一层。 面向过程注重的是每一个步骤，面向对象关注点在于整件事情的模块化结构。\n 类和对象  类和对象的关系 每个对象都有特定的特征：1、属性。2、方法。 属性指的是对象的静态特征，方法用来描述对象的动态特征。 对象是用来描述客观存在的一个实体，改实体是由一组属性和方法构成。 类是与对象紧密结合的另外一个概念，类是产生对象的模版，所有的对象都是通过类来创建的。 二者的关系：类是对象的抽象化描述，这些对象具有相同的特征和动作（属性和方法）。 对象是类的具体实例。 Java 程序是以类位组织单元，程序运行时的主体是通过类创建的具体对象。\n三大特征：封装、继承、多态\n定义类 1 2 3 4 5 6 7 8  public class 类名{ //定义属性，属性名符合驼峰式命名法  public 数据类型 属性名; //定义方法，方法名符合驼峰式命名法  public 返回值类型 方法名(参数列表:数据类型 参数名){ //方法体  } }   Java 关于返回值的定义分为两类：有返回值和无返回值，有返回值的方法需要在方法定义时指定返回值的数据类型，并在方法体中用 return 将结果返回给外部调用者，加法运算。 如果一个方法不需要进行返回操作，将返回值类型定义为 void。 参数列表是指外部在调用该方法时需要传入到方法内部进行运算的数据。\n构造函数、构造方法、构造器 构造函数是一种特殊的方法，普通方法是用来描述某个动作的，构造方法是用来创建对象的。\n 方法名必须与类名一致。 不需要定义返回值类型。  构造函数可分为有参构造和无参构造，有参构造是指带参数的构造函数，无参构造是指没有参数的构造函数。 任何一个类都默认自带一个无参构造函数，如果手动在类中定义一个有参构造，则会覆盖默认的无参构造。\nthis 关键字 this 用来指代当前类的实例化对象，通过 this 可以调用当前类的属性和方法，比如在有参构造中，通过 this 将外部传入的值赋给当前类的实例化对象。 this 除了可以在类中访问属性也可以在类中调用方法，类中的方法可以分为两类：构造方法、普通方法，用 this 调用这两类方法的语法也不同。\n1、调用构造函数的语法是 this(参数列表)，不能在普通方法中使用 this 调用构造函数。 2、用 this 调用普通方法，this.方法名(参数列表)，可以在构造函数中使用，也可以在普通方法中使用。\n成员变量和局部变量 变量的作用域是指在程序中可以通过变量名来访问该变量的范围，变量的作用域由变量被声明时所在位置决定的，Java 中根据不同的作用域可以将变量分为成员变量和局部变量。 局部变量：如果一个变量在方法中声明，则该变量是局部变量。 成员变量：如果一个变量在方法外，类中声明，则该变量是成员变量。\n1 2 3 4 5 6  public class HelloWorld{ int num2 = 2; //成员变量  public int test(){ int num1 = 1; //局部变量  } }   1、成员变量和局部变量的区别在于作用域不同，成员变量的作用域在整个类中，类中的每个方法都可以访问该变量，局部变量的作用域只在定义该变量的方法中，出了方法体就无法访问。 2、成员变量和局部变量的初始值也不同，局部变量不会赋初始值，成员变量会赋初始值，具体的值是由成员变量的数据类型决定的。\n封装 封装是指将类的属性隐藏在内部，外部不能直接访问和修改，如何实现？通过修改成员变量的可见性，从公有改为私有。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33  public class Student { private int id; private String name; private int age; public void show() { System.out.println(\u0026#34;学生信息如下：\u0026#34;); System.out.println(\u0026#34;学生编号：\u0026#34;+id); System.out.println(\u0026#34;学生姓名：\u0026#34;+name); System.out.println(\u0026#34;学生年龄：\u0026#34;+age); } public int getId() { return id; } public void setId(int id) { this.id = id; } public String getName() { return name; } public void setName(String name) { this.name = name; } public int getAge() { return age; } public void setAge(int age) { if(age \u0026lt;= 0) { System.out.println(\u0026#34;输入的数值有误！\u0026#34;); age = 18; } this.age = age; } }   封装的核心思想就是尽可能把属性都隐藏在内部，对外提供方法来访问，我们可以在这些方法中添加逻辑处理来实现过滤，以屏蔽错误数据的赋值。 封装的步骤：\n 修改属性（成员变量）的访问权限为私有，使得外部不能直接访问。 提供外部可以直接调用的方法。 在该方法中加入对于属性的逻辑控制，避免出现逻辑上的错误。   什么是访问权限？\n 访问权限是指该属性可以被直接访问的范围，是在属性定义时设定的，访问权限的可选项一共有 4 种：区别在于作用域范围不同。\n public private 默认（不写） protected  static static 表示静态或者全局，可以用来修饰成员变量和成员方法以及代码块。 使用 static 修饰的成员变量和成员方法独立于该类的任何一个实例化对象，访问时不依赖于该类的对象，而是直接通过类去访问，可以理解为被该类的所有实例对象所共用，所以说是全局的。 static 还可以修饰代码块，被 static 修饰的代码块叫做静态代码块。\n1 2 3  static { System.out.println(1); }   静态代码块的特点是只执行一次，什么时候执行？当这个类被加载到内存时执行，不需要开发者手动调用，会自动执行。 被加载到内存中的类叫做运行时类，静态代码块就是在加载类的时候执行的，因为类只加载一次，所以静态代码块也只执行一次。\n继承  什么是继承？  继承是用来描述类之间的关系的，即一个类继承（拥有）另外一个类中的属性和方法，被继承的类叫做父类，继承父类的类叫做子类。 继承的基本语法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36  public class 类名 extends 父类名{ } public class People { private int id; private String name; private int age; private char gender; public int getId() { return id; } public void setId(int id) { this.id = id; } public String getName() { return name; } public void setName(String name) { this.name = name; } public int getAge() { return age; } public void setAge(int age) { this.age = age; } public char getGender() { return gender; } public void setGender(char gender) { this.gender = gender; } } public class Student extends People { }   Java 中的继承是单继承，也就是说一个子类只能有一个直接父类。\n子类访问父类 创建一个子类对象的时候，会默认先创建一个父类对象，无论是通过有参构造或是无参构造来创建子类对象，都是通过【无参构造来创建父类对象的】。 可以通过 super 关键字让子类创建对象时调用父类的有参构造。\n1 2 3 4  public Student() { super(1); System.out.println(\u0026#34;通过无参构造创建了Student对象\u0026#34;); }   子类可以访问父类的构造方法、普通方法、成员变量，都是通过 super 关键字来完成，具体语法： 构造方法：super(参数列表) 普通方法：super.方法名(参数列表) 成员变量：super.成员变量名 在子类的构造方法中，可以通过 super 访问父类的构造方法和普通方法。 在子类的普通方法中，只能通过 super 访问父类的普通方法。\n子类的访问权限 访问权限修饰符：public、protected、默认修饰符、private。\n   属性 同一个类中 同包 子类（不同包） 不同包     public 可以访问 可以访问 可以访问 可以访问   protected 可以访问 可以访问 可以访问 不能访问   默认修饰符 可以访问 可以访问 不能访问 不能访问   private 可以访问 不能访问 不能访问 不能访问    包：package，用来管理 Java 文件，一个项目中不可避免会出现同名的 Java 类，为了防止产生冲突，可以把同名的 Java 类分别放入不同的包中。 包的命名规范：包名由小写字母组成，不能以 . 开头或结尾，可以包含数字，但不能以数字开头，使用 . 来分层。 包的命名方式一般采用网络域名的反向输出，如 com.company.test/com.company.entity。\n方法重写 子类在继承父类方法的基础上，对父类方法重新定义并覆盖的操作叫做方法重写。 构造方法不能被重写，方法重写的规则： 1、父子类的方法名相同。 2、父子类的方法参数列表相同。 3、子类方法的返回值与父类方法返回值类型相同或者是其子类。 4、子类方法的访问权限不能小于父类。\n方法重写 VS 方法重载 位置：方法重写在子类中对父类方法进行重写，方法重载是在同一个类中。 方法名：方法重写相同，方法重载相同。 参数列表：方法重写相同，方法重载不同。 返回值：方法重写相同或是其子类，方法重载没有要求。 访问权限：方法重写不能小于父类，方法重载没有要求。\n多态 一个事物具有多种表现形态，在 Java 程序中，定义一个方法，在具体的生成环境中根据不同的需求呈现不同的业务逻辑，多态的前提是继承。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47  public class Memeber { public void buyBook() { } } //子类一 public class OrdinaryMember extends Memeber { public void buyBook() { System.out.println(\u0026#34;普通会员买书打9折\u0026#34;); } } //子类二 public class SuperMember extends Memeber { public void buyBook() { System.out.println(\u0026#34;超级会员买书打6折\u0026#34;); } } public class Cashier { private Memeber memeber; public Memeber getMemeber() { return memeber; } public void setMemeber(Memeber memeber) { this.memeber = memeber; } public void settlement() { this.memeber.buyBook(); } } public class Test { public static void main(String[] args) { OrdinaryMember ordinaryMember = new OrdinaryMember(); SuperMember superMember = new SuperMember(); Cashier cashier = new Cashier(); cashier.setMemeber(superMember); cashier.settlement(ordinaryMember); } }   多态的具体使用有两种形式： 1、定义方法时形参类型为父类，实际调用方法时传入子类类型的参数。 2、定义方法时返回值类型为父类，实际调用方法时返回子类对象。 以上两种形式的基本原理都是父类引用可以指向子类对象。\n抽象方法和抽象类 如果一个方法只有方法的声明而没有具体的方法实现，这个方法就叫做抽象方法，Java 中的抽象方法需要使用 abstract 关键字来修饰。\n1  public abstract void buyBook();   一旦类中定义了抽象方法，则该类也必须声明为抽象类，需要在类定义处添加 abstract 关键字。\n1 2 3  public abstract class Member { public abstract void buyBook(); }   抽象类与普通类的区别是抽象类不能被实例化，抽象方法与普通方法的区别是抽象方法没有方法体。 抽象类中可以没有抽象方法，但是包含了抽象方法的类必须定义为抽象类。即我们可以在抽象类中定义普通方法，但是在普通类中不能定义抽象方法。 如果父类是抽象类，一旦子类继承了该抽象父类，则子类必须对父类的抽象方法进行重写，否则程序报错。\n1 2 3 4 5 6 7 8 9 10 11  public abstract class Member { public abstract void buyBook(); } package com.southwind.test; public class SuperMember extends Member { @Override public void buyBook() { // TODO Auto-generated method stub  System.out.println(\u0026#34;超级会员买书打6折\u0026#34;); } }   如果子类也是抽象类，则可以不用重写父类的抽象方法。\n接口  什么是接口？  接口是由抽象类衍生出来的一个概念，并由此产生了一种编程方式：面向接口编程。 面向接口编程就是将程序中的业务模块进行分离，以接口的形式去对接不同的业务模块。 面向接口编程的优点：当用户需求变更时，只需要切换不同的实现类，而不需要修改串联模块的接口，减少对系统的影响。 1、能够最大限度实现解耦合，降低程序的耦合性。 2、使程序易于扩展。 3、有利于程序的后期维护。\n 如何使用接口  接口在 Java 中是独立存在的一种结构，和类相似，我们需要创建一个接口文件，Java 中用 class 关键字来标识类，用 interface 来标识接口，基本语法：\n1 2 3  public interface 接口名{ public 返回值 方法名(参数列表) }   接口其实就是一个抽象类，极度抽象的抽象类。 抽象类：一个类中一旦存在没有具体实现的抽象方法时，那么该类就必须定义为抽象类，同时抽象类允许存在非抽象方法。 但是接口完全不同，接口中不能存在非抽象方法，接口中必须全部是抽象方法。 因为接口中必须全部都是抽象方法，所以修饰抽象方法的关键字 abstract 可以省略。 接口中允许定义成员变量，但是有如下要求： 1、不能定义 private 和 protected 修饰的成员变量，只能定义public和默认访问权限修饰符修饰的成员变量。 2、接口中的成员变量在定义时就必须完成初始化。 3、接口中的成员变量都是静态常量，即可以直接通过接口访问，同时值不能被修改。\n1 2 3 4 5  public interface MyInterface { public int ID = 0; String NAME = \u0026#34;张三\u0026#34;; public void test(); }   使用接口时，不能直接实例化接口对象，而必须实例化其实现类对象，实现类本身就是一个普通的 Java 类，创建实现类的代码如下所示。\n1 2 3 4 5 6 7 8  public class MyInterfaceImpl implements MyInterface { @Override public void test() { // TODO Auto-generated method stub  } }   通过 implements 关键字来指定实现类具体要实现的接口，在实现类的内部需要对接口的所有抽象方法进行实现，同时要求访问权限修饰符、返回值类型、方法名和参数列表必须完全一致。 接口和继承，Java 只支持单继承，但是接口可以多实现（一个实现类可以同时实现多个接口）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  //接口一 public interface MyInterface { public int ID = 0; String NAME = \u0026#34;张三\u0026#34;; public void fly(); } //接口二 public interface MyInterface2 { public void run(); } //继承两个接口 public class MyInterfaceImpl implements MyInterface,MyInterface2 { @Override public void run() { // TODO Auto-generated method stub  System.out.println(\u0026#34;实现了跑步的方法\u0026#34;); } @Override public void fly() { // TODO Auto-generated method stub  System.out.println(\u0026#34;实现了飞行的方法\u0026#34;); } } //测试 public class Test { public static void main(String[] args) { MyInterfaceImpl myInterfaceImpl = new MyInterfaceImpl(); myInterfaceImpl.fly(); myInterfaceImpl.run(); } }   常用类 Object Object 是 Java 官方提供的类，存放在 java.lang 包中，该类是所有类的直接父类或者间接父类，无论是 Java 提供的类还是开发者自定义的类，都是 Object 的直接子类或间接子类，Java 中的任何一个类都会继承 Object 中的 public 和 protected 方法。\n1 2 3 4 5 6 7 8 9 10 11  hashCode(); getClass(); equals(null); clone(); toString(); notify(); notifyAll(); wait(); wait(1000L); wait(1000L, 100); 12345678910   Object 类中经常被子类重写的方法： 1、public String toString() 以字符串的形式返回对象的信息 2、public boolean equals(Object obj) 判断两个对象是否相等 3、public native int hashCode() 返回对象的散列码\n toString  1 2 3 4 5 6 7 8 9  Object public String toString() { return getClass().getName() + \u0026#34;@\u0026#34; + Integer.toHexString(hashCode()); } //重写之后 @Override public String toString() { return \u0026#34;People [id=\u0026#34; + id + \u0026#34;, name=\u0026#34; + name + \u0026#34;, score=\u0026#34; + score + \u0026#34;]\u0026#34;; }    equals  1 2 3 4 5 6 7 8 9 10 11 12 13 14  Object public boolean equals(Object obj) { return (this == obj); } //重写之后 @Override public boolean equals(Object obj) { // TODO Auto-generated method stub  People people = (People)obj; if(this.id == people.id \u0026amp;\u0026amp; this.name.equals(people.name) \u0026amp;\u0026amp; this.score.equals(people.score)) { return true; } return false; }    hashCode  1 2 3 4 5 6 7 8  Object public native int hashCode(); //重写之后 @Override public int hashCode() { // TODO Auto-generated method stub  return (int) (id*name.hashCode()*score); }   包装类  什么是包装类？  包装类是 Java 提供的一组类，专门用来创建 8 种基本数据类型对应的对象，一共有 8 个包装类，存放在 java.lang 包中，基本数据类型对应的包装类。\n   byte Byte     short Short   int Integer   long Long   float Float   double Double   char Character   boolean Boolean    包装类的体系结构\nJava 官方提供的一组类，这组类的作用是将基本数据类型的数据封装成引用类型。 Byte、Integer、Short、Long、Float、Double、Boolean、Characte\n装箱和拆箱 装箱和拆箱是包装类的特有名词，装箱是指将基本数据类型转为对应的包装类对象，拆箱就是将包装类对象转为对应的基本数据类型。\n装箱与拆箱 装箱是指将基本数据类型转换为包装类对象。 拆箱是指将包装类对象转换为基本数据类型。\n构造函数 1、public Type(type value) 【即原类型】 每个包装类都提供了一个有参构造函数：public Type(type value)，用来实例化包装类对象。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  byte b = 1; Byte byt = new Byte(b); short s = 2; Short shor = new Short(s); int i = 3; Integer integer = new Integer(i); long l = 4; Long lon = new Long(l); float f = 5.5f; Float flo = new Float(f); double d = 6.6; Double dou = new Double(d); char cha = \u0026#39;J\u0026#39;; Character charac = new Character(cha); boolean bo = true; Boolean bool = new Boolean(bo); System.out.println(byt); System.out.println(shor); System.out.println(integer); System.out.println(lon); System.out.println(flo); System.out.println(dou); System.out.println(charac); System.out.println(bool);   2、public Type(String value)/public Type(char value) 【即字符/字符串类型】 每个包装类还有一个重载构造函数：\nCharacter 类的重载构造函数：public Type(char value)，其他包装类的重载构造函数：public Type(String value)。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  Byte byt = new Byte(\u0026#34;1\u0026#34;); Short shor = new Short(\u0026#34;2\u0026#34;); Integer integer = new Integer(\u0026#34;3\u0026#34;); Long lon = new Long(\u0026#34;4\u0026#34;); Float flo = new Float(\u0026#34;5.5f\u0026#34;); Double dou = new Double(\u0026#34;6.6\u0026#34;); Character charac = new Character(\u0026#39;J\u0026#39;); Boolean bool = new Boolean(\u0026#34;abc\u0026#34;); System.out.println(byt); System.out.println(shor); System.out.println(integer); System.out.println(lon); System.out.println(flo); System.out.println(dou); System.out.println(charac);   需要注意的是，Boolean 类的构造函数中，当参数为 “true” 时，Boolean 值为 true，当参数不为 “true”，Boolean 值为 false。\n装箱 1、public Type(type value) 2、public Type(String value)/public Type(char value) 3、valueOf(type value) 静态方法，参数是基本数据类型的数据 每一个包装类都有一个 valueOf(type value) 方法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  byte b = 1; Byte byt = Byte.valueOf(b); short s = 2; Short shot = Short.valueOf(s); int i = 3; Integer integer = Integer.valueOf(i); long l = 4L; Long lon = Long.valueOf(l); float f = 5.5f; Float floa = Float.valueOf(f); double d = 6.6; Double doub = Double.valueOf(d); boolean boo = true; Boolean bool = Boolean.valueOf(boo); char ch = \u0026#39;J\u0026#39;; Character cha = Character.valueOf(ch);   其中：\n1 2 3 4 5 6 7 8 9 10  //valueOf(String value)/valueOf(char value) 专门为 Character 转换使用的， //其他的 7 个包装类都可以使用 valueOf(String value)。 Byte byt = Byte.valueOf(\u0026#34;1\u0026#34;); Short sho = Short.valueOf(\u0026#34;2\u0026#34;); Integer integer = Integer.valueOf(\u0026#34;3\u0026#34;); Long lon = Long.valueOf(\u0026#34;4\u0026#34;); Float flo = Float.valueOf(\u0026#34;5.5f\u0026#34;); Double dou = Double.valueOf(\u0026#34;6.6\u0026#34;); Boolean boo = Boolean.valueOf(\u0026#34;true\u0026#34;); Character cha = Character.valueOf(\u0026#39;J\u0026#39;);   需要注意的是 Boolean.valueOf(String value) 方法中，当 value 为 “true” 时，Boolean 的值为 true，否则，Boolean 的值为 false。\n拆箱 1、*Value() 每个包装类都有一个 *Value() 方法，通过该方法可以将包装类转为基本数据类型。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  Byte byt = Byte.valueOf(\u0026#34;1\u0026#34;); Short sho = Short.valueOf(\u0026#34;2\u0026#34;); Integer integer = Integer.valueOf(\u0026#34;3\u0026#34;); Long lon = Long.valueOf(\u0026#34;4\u0026#34;); Float flo = Float.valueOf(\u0026#34;5.5f\u0026#34;); Double dou = Double.valueOf(\u0026#34;6.6\u0026#34;); Boolean boo = Boolean.valueOf(\u0026#34;true\u0026#34;); Character cha = Character.valueOf(\u0026#39;J\u0026#39;); byte b = byt.byteValue(); short sh = sho.shortValue(); int i = integer.intValue(); long l = lon.longValue(); float f = flo.floatValue(); double d = dou.doubleValue(); boolean bo = boo.booleanValue(); char c = cha.charValue();   2、parse*(String value) 除了 Character 类以外的每一个包装类都有一个静态方法可以将字符串类型转为基本数据类型。\n1 2 3 4 5 6 7  byte b = Byte.parseByte(\u0026#34;1\u0026#34;); short s = Short.parseShort(\u0026#34;2\u0026#34;); int i = Integer.parseInt(\u0026#34;3\u0026#34;); long l = Long.parseLong(\u0026#34;4\u0026#34;); float f = Float.parseFloat(\u0026#34;5.5\u0026#34;); double d = Double.parseDouble(\u0026#34;6.6\u0026#34;); boolean bo = Boolean.parseBoolean(\u0026#34;true\u0026#34;);   3、toString(type value) 每个包装类都有该方法，作用是将基本数据类型转为 String 类型。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  byte b = 1; String bstr = Byte.toString(b); short s = 2; String sstr = Short.toString(s); String i = Integer.toString(3); long l = 4L; String lstr = Long.toString(l); float f = 5.5f; String fstr = Float.toString(f); double d = 6.6; String dstr = Double.toString(d); boolean bo = true; String bostr = Boolean.toString(bo); String chstr = Character.toString(\u0026#39;J\u0026#39;);   异常 基本概念  什么是异常？  Java 中的错误大致可以分为两类： 1、一类是编译时错误，一般是指语法错误。 2、另一类是运行时错误。 Java 中有一组专门用来描述各种不同的运行时异常，叫做异常类，Java 结合异常类提供了处理错误的机制。 具体步骤是当程序出现错误时，会创建一个包含错误信息的异常类的实例化对象，并自动将该对象提交给系统，由系统转交给能够处理异常的代码进行处理。 异常可以分为两类： 【Error 和 Exception】： 1、Error 是指系统错误，JVM 生成，我们编写的程序无法处理。 2、Exception 指程序运行期间出现的错误，我们编写的程序可以对其进行处理。\nError 和 Exception 都是 Throwable 的子类，Throwable、Error、Exception 都是存放在 java.lang 包中。\n 异常的使用  异常的使用需要用到两个关键字 try 和 catch，并且这两个关键字需要结合起来使用，用 try 来监听可能会抛出异常的代码，一旦捕获到异常，生成异常对象并交给 catch 来处理，基本语法如下所示。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  try{ //可能抛出异常的代码 }catch(Exception e){ //处理异常 } public class Test { public static void main(String[] args) { try { int num = 10/10; }catch (Exception e) { // TODO: handle exception  if(e.getMessage().equals(\u0026#34;/ by zero\u0026#34;)) { System.err.println(\u0026#34;分母不能为0\u0026#34;); } } } }   除了 try 和 catch，还可以使用 finally 关键字来处理异常，finally 的作用？ 无论程序是否抛出异常，finally 代码块中的代码一定都会执行，finally 一般跟在 catch 代码块的后面，基本语法如下所示。\n1 2 3 4 5 6 7 8  try{ //可能抛出异常的代码 }catch(Exception e){ //处理异常 }finally{ //必须执行的代码 } 1234567   异常类 Java 将运行时出现的错误全部封装成类，并且不是一个类，而是一组类。同时这些类之间是有层级关系的，由树状结构一层层向下分级，处在最顶端的类是 Throwable，是所有异常类的根结点。 Throwable 有两个直接子类：\n Error  VirtualMachineError  StackOverflowError OutOfMemoryError   AWTError IOError   Exception。 IOException FileLockInterruptionException FileNotFoundException FilerException RuntimeException  ArithmeticException ClassNotFoundException IllegalArggumentException ArrayIndexOutOfBoundsException NullPointerException NoSuchMethodException NumberFormatException    throw 和 throws throw 和 throws 是 Java 在处理异常时使用的两个关键字，都可以用来抛出异常，但是使用的方式和表示的含义完全不同。 Java 中抛出异常有 3 种方式：\n try-catch 使用 throw 是开发者主动抛出异常，即读到 throw 代码就一定抛出异常，基本语法：throw new Exception()，是一种基于代码的逻辑而主动抛出异常的方式。  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  public class Test { public static void main(String[] args) { int[] array = {1,2,3}; test(array,2); } public static void test(int[] array,int index) { if(index \u0026gt;= 3 || index \u0026lt; 0) { try { throw new Exception(); } catch (Exception e) { // TODO Auto-generated catch block  e.printStackTrace(); } }else { System.out.println(array[index]); } } }    try-catch 和 throw 都是作用于具体的逻辑代码，throws 是作用于方法的，用来描述方法可能会抛出的异常。   如果方法 throws 的是 RuntimeException 异常或者其子类，外部调用时可以不处理，JVM 会处理。 如果方法 throws 的是 Exception 异常或者其子类，外部调用时必须处理，否则报错。\n 1 2 3 4 5 6 7 8 9  public class Test { public static void main(String[] args) throws Exception { test(\u0026#34;123\u0026#34;); } public static void test(String str) throws Exception { int num = Integer.parseInt(str); } }   异常捕获  自动捕获 try-cath throw 主动抛出异常 throws 修饰可能抛出异常的方法  自定义异常 除了使用 Java 提供的异常外，也可以根据需求来自定义异常。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  public class MyNumberException extends RuntimeException { public MyNumberException(String error) { super(error); } } public class Test { public static void main(String[] args){ Test test = new Test(); System.out.println(test.add(\u0026#34;a\u0026#34;)); } public int add(Object object){ if(object instanceof Integer) { int num = (int)object; return ++num; }else { String error = \u0026#34;传入的参数不是整数类型\u0026#34;; MyNumberException myNumberException = new MyNumberException(error); throw myNumberException; } } }   综合练习 封装、继承、多态、抽象、接口、异常完成一个汽车查询系统。\n需求描述：共有 3 种类型的汽车：小轿车、大巴车、卡车，其中小轿车的座位数是 4 座，大巴车座位数是 53 座，卡车座位数是 2 座，要求使用封装、继承、抽象来完成车辆的定义。\n可以对车辆信息进行修改，卡车可以运货但是载重量不能超过 12 吨，使用自定义异常来处理错误，小轿车和大巴车没有此功能，要求使用接口来实现。\nCar\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  public abstract class Car { private String name; private String color; public String getName() { return name; } public void setName(String name) { this.name = name; } public String getColor() { return color; } public void setColor(String color) { this.color = color; } public Car(String name, String color) { super(); this.name = name; this.color = color; } public abstract String seatNum(); }   Sedan\n1 2 3 4 5 6 7 8 9 10 11 12 13  public class Sedan extends Car { public Sedan(String name, String color) { super(name, color); } @Override public String seatNum() { // TODO Auto-generated method stub \treturn \u0026#34;4座\u0026#34;; } }   Bus\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  public class Bus extends Car { public Bus(String name, String color) { super(name, color); // TODO Auto-generated constructor stub \t} @Override public String seatNum() { // TODO Auto-generated method stub \treturn \u0026#34;53座\u0026#34;; } }   Truck\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  public class Truck extends Car implements Container { private int weight; public Truck(String name, String color,int weight) { super(name, color); this.weight = weight; // TODO Auto-generated constructor stub \t} @Override public String seatNum() { // TODO Auto-generated method stub \treturn \u0026#34;2座\u0026#34;; } @Override public int getweight() { // TODO Auto-generated method stub \treturn this.weight; } }   Container\n1 2 3 4 5  package com.southwind.test; public interface Container { public int getweight(); }   CarException\n1 2 3 4 5  public class CarException extends Exception { public CarException(String error) { super(error); } }   Test\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96  import java.util.Scanner; public class Test { private static Scanner scanner; private static Sedan sedan; private static Bus bus; private static Truck truck; private static Car[] cars; static { scanner = new Scanner(System.in); sedan = new Sedan(\u0026#34;小轿车\u0026#34;,\u0026#34;黑色\u0026#34;); bus = new Bus(\u0026#34;大巴车\u0026#34;,\u0026#34;绿色\u0026#34;); truck = new Truck(\u0026#34;卡车\u0026#34;,\u0026#34;蓝色\u0026#34;,2); cars = new Car[3]; cars[0] = sedan; cars[1] = bus; cars[2] = truck; } public void showCars() { System.out.println(\u0026#34;欢迎使用本汽车管理系统\u0026#34;); System.out.println(\u0026#34;车辆名称\\t\\t车辆颜色\\t\\t座位数\\t\\t载重量\u0026#34;); for(Car car:cars) { if(car instanceof Truck) { Truck truck = (Truck)car; System.out.println(car.getName()+\u0026#34;\\t\\t\u0026#34;+car.getColor()+\u0026#34;\\t\\t\u0026#34;+car.seatNum()+\u0026#34;\\t\\t\u0026#34;+truck.getweight()); }else { System.out.println(car.getName()+\u0026#34;\\t\\t\u0026#34;+car.getColor()+\u0026#34;\\t\\t\u0026#34;+car.seatNum()+\u0026#34;\\t\\t不能拉货\u0026#34;); } } System.out.println(\u0026#34;1.小轿车\\t2.大巴车\\t3.卡车\u0026#34;); System.out.print(\u0026#34;请选择要修改的车辆：\u0026#34;); int num = scanner.nextInt(); switch(num) { case 1: update(\u0026#34;sedan\u0026#34;); break; case 2: update(\u0026#34;bus\u0026#34;); break; case 3: update(\u0026#34;truck\u0026#34;); break; default: System.out.println(\u0026#34;车辆不存在!\u0026#34;); break; } } public void update(String type) { String name = null; String color = null; if(type.equals(\u0026#34;sedan\u0026#34;)) { System.out.print(\u0026#34;输入车辆名称\u0026#34;); name = scanner.next(); System.out.print(\u0026#34;输入车辆颜色\u0026#34;); color = scanner.next(); Sedan sedan = new Sedan(name,color); cars[0] = sedan; } if(type.equals(\u0026#34;bus\u0026#34;)) { System.out.print(\u0026#34;输入车辆名称\u0026#34;); name = scanner.next(); System.out.print(\u0026#34;输入车辆颜色\u0026#34;); color = scanner.next(); Bus bus = new Bus(name,color); cars[1] = bus; } if(type.equals(\u0026#34;truck\u0026#34;)) { System.out.print(\u0026#34;输入车辆名称\u0026#34;); name = scanner.next(); System.out.print(\u0026#34;输入车辆颜色\u0026#34;); color = scanner.next(); System.out.print(\u0026#34;输入载重量\u0026#34;); int weight = scanner.nextInt(); if(weight \u0026gt; 12) { CarException carException = new CarException(\u0026#34;卡车的载重量不能超过12吨\u0026#34;); try { throw carException; } catch (CarException e) { // TODO Auto-generated catch block \te.printStackTrace(); return; } } Truck truck = new Truck(name,color,weight); cars[2] = truck; } showCars(); } public static void main(String[] args) { Test test = new Test(); test.showCars(); } }   讲解了面向对象的高级部分，包括 Object 类、包装类、接口和异常。其中 Object 类是所有 Java 类的父类，定义了 Java 体系的基础资料，通过继承传递给 Java 的每一个类，通过方法重写和多态让整个 Java 体系具有很强的灵活性。\n包装类是 Java 为基本数据类型提供封装的一组类，通过包装类我们可以将基本数据类型转为对象，这一点在面向对象编程中很重要。\n接口是抽象类的扩展，是 Java 中实现多态的重要方式，可以降低程序的耦合性，让程序变得更加灵活多变。接口就相当于零件，我们可以自由地将这些零件进行组装、整合。\n异常是 Java 中处理错误的一种机制，同样是基于面向对象的思想，将错误抽象成对象然后进行处理，这里需要关注的是对异常相关的几个关键字的使用，try、catch、finally、throw、throws。\n多线程 多线程是提升程序性能非常重要的一种方式，必须掌握的技术。 使用多线程可以让程序充分利用 CPU 资源。\n 优点：\n  系统资源得到更合理的利用。 程序设计更加简洁。 程序响应更快，运行效率更高。   缺点:\n  需要更多的内存空间来支持多线程。 多线程并发访问的情况可能会影响数据的准确性。 数据被多线程共享，可能会出现死锁的情况。  进程和线程  什么是进程：进程就是计算机正在运行的一个独立的应用程序。\n 进程是一个动态的概念，当我们启动某个应用的时候，进程就产生了，当我们关闭该应用的时候，进程就结束了，进程的生命周期就是我们在使用该软件的整个过程。\n 什么是线程？ 线程是组成进程的基本单位，可以完成特定的功能，一个进程是由一个或多个线程组成的。 应用程序是静态的，进程和线程是动态的，有创建有销毁，存在是暂时的，不是永久的。\n 进程和线程的区别：\n进程在运行时拥有独立的内存空间，即每个进程所占用的内存空间都是独立的，互不干扰。 线程是共享内存空间的，但是每个线程的执行都是相互独立的，单独的线程是无法执行的，由进程来控制多个线程的执行。\n多线程 多线程是指在一个进程中，多个线程同时执行，这里说的同时执行并不是真正意义的同时执行。\n系统会为每个线程分配 CPU 资源，在某个具体的时间段内 CPU 资源会被一个线程占用，在不同的时间段内由不同的线程来占用 CPU 资源，所以多个线程还是在交替执行，只不过因为 CPU 运行速度太快，我们感觉是在同时执行。\n整个程序如果是一条回路，说明程序只有一个线程。\n程序有两条回路，同时向下执行，这种情况就是多线程，两个线程同时在执行。\nJava 中线程的使用 Java 中使用线程有两种方式：\n 继承 Thread 类 实现 Runnable 接口   Java 写程序三部分组成：\n 1、JDK 系统类库 JRE：Java Runtime Enviroment（Java 运行环境），仅供运行程序的。 JDK：Java Development Kit（Java 开发工具包），如果需要进行程序开发，必须安装 JDK。 String、Scanner、包装类。。。 java.lang.Thread javax.servlet.Servlet 2、第三方类库 非 Java 官方的组织提供的一些成熟好用的工具，C3P0 数据库连接池、Spring 框架、DBUtils、Dom4J… github：全球最大的同性交友网站 3、开发者自定义的代码 根据具体的业务需求编写的业务代码。\nJava 中线程的使用  继承 Thread 类  1、创建自定义类并继承 Thread 类。 2、重写 Thread 类中的 run 方法，并编写该线程的业务逻辑代码。\n1 2 3 4 5 6 7 8 9 10  public class MyThread extends Thread { @Override public void run() { // TODO Auto-generated method stub  //定义业务逻辑  for(int i = 0;i\u0026lt;10;i++) { System.out.println(\u0026#34;-------------MyThread\u0026#34;); } } }   3、使用。\n1 2 3 4 5 6 7 8 9  public class Test { public static void main(String[] args) { //开启两个子线程  MyThread thread1 = new MyThread(); MyThread2 thread2 = new MyThread2(); thread1.start(); thread2.start(); } }   注意：不能通过 run 方法来调用线程的任务，因为 run 方法调用相当于普通对象的执行，并不会去抢占 CPU 资源。 只有通过start方法才能开启线程，进而去抢占 CPU 资源，当某个线程抢占到 CPU 资源后，会自动调用 run 方法。\n 实现 Runnable 接口  1、创建自定义类并实现 Runnable 接口。 2、实现 run 方法，编写该线程的业务逻辑代码。\n1 2 3 4 5 6 7 8 9 10  public class MyRunnable implements Runnable { @Override public void run() { // TODO Auto-generated method stub  for(int i=0;i\u0026lt;1000;i++) { System.out.println(\u0026#34;========MyRunnable=======\u0026#34;); } } }   3、使用。\n1 2 3 4 5 6  MyRunnable runnable = new MyRunnable(); Thread thread = new Thread(runnable); thread.start(); MyRunnable2 runnable2 = new MyRunnable2(); Thread thread2 = new Thread(runnable2); thread2.start();   线程和任务： 线程是去抢占 CPU 资源的，任务是具体执行业务逻辑的，线程内部会包含一个任务，线程启动(start)，当抢占到资源之后，任务就开始执行(run)。 两种方式的区别： 1、MyThread，继承 Thread 类的方式，直接在类中重写 run 方法，使用的时候，直接实例化 MyThread，start 即可，因为 Thread 内部存在 Runnable。 2、MyRunnbale，实现 Runnable 接口的方法，在实现类中重写 run 方法，使用的时候，需要先创建 Thread 对象，并将 MyRunnable 注入到 Thread 中，Thread.start。 实际开发中推荐使用第二种方式。\n线程的状态 线程共有 5 种状态，在特定的情况下，线程可以在不同的状态之间切换，5 种状态如下所示。\n 创建状态：实例化一个新的线程对象，还未启动。 就绪状态：创建好的线程对象调用 start 方法完成启动，进入线程池等待抢占 CPU 资源。 运行状态：线程对象获取了 CPU 资源，在一定的时间内执行任务。 阻塞状态：正在运行的线程暂停执行任务，释放所占用的 CPU 资源，并在解除阻塞状态之后也不能直接回到运行状态，而是重新回到就绪状态，等待获取 CPU 资源。 终止状态：线程运行完毕或因为异常导致该线程终止运行。  线程状态之间的转换图。\nJava 多线程的实现  继承 Thread 实现 Runnable  线程调度 线程休眠 让当前线程暂停执行，从运行状态进入阻塞状态，将 CPU 资源让给其他线程的调度方式，通过 sleep() 来实现。\nsleep(long millis)，调用时需要传入休眠时间，单位为豪秒。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  public class MyThread extends Thread{ @Override public void run() { // TODO Auto-generated method stub  for(int i=0;i\u0026lt;10;i++) { if(i == 5) { try { sleep(5000); } catch (InterruptedException e) { // TODO Auto-generated catch block  e.printStackTrace(); } } System.out.println(i+\u0026#34;---------MyThread\u0026#34;); } } }   也可以在类的外部调用 sleep 方法。\n1 2 3 4 5 6 7 8  MyThread2 thread = new MyThread2(); try { thread.sleep(5000); } catch (InterruptedException e) { // TODO Auto-generated catch block  e.printStackTrace(); } thread.start();   在外部调用需要注意，休眠一定要放在启动之前。？？？\n如何让主线程休眠？直接通过静态方式调用 sleep 方法。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  public class Test2 { public static void main(String[] args) { for(int i=0;i\u0026lt;10;i++) { if(i == 5) { try { Thread.sleep(3000); } catch (InterruptedException e) { // TODO Auto-generated catch block  e.printStackTrace(); } } System.out.println(i+\u0026#34;+++++Test2+++++\u0026#34;); } } } public static native void sleep(long millis) throws InterruptedException;   sleep 是静态本地方法，可以通过类调用，也可以通过对象调用，方法定义抛出 InterruptedException，InterruptedException 继承 Exception，外部调用时必须手动处理异常。\n线程合并 合并是指将指定的某个线程加入到当前线程中，合并为一个线程，由两个线程交替执行变成一个线程中的两个自线程顺序执行。\n通过调用 join 方法来实现合并，具体如何合并？\n线程甲和线程乙，线程甲执行到某个时间点的时候调用线程乙的 join方法，则表示从当前时间点开始 CPU 资源被线程乙独占，线程甲进入阻塞状态，直到线程乙执行完毕，线程甲进入就绪状态，等待获取 CPU 资源进入运行状态。\njoin 方法重载，join() 表示乙线程执行完毕之后才能执行其他线程，join(long millis) 表示乙线程执行 millis 毫秒之后，无论是否执行完毕，其他线程都可以和它争夺 CPU 资源。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67  public class JoinRunnable implements Runnable { @Override public void run() { // TODO Auto-generated method stub  for(int i=0;i\u0026lt;200;i++) { System.out.println(i+\u0026#34;------JoinRunnable\u0026#34;); } } } public class JoinTest { public static void main(String[] args) { /** * 两个线程，主线程、join线程 * 主线程的逻辑：当i==10，join线程合并到主线程中 */ JoinRunnable joinRunnable = new JoinRunnable(); Thread thread = new Thread(joinRunnable); thread.start(); for(int i=0;i\u0026lt;100;i++) { if(i == 10) { try { thread.join(); } catch (InterruptedException e) { // TODO Auto-generated catch block  e.printStackTrace(); } } System.out.println(i+\u0026#34;main+++++++++\u0026#34;); } } } public class JoinRunnable2 implements Runnable { @Override public void run() { // TODO Auto-generated method stub \tfor(int i=0;i\u0026lt;20;i++) { try { Thread.sleep(1000); } catch (InterruptedException e) { // TODO Auto-generated catch block \te.printStackTrace(); } System.out.println(i+\u0026#34;--------JoinRunnable\u0026#34;); } } } public class Test2 { public static void main(String[] args) { for(int i=0;i\u0026lt;10;i++) { if(i == 5) { try { Thread.sleep(3000); } catch (InterruptedException e) { // TODO Auto-generated catch block  e.printStackTrace(); } } System.out.println(i+\u0026#34;+++++Test2+++++\u0026#34;); } } }   线程礼让 线程礼让是指在某个特定的时间点，让线程暂停抢占 CPU 资源的行为，运行状态/就绪状态—》阻塞状态，将 CPU 资源让给其他线程来使用。\n假如线程甲和线程乙在交替执行，某个时间点线程甲做出了礼让，所以在这个时间节点线程乙拥有了 CPU 资源，执行业务逻辑，但不代表线程甲一直暂停执行。\n线程甲只是在特定的时间节点礼让，过了时间节点，线程甲再次进入就绪状态，和线程乙争夺 CPU 资源。\n通过 yield 方法实现。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35  public class YieldThread1 extends Thread { @Override public void run() { // TODO Auto-generated method stub \tfor(int i = 0; i \u0026lt; 10;i++) { if(i == 5) { yield(); } System.out.println(Thread.currentThread().getName()+\u0026#34;-----\u0026#34;+i); } } } public class YieldThread2 extends Thread { @Override public void run() { // TODO Auto-generated method stub \tfor(int i=0;i\u0026lt;10;i++) { System.out.println(Thread.currentThread().getName()+\u0026#34;======\u0026#34;+i); } } } public class Test { public static void main(String[] args) { YieldThread1 thread = new YieldThread1(); thread.setName(\u0026#34;线程1\u0026#34;); YieldThread2 thread2 = new YieldThread2(); thread2.setName(\u0026#34;线程2\u0026#34;); thread.start(); thread2.start(); } }   线程中断 有很多种情况会造成线程停止运行：\n线程执行完毕自动停止\n线程执行过程中遇到错误抛出异常并停止\n线程执行过程中根据需求手动停止\nJava 中实现线程中断有如下几个常用方法：\n public void stop() public void interrupt() public boolean isInterrupted()   stop 方法在新版本的 JDK 已经不推荐使用，重点关注后两个方法。\ninterrupt 是一个实例方法，当一个线程对象调用该方法时，表示中断当前线程对象。\n每个线程对象都是通过一个标志位来判断当前是否为中断状态。\n isInterrupted函数就是用来获取当前线程对象的标志位：\n1、true 表示清除了标志位，当前线程已经中断。\n2、false 表示没有清除标志位，当前对象没有中断。\n当一个线程对象处于不同的状态时，中断机制也是不同的。\n创建状态：实例化线程对象，不启动。\n1 2 3 4 5 6 7 8  public class Test { public static void main(String[] args) { Thread thread = new Thread(); System.out.println(thread.getState()); thread.interrupt(); System.out.println(thread.isInterrupted()); } }   NEW 表示当前线程对象为创建状态，false 表示当前线程并未中断，因为当前线程没有启动，不存在中断，不需要清除标志位。\n 匿名内部类\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33  Thread thread = new Thread(new Runnable() { @Override public void run() { // TODO Auto-generated method stub  for(int i = 0; i \u0026lt; 10;i++) { System.out.println(i+\u0026#34;---main\u0026#34;); } } }); thread.start(); public class Test2 { public static void main(String[] args) { //\tMyRunnable runnable = new MyRunnable(); //\tThread thread = new Thread(runnable); //\tthread.start(); \tThread thread = new Thread(new Runnable() { @Override public void run() { // TODO Auto-generated method stub \tfor(int i = 0; i \u0026lt; 10;i++) { System.out.println(i+\u0026#34;---main\u0026#34;); } } }); thread.start(); System.out.println(thread.getState()); thread.interrupt(); System.out.println(thread.isInterrupted()); System.out.println(thread.getState()); } }   线程同步（synchronized） Java 中允许多线程并行访问，同一时间段内多个线程同时完成各自的操作。 多个线程同时操作同一个共享数据时，可能会导致数据不准确的问题。 使用线程同步可以解决上述问题。 可以通过 synchronized 关键字修饰方法实现线程同步，每个Java 对象都有一个内置锁，内置锁会保护使用 synchronized 关键字修饰的方法，要调用该方法就必须先获得锁，否则就处于阻塞状态。\n 非线程同步\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  public class Account implements Runnable { private static int num; @Override public void run() { // TODO Auto-generated method stub  //1.num++操作  num++; //2.休眠1毫秒  try { Thread.currentThread().sleep(1000); } catch (InterruptedException e) { // TODO Auto-generated catch block  e.printStackTrace(); } //3.打印输出  System.out.println(Thread.currentThread().getName()+\u0026#34;是当前的第\u0026#34;+num+\u0026#34;位访问\u0026#34;); } }    线程同步\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  public class Account implements Runnable { private static int num; @Override public synchronized void run() { // TODO Auto-generated method stub  //1.num++操作  num++; //2.休眠1毫秒  try { Thread.currentThread().sleep(1000); } catch (InterruptedException e) { // TODO Auto-generated catch block  e.printStackTrace(); } //3.打印输出  System.out.println(Thread.currentThread().getName()+\u0026#34;是当前的第\u0026#34;+num+\u0026#34;位访问\u0026#34;); } } public class Test { public static void main(String[] args) { Account account = new Account(); Thread t1 = new Thread(account,\u0026#34;张三\u0026#34;); Thread t2 = new Thread(account,\u0026#34;李四\u0026#34;); t1.start(); t2.start(); } }   synchronized 关键字可以修饰实例方法，也可以修饰静态方法，两者在使用的时候是有区别的。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36  public class SynchronizedTest { public static void main(String[] args) { for(int i = 0; i \u0026lt; 5;i++) { Thread thread = new Thread(new Runnable() { @Override public void run() { // TODO Auto-generated method stub  SynchronizedTest.test(); } }); thread.start(); } } /** * 先输出start... * 间隔1s * 再输出end... * 输出start... * ... */ public synchronized static void test() { //1.输出start  System.out.println(\u0026#34;start......\u0026#34;); //2.休眠  try { Thread.currentThread().sleep(1000); } catch (InterruptedException e) { // TODO Auto-generated catch block  e.printStackTrace(); } //3.输出end  System.out.println(\u0026#34;end......\u0026#34;); } }   synchronized 修饰非静态方法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  public class SynchronizedTest2 { public static void main(String[] args) { for(int i=0;i\u0026lt;5;i++) { Thread thread = new Thread(new Runnable() { @Override public void run() { // TODO Auto-generated method stub  SynchronizedTest2 synchronizedTest2 = new SynchronizedTest2(); synchronizedTest2.test(); } }); thread.start(); } } public synchronized void test() { System.out.println(\u0026#34;start......\u0026#34;); try { Thread.currentThread().sleep(1000); } catch (InterruptedException e) { // TODO Auto-generated catch block  e.printStackTrace(); } System.out.println(\u0026#34;end......\u0026#34;); } }   给实例方法（非静态方法）添加 synchronized 关键字并不能实现线程同步。 线程同步的本质是锁定多个线程所共享的资源，synchronized 还可以修饰代码块，会为代码块加上内置锁，从而实现同步。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  public class SynchronizedTest3 { public static void main(String[] args) { for(int i=0;i\u0026lt;5;i++) { Thread thread = new Thread(new Runnable() { @Override public void run() { // TODO Auto-generated method stub  SynchronizedTest3.test(); } }); thread.start(); } } public static void test() { synchronized (SynchronizedTest3.class) { System.out.println(\u0026#34;start...\u0026#34;); try { Thread.currentThread().sleep(1000); } catch (InterruptedException e) { // TODO Auto-generated catch block  e.printStackTrace(); } System.out.println(\u0026#34;end...\u0026#34;); } } }   如何判断线程同步或是不同步？ 找到关键点：锁定的资源在内存中是一份还是多份？一份大家需要排队，线程同步，多份（一人一份），线程不同步。 无论是锁定方法还是锁定对象，锁定类，只需要分析这个方法、对象、类在内存中有几份即可。\n 对象一般都是多份 类一定是一份 方法就看是静态方法还是非静态方法，静态方法一定是一份，非静态方法一般是多份\n 线程安全的单例模式 单例模式是一种常见的软件设计模式，核心思想是一个类只有一个实例对象。 JVM：栈内存、堆内存 单线程模式下的单例模式\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  public class SingletonDemo { private static SingletonDemo singletonDemo; private SingletonDemo() { System.out.println(\u0026#34;创建了SingletonDemo...\u0026#34;); } public static SingletonDemo getInstance() { if(singletonDemo == null) { singletonDemo = new SingletonDemo(); } return singletonDemo; } }   多线程模式下的单例模式\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  public class SingletonDemo { private static SingletonDemo singletonDemo; private SingletonDemo() { System.out.println(\u0026#34;创建了SingletonDemo...\u0026#34;); } public synchronized static SingletonDemo getInstance() { if(singletonDemo == null) { singletonDemo = new SingletonDemo(); } return singletonDemo; } }   双重检测，synchronized 修饰代码块。 1、线程同步是为了实现线程安全，如果只创建一个对象，那么线程就是安全的。 2、如果 synchronized 锁定的是多个线程共享的数据（同一个对象），那么线程就是安全的。 3、\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  public class SingletonDemo { private volatile static SingletonDemo singletonDemo; private SingletonDemo() { System.out.println(\u0026#34;创建了SingletonDemo...\u0026#34;); } public static SingletonDemo getInstance() { if(singletonDemo == null) { synchronized (SingletonDemo.class) { if(singletonDemo == null) { singletonDemo = new SingletonDemo(); } } } return singletonDemo; } }   volatile 的作用时候可以使内存中的数据对象线程可见。 主内存对线程是不可见的，添加 volatile 关键字之后，主内存对线程可见。\n线程同步 并发、并行\n使用并发编程的目的？为了充分利用计算机的资源，提高性能，企业以盈利为目的。\n并发：多个线程访问同一个共享资源，前提是计算机是单核 CPU，多个线程不是同时在访问，而是交替进行，只是因为 CPU 运行速度太快，看起来是同时在运行。\n并行：多核 CPU，多个线程是真正的同时在运行，各自占用不同的 CPU，相互之间没有影响，也不会争夺资源。\nJava 默认线程有两个，main（主线程），GC（垃圾回收机制）\nsynchronized 关键字实现线程同步，让在访问同一个资源的多个线程排队去完成业务，避免出现数据错乱的情况。\n死锁 DeadLock 前提：一个线程完成业务需要同时访问两个资源。\n死锁：多个线程同时在完成业务，出现争抢资源的情况。\n资源类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56  public class DeadLockRunnable implements Runnable { //编号 \tpublic int num; //资源 \tprivate static Chopsticks chopsticks1 = new Chopsticks(); private static Chopsticks chopsticks2 = new Chopsticks(); /** * num = 1 拿到 chopsticks1，等待 chopsticks2 * num = 2 拿到 chopsticks2，等待 chopsticks1 */ @Override public void run() { // TODO Auto-generated method stub \tif(num == 1) { System.out.println(Thread.currentThread().getName()+\u0026#34;拿到了chopsticks1，等待获取chopsticks2\u0026#34;); synchronized (chopsticks1) { try { Thread.sleep(100); } catch (InterruptedException e) { // TODO Auto-generated catch block \te.printStackTrace(); } synchronized (chopsticks2) { System.out.println(Thread.currentThread().getName()+\u0026#34;用餐完毕！\u0026#34;); } } } if(num == 2) { System.out.println(Thread.currentThread().getName()+\u0026#34;拿到了chopsticks2，等待获取chopsticks1\u0026#34;); synchronized (chopsticks2) { try { Thread.sleep(100); } catch (InterruptedException e) { // TODO Auto-generated catch block \te.printStackTrace(); } synchronized (chopsticks1) { System.out.println(Thread.currentThread().getName()+\u0026#34;用餐完毕！\u0026#34;); } } } } } public class DeadLockTest { public static void main(String[] args) { DeadLockRunnable deadLockRunnable1 = new DeadLockRunnable(); deadLockRunnable1.num = 1; DeadLockRunnable deadLockRunnable2 = new DeadLockRunnable(); deadLockRunnable2.num = 2; new Thread(deadLockRunnable1,\u0026#34;张三\u0026#34;).start(); new Thread(deadLockRunnable2,\u0026#34;李四\u0026#34;).start(); } }   如何破解死锁 不要让多线程并发访问\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  public class DeadLockTest { public static void main(String[] args) { DeadLockRunnable deadLockRunnable1 = new DeadLockRunnable(); deadLockRunnable1.num = 1; DeadLockRunnable deadLockRunnable2 = new DeadLockRunnable(); deadLockRunnable2.num = 2; new Thread(deadLockRunnable1,\u0026#34;张三\u0026#34;).start(); try { //确保deadLockRunnable1已经执行完成  Thread.sleep(2000); } catch (InterruptedException e) { // TODO Auto-generated catch block  e.printStackTrace(); } new Thread(deadLockRunnable2,\u0026#34;李四\u0026#34;).start(); } }   lambda 表达式 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  public class Test3 { public static void main(String[] args) { //lambda表达式  new Thread(()-\u0026gt;{ for(int i=0;i\u0026lt;100;i++) { System.out.println(\u0026#34;+++++++++++Runnable\u0026#34;); } }) .start(); } } public class Test3 { public static void main(String[] args) { new Thread(()-\u0026gt;{for(int i=0;i\u0026lt;100;i++) System.out.println(\u0026#34;+++++++Runnable\u0026#34;);}).start(); new Thread(()-\u0026gt;{for(int i=0;i\u0026lt;100;i++) System.out.println(\u0026#34;----Runnable\u0026#34;);}).start(); new Thread(()-\u0026gt;{for(int i=0;i\u0026lt;100;i++) System.out.println(\u0026#34;++++=====++Runnable\u0026#34;);}).start(); } }   Lock java.util.concurrent（JUC）\nLock 是一个接口，用来实现线程同步的，功能与 synchronized 一样。\nLock 使用频率最高的实现类是 ReentrantLock（重入锁），可以重复上锁。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  public class Test2 { public static void main(String[] args) { Account account = new Account(); new Thread(account,\u0026#34;A\u0026#34;).start(); new Thread(account,\u0026#34;B\u0026#34;).start(); } } class Account implements Runnable{ private static int num; private Lock lock = new ReentrantLock(); @Override public void run() { // TODO Auto-generated method stub  lock.lock(); num++; System.out.println(Thread.currentThread().getName()+\u0026#34;是当前的第\u0026#34;+num+\u0026#34;位访客\u0026#34;); lock.unlock(); } }   实现资源和 Runnable 接口的解耦合。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  public class Test2 { public static void main(String[] args) { Account account = new Account(); new Thread(()-\u0026gt;{ account.count(); },\u0026#34;A\u0026#34;).start(); new Thread(()-\u0026gt;{ account.count(); },\u0026#34;B\u0026#34;).start(); } } class Account { private int num; private Lock lock = new ReentrantLock(); public void count() { lock.lock(); num++; System.out.println(Thread.currentThread().getName()+\u0026#34;是第\u0026#34;+num+\u0026#34;位访客\u0026#34;); lock.unlock(); } }   JUC java.util.concurrent\nJava 并发编程工具包，Java 官方提供的一套专门用来处理并发编程的工具集合（接口+类）\n并发：单核 CPU，多个线程“同时”运行，实际是交替执行，只不过速度太快，看起来是同时执行。\n1  两个厨师一口锅   并行：多核 CPU，真正的多个线程同时运行。\n1  两个厨师两口锅   重入锁是 JUC 使用频率非常高的一个类 ReentrantLock\nReentrantLock 就是对 synchronized 的升级，目的也是为了实现线程同步。\n ReentrantLock 是一个类，synchronized 是一个关键字。 ReentrantLock 是 JDK 实现，synchronized 是 JVM 实现。 synchronized 可以自动释放锁，ReentrantLock 需要手动释放。  ReentrantLock 是 Lock 接口的实现类。\n公平锁和非公平锁的区别\n公平锁：线程同步时，多个线程排队，依次执行\n非公平锁：线程同步时，可以插队\n线程的实现有两种方式\n 继承 Thread 实现 Runnable  实现 Runnable 的耦合度更低\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55  public class Test { public static void main(String[] args) { Account account = new Account(); new Thread(()-\u0026gt;{ account.count(); },\u0026#34;A\u0026#34;) .start(); new Thread(()-\u0026gt;{ account.count(); },\u0026#34;B\u0026#34;) .start(); } } /** * 将资源和 Runnable 进行解耦合 */ class Account { private static int num; public void count() { num++; try { TimeUnit.MILLISECONDS.sleep(1000); } catch (InterruptedException e) { // TODO Auto-generated catch block \te.printStackTrace(); } System.out.println(Thread.currentThread().getName()+\u0026#34;是当前的第\u0026#34;+num+\u0026#34;位访客\u0026#34;); } } public class Test2 { public static void main(String[] args) { Account2 account = new Account2(); new Thread(account,\u0026#34;A\u0026#34;).start(); new Thread(account,\u0026#34;B\u0026#34;).start(); } } class Account2 implements Runnable{ private static int num; @Override public void run() { // TODO Auto-generated method stub  num++; try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { // TODO Auto-generated catch block  e.printStackTrace(); } System.out.println(Thread.currentThread().getName()+\u0026#34;是当前的第\u0026#34;+num+\u0026#34;位访客\u0026#34;); } }   Tips 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  class Account{ private static Integer num = 0; private static Integer id = 0; public void count() { synchronized (num) { num++; try { TimeUnit.MILLISECONDS.sleep(1000); } catch (InterruptedException e) { // TODO Auto-generated catch block  e.printStackTrace(); } System.out.println(Thread.currentThread().getName()+\u0026#34;是当前的第\u0026#34;+num+\u0026#34;位访客\u0026#34;); }\t} }   如果锁定 num 不能同步，锁定 id 可以同步，原因是什么？\nsynchronized 必须锁定唯一的元素才可以实现同步\nnum 的值每次都在变，所以 num 所指向的引用一直在变，所以不是唯一的元素，肯定无法实现同步。\nid 的值永远不变，所以是唯一的元素，可以实现同步。\n中断 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33  public class Test3 { public static void main(String[] args) { Account3 account = new Account3(); new Thread(()-\u0026gt;{ account.count(); },\u0026#34;A\u0026#34;).start(); new Thread(()-\u0026gt;{ account.count(); },\u0026#34;B\u0026#34;).start(); } } class Account3{ private static int num; private ReentrantLock reentrantLock = new ReentrantLock(); public void count() { //上锁  reentrantLock.lock(); reentrantLock.lock(); num++; try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { // TODO Auto-generated catch block  e.printStackTrace(); } System.out.println(Thread.currentThread().getName()+\u0026#34;是当前的第\u0026#34;+num+\u0026#34;位访客\u0026#34;); //解锁  reentrantLock.unlock(); reentrantLock.unlock(); } }    Lock 上锁和解锁都需要开发者手动完成。 可以重复上锁，上几把锁就需要解几把锁。  ReentrantLock 除了可以重入之外，还有一个可以中断的特点，可中断是指某个线程在等待获取锁的过程中可以主动过终止线程。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47  public class Test5 { public static void main(String[] args) { StopLock stopLock = new StopLock(); Thread t1 = new Thread(()-\u0026gt;{ stopLock.service(); },\u0026#34;A\u0026#34;); Thread t2 =new Thread(()-\u0026gt;{ stopLock.service(); },\u0026#34;B\u0026#34;); t1.start(); t2.start(); try { TimeUnit.SECONDS.sleep(1); t2.interrupt(); } catch (InterruptedException e) { // TODO Auto-generated catch block  e.printStackTrace(); } } } class StopLock{ private ReentrantLock reentrantLock = new ReentrantLock(); public void service() { try { reentrantLock.lockInterruptibly(); System.out.println(Thread.currentThread().getName()+\u0026#34;get lock\u0026#34;); try { TimeUnit.SECONDS.sleep(5); } catch (InterruptedException e) { // TODO Auto-generated catch block  e.printStackTrace(); } } catch (InterruptedException e1) { // TODO Auto-generated catch block  e1.printStackTrace(); } finally { reentrantLock.unlock(); } } }   重入锁 ReentrantLock 限时性：判断某个线程在一定的时间内能否获取锁，通过 tryLock 方法来实现\ntryLock(long time,TimeUnit unit)\ntime 指时间数值\nunit 时间单位\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38  public class Test { public static void main(String[] args) { TimeLock timeLock = new TimeLock(); /** * A 拿到锁，执行业务代码，休眠 5 秒钟 * B 尝试拿锁，需要在 3 秒钟之内拿到锁 */ new Thread(()-\u0026gt;{ timeLock.lock(); },\u0026#34;A\u0026#34;).start(); new Thread(()-\u0026gt;{ timeLock.lock(); },\u0026#34;B\u0026#34;).start(); } } class TimeLock{ private ReentrantLock reentrantLock = new ReentrantLock(); public void lock(){ /** * 尝试在3S内获取锁 */ try { if(reentrantLock.tryLock(3, TimeUnit.SECONDS)){ System.out.println(Thread.currentThread().getName()+\u0026#34; get lock\u0026#34;); TimeUnit.SECONDS.sleep(5); }else{ System.out.println(Thread.currentThread().getName()+\u0026#34; not lock\u0026#34;); } } catch (InterruptedException e) { e.printStackTrace(); } finally { if(reentrantLock.isHeldByCurrentThread()){ reentrantLock.unlock(); } } } }   生产者消费者模式 在一个生产环境中，生产者和消费者在同一时间段内共享同一块缓冲区，生产者负责向缓冲区添加数据，消费者负责从缓冲区取出数据。\n汉堡类 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  public class Hamburger { private int id; public int getId() { return id; } public void setId(int id) { this.id = id; } @Override public String toString() { return \u0026#34;Hamburger{\u0026#34; + \u0026#34;id=\u0026#34; + id + \u0026#39;}\u0026#39;; } }   容器类 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39  public class Container { public Hamburger[] array = new Hamburger[6]; public int index = 0; /** * 向容器中添加汉堡 */ public synchronized void push(Hamburger hamburger){ while(index == array.length){ try { this.wait(); } catch (InterruptedException e) { e.printStackTrace(); } } this.notify(); array[index] = hamburger; index++; System.out.println(\u0026#34;生产类一个汉堡\u0026#34;+hamburger); } /** * 从容器中取出汉堡 */ public synchronized Hamburger pop(){ while(index == 0){ //当前线程暂停  //让正在访问当前资源的线程暂停  try { this.wait(); } catch (InterruptedException e) { e.printStackTrace(); } } //唤醒之前暂停的线程  this.notify(); index--; System.out.println(\u0026#34;消费了一个汉堡\u0026#34;+array[index]); return array[index]; } }   生产者 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  /** * 生产者 */ public class Producer { private Container container; public Producer(Container container){ this.container = container; } public void product(){ for (int i = 0; i \u0026lt; 30; i++) { Hamburger hamburger = new Hamburger(i); this.container.push(hamburger); try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); } } } }   消费者 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  public class Consumer { private Container container; public Consumer(Container container) { this.container = container; } public void consum(){ for (int i = 0; i \u0026lt; 30; i++) { this.container.pop(); try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); } } } }   测试类 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  public class Test { public static void main(String[] args) { Container container = new Container(); Producer producer = new Producer(container); Consumer consumer = new Consumer(container); new Thread(()-\u0026gt;{ producer.product(); }).start(); new Thread(()-\u0026gt;{ producer.product(); }).start(); new Thread(()-\u0026gt;{ consumer.consum(); }).start(); new Thread(()-\u0026gt;{ consumer.consum(); }).start(); new Thread(()-\u0026gt;{ consumer.consum(); }).start(); } }   多线程并发卖票 一场球赛的球票分 3 个窗口出售，共 15 张票，用多线程并发来模拟 3 个窗口的售票情况\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43  public class Ticket { //剩余球票  private int surpluCount = 15; //已售出球票  private int outCount = 0; public synchronized void sale(){ while(surpluCount \u0026gt; 0){ try { TimeUnit.MILLISECONDS.sleep(500); } catch (InterruptedException e) { e.printStackTrace(); } if(surpluCount == 0){ return; } surpluCount--; outCount++; if(surpluCount == 0){ System.out.println(Thread.currentThread().getName()+\u0026#34;售出第\u0026#34;+outCount+\u0026#34;张票，球票已售罄\u0026#34;); }else{ System.out.println(Thread.currentThread().getName()+\u0026#34;售出第\u0026#34;+outCount+\u0026#34;张票，剩余\u0026#34;+surpluCount+\u0026#34;张票\u0026#34;); } } } } public class Test { public static void main(String[] args) { Ticket ticket = new Ticket(); new Thread(()-\u0026gt;{ ticket.sale(); },\u0026#34;A\u0026#34;).start(); new Thread(()-\u0026gt;{ ticket.sale(); },\u0026#34;B\u0026#34;).start(); new Thread(()-\u0026gt;{ ticket.sale(); },\u0026#34;C\u0026#34;).start(); } }   Java 并发编程 为什么很重要？\n并发编程可以充分利用计算机的资源，把计算机的性能发挥到最大，可以最大程度节约公司的成本，提高效率。\n什么是高并发 并发 VS 并行的区别\n 并发 concurrency：多线程“同时”操作同一个资源，并不是真正的同时操作，而是交替操作，单核 CPU 的情况下，资源按时间段分配给多个线程。张三李四王五使用一口锅炒菜，交替\n  并行 parallelism：是真正的多个线程同时执行，多核 CPU，每个线程使用一个 CPU 资源来运行。张三李四王五使用三口锅炒菜，同时进行\n 并发编程描述的是一种使系统允许多个任务可以在重叠的时间段内执行的设计结构，不是指多个任务在同一时间段内执行，而是指系统具备处理多个任务在同一时间段内同时执行的能力。\n高并发是指我们设计的程序，可以支持海量任务的执行在时间段上重叠的情况。\n高并发的标准：\n QPS：每秒响应的 HTTP 请求数量，QPS 不是并发数。 吞吐量：单位时间内处理的请求数，由 QPS 和并发数来决定。 平均响应时间：系统对一个请求作出响应的评价时间。  QPS = 并发数 / 平均响应时间\n 并发用户数：同时承载正常使用系统的用户人数  互联网分布式架构设计，提高系统并发能力的方式：\n 垂直扩展 水平扩展  垂直扩展 提升单机处理能力 1、提升单机的硬件设备，增加 CPU 核数，升级网卡，硬盘扩容，升级内存。 2、提升单机的架构性能，使用 Cache 提高效率，使用异步请求来增加单服务吞吐量，NoSQL 提升数据库访问能力。\n水平扩展 集群：一个厨师搞不定，多雇几个厨师一起炒菜，多个人干同一件事情。\n分布式：给厨师雇两个助手，一个负责洗菜，一个负责切菜，厨师只负责炒菜，一件事情拆分成多个步骤，由不同的人去完成。\n站点层扩展：Nginx 反向代理，一个 Tomcat 跑不动，那就 10 个 Tomcat 去跑。\n服务层扩展：RPC 框架实现远程调用，Spring Boot/Spring Cloud，Dubbo，分布式架构，将业务逻辑拆分到不同的 RPC Client，各自完成对应的业务，如果某项业务并发量很大，增加新的 RPC Client，就能扩展服务层的性能，做到理论上的无限高并发。\n数据层扩展：在数据量很大的情况下，将原来的一台数据库服务器，拆分成多台，以达到扩充系统性能的目的，主从复制，读写分离，分表分库。\nJUC JDK 提供的一个工具包，专门用来帮助开发者完成 Java 并发编程。\n进程和线程 Java 默认的线程数 2 个\n mian 主线程 GC 垃圾回收机制  Java 本身是无法开启线程的，Java 无法操作硬件，只能通过调用本地方法，C++ 编写的动态函数库。\n Java 中实现多线程有几种方式？\n 1、继承 Thread 类\n2、实现 Runnable 接口\n3、实现 Callable 接口\nCallable 和 Runnable 的区别在于 Runnable 的 run 方法没有返回值，Callable 的 call 方法有返回值。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  public class Test { public static void main(String[] args) { MyCallable myCallable = new MyCallable(); FutureTask\u0026lt;String\u0026gt; futureTask = new FutureTask(myCallable); Thread thread = new Thread(futureTask); thread.start(); try { String value = futureTask.get(); System.out.println(value); } catch (InterruptedException e) { e.printStackTrace(); } catch (ExecutionException e) { e.printStackTrace(); } } } class MyCallable implements Callable\u0026lt;String\u0026gt;{ @Override public String call() throws Exception { System.out.println(\u0026#34;callable\u0026#34;); return \u0026#34;hello\u0026#34;; } }   sleep 和 wait sleep 是让当前线程休眠，wait 是让访问当前对象的线程休眠。\nsleep 不会释放锁，wait 会释放锁。\nsynchronized 锁定的是什么 1、synchronized 修饰非静态方法，锁定方法的调用者\n2、synchronized 修饰静态方法，锁定的是类\n3、synchronized 静态方法和实例方法同时存在，静态方法锁定的是类，实例方法锁定的是对象\nLock JUC 提供的一种锁机制，功能和 synchronized 类似，是对 synchronized 的升级，它是一个接口。\n它的常用实现类是 ReentrantLock。\nsynchronized 是通过 JVM 实现锁机制，ReentrantLock 是通过 JDK 实现锁机制。\nsynchronized 是一个关键字，ReentrantLock 是一个类。\n重入锁：可以给同一个资源添加多把锁。\nsynchronized 是线程执行完毕之后自动释放锁，ReentrantLock 需要手动解锁。\n用 synchronized 实现卖票\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34  public class Test { public static void main(String[] args) { Ticket ticket = new Ticket(); new Thread(()-\u0026gt;{ for (int i = 0; i \u0026lt; 40; i++) { ticket.sale(); } },\u0026#34;A\u0026#34;).start(); new Thread(()-\u0026gt;{ for (int i = 0; i \u0026lt; 40; i++) { ticket.sale(); } },\u0026#34;B\u0026#34;).start(); } } class Ticket{ private Integer saleNum = 0; private Integer lastNum = 30; public synchronized void sale(){ if(lastNum \u0026gt; 0){ saleNum++; lastNum--; try { TimeUnit.MILLISECONDS.sleep(500); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(Thread.currentThread().getName()+\u0026#34;卖出了第\u0026#34;+saleNum+\u0026#34;张票，剩余\u0026#34;+lastNum+\u0026#34;张票\u0026#34;); } } }   用 Lock 完成卖票\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43  import java.util.concurrent.TimeUnit; import java.util.concurrent.locks.Lock; import java.util.concurrent.locks.ReentrantLock; public class Test2 { public static void main(String[] args) { Ticket2 ticket = new Ticket2(); new Thread(()-\u0026gt;{ for (int i = 0; i \u0026lt; 40; i++) { ticket.sale(); } },\u0026#34;A\u0026#34;).start(); new Thread(()-\u0026gt;{ for (int i = 0; i \u0026lt; 40; i++) { ticket.sale(); } },\u0026#34;B\u0026#34;).start(); } } class Ticket2{ private Integer saleNum = 0; private Integer lastNum = 30; private Lock lock = new ReentrantLock(); public void sale(){ lock.lock(); lock.lock(); if(lastNum \u0026gt; 0){ saleNum++; lastNum--; try { TimeUnit.MILLISECONDS.sleep(500); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(Thread.currentThread().getName()+\u0026#34;卖出了第\u0026#34;+saleNum+\u0026#34;张票，剩余\u0026#34;+lastNum+\u0026#34;张票\u0026#34;); } lock.unlock(); lock.unlock(); } }    synchronized 和 lock 的区别\n 1、synchronized 自动上锁，自动释放锁，Lock 手动上锁，手动释放锁。\n2、synchronized 无法判断是否获取到了锁，Lock 可以判断是否拿到了锁。\n3、synchronized 拿不到锁就会一直等待，Lock 不一定会一直等待。\n4、synchronized 是 Java 关键字，Lock 是接口。\n5、synchronized 是非公平锁，Lock 可以设置是否为公平锁。\n公平锁：很公平，排队，当锁没有被占用时，当前线程需要判断队列中是否有其他等待线程。\n非公平锁：不公平，插队，当锁没有被占用时，当前线程可以直接占用，而不需要判断当前队列中是否有等待线程。\n实际开发中推荐使用 Lock 的方式。\nReentrantLock 具备限时性的特点，可以判断某个线程在一定的时间段内能否获取到锁，使用 tryLock 方法，返回值是 boolean 类型，true 表示可以获取到锁，false 表示无法获取到锁。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33  public class Test { public static void main(String[] args) { TimeLock timeLock = new TimeLock(); new Thread(()-\u0026gt;{ timeLock.getLock(); },\u0026#34;A\u0026#34;).start(); new Thread(()-\u0026gt;{ timeLock.getLock(); },\u0026#34;B\u0026#34;).start(); } } class TimeLock{ private ReentrantLock lock = new ReentrantLock(); public void getLock(){ try { if(lock.tryLock(3, TimeUnit.SECONDS)){ System.out.println(Thread.currentThread().getName()+\u0026#34;拿到了锁\u0026#34;); TimeUnit.SECONDS.sleep(5); }else{ System.out.println(Thread.currentThread().getName()+\u0026#34;拿不到锁\u0026#34;); } } catch (InterruptedException e) { e.printStackTrace(); } finally { if(lock.isHeldByCurrentThread()){ lock.unlock(); } } } }   生产者消费者模式 synchronized 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45  public class Test { public static void main(String[] args) { Data data = new Data(); new Thread(()-\u0026gt;{ for (int i = 0; i \u0026lt; 30; i++) { data.increment(); } },\u0026#34;A\u0026#34;).start(); new Thread(()-\u0026gt;{ for (int i = 0; i \u0026lt; 30; i++) { data.decrement(); } },\u0026#34;B\u0026#34;).start(); } } class Data{ private Integer num = 0; public synchronized void increment(){ while(num!=0){ try { this.wait(); } catch (InterruptedException e) { e.printStackTrace(); } } num++; this.notify(); System.out.println(Thread.currentThread().getName()+\u0026#34;生产了汉堡\u0026#34;+num); } public synchronized void decrement(){ while(num == 0){ try { this.wait(); } catch (InterruptedException e) { e.printStackTrace(); } } num--; this.notify(); System.out.println(Thread.currentThread().getName()+\u0026#34;消费了汉堡\u0026#34;+num); } }   必须使用 while 判断，不能用 if，因为 if 会存在线程虚假唤醒的问题，虚假唤醒就是一些 wait 方法会在除了 notify 的其他情况被唤醒，不是真正的唤醒，使用 while 完成多重检测，避免这一问题。\nLock 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53  public class Test { public static void main(String[] args) { Data data = new Data(); new Thread(()-\u0026gt;{ for (int i = 0; i \u0026lt; 30; i++) { data.increment(); } },\u0026#34;A\u0026#34;).start(); new Thread(()-\u0026gt;{ for (int i = 0; i \u0026lt; 30; i++) { data.decrement(); } },\u0026#34;B\u0026#34;).start(); } } class Data{ private Integer num = 0; private Lock lock = new ReentrantLock(); private Condition condition = lock.newCondition(); public void increment(){ lock.lock(); while(num!=0){ try { condition.await(); } catch (InterruptedException e) { e.printStackTrace(); } } num++; condition.signal(); System.out.println(Thread.currentThread().getName()+\u0026#34;生产了汉堡\u0026#34;+num); lock.unlock(); } public synchronized void decrement(){ lock.lock(); while(num == 0){ try { condition.await(); } catch (InterruptedException e) { e.printStackTrace(); } } num--; condition.signal(); System.out.println(Thread.currentThread().getName()+\u0026#34;消费了汉堡\u0026#34;+num); lock.unlock(); } }   使用 Lock 锁，就不能通过 wait 和 notify 来暂停线程和唤醒线程，而应该使用 Condition 的 await和 signal来暂停和唤醒线程。\nConcurrentModificationException 并发访问异常 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  public class Test { public static void main(String[] args) { List\u0026lt;String\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); for (int i = 0; i \u0026lt; 10; i++) { new Thread(()-\u0026gt;{ try { TimeUnit.MILLISECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); } //写  list.add(\u0026#34;a\u0026#34;); //读  System.out.println(list); },String.valueOf(i)).start(); } } }   如何解决？ Vector Collections.synchronizedList JUC：CopyOnWriteArrayList 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  public class Test2 { public static void main(String[] args) { List\u0026lt;String\u0026gt; list = new CopyOnWriteArrayList\u0026lt;\u0026gt;(); for (int i = 0; i \u0026lt; 10; i++) { new Thread((()-\u0026gt;{ try { TimeUnit.MILLISECONDS.sleep(10); } catch (InterruptedException e) { e.printStackTrace(); } list.add(\u0026#34;a\u0026#34;); System.out.println(list); })).start(); } } }   CopyOnWrite 写时复制，当我们往一个容器添加元素的时候，不是直接给容器添加，而是先将当前容器复制一份，向新的容器中添加数据，添加完成之后，再将原容器的引用指向新的容器。\nSet 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  public class Test2 { public static void main(String[] args) { Set\u0026lt;String\u0026gt; set = new CopyOnWriteArraySet\u0026lt;\u0026gt;(); for (int i = 0; i \u0026lt; 10; i++) { final int temp = i; new Thread((()-\u0026gt;{ try { TimeUnit.MILLISECONDS.sleep(10); } catch (InterruptedException e) { e.printStackTrace(); } set.add(String.valueOf(temp)+\u0026#34;a\u0026#34;); System.out.println(set); })).start(); } } }   Map 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  public class Test2 { public static void main(String[] args) { Map\u0026lt;String,String\u0026gt; map = new ConcurrentHashMap\u0026lt;\u0026gt;(); for (int i = 0; i \u0026lt; 10; i++) { final int temp = i; new Thread((()-\u0026gt;{ try { TimeUnit.MILLISECONDS.sleep(10); } catch (InterruptedException e) { e.printStackTrace(); } map.put(UUID.randomUUID().toString().substring(0,3),UUID.randomUUID().toString().substring(0,2)); System.out.println(map); })).start(); } } }   JUC 工具类 CountDownLatch：减法计数器 可以用来倒计时，当两个线程同时执行时，如果要确保一个线程优先执行，可以使用计数器，当计数器清零的时候，再让另一个线程执行。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  public class Test { public static void main(String[] args) { //创建一个 CountDownLatch  CountDownLatch countDownLatch = new CountDownLatch(100); new Thread(()-\u0026gt;{ for (int i = 0; i \u0026lt; 100; i++) { System.out.println(\u0026#34;+++++++++++++++Thread\u0026#34;); countDownLatch.countDown(); } }).start(); try { countDownLatch.await(); } catch (InterruptedException e) { e.printStackTrace(); } for (int i = 0; i \u0026lt; 100; i++) { System.out.println(\u0026#34;main-----------------\u0026#34;); } } }   coutDown()：计数器减一\nawait()：计数器停止，唤醒其他线程\nnew CountDownLatch(100)、coutDown()、await() 必须配合起来使用，创建对象的时候赋的值是多少，coutDown() 就必须执行多少次，否则计数器是没有清零的，计数器就不会停止，其他线程也无法唤醒，所以必须保证计数器清零，coutDown() 的调用次数必须大于构造函数的参数值。\nCyclicBarrier：加法计数器 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  public class CyclicBarrierTest { public static void main(String[] args) { CyclicBarrier cyclicBarrier = new CyclicBarrier(100,()-\u0026gt;{ System.out.println(\u0026#34;放行\u0026#34;); }); for (int i = 0; i \u0026lt; 100; i++) { final int temp = i; new Thread(()-\u0026gt;{ System.out.println(\u0026#34;--\u0026gt;\u0026#34;+temp); try { cyclicBarrier.await(); } catch (InterruptedException e) { e.printStackTrace(); } catch (BrokenBarrierException e) { e.printStackTrace(); } }).start(); } } }   await()：在其他线程中试图唤醒计数器线程，当其他线程的执行次数达到计数器的临界值时，则唤醒计数器线程，并且计数器是可以重复使用的，当计数器的线程执行完成一次之后，计数器自动清零，等待下一次执行。\nnew CyclicBarrier(30），for 执行 90 次，则计数器的任务会执行 3 次。\nSemaphore：计数信号量 实际开发中主要使用它来完成限流操作，限制可以访问某些资源的线程数量。\nSemaphore 只有 3 个操作：\n 初始化 获取许可 释放  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  public class SemaphoreTest { public static void main(String[] args) { //初始化  Semaphore semaphore = new Semaphore(5); for (int i = 0; i \u0026lt; 15; i++) { new Thread(()-\u0026gt;{ //获得许可  try { semaphore.acquire(); System.out.println(Thread.currentThread().getName()+\u0026#34;进店购物\u0026#34;); TimeUnit.SECONDS.sleep(5); System.out.println(Thread.currentThread().getName()+\u0026#34;出店\u0026#34;); } catch (InterruptedException e) { e.printStackTrace(); }finally { //释放  semaphore.release(); } },String.valueOf(i)).start(); } } }   每个线程在执行的时候，首先需要去获取信号量，只有获取到资源才可以执行，执行完毕之后需要释放资源，留给下一个线程。\n读写锁 接口 ReadWriteLock，实现类是 ReentrantReadWriteLock，可以多线程同时读，但是同一时间内只能有一个线程进行写入操作。\n读写锁也是为了实现线程同步，只不过粒度更细，可以分别给读和写的操作设置不同的锁。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49  public class ReadWriteLockTest { public static void main(String[] args) { Cache cache = new Cache(); for (int i = 0; i \u0026lt; 5; i++) { final int temp = i; new Thread(()-\u0026gt;{ cache.write(temp,String.valueOf(temp)); }).start(); } for (int i = 0; i \u0026lt; 5; i++) { final int temp = i; new Thread(()-\u0026gt;{ cache.read(temp); }).start(); } } } class Cache{ //使用hashmap，是因为每个只有一个线程进行写操作  //如果有多个线程操作，需使用ConcurrentHashMap  private Map\u0026lt;Integer,String\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); private ReadWriteLock readWriteLock = new ReentrantReadWriteLock(); /** * 写操作 */ public void write(Integer key,String value){ readWriteLock.writeLock().lock(); System.out.println(key+\u0026#34;开始写入\u0026#34;); map.put(key,value); System.out.println(key+\u0026#34;写入完毕\u0026#34;); readWriteLock.writeLock().unlock(); } /** * 读操作 */ public void read(Integer key){ readWriteLock.readLock().lock(); System.out.println(key+\u0026#34;开始读取\u0026#34;); map.get(key); System.out.println(key+\u0026#34;读取完毕\u0026#34;); readWriteLock.readLock().unlock(); } }   写入锁也叫独占锁，只能被一个线程占用，读取锁也叫共享锁，多个线程可以同时占用。\n线程池 预先创建好一定数量的线程对象，存入缓冲池中，需要用的时候直接从缓冲池中取出，用完之后不要销毁，还回到缓冲池中，为了提高资源的利用率。\n优势：\n 提高线程的利用率 提高响应速度 便于统一管理线程对象 可以控制最大的并发数  1、线程池初始化的时候创建一定数量的线程对象。\n2、如果缓冲池中没有空闲的线程对象，则新来的任务进入等待队列。\n3、如果缓冲池中没有空闲的线程对象，等待队列也已经填满，可以申请再创建一定数量的新线程对象，直到到达线程池的最大值，这时候如果还有新的任务进来，只能选择拒绝。\n无论哪种线程池，都是工具类 Executors 封装的，底层代码都一样，都是通过创建 ThreadPoolExecutor 对象来完成线程池的构建。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue\u0026lt;Runnable\u0026gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) { if (corePoolSize \u0026lt; 0 || maximumPoolSize \u0026lt;= 0 || maximumPoolSize \u0026lt; corePoolSize || keepAliveTime \u0026lt; 0) throw new IllegalArgumentException(); if (workQueue == null || threadFactory == null || handler == null) throw new NullPointerException(); this.acc = (System.getSecurityManager() == null) ? null : AccessController.getContext(); this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); this.threadFactory = threadFactory; this.handler = handler; }    corePoolSize：核心池大小，初始化的线程数量 maximumPoolSize：线程池最大线程数，它决定了线程池容量的上限  corePoolSize 就是线程池的大小，maximumPoolSize 是一种补救措施，任务量突然增大的时候的一种补救措施。\n keepAliveTime：线程对象的存活时间 unit：线程对象存活时间单位 workQueue：等待队列 threadFactory：线程工厂，用来创建线程对象 handler：拒绝策略  ThreadPoolExecutor 池化技术 池化思想\n优势：\n 提高线程的利用率 提高响应速度 便于统一管理线程对象 可控制最大并发数  线程池的具体设计思想\n 核心池的大小 线程池的最大容量 等待队列 拒绝策略  线程池启动的时候会按照核心池的数来创建初始化的线程对象 2 个。\n开始分配任务，如果同时来了多个任务， 2 个线程对象都被占用了，第 3 个以及之后的任务进入等待队列，当前有线程完成任务恢复空闲状态的时候，等待队列中的任务获取线程对象。\n如果等待队列也占满了，又有新的任务进来，需要去协调，让线程池再创建新的线程对象，但是线程池不可能无限去创建线程对象，一定会有一个最大上限，就是线程池的最大容量。\n如果线程池已经达到了最大上限，并且等待队列也占满了，此时如果有新的任务进来，只能选择拒绝，并且需要根据拒绝策略来选择对应的方案。\nThreadPoolExecutor\n直接实例化 ThreadPoolExecutor ，实现定制化的线程池，而不推荐使用 Executors 提供的封装好的方法，因为这种方式代码不够灵活，无法实现定制化。\nThreadPoolExecutor 核心参数一共有 7 个\n1 2 3 4 5 6 7 8 9 10 11  corePoolSize：核心池的大小 maximumPoolSize：线程池的最大容量 keepAliveTime：线程存活时间（在没有任务可执行的情况下），必须是线程池中的数量大于 corePoolSize，才会生效 TimeUnit：存活时间单位 BlockingQueue：等待队列，存储等待执行的任务 ThreadFactory：线程工厂，用来创建线程对象 RejectedExecutionHandler：拒绝策略 1、AbortPolicy：直接抛出异常 2、DiscardPolicy：放弃任务，不抛出异常 3、DiscardOldestPolicy：尝试与等待队列中最前面的任务去争夺，不抛出异常 4、CallerRunsPolicy：谁调用谁处理   单例 1\n固定 5\n缓存\n\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35  public class Test { public static void main(String[] args) { ExecutorService executorService = null; try { /** * 自己写7大参数，完全定制化 */ executorService = new ThreadPoolExecutor( 2, 3, 1L, TimeUnit.SECONDS, new ArrayBlockingQueue\u0026lt;\u0026gt;(2), Executors.defaultThreadFactory(), new ThreadPoolExecutor.AbortPolicy() ); for (int i = 0; i \u0026lt; 6; i++) { executorService.execute(()-\u0026gt;{ try { TimeUnit.MILLISECONDS.sleep(100); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(Thread.currentThread().getName()+\u0026#34;===\u0026gt;办理业务\u0026#34;); }); } } catch (Exception e) { e.printStackTrace(); } finally { executorService.shutdown(); } } }   new ThreadPoolExecutor.AbortPolicy()\nnew ThreadPoolExecutor.CallersunsPolicy()\nnew ThreadPoolExecutor.DiscardOldestPolicy()\nnew ThreadPoolExecutor.DiscardPolicy()\n不会抛出异常\n线程池 3 大考点：\n1、Executors 工具类的 3 种实现\n1 2 3  ExecutorService executorService = Executors.newSingleThreadExecutor(); ExecutorService executorService = Executors.newFixedThreadPool(5); ExecutorService executorService = Executors.newCachedThreadPool();   2、7 个参数\n1 2 3 4 5 6 7  corePoolSize：核心池的大小 maximumPoolSize：线程池的最大容量 keepAliveTime：线程存活时间（在没有任务可执行的情况下），必须是线程池中的数量大于 corePoolSize，才会生效 TimeUnit：存活时间单位 BlockingQueue：等待队列，存储等待执行的任务 ThreadFactory：线程工厂，用来创建线程对象 RejectedExecutionHandler：拒绝策略   3、4 种拒绝策略\n1 2 3 4  1、AbortPolicy：直接抛出异常 2、DiscardPolicy：放弃任务，不抛出异常 3、DiscardOldestPolicy：尝试与等待队列中最前面的任务去争夺，不抛出异常 4、CallerRunsPolicy：谁调用谁处   ForkJoin 框架 ForkJoin 是 JDK 1.7 后发布的多线程并发处理框架，功能上和 JUC 类似，JUC 更多时候是使用单个类完成操作，ForkJoin 使用多个类同时完成某项工作，处理上比 JUC 更加丰富，实际开发中使用的场景并不是很多，互联网公司真正有高并发需求的情况才会使用，面试时候会加分\n本质上是对线程池的一种的补充，对线程池功能的一种扩展，基于线程池的，它的核心思想就是将一个大型的任务拆分成很多个小任务，分别执行，最终将小任务的结果进行汇总，生成最终的结果。\n本质就是把一个线程的任务拆分成多个小任务，然后由多个线程并发执行，最终将结果进行汇总。\n比如 A B 两个线程同时还执行，A 的任务比较多，B 的任务相对较少，B 先执行完毕，这时候 B 去帮助 A 完成任务（将 A 的一部分任务拿过来替 A 执行，执行完毕之后再把结果进行汇总），从而提高效率。\n工作窃取 ForkJoin 框架，核心是两个类\n ForkJoinTask （描述任务） ForkJoinPool（线程池）提供多线程并发工作窃取  使用 ForkJoinTask 最重要的就是要搞清楚如何拆分任务，这里用的是递归思想。\n1、需要创建一个 ForkJoinTask 任务，ForkJoinTask 是一个抽象类，不能直接创建 ForkJoinTask 的实例化对象，开发者需要自定义一个类，继承 ForkJoinTask 的子类 RecursiveTask ，Recursive 就是递归的意思，该类就提供了实现递归的功能。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51  /** * 10亿求和 */ public class ForkJoinDemo extends RecursiveTask\u0026lt;Long\u0026gt; { private Long start; private Long end; private Long temp = 100_0000L; public ForkJoinDemo(Long start, Long end) { this.start = start; this.end = end; } @Override protected Long compute() { if((end-start)\u0026lt;temp){ Long sum = 0L; for (Long i = start; i \u0026lt;= end; i++) { sum += i; } return sum; }else{ Long avg = (start+end)/2; ForkJoinDemo task1 = new ForkJoinDemo(start,avg); task1.fork(); ForkJoinDemo task2 = new ForkJoinDemo(avg,end); task2.fork(); return task1.join()+task2.join(); } } } public class Test { public static void main(String[] args) { Long startTime = System.currentTimeMillis(); ForkJoinPool forkJoinPool = new ForkJoinPool(); ForkJoinTask\u0026lt;Long\u0026gt; task = new ForkJoinDemo(0L,10_0000_0000L); forkJoinPool.execute(task); Long sum = 0L; try { sum = task.get(); } catch (InterruptedException e) { e.printStackTrace(); } catch (ExecutionException e) { e.printStackTrace(); } Long endTime = System.currentTimeMillis(); System.out.println(sum+\u0026#34;，供耗时\u0026#34;+(endTime-startTime)); } }   Volatile 关键字 \nVolatile 是 JVM 提供的轻量级同步机制，可见性，主内存对象线程可见。\n一个线程执行完任务之后还，会把变量存回到主内存中，并且从主内存中读取当前最新的值，如果是一个空的任务，则不会重新读取主内存中的值\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50  public class Test { private static int num = 0; public static void main(String[] args) { /** * 循环 */ new Thread(()-\u0026gt;{ while(num == 0){ System.out.println(\u0026#34;---Thread---\u0026#34;); } }).start(); try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); } num = 1; System.out.println(num); } } import java.util.concurrent.TimeUnit; public class Test { private static volatile int num = 0; public static void main(String[] args) { /** * 循环 */ new Thread(()-\u0026gt;{ while(num == 0){ } }).start(); try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); } num = 1; System.out.println(num); } }   线程池 workQueue 一个阻塞队列，用来存储等待执行的任务，常用的阻塞队列有以下几种：\n ArrayBlockingQueue：基于数组的先进先出队列，创建时必须指定大小。 LinkedBlockingQueue：基于链表的先进先出队列，创建时可以不指定大小，默认值时 Integer.MAX_VALUE。 SynchronousQueue：它不会保持提交的任务，而是直接新建一个线程来执行新来的任务。 PriorityBlockingQueue：具有优先级的阻塞队列。  递归 二叉树遍历，深度优先搜索等。\n什么是递归？\n常规的定义：编程语言中，函数 func 直接或者间接调用函数本身，则该函数称为递归函数。\n问前排人是第几排 -\u0026gt; 函数\n所有的递归问题都可以用递推公式来表示，所以要用递归解决问题，关键就是先找到递推公式。\n1 2 3  f(n) = f(n-1)+1 f(1) = 1 12   f(n) 表示你当前是第几排，f(n-1) 前面一排所在的排数，f(1) = 1 表示第一排的人知道自己是第一排。\n1 2 3 4  int f(int n){ if(n == 1) return 1; return f(n-1)+1; }   递归需要满足 3 要素：\n1、一个父问题可以拆分成若干个子问题，并且若干子问题的结果汇总起来就是父问题的答案。\n2、父问题和子问题，解题思路必须完全一致，只是数据规模不同。\n3、存在终止条件。\n问题在不断拆分的同时，一定要在某个节点终止拆分，得到一个明确的答案。\n问题：假设有 n 个台阶，每次可以跨 1 个台阶或者 2 个台阶，请问走完这 n 个台阶一共有多少种走法？\n1、假设有 1 个台阶，一共有（1） 种走法\n2、假设有 2 个台阶，一共有 2 种走法 【1，1】【2】\n3、假设有 3 个台阶，一共有（）种走法？【1，1，1】【1，2】【2，1】\n…\n可以根据第一步的走法进行分类\n第一类是第一步走了 1 个台阶\n第二类是第一步走了 2 个台阶\n所以 n 个台阶的走法就等于先走 1 个台阶后，n-1 个台阶的走法+先走 2 个台阶后，n-2 个台阶的走法。\n1 2  f(n) = f(n-1)+f(n-2) 1   f(1) = 1，能否作为终止条件？\nn = 2，f(2) = f(1)+f(0)，如果终止条件只有一个 f(1) = 1，f(2) 就无法求解， 因为 f(0) 的值无法确定，\n把 f(2) = 2 作为一个终止条件\n终止条件有两个：\nf(1) = 1;\nf(2) = 2;\nn = 3，f(3) = f(2)+f(1) = 3\nn = 4，f(4) = f(3)+f(2) = 3 + 2 = 5\n递推公式\n1 2 3 4  f(1) = 1; f(2) = 2; f(n) = f(n-1)+f(n-2); 123   推导出递归代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40  int f(int n){ if(n == 1) return 1; if(n == 2) return 2; return f(n-1) + f(n-2); } 12345 public class Test { public static void main(String[] args) { for (int i = 1; i \u0026lt;= 30; i++) { System.out.println(i+\u0026#34;个台阶共有\u0026#34;+f(i)+\u0026#34;种走法\u0026#34;); } } public static int f(int n){ if(n == 1) return 1; if(n == 2) return 2; return f(n-1) + f(n-2); } } public class Test2 { public static void main(String[] args) { int d = f(10); System.out.println(\u0026#34;d:\u0026#34;+d); } public static int f(int n){ if(n == 1){ System.out.println(\u0026#34;m:\u0026#34;+n); return 1; }else{ System.out.println(\u0026#34;n:\u0026#34;+n); //n=4  int c = f(n-1)+1; System.out.println(\u0026#34;c:\u0026#34;+c); return c; } } }   \n集合框架 为什么要使用集合框架？\n1、数组的长度是固定\n2、数组无法同时存储多个不同的数据类型\n集合简单理解就是一个长度可以改变，可以保持任意数据类型的动态数组。\n集合本身是数据结果的基本概念之一，我们这里说的集合是 Java 语言对这种数据结果的具体实现。\nJava 中的集合不是由一个类来完成的，而是由一组接口和类构成了一个框架体系。大致可分为 3 层，最上层是一组接口，继而是接口的实现类。\n接口 Collection：集合框架最基础的接口，最顶层的接口。\nList：Collection 的子接口，存储有序、不唯一（元素可重复）的对象，最常用的接口。\nSet：Collection 的子接口，存储无序、唯一（元素不可重复）的对象。\nMap：独立于 Collection 的另外一个接口，最顶层的接口，存储一组键值对象，提供键到值的映射。\nIterator：输出集合元素的接口，一般适用于无序集合，从前往后输出。\nListIterator：Iterator 子接口，可以双向输出集合中的元素。\nEnumeration：传统的输出接口，已经被 Iterator 取代。\nSortedSet：Set 的子接口，可以对集合中的元素进行排序。\nSortedMap：Map 的子接口，可以对集合中的元素进行排序。\nQueue：队列接口。\nMap.Entry：Map 的内部接口，描述 Map 中存储的一组键值对元素。\nCollection 接口 Collection 是集合框架中最基础的父接口，可以存储一组无序，不唯一的对象。 Collection 接口可以存储一组无序，不唯一（可重复）的对象，一般不直接使用该接口，也不能被实例化，只是用来提供规范。\nCollection 是 Iterable 接口的子接口。\n   int size() 获取集合长度     boolean isEmpty() 判断集合是否为空   boolean contains(Object o) 判断集合中是否存在某个对象   Iterator iterator() 实例化 Iterator 接口，遍历集合   Object[] toArray() 将集合转换为一个 Object 数组   T[] toArray(T[] a) 将集合转换为一个指定数据类型的数组   boolean add(E e) 向集合中添加元素   boolean remove(Object o) 从集合中删除元素   boolean containsAll(Collection c) 判断集合中是否存在另一个集合的所有元素   boolean addAll(Collection c) 向集合中添加某个集合的所有元素   boolean removeAll(Collection c) 从集合中删除某个集合的所有元素   void clear() 清除集合中的所有元素   boolean equals(Collection c) 判断两个集合是否相等   int hashCode() 返回集合的哈希值    Collection 子接口  List：存放有序、不唯一的元素 Set：存放无序、唯一的元素 Queue：队列接口  List 接口 List 常用的扩展方法：\n   方法 含义     T get(int index) 通过下标返回集合中对应位置的元素   T set(int index,T element) 在集合中的指定位置存入对象   int indexOf(Object o) 从前向后查找某个对象在集合中的位置   int lastIndexOf(Object o) 从后向前查找某个对象在集合中的位置   ListIterator listIterator() 实例化 ListIterator 接口，用来遍历 List 集合   List subList(int fromIndex,int toIndex) 通过下标截取 List 集合    List 接口的实现类 ArrayList ArrayList 是开发中使用频率最高的 List 实现类，实现了长度可变的数组，在内存中分配连续空间，所以读取快，增删慢。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33  public class Test { public static void main(String[] args) { ArrayList list = new ArrayList(); list.add(\u0026#34;Hello\u0026#34;); list.add(\u0026#34;World\u0026#34;); list.add(\u0026#34;JavaSE\u0026#34;); list.add(\u0026#34;JavaME\u0026#34;); list.add(\u0026#34;JavaEE\u0026#34;); System.out.println(\u0026#34;list:\u0026#34;+list); System.out.println(\u0026#34;list长度:\u0026#34;+list.size()); System.out.println(\u0026#34;list是否包含Java:\u0026#34;+list.contains(\u0026#34;Java\u0026#34;)); for (int i = 0; i \u0026lt; list.size(); i++) { System.out.println(list.get(i)); } Iterator iterator = list.iterator(); while(iterator.hasNext()){ System.out.println(iterator.next()); } list.remove(\u0026#34;Hello\u0026#34;); list.remove(0); System.out.println(\u0026#34;******************\u0026#34;); System.out.println(list); list.add(1,\u0026#34;Spring\u0026#34;); System.out.println(list); list.add(1,\u0026#34;Spring Boot\u0026#34;); System.out.println(list); list.set(1,\u0026#34;Spring Cloud\u0026#34;); System.out.println(list); System.out.println(\u0026#34;*************\u0026#34;); System.out.println(list.indexOf(\u0026#34;Spring\u0026#34;)); System.out.println(list.subList(1,3)); } }   ArrayList：基于数组的实现，非线程安全，效率高，所有的方法都没有 synchronized 修饰。\nVector 线程安全，效率低，实现线程安全直接通过 synchronized 修饰方法来完成。\nStack Vector 的子类，实现了栈的数据结构，（后进先出）\n push：入栈方法 peek：取出栈顶元素，将栈顶复制一份取出，取完之后栈内的数据不变。 pop：取出栈顶元素，直接取出栈顶元素，取完之后栈内的数据减一。  LikedList 实现了先进先出的队列，采用链表的形式存储。\nArrayList 和 LikedList 的区别：内存中存储的形式不同，ArrayList 采用的数组的方式，LinkedList 采用的是链表的形式。\n数组在内存中存储空间是连续的，读取快，增删慢。\n因为数组在内存中是连续的，所以取数据可以通过寻址公式很快求出目标元素的内存地址，因为内存是连续的，所以新增或者删除元素，必然需要移动数据，而且数组长度越长，需要移动的元素越多，操作就越慢。\n链表在内存中存储空间是不连续的，读取慢，增删快。链表在内存中是不连续的，没有固定的公式可以使用，要读取只能从第一位开始一直遍历到目标元素，数据规模越大，操作越慢。\n增删快，因为只需要重新设置目标元素前后两个节点的后置指针即可，与数据规模无关。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  public class Test { public static void main(String[] args) { LinkedList linkedList = new LinkedList(); linkedList.add(\u0026#34;Hello\u0026#34;); linkedList.add(\u0026#34;World\u0026#34;); linkedList.add(\u0026#34;Java\u0026#34;); System.out.println(linkedList); linkedList.offer(\u0026#34;JavaSE\u0026#34;); System.out.println(linkedList); linkedList.push(\u0026#34;JavaME\u0026#34;); System.out.println(linkedList); linkedList.addFirst(\u0026#34;First\u0026#34;); System.out.println(linkedList); linkedList.addLast(\u0026#34;Last\u0026#34;); System.out.println(linkedList); System.out.println(linkedList.peek()); System.out.println(linkedList.peekFirst()); System.out.println(linkedList.peekLast()); System.out.println(linkedList.pop()); System.out.println(linkedList); } }   LinkedList 和 Stack 都有 pop 方法，有什么区别和相同点？\npop 方法都是取出集合中的第一个元素，但是两者的顺序是相反的，Stack 是“后进先出”，所以 pop 取出的是最后一个元素，LinkedList 是“先进先出”，所以 pop 取出的是第一个元素。\nQueue LinkedList 实现了 Deque 接口，而 Deque 接口是 Queue 的子接口，Queue 就是队列，底层实现了队列的数据结构。\n实际开发中，不能直接实例化 Queue 对象。\nQueue 的实现类是 AbstractQueue，它是一个抽象类，不能直接实例化，开发中需要实现它的子类 PriorityQueue。\nQueue 中添加的数据必须是有顺序的。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47  package com.southwind.demo5; import java.util.PriorityQueue; public class Test { public static void main(String[] args) { PriorityQueue queue = new PriorityQueue(); // queue.add(1); // queue.add(2); // queue.add(3); // queue.add(\u0026#34;a\u0026#34;); // queue.add(\u0026#34;b\u0026#34;); // queue.add(\u0026#34;c\u0026#34;);  queue.add(new A(1)); queue.add(new A(2)); System.out.println(queue); } } class A implements Comparable{ private int num; public A(int num) { this.num = num; } @Override public int compareTo(Object o) { A a = (A)o; if(this.num \u0026gt; a.num){ return 1; }else if(this.num == a.num){ return 0; }else{ return -1; } } @Override public String toString() { return \u0026#34;A{\u0026#34; + \u0026#34;num=\u0026#34; + num + \u0026#39;}\u0026#39;; } }   Queue 默认给元素进行升序排列，即自然排序。\nJava 集合框架  List（有序不唯一） Set Map  List Set：存储的是单个数据，List 可以存储重复的数据，Set 数据不能重复\nMap：存储的是一组数据\nSet 跟 List 一样，Set 是 Collection 的子接口，Set 集合是以散列的形式存储数据，所以元素是没有顺序的，可以存储一组无序且唯一的数据。\nSet 常用实现类：\n HashSet LinkedHashSet TreeSet  HashSet HashSet 是开发中经常使用的一个实现类，存储一组无序且唯一的对象。\n无序：元素的存储顺序和遍历顺序不一致。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  public class Test { public static void main(String[] args) { HashSet set = new HashSet(); set.add(\u0026#34;Hello\u0026#34;); set.add(\u0026#34;World\u0026#34;); set.add(\u0026#34;Java\u0026#34;); set.add(\u0026#34;Hello\u0026#34;); Iterator iterator = set.iterator(); while(iterator.hasNext()){ System.out.println(iterator.next()); } set.remove(\u0026#34;World\u0026#34;); System.out.println(\u0026#34;****************\u0026#34;); iterator = set.iterator(); while(iterator.hasNext()){ System.out.println(iterator.next()); } } }   LinkedHashSet LinkedHasSet 是 Set 的另外一个实现类，可以存储一组有序且唯一的元素.\n有序：元素的存储顺序和遍历顺序一致。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  public class Test { public static void main(String[] args) { LinkedHashSet linkedHashSet = new LinkedHashSet(); linkedHashSet.add(\u0026#34;Hello\u0026#34;); linkedHashSet.add(\u0026#34;World\u0026#34;); linkedHashSet.add(\u0026#34;Java\u0026#34;); linkedHashSet.add(\u0026#34;Hello\u0026#34;); System.out.println(\u0026#34;LinkedHashSet的长度是\u0026#34;+linkedHashSet.size()); System.out.println(\u0026#34;遍历LinkedHashSet\u0026#34;); Iterator iterator = linkedHashSet.iterator(); while(iterator.hasNext()){ System.out.println(iterator.next()); } linkedHashSet.remove(\u0026#34;Java\u0026#34;); System.out.println(linkedHashSet.contains(\u0026#34;Java\u0026#34;)); } }   equals 和 == 的区别？ 所有类中的 equals 都是继承自 Object 类，Object 类中原生的 eqauls 方法就是在通过 == 进行判断\n但是每个类都可以对 equals 方法进行重写，覆盖掉之前使用 == 进行判断的逻辑，改用新的逻辑进行判断是否相等。\nLinkedHashSet 如何判断两个对象是否相等？\n首先会判断两个对象的 hashCode 是否相等\n 什么是 hashCode？\n 将对象的内部信息（内存地址、属性值等），通过某种特定规则转换成一个散列值，就是该对象的 hashCode。\n 两个不同对象的 hashCode 值可能相等。 hashCode 不相等的两个对象一定不是同一个对象。  集合在判断两个对象是否相等的时候：\n1、会先比较他们的 hashCode，如果 hashCode 不相等，则认为不是同一个对象，可以添加。\n2、如果 hashCode 值相等，还不能认为两个对象是相等的，需要通过 equals 进行进一步的判断，equals 相等，则两个对象相等，否则两个对象不相等。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52  public class Test { public static void main(String[] args) { LinkedHashSet set = new LinkedHashSet(); Data data1 = new Data(1); set.add(data1); Data data2 = new Data(1); set.add(data2); //是一个对象  System.out.println(data1.equals(data2)); //不是一个对象  System.out.println(set); } } class Data { private int num; public Data(int num) { this.num = num; } @Override public String toString() { return \u0026#34;Data{\u0026#34; + \u0026#34;num=\u0026#34; + num + \u0026#39;}\u0026#39;; } //hashcode  @Override public boolean equals(Object obj) { if (this == obj) { return true; } //instanceof 判断对象是否属于某个类  if(obj instanceof Data){ Data data = (Data) obj; if(this.num == data.num){ return true; } } return false; } @Override public int hashCode() { return 1; } } 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051   ==：判断的是栈内存中的值。 引用类型的数据：栈内存中存储的是地址，所以此时 == 判断的是引用地址。\n基本数据类型：栈内存中存储的是具体的数值。\n栈中存储的是变量\nData data;\nint num;\n引用类型具体的对象（属性）存储在堆中的，再将堆中对象的内存地址赋值给栈中的变量 data，data 中存储的就是地址。\n基本数据类型不需要用到堆内存，变量在栈中，变量的值直接存储在变量中。\nTreeSet LinkedHashSet 和 TreeSet 都是存储一组有序且唯一的数据，但是这里的两个有序是有区别的。\nLinkedHashSet 的有序是指元素的存储顺序和遍历顺序是一致的。\n如：6,3,4,5,1,2–\u0026gt;6,3,4,5,1,2\nTreeSet 的有序是指集合内部会自动对所有的元素按照升序进行排列，无论存入的顺序是什么，遍历的时候一定按照生序输出。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81  public class Test { public static void main(String[] args) { TreeSet treeSet = new TreeSet(); // treeSet.add(1);  // treeSet.add(3);  // treeSet.add(6);  // treeSet.add(2);  // treeSet.add(5);  // treeSet.add(4);  // treeSet.add(1);  treeSet.add(\u0026#34;b11\u0026#34;); treeSet.add(\u0026#34;e22\u0026#34;); treeSet.add(\u0026#34;a33\u0026#34;); treeSet.add(\u0026#34;c44\u0026#34;); treeSet.add(\u0026#34;d55\u0026#34;); System.out.println(\u0026#34;treeSet的长度是\u0026#34;+treeSet.size()); System.out.println(\u0026#34;treeSet遍历\u0026#34;); Iterator iterator = treeSet.iterator(); while(iterator.hasNext()){ System.out.println(iterator.next()); } } } public class Test { public static void main(String[] args) { TreeSet treeSet = new TreeSet(); treeSet.add(new Data(1)); treeSet.add(new Data(3)); treeSet.add(new Data(6)); treeSet.add(new Data(2)); treeSet.add(new Data(5)); treeSet.add(new Data(4)); treeSet.add(new Data(1)); System.out.println(\u0026#34;treeSet的长度\u0026#34;+treeSet.size()); System.out.println(\u0026#34;treeSet遍历\u0026#34;); Iterator iterator = treeSet.iterator(); while(iterator.hasNext()){ System.out.println(iterator.next()); } } } class Data implements Comparable{ private int num; public Data(int num) { this.num = num; } /** * A.compareTo(B) * 返回值： * 1 表示A大于B * 0 表示A等于B * -1 表示A小于B * @param o * @return */ @Override public int compareTo(Object o) { if(o instanceof Data){ Data data = (Data) o; if(this.num \u0026lt; data.num){ return 1; }else if(this.num == data.num){ return 0; }else{ return -1; } } return 0; } @Override public String toString() { return \u0026#34;Data{\u0026#34; + \u0026#34;num=\u0026#34; + num + \u0026#39;}\u0026#39;; } }   Map key-value，数据字典\nList、Set 接口都是 Collection 的子接口，Map 接口是与 Collection 完全独立的另外一个体系。\nList \u0026amp; Set VS Map\nList \u0026amp; Set \u0026amp; Collection 只能操作单个元素，Map 可以操作一对元素，因为 Map 存储结构是 key - value 映射。\nMap 接口定义时使用了泛型，并且定义两个泛型 K 和 V，K 表示 key，规定键元素的数据类型，V 表示 value，规定值元素的数据类型。\n   方法 描述     int size() 获取集合长度   boolean isEmpty() 判断集合是否为空   boolean containsKey(Object key) 判断集合中是否存在某个 key   boolean containsValue(Object value) 判断集合中是否存在某个 value   V get(Object key) 取出集合中 key 对应的 value   V put(K key,V value) 向集合中存入一组 key-value 的元素   V remove(Object key) 删除集合中 key 对应的 value   void putAll(Map map) 向集合中添加另外一个 Map   void clear() 清除集合中所有的元素   Set keySet() 取出集合中所有的 key，返回一个 Set   Collection values() 取出集合中所有的 value，返回一个 Collection   Set\u0026lt;Map.Entry\u0026lt;K,V\u0026raquo; entrySet() 将 Map 以 Set 的形式输出   int hashCode() 获取集合的散列值   boolean equals(Object o) 比较两个集合是否相等    Map 接口的实现类  HashMap：存储一组无序，key 不可以重复，value 可以重复的元素。 Hashtable：存储一组无序，key 不可以重复，value 可以重复的元素。 TreeMap：存储一组有序，key 不可以重复，value 可以重复的元素，可以按照 key 进行排序。  HashMap 的使用 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43  public class Test { public static void main(String[] args) { HashMap hashMap = new HashMap(); hashMap.put(\u0026#34;h\u0026#34;,\u0026#34;Hello\u0026#34;); hashMap.put(\u0026#34;w\u0026#34;,\u0026#34;World\u0026#34;); hashMap.put(\u0026#34;j\u0026#34;,\u0026#34;Java\u0026#34;); hashMap.put(\u0026#34;s\u0026#34;,\u0026#34;JavaSE\u0026#34;); hashMap.put(\u0026#34;m\u0026#34;,\u0026#34;JavaME\u0026#34;); hashMap.put(\u0026#34;e\u0026#34;,\u0026#34;JavaEE\u0026#34;); System.out.println(hashMap); hashMap.remove(\u0026#34;e\u0026#34;); System.out.println(\u0026#34;删除之后\u0026#34;+hashMap); hashMap.put(\u0026#34;m\u0026#34;,\u0026#34;Model\u0026#34;); System.out.println(\u0026#34;添加之后\u0026#34;+hashMap); if (hashMap.containsKey(\u0026#34;a\u0026#34;)){ System.out.println(\u0026#34;集合中存在key=a\u0026#34;); }else{ System.out.println(\u0026#34;集合中不存在key=a\u0026#34;); } if(hashMap.containsValue(\u0026#34;Java\u0026#34;)){ System.out.println(\u0026#34;集合中存在value=Java\u0026#34;); }else { System.out.println(\u0026#34;集合中不存在value=Java\u0026#34;); } Set keys = hashMap.keySet(); System.out.println(\u0026#34;集合中的key\u0026#34;); Iterator iterator = keys.iterator(); while (iterator.hasNext()) { System.out.println(iterator.next()); } Collection values = hashMap.values(); for (Object value : values) { System.out.println(value); } System.out.println(\u0026#34;************\u0026#34;); iterator = keys.iterator(); while(iterator.hasNext()){ String key = (String) iterator.next(); String value = (String) hashMap.get(key); System.out.println(key+\u0026#34;-\u0026#34;+value); } } }   Hashtable Hashtable 用法与 HashMap基本一样，它们的区别是，Hashtable是线程安全的，但是性能较低。HashMap 是非线程安全的，但是性能较高。\nHashMap，方法没有用 synchronized 修饰，所以是非线程安全的。\nHashtable，方法用 synchronized 修饰，所以是线程安全的。\nHashtable 的使用\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  public class Test { public static void main(String[] args) { Hashtable hashtable = new Hashtable(); hashtable.put(\u0026#34;h\u0026#34;,\u0026#34;Hello\u0026#34;); hashtable.put(\u0026#34;w\u0026#34;,\u0026#34;World\u0026#34;); hashtable.put(\u0026#34;j\u0026#34;,\u0026#34;Java\u0026#34;); hashtable.put(\u0026#34;s\u0026#34;,\u0026#34;JavaSE\u0026#34;); hashtable.put(\u0026#34;m\u0026#34;,\u0026#34;JavaME\u0026#34;); hashtable.put(\u0026#34;e\u0026#34;,\u0026#34;JavaEE\u0026#34;); System.out.println(hashtable); hashtable.remove(\u0026#34;e\u0026#34;); System.out.println(hashtable); System.out.println(hashtable.containsKey(\u0026#34;a\u0026#34;)); System.out.println(hashtable.containsValue(\u0026#34;Java\u0026#34;)); Set keys = hashtable.keySet(); System.out.println(keys); Collection values = hashtable.values(); System.out.println(values); } }   HashMap 和 Hashtable，保存的书画家都是无序的，Map 的另外一个实现类 TreeMap 主要功能是按照 key 对集合中的元素进行排序。\nTreeMap TreeMap 的使用\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67  public class Test2 { public static void main(String[] args) { TreeMap treeMap = new TreeMap(); treeMap.put(new User(3,\u0026#34;Java\u0026#34;),\u0026#34;Java\u0026#34;); treeMap.put(new User(5,\u0026#34;JavaME\u0026#34;),\u0026#34;JavaME\u0026#34;); treeMap.put(new User(1,\u0026#34;Hello\u0026#34;),\u0026#34;Hello\u0026#34;); treeMap.put(new User(6,\u0026#34;JavaEE\u0026#34;),\u0026#34;JavaEE\u0026#34;); treeMap.put(new User(2,\u0026#34;World\u0026#34;),\u0026#34;World\u0026#34;); treeMap.put(new User(4,\u0026#34;JavaSE\u0026#34;),\u0026#34;JavaSE\u0026#34;); System.out.println(treeMap); Set set = treeMap.keySet(); Iterator iterator = set.iterator(); while(iterator.hasNext()){ Object key = iterator.next(); System.out.println(key+\u0026#34;-\u0026#34;+treeMap.get(key)); } } } class User implements Comparable{ private int id; private String name; public int getId() { return id; } public void setId(int id) { this.id = id; } public String getName() { return name; } public void setName(String name) { this.name = name; } public User(int id, String name) { this.id = id; this.name = name; } @Override public String toString() { return \u0026#34;User{\u0026#34; + \u0026#34;id=\u0026#34; + id + \u0026#34;, name=\u0026#39;\u0026#34; + name + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#39;}\u0026#39;; } @Override public int compareTo(Object o) { if (o instanceof User){ User user = (User)o; if(this.id \u0026gt; user.id){ return 1; }else if(this.id == user.id){ return 0; }else { return -1; } } return 0; } }   Collections 工具类 Collection 接口，List 和 Set的父接口。\nCollections不是接口，它是一个工具类，专门提供了一些对集合的操作，方便开发者去使用，完成相应的业务功能。\nColletions 针对集合的工具类，Collection\nArrays 针对数组的工具类，Array\n   name 描述     public static sort() 对集合进行排序   public static int binarySearch(List list,Object v) 查找 v 在 list 中的位置，集合必须是生序排列   public static get(List list,int index) 返回 list 中 index 位置的值   public static void reverse(List list) 对 list 进行反序输出   public static void swap(List list,int i,int j) 交换集合中指定位置的两个元素   public static void fill(List list,Object obj) 将集合中所有元素替换成 obj   public static Object min(List list) 返回集合中的最小值   public static Object max(List list) 返回集合中的最大值   public static boolean replaceAll(List list,Object old,Object new) 在 list 集合中用 new 替换 old   public static boolean addAll(List list,Object… obj) 向集合中添加元素    可变参数，在调用方法的时候，参数可以是任意个数，但是类型必须匹配。\n1 2 3  public static void test(int... arg){ } 12   但是下面这种写法，可以传任意类型，任意数量的参数，多态的一种具体表示形式。\n1 2 3  public static void test(Object... arg){ } 12   Java 中默认输出对象的格式：对象所属的全类名（全限定类名）带着包名的类名+@+对象的哈希值\n断点 breakpoint\nJavaScript js 脚本语言\nJava 是必须全部编译之后，统一执行，假如有 10 行 Java 代码，必须先对这 10 行代码进行编译，通过之后，再交给 JVM 执行。\nJS 逐行执行，执行一行算一行，假如有 10 行 JS 代码，一行一行开始执行，执行到第 5 行报错，那么后续 6-10 就不再执行，但是已经执行的前 5 行结果不变。\nJava 更加严谨，JS 更加随意\nJava 是强语言类型的，JS 是弱语言类型\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65  public class Test { public static void main(String[] args) { ArrayList list = new ArrayList(); // list.add(\u0026#34;Hello\u0026#34;); // list.add(\u0026#34;Java\u0026#34;); // Collections.addAll(list,\u0026#34;Java\u0026#34;,\u0026#34;JavaME\u0026#34;,\u0026#34;World\u0026#34;); // System.out.println(\u0026#34;排序之前\u0026#34;); // System.out.println(list);  //进行排序-》升序a // Collections.sort(list); // System.out.println(\u0026#34;排序之后\u0026#34;); // System.out.println(list);  //查找元素在集合中的下标,二分查找法（集合中的元素必须升序排列） // int index = Collections.binarySearch(list,\u0026#34;Java\u0026#34;); // System.out.println(\u0026#34;Java 在 list 中的下标\u0026#34;+index); // System.out.println(list); // Collections.replaceAll(list,\u0026#34;Java\u0026#34;,\u0026#34;Collections\u0026#34;); // System.out.println(list);  Collections.addAll( list, new User(1,\u0026#34;张三\u0026#34;,30), new User(2,\u0026#34;李四\u0026#34;,26), new User(3,\u0026#34;王五\u0026#34;,18) ); Collections.sort(list); System.out.println(list); } } class User implements Comparable{ private Integer id; private String name; private Integer age; public User(Integer id, String name, Integer age) { this.id = id; this.name = name; this.age = age; } @Override public String toString() { return \u0026#34;User{\u0026#34; + \u0026#34;id=\u0026#34; + id + \u0026#34;, name=\u0026#39;\u0026#34; + name + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#34;, age=\u0026#34; + age + \u0026#39;}\u0026#39;; } @Override public int compareTo(Object o) { if(o instanceof User){ User user = (User) o; if(this.age \u0026lt; user.age){ return 1; }else if(this.age == user.age){ return 0; }else{ return -1; } } return 0; } }   泛型 泛型（Generics），是指在类定义时不指定类中信息的具体数据类型，而是暂时用一个标识符来替代，当外部实例化对象的时候再来指定具体的数据类型。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  //定义 A 类的时候就指定了属性是 B 类型 public class A{ private B b; public C test(D d){ return new C(); } } //定义 A 类的时候不指定属性的类型 public class A\u0026lt;T,E,M\u0026gt;{ private T b; public E test(M m){ return E; } } A\u0026lt;B,C,D\u0026gt; a = new A();   优点：这样做极大地提升程序的灵活性，提升类的扩展性，泛型可以指代类中成员变量的数据类型，方法的返回值类型以及方法的参数类型。\n泛型的应用 自定义类中添加泛型\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  public class 类名\u0026lt;泛型1,泛型2,泛型3...\u0026gt;{ private 泛型1 属性名; public 泛型2 方法名(泛型3){ 方法体 } } public class Time\u0026lt;T\u0026gt; { private T value; public T getValue() { return value; } public void setValue(T value) { this.value = value; } } public class Test { public static void main(String[] args) { Time\u0026lt;Integer\u0026gt; time1 = new Time\u0026lt;\u0026gt;(); time1.setValue(10); System.out.println(\u0026#34;现在的时间是\u0026#34;+time1.getValue()); Time\u0026lt;String\u0026gt; time2 = new Time\u0026lt;\u0026gt;(); time2.setValue(\u0026#34;十点整\u0026#34;); System.out.println(\u0026#34;现在的时间是\u0026#34;+time2.getValue()); } }   泛型用哪个字母都可以，关键是类定义处的字母和类中信息的字母保持一致。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39  public class Time\u0026lt;H,M,S\u0026gt; { private H hour; private M minute; private S second; public H getHour() { return hour; } public void setHour(H hour) { this.hour = hour; } public M getMinute() { return minute; } public void setMinute(M minute) { this.minute = minute; } public S getSecond() { return second; } public void setSecond(S second) { this.second = second; } } public class Test { public static void main(String[] args) { Time\u0026lt;String,Integer,Float\u0026gt; time = new Time\u0026lt;\u0026gt;(); time.setHour(\u0026#34;十点\u0026#34;); time.setMinute(10); time.setSecond(10.0f); System.out.println(\u0026#34;现在的时间是\u0026#34;+time.getHour()+\u0026#34;:\u0026#34;+time.getMinute()+\u0026#34;:\u0026#34;+time.getSecond()); } }   泛型通配符 有一个参数为 ArrayList 的方法，希望这个方法即可接收泛型是 String 的集合，又可以接收泛型是 Integer 的集合，怎么实现？\n多态在泛型中不适用\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  public class Test { public static void main(String[] args) { ArrayList\u0026lt;String\u0026gt; list1 = new ArrayList\u0026lt;\u0026gt;(); ArrayList\u0026lt;Integer\u0026gt; list2 = new ArrayList\u0026lt;\u0026gt;(); test(list1); test(list2); } public static void test(ArrayList\u0026lt;?\u0026gt; list){ System.out.println(list); } }   ArrayList\u0026lt;?\u0026gt; 表示可以使用任意的泛型类型对象，这样 test 方法具备通用性了。\n泛型上限和下限 上限：表示实例化时具体的数据类型，可以是上限类型的子类或者是上限类型本身，用 extends 表示。\n下限：表示实例化时具体的数据类型，可以是下限类型的父类或者是下限类型本身，用 super 表示。\n类名\u0026lt;泛型标识 extends 上限类名\u0026gt;\n类名\u0026lt;泛型标识 super 下限类名\u0026gt;\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  public class Time\u0026lt;T\u0026gt; { public static void main(String[] args) { test(new Time\u0026lt;Float\u0026gt;()); test(new Time\u0026lt;Integer\u0026gt;()); test(new Time\u0026lt;Number\u0026gt;()); test2(new Time\u0026lt;String\u0026gt;()); test2(new Time\u0026lt;Object\u0026gt;()); } /** * 泛型上限 * @param time */ public static void test(Time\u0026lt;? extends Number\u0026gt; time){ } /** * 泛型下限 * @param time */ public static void test2(Time\u0026lt;? super String\u0026gt; time) { } }   泛型接口 接口\n1 2 3  public interface MyInterface\u0026lt;T\u0026gt; { public T getValue(); }   实现泛型接口有两种方式：\n 实现类在定义时继续使用泛型标识  1 2 3 4 5 6 7 8 9 10 11 12 13  public class MyInterfaceImpl\u0026lt;T\u0026gt; implements MyInterface { private T obj; public MyInterfaceImpl(T obj) { this.obj = obj; } @Override public T getValue() { return this.obj; } }    实现类在定义时直接给出具体的数据类型  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  public class MyInterfaceImpl2 implements MyInterface\u0026lt;String\u0026gt; { private String obj; public MyInterfaceImpl2(String obj) { this.obj = obj; } @Override public String getValue() { return this.obj; } } public class Test { public static void main(String[] args) { MyInterfaceImpl myInterface = new MyInterfaceImpl\u0026lt;String\u0026gt;(\u0026#34;接口\u0026#34;); String val = (String) myInterface.getValue(); MyInterfaceImpl2 myInterface1 = new MyInterfaceImpl2(\u0026#34;接口\u0026#34;); val = myInterface1.getValue(); } }   Java 实用类 枚举 枚举 Enum，是一种有确定值区间的数据类型，本质上就是一个类，具有简洁、安全、方便等特点。\n枚举的值被约束到了一个特定的范围内，只能从这个范围以内取值。\n为什么要有枚举？\n因为在描述某些对象的属性时，该属性的值不能随便定义，必须在某个特定的区间内取值。\n出于对数据的安全性考虑，类似这种有特定取值范围的数据我们就可以使用枚举来描述。\n枚举指由一组常量组成的类型，指定一个取值区间，我们只能从该区间中取值。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36  final class Week extends Enum{ public static final Week MONDAY; public static final Week TUESDAY; public static final Week WEDNSDAY; public static final Week THURSDAY; public static final Week FRIDAY; public static final Week SATURDAY; public static final Week SUNDAY; private static final Week $VALUES[]; static{ MONDAY = new Week(\u0026#34;MONDAY\u0026#34;,0); TUESDAY = new Week(\u0026#34;TUESDAY\u0026#34;,1); WEDNSDAY = new Week(\u0026#34;WEDNSDAY\u0026#34;,2); THURSDAY = new Week(\u0026#34;THURSDAY\u0026#34;,3); FRIDAY = new Week(\u0026#34;FRIDAY\u0026#34;,4); SATURDAY = new Week(\u0026#34;SATURDAY\u0026#34;,5); SUNDAY = new Week(\u0026#34;SUNDAY\u0026#34;,6); $VALUES[] = (new Week[]{ MONDAY,TUESDAY,WEDNSDAY,THURSDAY,FRIDAY,SATURDAY,SUNDAY }) } public static Week[] values(){ return $VALUES.clone(); } public static Week valueOf(String s){ return Enum.valueOf(s); } private Week(String s,int i){ super(s,i); } }   Math Math 类为开发者提供了一系列的数学方法，同时还提供了两个静态常量 E（自然对数的底数）和 PI（圆周率）。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  public class Test { public static void main(String[] args) { System.out.println(\u0026#34;常量E\u0026#34;+Math.E); System.out.println(\u0026#34;常量PI\u0026#34;+Math.PI); System.out.println(\u0026#34;9的平方根\u0026#34;+Math.sqrt(9)); System.out.println(\u0026#34;8的立方根\u0026#34;+Math.cbrt(8)); System.out.println(\u0026#34;2的3次方\u0026#34;+Math.pow(2,3)); System.out.println(\u0026#34;较大值\u0026#34;+Math.max(6.5,1)); System.out.println(\u0026#34;-10.3的绝对值\u0026#34;+Math.abs(-10.3)); System.out.println(Math.ceil(10.000001)); System.out.println(Math.floor(10.999999)); System.out.println((int)(Math.random()*10)); System.out.println(Math.rint(5.4)); } }   Random 用来产生随机数的类，并且可以任意指定一个区间，在此区间范围内产生一个随机数。\n   方法 描述     public Random() 创建一个无参的随机数构造器，使用系统时间作为默认种子   public Random(long seed) 使用 long 数据类型的种子创建一个随机数构造器   public boolean nextBoolean() 返回一个 boolean 类型的随机数   public double nextDouble() 返回一个 double 类型的随机数，0.0 - 1.0 之间   public float nextFloat() 返回一个 float 类型的随机数，0.0 - 1.0 之间   public int nextInt() 返回一个 int 类型的随机数   public int nextInt(n) 返回一个 int 类型的随机数，0-n之间   public long nextLong 返回一个 long 类型的随机数，0-1 之间    1 2 3 4 5 6 7 8 9 10 11  public class Test { public static void main(String[] args) { Random random = new Random(); //生成订单编号（时间戳+随机数）  for (int i = 1; i \u0026lt;= 10000; i++) { //随机生成一个六位数  System.out.println(\u0026#34;订单\u0026#34;+i+\u0026#34;的编号是：\u0026#34;+System.currentTimeMillis()+random.nextInt(100000)+100000); } } }   String Java 通过 String 类来创建和操作字符串数据。\n String 实例化  1、直接赋值\n1  String str = \u0026#34;Hello World\u0026#34;;   2、通过构造函数创建对象\n1  String str = new String(\u0026#34;Hello World\u0026#34;);   1 2  isLatin1() ? StringLatin1.equals(value, aString.value) :StringUTF16.equals(value, aString.value);   三目运算符 三元表达式\nString 常用方法    方法 描述     public String() 创建一个空的字符串对象   public String(String value) 创建一个值为 value 的字符串对象   public String(char value[]) 将一个char数组转换为字符串对象   public String(char value[],int offset, int count) 将一个指定范围的char数组转为字符串对象   public String(byte value[]) 将一个byte数组转换为字符串对象   public String(byte value[],int offset, int count) 将一个指定范围的byte数组转为字符串对象   public int length() 获取字符串的长度   public boolean isEmpty() 判断字符串是否为空   public char charAt(int index) 返回指定下标的字符   public byte[] getBytes() 返回字符串对应的byte数组   public boolean equals(Object anObject) 判断两个字符串值是否相等   public boolean equalsIgnoreCase(Object anObject) 判断两个字符串值是否相等（忽略大小写）   public int compareTo(String value) 对字符串进行排序   public int compareToIgnoreCase(String value) 忽略大小写进行排序   public boolean startsWith(String value) 判断字符串是否以 value 开头   public boolean endsWith(String value) 判断字符串是否以 value 结尾   public int hashCode() 返回字符串的 hash 值   public int indexOf(String str) 返回 str 在字符串中的下标   public int indexOf(String str,int formIndex) 从指定位置查找字符串的下标   public String subString(int beginIndex) 从指定位置开始截取字符串   public String subString(int beginIndex,int endIndex) 截取指定区间的字符串   public String concat(String str) 追加字符串   public String replaceAll(String o,String n) 将字符串中所有的 o 替换成 n   public String[] split(String regex) 用指定的字符串对目标进行分割，返回数组   public String toLowerCase() 转小写   public String toUpperCase() 转大写   public char[] toCharArray() 将字符串转为字符数组    null 和空是两个概念。\nnull 是指对象不存在，引用地址为空。\n空是指对象存在，没有内容，长度为零。\nStringBuffer String 对象一旦创建，值不能修改（原来的值不能修改，一旦修改就是一个新的对象，只要一改动，就会创建一个新的对象）\n修改之后会重新开辟内存空间来存储新的对象，会修改 String 的引用。\nString 的值为什么不能修改？修改之后会创建一个新的对象？而不是在原有对象的基础上进行修改？\n因为 String 底层是用数组来存值的，数组长度一旦创建就不可修改，所以导致上述问题。\nStringBuffer 可以解决 String 频繁修改造成的空间资源浪费的问题。\nStringBuffer 底层也是使用数组来存值。\n StringBuffer 数组的默认长度为 16，使用无参构造函数来创建对象。   使用有参构造创建对象，数组长度=值的长度+16。   1 2 3 4 5 6 7 8 9 10 11 12  public class Test { public static void main(String[] args) { StringBuffer stringBuffer = new StringBuffer(\u0026#34;Hello\u0026#34;); StringBuffer stringBuffer1 = new StringBuffer(); //stringBuffer 底层数组的长度是 21  //stringBuffer1 底层数组的长度是 16  stringBuffer1.append(\u0026#34;Hello\u0026#34;); System.out.println(stringBuffer.toString().equals(stringBuffer1.toString())); System.out.println(stringBuffer.length()); System.out.println(stringBuffer1.length()); } }   length 方法返回的并不是底层数组的长度，而是它的有效长度（值的长度）。\nStringBuffer 一旦创建，默认会有 16 个字节的空间去修改，但是一旦追加的字符串长度超过 16，如何处理？\nStringBuffer 不会重新开辟一块新的内存区域，而是在原有的基础上进行扩容，通过调用父类 ensureCapacityInternal() 方法对底层数组进行扩容，保持引用不变。\nStringBuffer 的常用方法，StringBuffer 是线程安全的，但是效率较低，StringBuilder 是线程不安全的，但是效率较高。\nHashMap：线程不安全，效率高\nHashtable：线程安全，效率低\n   方法 描述     public StringBuffer() 创建一个空的 StringBuffer对象   public StringBuffer(String str) 创建一个值为 str 的 StringBuffer 对象   public synchronized int length() 返回 StringBuffer 的长度   public synchronized char charAt(int index) 返回指定位置的字符   public synchronized StringBuffer append(String str) 追加内容   public synchronized StringBuffer delete(int start,int end) 删除指定区间的值   public synchronized StringBuffer deleteCharAt(int index) 删除指定位置的字符   public synchronized StringBuffer replace(int start,int end,String str) 将指定区间的值替换成 str   public synchronized String substring(int start) 截取字符串从指定位置到结尾   public synchronized String substring(int start,int end) 截取字符串从start开始，到end结束   public synchronized StringBuffer insert(int offset,String str) 在指定位置插入 str   public int indexOf(String str) 从头开始查找指定字符的位置   public int indexOf(String str,int fromIndex) 从fromIndex开始查找指定字符的位置   public synchronized StringBuffer reverse() 进行反转   public synchronized String toString() 转为 String    读取数据不需要考虑线程安全问题，因为这种操作不存在安全隐患。\n日期类  java.util.Date  Date 对象表示当前的系统时间\n java.util.Calendar  Calendar 用来完成日期数据的逻辑运算\n运算思路：（op+com+t）\n1、将日期数据传给 Calendar（Calendar 提供了很多静态常量，专门用来记录日期数据）\n   常量 描述     public static final int YEAR 年   public static final int MONTH 月   public static final int DAY_OF_MONTH 天，以月为单位   public static final int DAY_OF_YEAR 天，以年为单位   public static final int HOUR_OF_DAY 小时   public static final int MINUTE 分钟   public static final int SECOND 秒   public static final int MILLSECOND 毫秒    2、调用相关方法进行运算\n   方法 描述     public static Calendar getInstance() 获取Calendar实例化对象   public void set(int field,int value) 给静态常量赋值   public int get(int field) 获取静态常量的值   public final Date getTime() 将Calendar转为Date对象    1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  public class Test { public static void main(String[] args) { //计算今天所在的周是2020年的第几周  Calendar calendar = Calendar.getInstance(); calendar.set(Calendar.YEAR,2020); //1月为0，4月为3  calendar.set(Calendar.MONTH,3); calendar.set(Calendar.DAY_OF_MONTH,9); int week = calendar.get(Calendar.WEEK_OF_YEAR); System.out.println(week); //今天之后的63天是几月几号  int days = calendar.get(Calendar.DAY_OF_YEAR); days += 63; calendar.set(Calendar.DAY_OF_YEAR,days); Date date = calendar.getTime(); SimpleDateFormat simpleDateFormat = new SimpleDateFormat(\u0026#34;yyyy-MM-dd\u0026#34;); System.out.println(simpleDateFormat.format(date)); //今天之前的63天是几月几号  // calendar.set(Calendar.YEAR,2020);  // //1月为0，4月为3  // calendar.set(Calendar.MONTH,3);  // calendar.set(Calendar.DAY_OF_MONTH,9);  calendar.set(Calendar.DAY_OF_YEAR,100); calendar.set(Calendar.DAY_OF_YEAR,calendar.get(Calendar.DAY_OF_YEAR)-63); date = calendar.getTime(); System.out.println(simpleDateFormat.format(date)); } }   文件 文件 File 类\njava.io.File，使用该类的构造函数就可以创建文件对象，将硬盘中的一个具体的文件以 Java 对象的形式来表示。\n   方法 描述     public File(String pathname) 根据路径创建对象   public String getName() 获取文件名   public String getParent() 获取文件所在的目录   public File getParentFile() 获取文件所在目录对应的File对象   public String getPath() 获取文件路径   public boolean exists() 判断文件是否存在   public boolean isDirectory() 判断对象是否为目录   public boolean isFile() 判断对象是否为文件   public long length() 获取文件的大小   public boolean createNewFile() 根据当前对象创建新文件   public boolean delete() 删除对象   public boolean mkdir() 根据当前对象创建目录   public boolean renameTo(File file) 为已存在的对象重命名    IO\nInput 输入流（将外部文件读入到 Java 程序中）\nOutput 输出流（将 Java 程序中的数据输出到外部）\nJava 中的流有很多种不同的分类。\n 按照方向分，输入流和输出流 按照单位分，可以分为字节流和字符流（字节流是指每次处理数据以字节为单位，字符流是指每次处理数据以字符为单位） 按照功能分，可以分为节点流和处理流。  方法定义时的异常如果直接继承自 Exception，实际调用的时候需要手动处理（捕获异常/丢给虚拟机去处理）\n方法定义时的异常如果继承自 RuntimeException，调用的时候不需要处理。\nIO流  按照方向分，可以分为输入流和输出流。 按照单位分，可以分为字节流和字符流。 按照功能分，可以分为节点流和处理流。  字节流 按照方向可以分为输入字节流和输出字节流。\nInputStream、OutputStream\n1 byte = 8 位二进制数 01010101\nInputStream常用方法\n   方法 描述     int read() 以字节为单位读取数据   int read(byte b[]) 将数据存入 byte 类型的数组中，返回数组中有效数据的长度   int read(byte b[],int off,int len) 将数据存入 byte 数组的指定区间内，返回数组长度   byte[] readAllBytes() 将所有数据存入 byte 数组并返回   int available() 返回当前数据流未读取的数据个数   void close() 关闭数据流    OutputStream\n   方法 描述     void write(int b) 以字节为单位输出数据   void write(byte b[]) 将byte数组中的数据输出   void write(byte b[],int off,int len) 将byte数组中指定区间的数据输出   void close() 关闭数据流   void flush() 将缓冲流中的数据同步到输出流中    字符流 字节流是单位时间内处理一个字节的数据（输入+输出）\n字符流是单位时间内处理一个字符的数据（输入+输出）\n字符流：\n 输入字符流 Reader 输出字符流 Writer  5、Reader 是一个抽象类\nReadable 接口的作用？\n可以将数据以字符的形式读入到缓冲区\n 方向：输入+输出 单位：字节+字符 功能：节点流（字节流） + 处理流（对节点流进行处理，生成其他类型的流）  InputStream(字节输入流) —\u0026gt; Reader（字符输入流）\nInputStreamReader 的功能是将字节输入流转换为字符输入流  英文、数字、符号\n 1 个字节 = 1 个字符\n如：a 1 个字符、1 个字节\n 汉字\n 1 个字符 = 3 个字节\n如：好 1个字符、3 个字节\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35  public class Test { public static void main(String[] args) throws Exception { //字符流  Reader reader = new FileReader(\u0026#34;/Users/southwind/Desktop/test.txt\u0026#34;); int temp = 0; System.out.println(\u0026#34;*******字符流读取********\u0026#34;); while ((temp = reader.read())!=-1){ System.out.println(temp); } reader.close(); //字节流  InputStream inputStream = new FileInputStream(\u0026#34;/Users/southwind/Desktop/test.txt\u0026#34;); temp = 0; System.out.println(\u0026#34;*******字节流读取********\u0026#34;); while ((temp = inputStream.read())!=-1){ System.out.println(temp); } inputStream.close(); } } public class Test2 { public static void main(String[] args) throws Exception { Reader reader = new FileReader(\u0026#34;/Users/southwind/Desktop/test.txt\u0026#34;); char[] chars = new char[8]; int length = reader.read(chars); System.out.println(\u0026#34;数据流的长度是\u0026#34;+length); System.out.println(\u0026#34;遍历数组\u0026#34;); for (char aChar : chars) { System.out.println(aChar); } } }   read() 返回的是 int ，直接将字符转成字节（1-1，1-3）\nread(char[] chars) 返回的是char数组，直接就返回字符，不会转成字节的。\nWriter Appendable 接口可以将 char 类型的数据读入到数据缓冲区 OutputStreamWriter 处理流\nOutputStreamWriter 的功能是将输出字节流转成输出字符流，与 InputStreamReader 相对应的，将输入字节流转成输入字符流 1 2 3 4 5 6 7 8 9 10 11 12  public class Test { public static void main(String[] args) throws Exception { Writer writer = new FileWriter(\u0026#34;/Users/southwind/Desktop/copy.txt\u0026#34;); //writer.write(\u0026#34;你好\u0026#34;); // char[] chars = {\u0026#39;你\u0026#39;,\u0026#39;好\u0026#39;,\u0026#39;世\u0026#39;,\u0026#39;界\u0026#39;}; // writer.write(chars,2,2);  String str = \u0026#34;Hello World,你好世界\u0026#34;; writer.write(str,10,6); writer.flush(); writer.close(); } }   处理流 读文件 1 2 3 4 5 6 7 8 9 10 11 12 13  public class Test { public static void main(String[] args) throws Exception { //基础管道  InputStream inputStream = new FileInputStream(\u0026#34;/Users/southwind/Desktop/test.txt\u0026#34;); //处理流  InputStreamReader inputStreamReader = new InputStreamReader(inputStream); char[] chars = new char[1024]; int length = inputStreamReader.read(chars); inputStreamReader.close(); String result = new String(chars,0,length); System.out.println(result); } }   写文件 1 2 3 4 5 6 7 8 9 10  public class Test2 { public static void main(String[] args) throws Exception { String str = \u0026#34;你好 世界\u0026#34;; OutputStream outputStream = new FileOutputStream(\u0026#34;/Users/southwind/Desktop/copy.txt\u0026#34;); OutputStreamWriter writer = new OutputStreamWriter(outputStream); writer.write(str,2,1); writer.flush(); writer.close(); } }   缓冲流 无论是字节流还是字符流，使用的时候都会频繁访问硬盘，对硬盘是一种损伤，同时效率不高，如何解决？\n可以使用缓冲流，缓冲流自带缓冲区，可以一次性从硬盘中读取部分数据存入缓冲区，再写入内存，这样就可以有效减少对硬盘的直接访问。\n缓冲流属于处理流，如何来区分节点流和处理流？\n1、节点流使用的时候可以直接对接到文件对象File\n2、处理流使用的时候不可以直接对接到文件对象 File，必须要建立在字节流的基础上才能创建。\n缓冲流又可以分为字节缓冲流和字符缓冲流，按照方向再细分，又可以分为字节输入缓冲流和字节输出缓冲流，以及字符输入缓冲流和字符输出缓冲流。\n 字节输入缓冲流\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  public class Test { public static void main(String[] args) throws Exception { //1、创建节点流  InputStream inputStream = new FileInputStream(\u0026#34;/Users/southwind/Desktop/test.txt\u0026#34;); //2、创建缓冲流  BufferedInputStream bufferedInputStream = new BufferedInputStream(inputStream); // int temp = 0;  // while ((temp = bufferedInputStream.read())!=-1){  // System.out.println(temp);  // }  byte[] bytes = new byte[1024]; int length = bufferedInputStream.read(bytes,10,10); System.out.println(length); for (byte aByte : bytes) { System.out.println(aByte); } bufferedInputStream.close(); inputStream.close(); } }    字符输入缓冲流\n readLine 方法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  public class Test2 { public static void main(String[] args) throws Exception { //1、创建字符流（节点流）  Reader reader = new FileReader(\u0026#34;/Users/southwind/Desktop/test.txt\u0026#34;); //2、创建缓冲流（处理流）  BufferedReader bufferedReader = new BufferedReader(reader); String str = null; int num = 0; System.out.println(\u0026#34;***start***\u0026#34;); while ((str = bufferedReader.readLine())!=null){ System.out.println(str); num++; } System.out.println(\u0026#34;***end***,共读取了\u0026#34;+num+\u0026#34;次\u0026#34;); bufferedReader.close(); reader.close(); } }    字节输出缓冲流\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  public class Test { public static void main(String[] args) throws Exception { OutputStream outputStream = new FileOutputStream(\u0026#34;/Users/southwind/Desktop/test2.txt\u0026#34;); BufferedOutputStream bufferedOutputStream = new BufferedOutputStream(outputStream); String str = \u0026#34;由于在开发Oak语言时，尚且不存在运行字节码的硬件平台，所以为了在开发时可以对这种语言进行实验研究，他们就在已有的硬件和软件平台基础上，按照自己所指定的规范，用软件建设了一个运行平台，整个系统除了比C++更加简单之外，没有什么大的区别。\u0026#34;; byte[] bytes = str.getBytes(); // for (byte aByte : bytes) { // bufferedOutputStream.write(aByte); // }  bufferedOutputStream.write(bytes,9,9); bufferedOutputStream.flush(); bufferedOutputStream.close(); outputStream.close(); } }    字符输出缓冲流\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14  public class Test2 { public static void main(String[] args) throws Exception { Writer writer = new FileWriter(\u0026#34;/Users/southwind/Desktop/test2.txt\u0026#34;); BufferedWriter bufferedWriter = new BufferedWriter(writer); // String str = \u0026#34;由于在开发语言时尚且不存在运行字节码的硬件平台，所以为了在开发时可以对这种语言进行实验研究，他们就在已有的硬件和软件平台基础上，按照自己所指定的规范，用软件建设了一个运行平台，整个系统除了比C++更加简单之外，没有什么大的区别。\u0026#34;; // bufferedWriter.write(str,5,10);  char[] chars = {\u0026#39;J\u0026#39;,\u0026#39;a\u0026#39;,\u0026#39;v\u0026#39;,\u0026#39;a\u0026#39;}; // bufferedWriter.write(chars,2,1);  bufferedWriter.write(22902); bufferedWriter.flush(); bufferedWriter.close(); writer.close(); } }   输入流没有 flush 方法，但不代表它没有缓冲流，输出流是有 flush 方法的，实际开发中在关闭输出缓冲流之前，需要调用 flush 方法。\n序列化和反序列化 序列化就是将内存中的对象输出到硬盘文件中保存。\n反序列化就是相反的操作，从文件中读取数据并还原成内存中的对象。\n 序列化\n 1、实体类需要实现序列化接口，Serializable\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44  public class User implements Serializable { private Integer id; private String name; private Integer age; public Integer getId() { return id; } public void setId(Integer id) { this.id = id; } public String getName() { return name; } public void setName(String name) { this.name = name; } public Integer getAge() { return age; } public void setAge(Integer age) { this.age = age; } @Override public String toString() { return \u0026#34;User{\u0026#34; + \u0026#34;id=\u0026#34; + id + \u0026#34;, name=\u0026#39;\u0026#34; + name + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#34;, age=\u0026#34; + age + \u0026#39;}\u0026#39;; } public User(Integer id, String name, Integer age) { this.id = id; this.name = name; this.age = age; } }   2、实体类对象进行序列化处理，通过数据流写入到文件中，ObjectOutputStream。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  import com.southwind.entity.User; import java.io.File; import java.io.FileOutputStream; import java.io.ObjectOutputStream; import java.io.OutputStream; public class Test { public static void main(String[] args) throws Exception { User user = new User(1,\u0026#34;张三\u0026#34;,22); OutputStream outputStream = new FileOutputStream(\u0026#34;/Users/southwind/Desktop/obj.txt\u0026#34;); ObjectOutputStream objectOutputStream = new ObjectOutputStream(outputStream); objectOutputStream.writeObject(user); objectOutputStream.flush(); objectOutputStream.close(); outputStream.close(); } }    反序列化\n 1 2 3 4 5 6 7 8 9 10  public class Test2 { public static void main(String[] args) throws Exception { InputStream inputStream = new FileInputStream(\u0026#34;/Users/southwind/Desktop/obj.txt\u0026#34;); ObjectInputStream objectInputStream = new ObjectInputStream(inputStream); User user = (User) objectInputStream.readObject(); System.out.println(user); objectInputStream.close(); inputStream.close(); } }   IO 流的应用 IO 流就是完成文件传输（上传文件：发朋友圈、换头像，文件下载：CSDN 下载源代码、文档）\n字符 a 你好\n文本类型的数据（txt、word、Excel、MD）可以使用字符去读取（当然也可以用字节）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  public class Test3 { public static void main(String[] args) throws Exception { Reader reader = new FileReader(\u0026#34;/Users/southwind/Desktop/test.txt\u0026#34;); BufferedReader bufferedReader = new BufferedReader(reader); Writer writer = new FileWriter(\u0026#34;/Users/southwind/myjava/test.txt\u0026#34;); BufferedWriter bufferedWriter = new BufferedWriter(writer); String str = \u0026#34;\u0026#34;; int num = 0; while ((str = bufferedReader.readLine())!=null){ bufferedWriter.write(str); num++; } System.out.println(\u0026#34;传输完毕，共读取了\u0026#34;+num+\u0026#34;次\u0026#34;); bufferedWriter.flush(); bufferedWriter.close(); writer.close(); bufferedReader.close(); reader.close(); } }   非文本类型的数据（图片、音频、视频）不能用字符去读取，只能用字节去读。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  public class Test { public static void main(String[] args) throws Exception { //1、通过输入流将文件读入到 Java  InputStream inputStream = new FileInputStream(\u0026#34;/Users/southwind/Desktop/1.png\u0026#34;); //2、通过输出流将文件从 Java 中写入到 myjava  OutputStream outputStream = new FileOutputStream(\u0026#34;/Users/southwind/myjava/1.png\u0026#34;); int temp = 0; int num = 0; long start = System.currentTimeMillis(); while((temp = inputStream.read())!=-1){ num++; outputStream.write(temp); } long end = System.currentTimeMillis(); System.out.println(\u0026#34;传输完毕，共耗时\u0026#34;+(end-start)); outputStream.flush(); outputStream.close(); inputStream.close(); } }   反射 地位：Java 中最核心的模块，Java 之所以称为动态语言的关键，大部分的类库、企业级框架底层都是通过反射来实现的，非常重要。\n反射顾名思义就反转执行，生活中的反射就是通过虚像映射到具体的实物，可以获取到实物的某些形态特征。\n程序中的反射，通过一个实例化对象映射到类。\n一句话理解反射：常规情况下是通过类来创建对象的，反射就是将这一过程进行反转，通过对象来获取类的信息。\n通过对象来获取类的信息\n类的信息我们也同样使用对象来描述，Class 类专门用来描述其他类的类，每一个 Class 的实例化对象都是对某个类的描述。\nClass 是反射的源头\n如何来创建 Class 的对象？\n1、调用 Class 的静态方法 forName(String name)，将目标类的全限定类名（全类名，带着包名的类名）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  package com.southwind.demo2; public class Test { public static void main(String[] args) throws Exception { User user = new User(); Class clazz = Class.forName(\u0026#34;com.southwind.demo2.User\u0026#34;); System.out.println(clazz.getName()); System.out.println(clazz.getTypeName()); System.out.println(clazz.getSuperclass().getName()); Class[] array = clazz.getInterfaces(); System.out.println(\u0026#34;****************\u0026#34;); for (Class aClass : array) { System.out.println(aClass); } } }   2、通过目标类的 class 创建，Java 中的每一个类都可以调用类.class，class 不是属性也不是方法，叫做“类字面量”，作用是获取内存中目标类型对象的引用（类的结构）。\n1 2  Class clazz2 = User.class; System.out.println(clazz2.getName());   3、通过目标类的实例化对象获取，getClass()\n1 2  Class clazz3 = user.getClass(); System.out.println(clazz3.getName());   内部类  成员内部类。 局部内部类。 匿名内部类 静态内部类  1  [https://www.cnblogs.com/dolphin0520/p/3811445.html]   ","date":"2021-04-03T13:36:41Z","image":"https://ahao.ink/15.jpg","permalink":"https://ahao.ink/posts/java%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/","title":"Java基础知识"}]